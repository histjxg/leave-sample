01 | 高并发系统：它的通用设计方法是什么？
高并发大流量：
    采用的方法：
        1。Scale-out（横向扩展）：分而治之，分布式集群
        2。Scale-up：加cpu或者内存
        3。缓存
        4。异步
02 | 架构分层：我们为什么一定要这么做？
    分层架构：
        将整体系统拆分成 N 个层次，每个层次有独立的职责，多个层次协同提供完整的功能
        例子：
            mvc，
            表现层，逻辑层，数据访问层
    分层的好处：
        1。可以简化系统设计，让不同的人专注做某一层次的事情
        2。分层之后可以做到很高的复用
        3。分层架构可以让我们更容易做横向扩展。
    如何做分层：
        参考阿里巴巴分层：
    分层架构的不足：
        1。增加了开发的成本：
        2。性能上有所损耗（多一跳）
    具体体现：
        单一职责原则：每个类只有单一的功能，在这里可以引申为每一层拥有单一职责，且层与层之间边界清晰
        迪米特法则：原意是一个对象应当对其它对象有尽可能少的了解，在分层架构的体现是数据的交互不能跨层，只能在相邻层之间进行
        开闭原则：要求软件对扩展开放，对修改关闭
            它的含义其实就是将抽象层和实现层分离，抽象层是对实现层共有特征的归纳总结，不可以修改，但是具体的实现是可以无限扩展，随意替换的

03 | 系统设计目标（一）：如何提升系统性能？
    高并发指标：性能，可用性：可扩展性
        性能：
            优化原则：
                1。性能优化一定不能盲目，一定是问题导向的
                2。性能优化也遵循“八二原则”
                3。性能优化也要有数据支撑
                4。性能优化的过程是持续的
            性能的度量指标：
                平均值，最大值，分位值
            高并发下的性能优化
                1。 提高系统的处理核心数
                2. 减少单次任务响应时间
                    角度：系统是 CPU 密集型还是 IO 密集型的
            遇到性能问题的思路：
                1。数据优先，你做一个新的系统在上线之前一定要把性能监控系统做好；
                2。掌握一些性能优化工具和方法，这就需要在工作中不断的积累
                3。计算机基础知识很重要，比如说网络知识、操作系统知识等等，掌握了基础知识才能让你在优化过程中抓住性能问题的关键，也能在性能优化过程中游刃有余。

04 | 系统设计目标（二）：系统怎样做到高可用？
    度量指标：
        MTBF（Mean Time Between Failure）：是平均故障间隔的意思，代表两次故障的间隔时间，也就是系统正常运转的平均时间。这个时间越长，系统稳定性越高
        MTTR（Mean Time To Repair）：表示故障的平均恢复时间，也可以理解为平均故障时间。这个值越小，故障对于用户的影响越小。
    系统的可用性：
        Availability = MTBF / (MTBF + MTTR)
    设计思路：
        1。系统设计
            “Design for failure”：
                要把发生故障作为一个重要的考虑点，预先考虑如何自动化地发现故障，发生故障之后要如何解决
            优化方法：
                failover（故障转移）、超时控制以及降级和限流
                    failover 的节点可能有两种情况：
                        1. 是在完全对等的节点之间做 failover
                        2. 是在不对等的节点之间，即系统中存在主节点也存在备节点。
                    超时问题：
                        1。通过收集系统之间的调用日志，统计比如说 99% 的响应时间是怎样的，然后依据这个时间来指定超时时间（下载文件的时候比较慢）
                        2。如果没有调用的日志，那么你只能按照经验值来指定超时时间。
                        处理方法：
                            牺牲了少量的请求却保证了整体系统的可用性
                    降级：
                        保证核心服务的稳定而牺牲非核心服务的做法
                        通过开关来控制：
                    限流:
                        通过对并发的请求进行限速来保护系统
        2。系统运维
            1。灰度发布
            2。故障演练

05 | 系统设计目标（三）：如何让系统易于扩展？
    为什么提升扩展性会很复杂
        考虑的因素：
            1。数据库、缓存、依赖的第三方、负载均衡、交换机带宽等等都是系统扩展时需要考虑的因素
            2。可能哪一个因素扩展好了，另一个因素又制约了
    高可扩展性的设计思路
        拆分：把庞杂的系统拆分成独立的，有单一职责的模块
    设计一个社区例子：
        用户：负责维护社区用户信息，注册，登陆等；
        关系：用户之间关注、好友、拉黑等关系的维护；
        内容：社区发的内容，就像朋友圈或者微博的内容；
        评论、赞：用户可能会有的两种常规互动操作；
        搜索：用户的搜索，内容的搜索。
        现有的三层架构：
            1。负载均衡负责请求的分发
            2。应用服务器负责业务逻辑的处理
            3。数据库负责数据的存储落地。
        方法：
            1. 存储层的扩展性
                从存储的数据量，访问量角度出发
                第一次按照业务拆分：
                    用户库、内容库、评论库、点赞库和关系库
                第二次按照数据库拆分：
                    数据库分库分表
            2. 业务层的扩展性
                思考角度：业务纬度，重要性纬度和请求来源纬度。
                    业务纬度：
                        1。把相同业务的服务拆分成单独的业务池  例如：按照业务的维度拆分成用户池、内容池、关系池、评论池、点赞池和搜索池
                        2。每个业务依赖独自的数据库资源，不会依赖其它业务的数据库资源
                    业务接口的重要程度：
                        把业务分为核心池和非核心池
                        目的：
                            我们可以优先保证核心池的性能，当整体流量上升时优先扩容核心池，降级部分非核心池的接口，从而保证整体系统的稳定性。
                    根据接入客户端类型的不同做业务池的拆分：
                        例子：
                            1。服务于客户端接口的业务可以定义为外网池
                            2。服务于小程序或者 HTML5 页面的业务可以定义为 H5 池
                            3。服务于内部其它部门的业务可以定义为内网池，等等

07 | 池化技术：如何减少频繁创建数据库连接的性能损耗？
    连接池：
        1。数据库连接池、HTTP 连接池、Redis 连接池等等
        2。连接池的管理是连接池设计的核心
    连接池获取连接的流程：（数据库）
        1。如果当前连接数小于最小连接数，则创建新的连接处理数据库请求；
        2。如果连接池中有空闲连接则复用空闲连接；
        3。如果空闲池中没有连接并且当前连接数小于最大连接数，则创建新的连接处理请求；
        4。如果当前连接数已经大于等于最大连接数，则按照配置中设定的时间（C3P0 的连接池配置是 checkoutTimeout）等待旧的连接可用；
        5。如果等待超过了这个设定时间则向用户抛出错误。
    线程池的参考文档
        作用：
            1。用池化技术解决了数据库连接复用的问题
            2。Web 工程和数据库之间增加了数据库连接池，减少了频繁创建连接的成本
08 | 数据库优化方案（一）：查询请求增加时，如何做主从分离？（访问量大的情况下）
    目的：
        可以解决突发的数据库读流量，是一种数据库横向扩展的方法
    主从读写分离：两个关键的技术点：
        1. 主从复制
            1。部署上的复杂度：一般一个主库最多挂 3～5 个从库
                原因：
                    随着从库数量增加，从库连接上来的 IO 线程比较多，主库也需要创建同样多的 log dump 线程来处理复制的请求，对于主库资源消耗比较高，同时受限于主库的网络带宽
            2。主从同步的延迟
                解决办法：
                    1。数据的冗余（优先考虑，需要考虑带宽）
                    2。数据的冗余（适合新增数据的场景），更新的场景需要考虑缓存一致性的问题；
                    3。查询主库（尽量不要选）

        2. 如何访问数据库
            1。第一类以代码形式内嵌运行在应用程序内部。
                例子：淘宝的 TDDL（ Taobao Distributed Data Layer）为代表
            2。单独部署的代理层方案
                早期阿里巴巴开源的 Cobar，基于 Cobar 开发出来的 Mycat，360 开源的 Atlas，美团开源的基于 Atlas 开发的 DBProxy 等等。
    考虑的问题：
        1。主从的一致性和写入性能的权衡
        2。主从的延迟问题
    优点：
        1。使得数据库实现了数据复制为多份，增强了抵抗大量并发读请求的能力
        2。提升了数据库的查询性能的同时，也提升了数据的安全性，当某一个数据库节点，无论是主库还是从库发生故障时，我们还有其他的节点中存储着全量的数据，保证数据不会丢失

09 | 数据库优化方案（二）：写入数据量增加时，如何实现分库分表？（写入或者更新操作量大）
    背景：
        数据库的查询还是写入性能都在下降，数据库的磁盘空间也在报警。
    考虑的问题：
        1。如何提升查询性能呢？
        2。如何让数据库系统支持如此大的数据量呢？
        3。如何做到不同模块的故障隔离呢？
        4。数据库系统如何来处理更高的并发写入请求呢？
    分库分表：
        将数据分片的方式，它的基本思想是依照某一种策略将数据尽量平均的分配到多个数据库节点或者多个表中
    方式：
        垂直拆分：按业务拆分，不通业务的数据放到不通的数据库中，关注点在于业务相关性
        水平拆分：将单一数据表按照某一种规则拆分到多个数据库和多个数据表中，关注点在数据的特点
    拆分规则：
        1. 按照某一个字段的哈希值做拆分，这种拆分规则比较适用于实体表（用户表）
        2。 另一种比较常用的是按照某一个字段的区间来拆分，比较常用的是时间字段（内容表里面有“创建时间”的字段）
    解决分库分表引入的问题
        1。我们之后所有的查询都需要带上这个字段，才能找到数据所在的库和表，否则就只能向所有的数据库和数据表发送查询命令
            解决办法：
                建立一个昵称和 ID 的映射表，在查询的时候要先通过昵称查询到 ID，再通过 ID 查询完整的数据
        2。到多个数据库之后就无法跨库执行 SQL 了
            解决办法：
                比方说将计数的数据单独存储在一张表中或者记录在 Redis 里面。

10 | 发号器：如何保证分库分表后ID的全局唯一性？
    数据库的主键要如何选择？
        1. 使用业务字段作为主键（不推荐使用）
        2. 使用生成的唯一 ID 作为主键。（推荐使用），注意不要使用自增id
    方法：
        基于 Snowflake 算法搭建发号器，uuid的应用可以应用宇每次请求requestid（不依赖于任何第三方系统，所以在性能和可用性上比较好）中
    原因：
        1。生成的 ID 做好具有单调递增性，也就是有序的
        2。在于 ID 有序也会提升数据的写入性能。
        3。 UUID 不能作为 ID 的另一个原因是它不具备业务含义
        4。作为数据库主键使用比较耗费空间。

    比方说我现在使用的发号器的组成规则就是：
        1 位兼容位恒为 0 + 41 位时间信息 + 6 位 IDC 信息（支持 64 个 IDC）+ 6 位业务信息（支持 64 个业务）+ 10 位自增信息（每毫秒支持 1024 个号）
    实现方式：
        1。嵌入到业务代码里，也就是分布在业务服务器中
        2。作为独立的服务部署，这也就是我们常说的发号器服务

11 | NoSQL：在高并发场景下，数据库和NoSQL如何做到互补？
    1.在性能方面，NoSQL 数据库使用一些算法将对磁盘的随机写转换成顺序写，提升了写的性能；
        例子：Hbase、Cassandra、LevelDB 都是用这种算法作为存储的引擎。
        传统的方式：传统的机械磁盘：
            对于机械磁盘的访问方式有两种：一种是随机 IO；另一种是顺序 IO

            写入时先写入内存，然后批量刷新到磁盘上，但是随机 IO 还是会发生。
        NoSql的解决办法：基于 LSM 树的存储引擎
            核心思想就是将随机 IO 变成顺序的 IO，从而提升写入的性能
    2.在某些场景下，比如全文搜索功能，关系型数据库并不能高效地支持，需要 NoSQL 数据库的支持：Elasticsearch
        1.就以倒排索引作为核心技术原理，为你提供了分布式的全文搜索服务，这在传统的关系型数据库中使用 SQL 语句是很难实现的
        解决一些常见的关系数据库无法解决的问题：例如模糊查询：
            select * from product where name like ‘% 电冰箱’；关系数据库没办法用索引，的全表扫描
    3.在扩展性方面，NoSQL 数据库天生支持分布式，支持数据冗余和数据分片的特性
        MongoDB解决大数据量存储的问题：
            三个特性：
                1. Replica，也叫做副本集，你可以理解为主从分离，也就是通过将数据拷贝成多份来保证当主挂掉后数据不会丢失
                2.是 Shard，也叫做分片，你可以理解为分库分表，即将数据按照某种规则拆分成多份，存储在不同的机器上
                3.其三是负载均衡，就是当 MongoDB 发现 Shard 之间数据分布不均匀，会启动 Balancer 进程对数据做重新的分配，最终让不同 Shard Server 的数据可以尽量的均衡

12 | 缓存：数据库成为瓶颈后，动态数据的查询要如何加速？
    缓存定义：（提升性能）
        是一种存储数据的组件，它的作用是让对数据的请求更快地返回。
        1. 缓存案例：linux内存管理，抖音，HTTP 协议也是有缓存机制的
        2. 缓存与缓冲区
            缓存：
                提高低速设备的访问速度，或者减少复杂耗时的计算带来的性能问题
            缓存区：
                是一块临时存储数据的区域，这些数据后面会被传输到其他设备上
        注意：
            凡是位于速度相差较大的两种硬件之间，用于协调两者数据传输速度差异的结构，均可称之为缓存
    缓存分类：
        静态缓存：
            1.文章如果放在数据库查询比较慢，
                解决方法：
                    每篇文章在录入的时候渲染成静态页面，放置在所有的前端 Nginx 或者 Squid 等 Web 服务器上
                优点：
                    用户在访问的时候会优先访问 Web 服务器上的静态页面，在对旧的文章执行一定的清理策略后，依然可以保证 99% 以上的缓存命中率。
        分布式缓存：
            例子：
                Memcached、Redis
        热点本地缓存：
            如 HashMap，Guava Cache 或者是 Ehcache 等，它们和应用程序部署在同一个进程中
            优势：
                是不需要跨网络调度，速度极快，所以可以来阻挡短时间内的热点查询
    缓存的不足：
        1.缓存比较适合于读多写少的业务场景，并且数据最好带有一定的热点属性
        2.缓存会给整体系统带来复杂度，并且会有数据不一致的风险。
        3.之前提到缓存通常使用内存作为存储介质，但是内存并不是无限的
        4.缓存会给运维也带来一定的成本
    注意：
        1.缓存多层：（将请求尽量挡在上层，因为越往下层，对于并发的承受能力越差）
            1.静态缓存处在负载均衡层
            2.分布式缓存处在应用层和数据库层之间
            3.本地缓存处在应用层
            工作中碰到慢的问题，缓存就是你第一时间想到的
    扩展：
        1.缓存不仅仅是一种组件的名字，更是一种设计思想
        2.任何能够加速读请求的组件和设计方案都是缓存思想的体现
    两种方式来实现：
        1.使用更快的介质，比方说课程中提到的内存
        2.缓存复杂运算的结果，比方说前面 TLB 的例子就是缓存地址转换的结果。

13 | 缓存的使用姿势（一）：如何选择缓存的读写策略？
    Cache Aside（旁路缓存）策略（经常使用的缓存策略）
        读策略：
            从缓存中读取数据；
            如果缓存命中，则直接返回数据；
            如果缓存不命中，则从数据库中查询数据；
            查询到数据后，将数据写入到缓存中，并且返回给用户。
        写策略：
            更新数据库中的记录；
            删除缓存记录。
        适用的场景：更新
        不适用的场景：
            写入比较频繁，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响
        如果对缓存命中率有严格的要求：
            方法一：
                在更新数据时也更新缓存，只是在更新缓存前先加一个分布式锁
            方法二：
                在更新数据时更新缓存，只是给缓存加一个较短的过期时间

    Read/Write Through（读穿 / 写穿）策略，需要缓存组件的支持
        核心原则：
            用户只与缓存打交道，由缓存和数据库通信，写入或者读取数据
        Write Through 的策略:
            1.先查询要写入的数据在缓存中是否已经存在，如果已经存在，则更新缓存中的数据
            2.并且由缓存组件同步更新到数据库中，如果缓存中数据不存在，我们把这种情况叫做“Write Miss（写失效）
        Read Through 策略:
            1.先查询缓存中数据是否存在，如果存在则直接返回
            2.如果不存在，则由缓存组件负责从数据库中同步加载数据。

    Write Back（写回）策略
        核心思想：
            1.在写入数据时只写入缓存，并且把缓存块儿标记为“脏”的
            2.而脏块儿只有被再次使用时才会将其中的数据写入到后端存储中。
        Write back 写的策略：
            写请求中都只需要更新缓存即可，而无需更新后端存储了
        Write back 读的策略：
            1.在读取缓存时如果发现缓存命中则直接返回缓存数据。
            2.如果缓存不命中则寻找一个可用的缓存块儿，如果这个缓存块儿是“脏”的，就把缓存块儿中之前的数据写入到后端存储中
            3.并且从后端存储加载数据到缓存块儿，如果不是脏的，则由缓存组件将后端存储中的数据加载到缓存中
            4.最后我们将缓存设置为不是脏的，返回数据就好了
        应用的场景：
            Page Cache，日志的异步刷盘，消息队列中消息的异步写入磁盘
        优点：
            避免了直接写磁盘造成的随机写问题

14 | 缓存的使用姿势（二）：缓存如何做到高可用？
    1.客户端方案
        在客户端配置多个缓存的节点，通过缓存写入和读取算法策略来实现分布式，从而提高缓存的可用性
        需要考虑两个角度：
            1.写数据时缓存数据如何分片
                1.Hash 分片算法：对缓存的 Key 做哈希计算，然后对总的缓存节点个数取余。
                2.一致性 Hash 分片算法：解决增加和删减节点时，命中率下降的问题
            2.Memcached 的主从机制
            3. 多副本
    2.中间代理层方案
        1.在应用代码和缓存节点之间增加代理层，客户端所有的写入和读取的请求都通过代理层
        2.而代理层中会内置高可用策略，帮助提升缓存系统的高可用。
    3.服务端方案
        Redis 2.4 版本后提出的 Redis Sentinel 方案。

15 | 缓存的使用姿势（三）：缓存穿透了怎么办？
    注意：
        命中率是缓存的生命线
    缓存穿透：
        缓存中没有查到数据，而不得不从后端系统（比如数据库）中查询的情况
    解决方案:
        回种空值:
            场景一：
                在于数据库中并不存在用户的数据，这就造成无论查询多少次，数据库中永远都不会存在这个用户的数据，穿透永远都会发生。
            场景二：
                比如由于代码的 bug 导致查询数据库的时候抛出了异常，这样可以认为从数据库查询出来的数据为空，同样不会回种缓存
            缺点：
                1.但如果有大量获取未注册用户信息的请求，缓存内就会有有大量的空值缓存，也就会浪费缓存的存储空间
                2.如果缓存空间被占满了，还会剔除掉一些已经被缓存的用户信息反而会造成缓存命中率的下降。
        使用布隆过滤器:
            步骤：
                1.那么当我们需要查询某一个用户的信息时，我们首先查询这个 ID 在布隆过滤器中是否存在
                2.如果不存在就直接返回空值，而不需要继续查询数据库和缓存
                3.这样就可以极大地减少异常查询带来的缓存穿透。
            缺陷：
                1.它在判断元素是否在集合中时是有一定错误几率的，比如它会把不是集合中的元素判断为处在集合中（hash冲突导致的）
                2.不支持删除元素。
            建议：
                1. 选择多个 Hash 函数计算多个 Hash 值，这样可以减少误判的几率；
                2. 布隆过滤器会消耗一定的内存空间，所以在使用时需要评估你的业务场景下需要多大的内存，存储的成本是否可以接受

    狗桩效应：
        有一个极热点的缓存项，它一旦失效会有大量请求穿透到数据库，这会对数据库造成瞬时极大的压力
        解决方案：
            1.在代码中，控制在某一个热点缓存项失效之后启动一个后台线程，穿透到数据库，将数据加载到缓存中，在缓存未加载之前，所有访问这个缓存的请求都不再穿透而直接返回
            2.通过在 Memcached 或者 Redis 中设置分布式锁，只有获取到锁的请求才能够穿透到数据库。

16 | CDN：静态资源如何加速？
    静态资源加速的考虑点
        关键点是就近访问
        思路：
            1.在业务服务器的上层，增加一层特殊的缓存，用来承担绝大部分对于静态资源的访问
            2.缓存的节点需要遍布在全国各地，这样可以让用户选择最近的节点访问。
            3.缓存的命中率也需要一定的保证，尽量减少访问资源存储源站的请求数量（回源请求）
    CDN 的关键技术
        CDN 就是将静态的资源分发到，位于多个地理位置机房中的服务器上
        搭建CDN考虑的两点：
            1.如何让用户的请求到达 CDN 节点
            2. 如何找到离用户最近的 CDN 节点

17 | 消息队列：秒杀时如何处理每秒上万次的下单请求？
    社区系统发展的前期：
        1.一个社区的系统初期一定是只有少量的种子用户在生产内容
        2.而大部分的用户都在“围观”别人在说什么
        理解：
            消息队列看作暂时存储数据的一个容器，认为消息队列是一个平衡低速系统和高速系统处理任务时间差的工具
        例子：
            1.在 Java 线程池中我们就会使用一个队列来暂时存储提交的任务，等待有空闲的线程处理这些任务；
            2.操作系统中，中断的下半部分也会使用工作队列来实现延后执行；
            3.我们在实现一个 RPC 框架时，也会将从网络上接收到的请求写到队列里，再启动若干个工作线程来处理。
    作用：
        1.：削峰填谷，但是会造成请求处理的延迟
        2.异步处理：
            1.提升系统性能的神器，但是你需要分清同步流程和异步流程的边界
            2.同时消息存在着丢失的风险，我们需要考虑如何确保消息一定到达。
        3.解耦合
            可以提升你的整体系统的鲁棒性。

18 | 消息投递：如何保证消息仅仅被消费一次？
    消息为什么会丢失
        1.消息从生产者写入到消息队列的过程
            解决办法：消息重传
        2.消息在消息队列中的存储场景
            通过部署从服务器和ack确认返回机制
        3.消息被消费者消费的过程
            消费过程的三步：
                1.接收消息（可能会发生异常或者失败）
                2.处理消息（可能会发生异常或者失败）
                3.更新消费进度（没有更新消费进度，导致重复消费）
            避免消息丢失带来的两个问题：
                1.一方面是性能的损耗
                2.一方面可能造成消息重复消费
    如何保证消息只被消费一次
        幂等：
            多次执行同一个操作和执行一次操作，最终得到的结果是相同的
        在生产、消费过程中增加消息幂等性的保证
            在消息生产过程中：
                虽然可能在生产端产生重复，但是最终在消息队列存储时只会存储一份。
                具体做法:
                    1.给每一个生产者一个唯一的 ID，并且为生产的每一条消息赋予一个唯一 ID
                    2.消息队列的服务端会存储 < 生产者 ID，最后一条消息 ID> 的映射
                    3.当某一个生产者产生新的消息时，消息队列服务端会比对消息 ID 是否与存储的最后一条 ID 一致
                    4.如果一致，就认为是重复的消息，服务端会自动丢弃。
            消费端,从通用层和业务层两个层面来考虑
                通用层面：
                    1.你可以在消息被生产的时候，使用发号器给它生成一个全局唯一的消息 ID，
                    2.消息被处理之后，把这个 ID 存储在数据库中，在处理下一条消息之前
                    3.先从数据库里面查询这个全局 ID 是否被消费过，如果被消费过就放弃消费
                    问题：
                        1.如果消息在处理之后，还没有来得及写入数据库，消费者宕机了重启之后发现数据库中并没有这条消息
                        2.还是会重复执行两次消费逻辑
                业务层面：
                    乐观锁来解决

19 | 消息队列：如何降低消息队列系统中消息的延迟？
    如何监控消息延迟:
        方式一：
            使用消息队列提供的工具，通过监控消息的堆积来完成；
            例子：
                Kafka 提供了工具叫做“kafka-consumer-groups.sh”和JMX。
            具体实现过程：
                1.你先定义一种特殊的消息，然后启动一个监控程序，将这个消息定时地循环写入到消息队列中
                2.消息的内容可以是生成消息的时间戳，并且也会作为队列的消费者消费数据
                3.业务处理程序消费到这个消息时直接丢弃掉，而监控程序在消费到这个消息时
                4.就可以和这个消息的生成时间做比较，如果时间差达到某一个阈值就可以向我们报警
        方式二：
            通过生成监控消息的方式来监控消息的延迟情况。
    从消费端和消息队列来完成：
        消费端：
            1.优化消费代码提升性能
            2.增加消费者的数量（这个方式比较简单）。
        消息队列：
            1.消息的存储；
                通过page cache的存在就可以提升消息的读取速度
            2.零拷贝技术。
                操作系统提供了 Sendfile 函数，可以减少数据被拷贝的次数
                一般的拷贝过程：
                    1. 数据从磁盘拷贝到内核缓冲区；
                    2. 系统调用将内核缓存区的数据拷贝到用户缓冲区；
                    3. 用户缓冲区的数据被写入到 Socket 缓冲区中；
                    4. 操作系统再将 Socket 缓冲区的数据拷贝到网卡的缓冲区中。

20 | 面试现场第二期：当问到项目经历时，面试官究竟想要了解什么？
21 | 系统架构：每秒1万次请求的系统要做服务化拆分吗？
    一体化架构：
        优点：
            1.开发简单直接，代码和项目集中式管理；
            2.只需要维护一个工程，节省维护系统运行的人力成本；
            3.排查问题的时候，只需要排查这个应用进程就可以了，目标性强。
        缺陷：
            1.在技术层面上，数据库连接数可能成为系统的瓶颈。
            2.一体化架构增加了研发的成本，抑制了研发效率的提升
            3.一体化架构对于系统的运维也会有很大的影响
    如何使用微服务化解决这些痛点：
        1.对应的服务连接对应的库，可以有效控制连接数，提升了系统的扩展性
        2.将与业务无关的公用服务抽取出来，下沉成单独的服务
22 | 微服务架构：微服务化后，系统架构要如何改造？
服务拆分的三个问题：
    1.服务拆分时要遵循哪些原则？
    2.服务的边界如何确定？服务的粒度是怎样呢？
    3.在服务化之后，会遇到哪些问题呢？我们又将如何来解决？
微服务拆分的原则：
    原则一：做到单一服务内部功能的高内聚，和低耦合
    原则二：关注服务拆分的粒度，先粗略拆分，再逐渐细化
    做法：
        拆分初期可以把服务粒度拆的粗一些，后面随着团队对于业务和微服务理解的加深，再考虑把服务粒度细化
    原则三：
        拆分的过程，要尽量避免影响产品的日常功能迭代，也就是说，要一边做产品功能迭代，一边完成服务化拆分
        参考点：
            1. 优先剥离比较独立的边界服务（比如短信服务、地理位置服务），从非核心的服务出
                发，减少拆分对现有业务的影响，也给团队一个练习、试错的机会；
            2.当两个服务存在依赖关系时，优先拆分被依赖的服务
        正确的做法：
            1.理清服务之间的调用关系
            2.内容服务会依赖用户服务获取用户信息，互动服务会依赖内容服务，所以要按照先用户服务
            3.再内容服务，最后互动服务的顺序来进行拆分。
    原则四：
        1.服务接口的定义要具备可扩展性
        例子：
            1.服务接口的参数类型最好是封装类，只需要在类中添加字段即就可以了
微服务化带来的问题和解决思路：
    1. 服务接口的调用，不再是同一进程内的方法调用，而是跨进程的网络调用，这会增加接口响应时间的增加。
        思考：
            1.选择高效的服务调用框架
            2.需要引入注册中心
    2. 多个服务之间有着错综复杂的依赖关系。
        问题：
            1.性能出现问题，产生大量的慢请求，就会导致依赖服务的工作线程池中的线程被占满，那么依赖的服务也会出现性能问题。
            2.问题就会沿着依赖网，逐步向上蔓延，直到整个系统出现故障为止
        解决办法：
            1.引入服务治理体系
              具体方法：
                熔断、降级、限流、超时控制的方法
    3.服务拆分到多个进程后，一条请求的调用链路上，涉及多个服务，那么一旦这个请求的
        响应时间增长，或者是出现错误，我们就很难知道，是哪一个服务出现的问题
        方法：
            引入分布式追踪工具，以及更细致的服务端监控报表。

23 | RPC框架：10万QPS下如何实现毫秒级的服务调用？
    服务拆分带来的问题：
        1.服务拆分单独部署后，引入的服务跨网络通信的问题；
        2.在拆分成多个小服务之后，服务如何治理的问题。
    方向：
        1.选择合适的网络模型，有针对性地调整网络参数，以优化网络传输性能；
        2.选择合适的序列化方式，以提升封包、解包的性能。
    RPC：
        网络传输和序列化
    如何提升网络传输性能：
        1.I/O 会经历一个等待资源的阶段
            阻塞：是在数据不可用时，I/O 请求一直阻塞，直到数据返回；
            非阻塞：是数据不可用时，I/O 请求立即返回，直到被通知资源可用为止；
        2.是使用资源的阶段
            1。同步处理：
                指的是 I/O 请求在读取或者写入数据时会阻塞，直到读取或者写入数据完成
            2.异步处理
                指的是 I/O 请求在读取或者写入数据时立即返回，当操作系统处理完成 I/O请求，
                并且将数据拷贝到用户提供的缓冲区后，再通知应用 I/O 请求执行完成。
        五种模型：
            1.同步阻塞 I/O
            2.同步非阻塞 I/O
            3.同步多路 I/O 复用
            4.信号驱动 I/O
            5.异步 I/O
    选择合适的序列化方式：
        1.数据的序列化和
        2.反序列化

24 | 注册中心：分布式系统如何寻址？
    注册：
        ZooKeeper，Kubernetes    使用的 ETCD，阿里的微服务注册中心 Nacos，Spring Cloud 的 Eureka
    注册中心的功能：
        1.提供了服务地址的存储
        2.当存储内容发生变化时，可以将变更的内容推送给客户端。
    服务和发现的过程：
        1.客户端会与注册中心建立连接，并且告诉注册中心，它对哪一组服务感兴趣；
        2.服务端向注册中心注册服务后，注册中心会将最新的服务注册信息通知给客户端；
        3.客户端拿到服务端的地址之后就可以向服务端发起调用请求了。
        可以实现优雅关闭
    服务状态管理如何来做
        第一种思路：
            主动探测
                第一个问题:
                    1.所有的 RPC 服务端都需要，开放一个统一的端口给注册中心探测
                    2.那时候还没有容器化，一台物理机上会混合部署很多的服务
                    3.你需要开放的端口很可能已经被占用，这样会造成 RPC 服务启动失败
                第二个问题：
                    1.如果 RPC 服务端部署的实例比较多，那么每次探测的成本也会比较高
                    2.探测的时间也比较长，这样当一个服务不可用时，可能会有一段时间的延迟，才会被注册中心探测到
        第二种思路：
            心跳模式（更广泛使用）
            通知风暴怎么解决：

        增加理解：
            服务的注册和发现：
                1.如果你新建了一条街道（相当于启动了一个新的服务节点），那么就要通知所有的车辆（流量）有新的道路可以走了；
                2.你关闭了一条街道，你也要通知所有车辆不要从这条路走了
            服务的监控：
                在道路上安装监控，监视每条道路的流量情况
            熔断以及引流：
                1.道路一旦出现拥堵或者道路需要维修，那么就需要暂时封闭这条道路
                2.由城市来统一调度车辆，走不堵的道路
            分布式追踪：
                1.道路之间纵横交错四通八达，一旦在某条道路上出现拥堵，但是又发现这条道路从头堵到尾
                2.说明事故并不是发生在这条道路上，那么就需要从整体链路上来排查事故究竟处在哪个位置
            负载均衡：
                1.不同道路上的车辆有多有少，那么就需要有一个警察来疏导，在某一个时间走哪一条路会比较快
25 | 分布式Trace：横跨几十个分布式组件的慢请求要如何排查？



26 | 负载均衡：怎样提升系统的横向扩展能力


27 | API网关：系统的门面要如何做呢？
    API 网关起到的作用：
        系统的边界，它可以对出入系统的流量做统一的管控
    分类：
        1。入口网关：
            部署在负载均衡服务器和应用服务器之间
            作用：
                1。它提供客户端一个统一的接入地址，API 网关可以将用户的请求动态路由到不同的业务服务上，并且做一些必要的协议转换工作
                2。在 API 网关中，我们可以植入一些服务治理的策略，比如服务的熔断、降级，流量控制和分流等
                3。客户端的认证和授权的实现，也可以放在 API 网关中。
                4。API 网关还可以做一些与黑白名单相关的事情，比如针对设备 ID、用户 IP、用户ID 等维度的黑白名单
                5。在 API 网关中也可以做一些日志记录的事情，比如记录 HTTP 请求的访问日志

        2。出口网关：
            场景：
                1。可以在应用服务器和第三方系统之间，部署出口网关，在出口网关中
                2。对调用外部的 API 做统一的认证、授权，审计以及访问控制。
            例子：
                会依赖很多外部的第三方系统，比如典型的例子：第三方账户登录、使用第三方工具支付等等

    API 网关要如何实现
        1。要考虑他的性能，API 入口网关承担从客户端的所有流量
            Zuul，在 1.0 版本的时候使用的是同步阻塞 I/O 模型，
            Zuul2.0，采用I/O 多路复用的模型处理接入的 I/O 请求
        2。API 网关的设计要注意扩展性
        3。并行的问题，不通的业务互相影响，思考的角度
            1。不通的业务使用不通的线程池，
            2。在线程池内部可以针对不同的服务，甚至不同的接口做线程的保护
                例如：
                    线程池的最大线程数是 1000，那么可以给每个服务设置一个最多可以使用的配额。
            两者方式结合使用
    如何在你的系统中引入 API 网关呢？
        Web 层做的事情主要有两方面：
            一方面是对服务层接口数据的聚合
            另一方面 Web 层还需要将 HTTP 请求转换为 RPC 请求，并且对前端的流量做一些限制，对于某些请求添加设备 ID 的黑名单等
        优化：
            1。可以先将 API 网关从 Web 层中独立出来，将协议转换、限流、黑白名单等事情
            2。挪到 API 网关中来处理，形成独立的入口网关层
        解决思路：
            1。再独立出一组网关专门做服务聚合、超时控制方面的事情，我们一般把前一种网关叫做流量网关，后一种可以叫做业务网关
            2。抽取独立的服务层，专门做接口聚合的操作。这样服务层就大概分为原子服务层和聚合服务层。

28 | 多机房部署：跨地域的分布式系统如何做？
    场景：
        假如我们有两个机房 A 和 B 都部署了应用服务，数据库的主库和从库部署在 A 机房，那么
        机房 B 的应用如何访问到数据呢
    思路：
        思路一：
            是直接跨机房读取 A 机房的从库
        思路二：
            在机房 B 部署一个从库，跨机房同步主库的数据，然后机房 B 的应用就可以
            读取这个从库的数据了：
    逐步迭代多机房部署方案：
        1. 同城双活
            注意：
                服务也是双机房部署的，那么也需要尽量保证只调用本机房的服务，降低调用的延迟。
        2. 异地多活
        数据同步：
            一种基于存储系统的主从复制，比如 MySQL 和 Redis
            另一种是基于消息队列的方式

29 | Service Mesh：如何屏蔽服务化系统的服务治理细节？
30 | 给系统加上眼睛：服务端监控要怎么做？
监控指标如何选择
    1。延迟：请求的响应时间
    2。通信量：单位时间内，请求量的大小
    3。错误：当前系统发生的错误数量
    4。饱和度：服务或者资源到达上限的程度（也可以说是服务或者资源的利用率）
如何采集数据指标
    1。，Agent 是一种比较常见的，采集数据指标的方式。
    2。代码中设置埋点
    3。日志也是你监控数据的重要来源之一
监控数据的处理和存储
背景：
    采集到的数据会先放到消息队列
一般会部署两个队列来消费消息：
一个消息队列：
    一个处理程序接收到数据后，把数据写入到 Elasticsearch，然后通过 Kibana 展示数据，
    这份数据主要是用来做原始数据的查询；
另一个是：
    处理程序是一些流式处理的中间件，比如，Spark、Storm。它们从消息队列里，接
    收数据后会做一些处理。
    处理过程包括：
        1。解析数据格式，尤其是日志格式
        2。对数据做一些聚合运算。
        3。将数据存储在时间序列数据库中
        4。你就可以通过 Grafana 来连接时序数据库，将监控数据绘制成报表，呈现给开发和运维的同学了


















