# 启动 mysql, 并设置为开机启动
brew services start mysql
# 关闭 mysql
brew services stop mysql
# 重启 mysql
brew services restart mysql
忘记密码处理：
参考博客：https://blog.csdn.net/q258523454/article/details/84555847
1。mysqld --skip-grant-tables 忘记密码输入这个
2。use mysql;
3。select user,host from user;
4。ALTER USER ‘root’@’%’ IDENTIFIED BY 'Hxg123...';
5。mysql -uroot -pHxg123...



show variables like 'character_set_client';#查询字符集
show databases;#列出所有的服务器上的数据库alter
create database if not exists histjxg_test;#创建一个数据库
drop database fk;#删除数据库
show tables from test;#显示一个数据库中的表
use test;
自增主键定义：NOT NULL PRIMARY KEY AUTO_INCREMENT。
查询慢查询日志：
show variables like 'slow_query%';
设置满查询开启：
set global slow_query_log=1;
查询mysql的执行计划：
explain select word from words order by rand() limit 3;
对于执行计划结果的解释
https://www.cnblogs.com/songwenjie/p/9409852.html

设置慢查寻时间，超过该时间就会存储到文件中
set session long_query_time=0.001;
set global long_query_time=0.001;
慢查询文件的位置可以通过
show variables like 'slow_query%';
查看 OPTIMIZER_TRACE 输出
SET optimizer_trace='enabled=on';


1。show processlist:查询线程及相关信息
2.select * from information_schema.innodb_trx;事务具体状态的话,

create database if not exists ds0;
create database if not exists ds1;
--mysql
SELECT  TIMESTAMPDIFF(HOUR,c1.create_date,c2.create_date) as createDate2
FROM
(select create_date from user_info where id=1 ) c1
cross join
(  select create_date from user_info where id=2)c2;
--oracle
SELECT  ROUND(TO_NUMBER(c2.create_date - c1.create_date) * 24) as createDate2
FROM
(select create_date from user_info where id=1 ) c1
cross join
(  select create_date from user_info where id=2)c2;

create database if not exists gpcat;

01 | 一条sql的查询语句是如何执行的：
    客户端 --连接器  --查询缓存
                    --分析器--优化器--执行器--存储引擎
    数据库中的连接
    长连接：是指连接成功后，如果客户端持续有请求，则一直使用同一个连接，可能会导致内存占用过大：解决办法，定期断开长连接，或者5。7设置重启连接
    短连接：每次执行完很少的几次查询就断开连接，下次查询再重新建立一个

    第二步：查询缓存（在一个表上有更新的时候，跟这个表有关的查询缓存会失效，会把这个表所有的缓存结果清空）
    key：是查询的键，value：查询的结果；，一般不建议使用查询缓存；
    对于更新频繁的操作，会带来额外的性能；关闭：query_cache_type 设置DEMAND
    需要用缓存使用：select SQL_CACHE * from T where ID=10；

    第三步：分析器
    词法分析：如select识别出来是一个查询语句；T识别出来是表名，字符串id识别出来是列id
    语法分析：语法分析器会根据输入的sql与酒判断是否满足sql语法；elect * from t where ID=1; 会提示第一个出现错误的位置

    优化器：优化器是在表里面有多个索引的时候，决定使用哪个索引，优化器阶段完成后，这个语句的执行方案就确定下来了
    select * from t1 join t2 using(ID)  where t1.c=10 and t2.d=20;
    选择那个索引

    执行器：
    select * from T where ID=10;先判断有没有查询权限
    执行流程：没有索引的
    1.调用对应的引擎接口，去这个表的第一行，判断ID是不是10，不是跳过，是将这行存在结果集中
    2.调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
    3.执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。

    可以在慢查询日志查到引擎扫描的行数：rows_examined
02 | 一条SQL更新语句是如何执行的
    更新流程：与查询流程不一样：redo log（重做日志）和 binlog（归档日志）innodb_flush_log_at_trx_commit=1可以持久化
    redo log（innodb引擎持有的）：WAL技术Write-Ahead Logging，先写日志，在写磁盘；类似先写粉板，再写账本；
    可以保证即使数据库发生异常重启，之前提交记录都不会丢失，这个能力称为crash-safe；循环写的，空间固定会用完；是物理日志，记录的是某个数据页做了什么修改
    binlog（server层）所有引擎都有的：归档日志，是可以追加写的，写到一定大笑后会切换到下一个，并不会覆盖以前的日志；
    binlog是逻辑日志，语句的原始逻辑，比如给"id=2"这一行的c字段加1；sync_binlog=1设置永久化
    1执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。
    如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。

    2执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。

    3引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，
      此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。

    4执行器生成这个操作的binlog，并把binlog写入磁盘。

    5执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。

    两阶段提交：将redo log的写入拆成了两个步骤：prepare和commit，这就是"两阶段提交"。
    两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使你不做数据库内核开发
    问题
    1。先写redo log后写binlog。假设在redo log写完，binlog还没有写完的时候，MySQL进程异常重启。由于我们前面说过的\
      ，redo log写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行c的值是1。
    但是由于binlog没写完就crash了，这时候binlog里面就没有记录这个语句。因此，之后备份日志的时候，
    存起来的binlog里面就没有这条语句。
    然后你会发现，如果需要用这个binlog来恢复临时库的话，由于这个语句的binlog丢失，
    这个临时库就会少了这一次更新，恢复出来的这一行c的值就是0，与原库的值不同。
    2。先写binlog后写redo log。如果在binlog写完之后crash，由于redo log还没写，
      崩溃恢复以后这个事务无效，所以这一行c的值是0。但是binlog里面已经记录了“把c从0改成1”这个日志。
      所以，在之后用binlog来恢复的时候就多了一个事务出来，恢复出来的这一行c的值就是1，与原库的值不同。
03 | 事务的隔离级别
    oracle默认隔离级别是："读提交"，mysql的隔离级别是："可重复度"
    show variables like 'transaction_isolation';查询隔离级别sql
    针对的是查询：
    读未提交：直接返回记录上的最新值
    读提交：每个sql语句开始执行时开始创建的一个视图（不会加间隙锁）
    可重复读的场景：事务启动时创建的视图，不受其他事务更新的影像；应用场景：判断上个月的余额和当前余额的差额，是否与本月的账单明细一致
            事务启动时的视图可以认为是静态的，不受其他事务更新的影响。
    串行化：直接加锁避免并行访问；
    如何实现隔离级别：通过一个行多版本并发控制（MVCC）；
    长事务的弊端：。可能访问数据库里面的任何数据，事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。
    长事务还占用锁资源，也可能拖垮整个库

    事务的启动方式： 1begin 或 start transaction配套commit 2。set autocommit=0
    查询超过60秒的长事务：select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60

04 05| 深入浅出索引：
    索引的常见模型：哈希表，有序数组，搜索树；
    哈希表：哈希表这种结构适用于只有等值查询的场景，比如Memcached及其他一些NoSQL引擎，如果是范围查找就需要全部扫描一遍了
    有序数组：等值查询（二分查找O（logN））和范围查询（先用二分查找找到第一个左范围，如果不存在，就找到大于左范围的第一个数，然后向右遍历，直到查到第一个大于右区间的范围）
            如果有序数组更新数据就麻烦啦，挪动成本太高；适用于静态存储引擎

    N叉树：查询尽量少的读取磁盘，就必须让查询过程访问尽量少的数据块。“N”取决于数据块的大小
    举个例子：
    以InnoDB的一个整数字段索引为例，这个N差不多是1200。这棵树高是4的时候，就可以存1200的3次方个值，
    这已经17亿了。考虑到树根的数据块总是在内存中的，一个10亿行的表上一个整数字段的索引，
    查找一个值最多只需要访问3次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了

    数据库底层的存储的核心是基于数据模型的：每碰到一个新数据库，我们需要先关注它的数据模型，这样才能从理论上分析出这个数据库的适用场景。

    mysql中：索引是存储引擎实现的，并没有统一的索引标准，不同的存储索引的工作方式并不一样，

    innodb的索引模型：B+树索引模型
    索引类型：主键索引和非主键索引
    主键索引：叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引（clustered index）。select * from T where ID=500只需要搜索ID这颗B+树，尽量使用主键查询
    非主键索引：叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引（secondary index）select * from T where k=5（普通索引）先搜索
    k索引树，得到id的值为500，再到ID索引树搜索yi词，这个过程称为回表；

    索引的维护：
    插入数据：会带来数据的挪动，更糟糕的是，页已经满了，导致页分裂，导致数据页的利用率，原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约50%
    删除数据：相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并，合并的过程，可以认为是分裂过程的逆过程。

    自增主键：插入数据，符合递增插入的场景，每次插入一条数据，都是追加操作，都不涉及挪动其他记录，也不会触发叶子节点的分裂；
    存储空间方面，如果用整形做主键，二级索引的叶子节点可能只要4个字节，

    业务数据字段做主键：不容易保证有序插入，写数据成本相对较高，存储空间方面，如果用其他字段做索引，长度较长，可能二级索引的叶子节点的空间超过主键空间
    重要：
    主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。

    适合用业务字段直接做主键的：1只有一个索引2。该索引必须是唯一索引，由于没有其他索引，不用考虑其他索引叶子节点大小的问题；


    重建索引k（合理）：索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间
    alter table T drop index k;
    alter table T add index(k);
    重建主键索引（不合理）：不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。这两个语句，你可以用这个语句代替 ： alter table T engine=InnoDB
    alter table T drop index k;
    alter table T add index(k);

    select * from T where k between 3 and 5
    索引优化：
    覆盖索引：避免回表：只需要查询主键，建立冗余索引来支持覆盖索引时就需要权衡考虑，select ID from T where k between 3 and 5
        优势：可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。
    最左前缀索引：可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符
    第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。
    （a,b）少维护一个索引；
    如果既有联合查询，又有基于a、b各自的查询呢：要考虑的原则就是空间了，如果a字段比b字段大
    （a，b）联合索引和一个（b）单字段索引

    索引下推（name，age）联合索引：select * from tuser where name like '张%' and age=10 and ismale=1;
    前缀索引：“张”索引找到匹配的；5.6之前：开始一个个回表。到主键索引上找出数据行，再对比字段值。
    5.6之后：索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，
      直接过滤掉不满足条件的记录，减少回表次数。

    CREATE TABLE `geek` (
    `a` int(11) NOT NULL,
    `b` int(11) NOT NULL,
    `c` int(11) NOT NULL,
    `d` int(11) NOT NULL,
    PRIMARY KEY (`a`,`b`),
    KEY `c` (`c`),
    KEY `ca` (`c`,`a`),
    KEY `cb` (`c`,`b`)
    ) ENGINE=InnoDB;

    公司的同事告诉他说，由于历史原因，这个表需要a、b做联合主键，这个小吕理解了。

    但是，学过本章内容的小吕又纳闷了，既然主键包含了a、b这两个字段，那意味着单独在字段c上创建一个索引，就已经包含了三个字段了呀，为什么要创建“ca”“cb”这两个索引？

    同事告诉他，是因为他们的业务里面有这样的两种语句：

    select * from geek where c=N order by a limit 1;
    select * from geek where c=N order by b limit 1;
    结论是ca可以去掉，cb需要保留。
05 | 全局锁和表锁
    加锁的范围：全局锁和表锁，行锁
    使用场景：全库逻辑备份。也就是把整库每个表都select出来存成文本
    带来的问题
      如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆
      如果你在从库上备份，那么备份期间从库不能执行主库同步过来的binlog，会导致主从延迟。
    不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。（可能会有更新数据）
    全剧锁：命令，Flush tables with read lock (FTWRL)
    当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。
    而由于MVCC的支持，这个过程中数据是可以正常更新的。前提是需要引擎支持这个事务（比如myisam不支持）
    既然要全库只读，为什么不使用set global readonly=true的方式呢
    一：修改global变量的方式影响面更大，我不建议你使用
    二是：异常处理机制上FTWRL发生异常会释放锁，readonly，客户端发生异常，数据库就会一直保持readonly状态
    业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的。

    表级锁：表锁和元数据锁
        表锁的语法是 lock tables … read/write；与FTWRL类似，可以用unlock tables主动释放锁，
        也可以在客户端断开的时候自动释放。需要注意，lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。
        如果在某个线程A中执行lock tables t1 read, t2 write; 这个语句，则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执行unlock tables之前，
          也只能执行读t1、读写t2的操作。连写t1都不允许，自然也不能访问其他表

        MDL锁（metadata lock）：
        在MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁
        读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。

        读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，
        如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

        sesssionA加MDL读锁，sesssionB加MDL读锁，sesssionC增加字段加MDL写锁（blocked），这个表如果有
        频繁的查询语句，而且客服端有重试机制，线程很快会爆满；
        如何安全的添加小字段：首先考虑有没有长事务，如果需要做ddl，先考虑暂停ddl，或者kill掉这个长事务

07 | 怎么减少行锁对性能的影响：
    在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。
    如果事务中需要锁多个行，要把最可能影响并发度的锁尽量往后放；可以提高并发度
    当出现死锁以后，有两种策略：
    一种：进入等待，直到超时，innodb_lock_wait_timeout设置，超时时间设置太短，会出现很多误伤；
    一种：死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑
    死锁的解决办法：
    确保这个业务不会死锁，可以临时把死锁检测关掉
    另一个思路是控制并发度
    标记：where条件之后不是索引，锁表，间隙锁也会加上
        where 条件是索引 ，锁记录加间隙锁


08 | 事务到底是隔离的还是不隔离的？
    可重复读隔离级别：事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；
    读提交隔离级别：每一个语句执行前都会重新算出一个新的视图
    事务更新数据：当前读
    begin/start transaction：不是一个事务的起点，执行到第一个操作才是第一个操作InnoDB事务的起点；
    start transaction with consistent snapshot：马上启动一个事务
    mysql中两个视图的概念：
        1。用查询语句定义的虚拟表；如create view …
        2。InnoDB在实现MVCC时用到的一致性读视图（consistent read view），读提交（RC）视图，可重复读（RR）视图
    undo log（回滚日志）：如果要知道之前的版本，根据当前版本和undo log计算出来
    事务的数据版本：row_trx_id：
      解释：【a，b】a是低水位，b是高水位，低于a的是已提交事务（可见），高于b是未开始事务（不可见），
        ab之间是未提交事务集合（两种情况，1。row_trx_id在数组中，表示还没提交的事务生成的，不可见；
                                    2。若 row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见）
    一个数据版本对事务的可见性（三种情况）：针对的是查询，且是可重复读级别
        1。版本未提交，不可见；
        2。版本已提交，但是是在视图创建后提交的，不可见；
        3。版本已提交，而且是在视图创建前提交的，可见。
    更新读：
       更新数据都是限度后写的，而这个读只能读当前的值，称为"当前读"


09 | 普通索引和唯一索引，应该怎么选择？
    数据页：InnoDB的数据是按数据页为单位来读写，每个数据也的大小默认为16KB，一个数据页可以放近千个key
    查询：
        普通索引：多做的那一次“查找和判断下一条记录”的操作多做的那一次“查找和判断下一条记录”的操作
        唯一索引：只需要一次指针寻找和一次计算
    更新
        change buffer：将记录的变更动作缓存下来，所以在一个数据页做merge之前，change buffer记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。
            而且，数据读入内存是需要占用buffer pool的，所以这种方式还能够避免占用内存，提高内存利用率
            merch的执行流程：
                1。磁盘读入数据页到内存（老版本的数据页）；
                2。从change buffer里找出这个数据页的change buffer 记录(可能有多个），依次应用，得到新版数据页；
                3。写redo log。这个redo log包含了数据的变更和change buffer的变更。
        普通索引：更新的时侯目标页在内存中，插入这个值；目标页不在内存中，将更新记录在change buffer，语句执行就结束了
        唯一索引：数据页在不在内存（是否加载），然后校验有没有冲突，没必要使用change buffer
        普通索引减少了磁盘的访问

    change buffer不同场景：
      目的：change buffer记录的变更越多，收益就越大
      写多读少，写完之后，访问的概率比较小，就是账单类、日志类的系统
      如果写入之后，立即访问：先将记录记录在change buffer，会立即触发merge过程，导致随机访问I/O次数不会减小，
      反而增加了change buffer的维护代价（关闭change buffer）
    案例一：
    普通索引改成唯一索引，在大量更新的时候，内存的命中率从99%降到了75%，整个系统处于阻塞状态，更新语句全部堵住
    案例二：
    当有一个类似"历史数据"的库，并且出于成本考虑机械硬盘时，应该特别关注表里的索引，尽量使用普通索引，然后把change buffer尽量开大
    以确保这个“历史数据”表的数据写入速度。
    redo log和change buffer的关系：
    redo log：主要节省的是随机写磁盘的IO消耗（转成顺序写）
    change buffer：主要节省的则是随机读磁盘的IO消耗。注明：不用像唯一索引，需要将数据页读入内存中，校验
        更新
            针对普通索引的两个更新语句，分别对应的page1在内存中，page2不在内存中 执行顺序如下
            1。page1直接更新内存
            2。page2没在缓存中，会在change buffer 记录在往page2更新记录
            3。将上述两个动作记录在redo log中
        查询
            针对普通索引的两个查询语句，分别对应的page1在内存中，page2不在内存中
            1、读page1的时候，直接从内存返回；不用让redo log里面的数据更新以后才返回，磁盘还是原来的数据，直接从内存返回，结果是正确的
            2。读Page 2的时候，需要把Page 2从磁盘读入内存中，然后应用change buffer里面的操作日志，生成一个正确的版本并返回结果
      应用场景
        业务不能保证数据的唯一性，需要数据库约束：那么没得选，必须创建唯一索引。
        归档数据：可以把唯一索引改成普通索引
        问题：主机异常重启是否会导致change buffer和数据丢失
             不会丢失：原因是只更新内存，但是在事务提交的时候，我们把change buffer的操作也记录到redo log里了，所以崩溃恢复的时候，change buffer也能找回来。


10 | MySQL为什么有时候会选错索引？
    优化器选择索引参考的指标：扫描行数，是否使用临时表，是否排序等因素
        扫描行数：执行sql时，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息（区分度）来估算记录数
            区分度（统计信息）：一个索引上不同的值越多（基数越大），这个索引的区分度就越好。
                基数：不同的值的个数，我们称之为“基数”
                    基数的计算：InnoDB默认会选择N个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。

            mysql统计的两种方式：innodb_stats_persistent参数控制
                1。设置为on的时候，表示统计信息会持久化存储。这时，默认的N是20，M是10。
                2。设置为off的时候，表示统计信息只存储在内存中。这时，默认的N是8，M是16。
            优化器使用普通索引会把会把回表的代价算进去，从而导致不选择索引；（可能会带来误判失误）
        统计信息不对的时候：
            analyze table t 命令，可以用来重新统计索引信息修正；  
        优化器没有选择正确的索引：
            1force index起到了“矫正”的作用。
            2。修改语句，引导mysql使用我们期望的sql
            3。可以新建一个更合适的索引，来提供更优化给优化器做选择，来删掉误用的索引；
        主键：直接按照表的行数来估计的。
        show table status：优化器用来估计表的行数
    案例一：平常不断删除历史数据和新增数据时，会导致mysql优化器选错索引
        可能在删除之前还有其他事务启动者，导致每一行数据都有两个版本；
        1（误判扫描行数导致的），解决办法，analyze table t 命令，或者force index
    案例二：
        select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1
        语句应该用a索引，但是用了b索引，因为它认为使用索引b可以避免排序（b本身是索引，已经是有序的了，
            如果选择索引b的话，不需要再做排序，只需要遍历），所以即使扫描行数多，也判定为代价更小。
        解决办法：
        1force index起到了“矫正”的作用。
            select * from t force index(a) where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1
        2。修改语句，引导mysql使用我们期望的sql
            select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b,a limit 1

11 | 怎么给字符串字段加索引？
        索引：长度越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。
        一：前缀索引，关注区分度，区分度越高重复的健值越少，从而减少重复判断，而导致的回表消耗性能；
            前缀区分的计算：
                1。先算出针对这个设置索引的字段在表的不同的个数：select count(distinct email) as L from SUser;
                2。依次选取不同长度的前缀来看这个值
                    select
                    count(distinct left(email,4)）as L4,
                    count(distinct left(email,5)）as L5,
                    count(distinct left(email,6)）as L6,
                    count(distinct left(email,7)）as L7,
                    from SUser;
                3。计算出一个可以接受的损失比例
            缺点：不能使用覆盖索引，系统统并不确定前缀索引的定义是否截断了完整信息
                select id,email from SUser where email='zhangssxyz@xxx.com';前缀索引可能需要回表，完整索引，可以用覆盖索引
    身份证号做等值查询优化
            二。倒序存储（创建索引），身份证最后6位区分度高，在创建索引
                   例子： select field_list from t where id_card = reverse('input_id_card_string');
                缺点：不支持范围查询
                区别：
                    占用的额外的空间：主要在主键索引上，不会消耗额外的存储空间
                    cpu：每次写和读的时候，都需要额外调用一次reverse函数，相比crc32（）函数，消耗的cpu资源更小
                    从查询效率上看：前缀索引的方式，也就是说还是会增加扫描行数
            三。增加hash字段
                使用hash字段，可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。
                alter table t add id_card_crc int unsigned, add index(id_card_crc);
                缺点：不支持范围查询，只能等值查询
                区别：
                    占用的额外的空间：方法需要增加一个字段。当然，倒序存储方式使用4个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个hash字段也差不多抵消了。
                    cpu：需要额外调用一次crc32()函数
                    从查询效率上看：使用hash字段方式的查询性能相对更稳定一些。因为crc32算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近1。
            四。创建完整索引，这样可能比较占用空间；

12 | 为什么我的MySQL会“抖”一下？
        1。一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长
        2。日志写满，更新全部堵住，写性能跌为0，这种情况对敏感业务来说，是不能接受的。
        innodb_io_capacity：影响磁盘的能力
        fio：测试磁盘的IOPS
            InnoDB的刷盘速度：如果你来设计策略控制刷脏页的速度，会参考哪些因素呢？
                一个是脏页比例：
                一个是redo log写盘速度
        原因：InnoDB会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。
            无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用IO资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到MySQL“抖”了一下的原因
        innodb_flush_neighbors：参数就是用来控制这个行为的，值为1的时候会有上述的“连坐”机制，值为0时表示不找邻居，自己刷自己的。

13 | 为什么表数据删掉一半，表文件大小不变？
    表数据：既可以存在共享表空间里，也可以是单独的文件
       innodb_file_per_table：从MySQL 5.6.6版本开始，它的默认值就是ON了。
            1。这个参数设置为OFF表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起
            2。这个参数设置为ON表示的是，每个InnoDB表数据存储在一个以 .ibd为后缀的文件中
        不论使用那个版本，都将他设置为true
            原因：表中的数据被删除了，但是表空间却没有被回收。
    数据删除流程：
        记录删除：可能会复用这个位置，但是磁盘文件不会缩小
            记录的复用，只限于符合范围条件的数据
        数据页删除：删掉了一个数据页上的所有记录
            数据页的复用：可以复用到任何位置
        复用扩展：相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用
        delete命令把整个表的数据删除：所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。
        插入数据导致页分裂，数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。
        大量增删改的表，都是可能是存在空洞的
        重建表（解决方案，去除空洞）
        MySQL 5.5版本之前   alter table A engine=InnoDB命令来重建表，不允许表A有更新，否则数据有丢失，这个是在server层完成
        MySQL 5.6   Online DDL，对这个操作流程做了优化。禁止对A表DDL操作，整个DDL过程是在Innodb内部完成
           1 建立一个临时文件，扫描表A主键的所有数据页；

           2 用数据页中表A的记录生成B+树，存储到临时文件中；

           3 生成临时文件的过程中，将所有对A的操作记录在一个日志文件（row log）中，对应的是图中state2的状态；

           4 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表A相同的数据文件，对应的就是图中state3的状态；

           4 用临时文件替换表A的数据文件。
    Online 和 inplace
    inplace：对于server层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。
    关系
        1。DDL过程如果是Online的，就一定是inplace的；
        2反过来未必，也就是说inplace的DDL，有可能不是Online的。截止到MySQL 8.0，\
          添加全文索引（FULLTEXT index）和空间索引(SPATIAL index)就属于这种情况。
14 | count(*)这么慢，我该怎么办？
    MyISAM:把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高；
    InnoDB引擎:它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。
        MyISAM表虽然count(*)很快，但是不支持事务；
        show table status命令虽然返回很快，但是不准确；
        InnoDB表直接count(*)会遍历全表，虽然结果准确，但会导致性能问题
    方案一：将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使Redis正常工作，这个值还是逻辑上不精确的。
    性能差别的几个原则：
        1server层要什么就给什么；
        2InnoDB只给必要的值；
        3现在的优化器只优化了count(*)的语义为“取行数”，其他“显而易见”的优化并没有做。
    count(主键id)：InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层。server层拿到id后，判断是不可能为空的，就按行累加。
    count(1)：InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。
    count(字段)
           1。如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加；
           2。如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。
    count(*)：并不会把全部字段取出来，而是专门做了优化，不取值。count(*)肯定不是null，按行累加。
    按照效率排序的话，count(字段)<count(主键id)<count(1)≈count(*)，所以我建议你，尽量使用count(*)。
        问题：用一个计数表记录一个业务表的总行数，在往业务表插入数据的时候，需要给计数值加1。
            逻辑实现上是启动一个事务，执行两个语句：
                insert into 数据表
                update 计数表，计数值加1。
            从系统并发能力的角度考虑，怎么安排这两个语句的顺序。
        应该把update计数表放后面：
          原因：
        1。在更新计数表的时候，一定会传入where table_name=$table_name，使用主键索引，更新加行锁只会锁在一行上。
        2。不同业务表插入数据，是更新不同的行，不会有行锁。

16 | “order by”是怎么工作的？
   需要排序： Extra这个字段中的“Using filesort”表示的就是需要排序，
        select city,name,age from t where city='杭州' order by name limit 1000;需要排序
        全字段排序:所有的字段放到sort_buffer
            sort_buffer：MySQL会给每个线程分配一块内存用于排序
            sort_buffer_size：MySQL为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。
            number_of_tmp_files表示的是，排序过程中使用的临时文件数
               例子：如果sort_buffer_size超过了需要排序的数据量的大小，number_of_tmp_files就是0，表示排序可以直接在内存中完成。
            新的算法放入sort_buffer的字段，只有要排序的列（即name字段）和主键id。

            问题：排序是在sort_buffer和临时文件中执行的，就是如果查询要返回的字段很多的话，那么sort_buffer里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。
                单行的长度太长：
            场景：内存足够大，会优先选择全字段排序，把需要的字段都放到sort_buffer中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。
                对于InnoDB表来说，执行全字段排序会减少磁盘访问，因此会被优先选择。
        rowid排序：需要字段放和主键到sort_buffe
            max_length_for_sort_data：超过设定的这个值，MySQL就认为单行太大，要换一个算法
                新的算法放入sort_buffer的字段，只有要排序的列和主键
                  实现逻辑：实际上MySQL服务端从排序后的sort_buffer中依次取出id，然后到原表查到city、name和age这三个字段的结果，不需要在服务端再耗费内存存储结果，是直接返回给客户端的。

            应用场景：担心排序内存太小，会影响排序效率，才会采用rowid排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。
                    “InnoDB表”，你肯定想到了，对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，
                        根本不会导致多访问磁盘。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越少越好了，所以，MySQL这时就会选择rowid排序。

    不需要排序：Extra这个字段没有这个“Using filesort”值
            alter table t add index city_user(city, name);
            select city,name,age from t where city='杭州' order by name limit 1000 
                原因：联合索引本身有序
                进一步优化：覆盖索引
                    创建一个city、name和age的联合索引：alter table t add index city_user_age(city, name, age);
        Extra字段里面多了“Using index”，表示的就是使用了覆盖索引，性能上会快很多。
        *并不是每个查询都需要用上覆盖索引，毕竟维护索引也是需要一定的代价的，这是一个权衡的决定
        思考题：select * from t where city in (“杭州”," 苏州 ") order by name limit 100;是否需要排序，如何避免排序
            思路：虽然有(city,name)联合索引，对于单个city内部，name是递增的。但是由于这条SQL语句不是要单独地查一个city的值，而是同时查了"杭州"和" 苏州 "两个城市，因此所有满足条件的name就不是递增的了。也就是说，这条SQL语句需要排序。
            解决方法：用到(city,name)联合索引
                1。执行select * from t where city=“杭州” order by name limit 100; 这个语句是不需要排序的，客户端用一个长度为100的内存数组A保存结果。
                2。执行select * from t where city=“苏州” order by name limit 100; 用相同的方法，假设结果被存进了内存数组B
                3。现在A和B是两个有序数组，然后你可以用归并排序的思想，得到name最小的前100值，就是我们需要的结果了。
        把limit100改成limit改成10100，也可以按上面的方案，但是从数据库返回给客户端的数据量变大了
         如果数据单行比较大：优化方案：
            select id,name from t where city="杭州" order by name limit 10100; 
            select id,name from t where city="苏州" order by name limit 10100。
            归并排序的方法取得按name顺序第10001~10100的name、id的值，然后拿着这100个id到数据库中去查出所有记录。

17 | 如何正确地显示随机消息？
    select word from words order by rand() limit 3;
        内存临时表
            执行过程：
                Extra字段显示Using temporary，表示的是需要使用临时表
                Using filesort，表示的是需要执行排序操作。
                    1。建一个临时表。这个临时表使用的是memory引擎，表里有两个字段，第一个字段是double类型，为了后面描述方便，记为字段R，第二个字段是varchar(64)类型，记为字段W。并且，这个表没有建索引。
                    2。从words表中，按主键顺序取出所有的word值。对于每一个word值，调用rand()函数生成一个大于0小于1的随机小数，并把这个随机小数和word分别存入临时表的R和W字段中，到此，扫描行数是10000。
                    3。在临时表有10000行数据了，接下来你要在这个没有索引的内存临时表上，按照字段R排序。
                    4。初始化 sort_buffer。sort_buffer中有两个字段，一个是double类型，另一个是整型。
                    5。从内存临时表中一行一行地取出R值和位置信息（我后面会和你解释这里为什么是“位置信息”），分别存入sort_buffer中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加10000，变成了20000。
                    6。在sort_buffer中根据R的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。
                    7。排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出word值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了20003。
               ** order by rand()使用了内存临时表，内存临时表排序的时候使用了rowid排序方法。    
                MySQL的表是用什么方法来定位“一行数据”的：
                        1。对于有主键的InnoDB表来说，这个rowid就是主键ID；
                        2。对于没有主键的InnoDB表来说，这个rowid就是由系统生成的；
                        3。MEMORY引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个rowid其实就是数组的下标。
        磁盘临时表
            tmp_table_size：默认值16M
                    如果临时表大小超过了tmp_table_size，那么内存临时表就会转成磁盘临时表。
            有些时候超过了tmp_table_size这个值却没有使用磁盘临时表
            优先队列排序算法：MySQL 5.6版本引入的一个新的排序算法 （不需要使用磁盘临时表）
                例子：select city,name,age from t where city='杭州' order by name limit 3  ;
                1。对于这10000个准备排序的(R,rowid)，先取前三行，构造成一个堆；
                2。取下一个行(R’,rowid’)，跟当前堆里面最大的R比较，如果R’小于R，把这个(R,rowid)从堆中去掉，换成(R’,rowid’)；
                3。重复第2步，直到第10000个(R’,rowid’)完成比较。
            归并排序算法：
                select city,name,age from t where city='杭州' order by name limit 1000  ;
                原因：维护的堆的大小就是1000行的(name,rowid)，超过了我设置的sort_buffer_size大小
                需要使用磁盘临时表
            不论是使用哪种类型的临时表，order by rand()这种写法都会让计算过程非常复杂，需要大量的扫描行数，因此排序过程的资源消耗也会很大。
    随机排序方法
            随机算法一：
                1。取得这个表的主键id的最大值M和最小值N;
                2。用随机函数生成一个最大值到最小值之间的数 X = (M-N)*rand() + N;
                3。取不小于X的第一个ID的行。
    随机算法二：
    1。取得整个表的行数，并记为C。
    2。取得 Y = floor(C * rand())。 floor函数在这里的作用，就是取整数部分。
    3。用limit Y,1 取得一行。
    思考题：上面的随机算法3的总扫描行数是 C+(Y1+1)+(Y2+1)+(Y3+1)，实际上它还是可以继续优化，来进一步减少扫描行数的。
        取Y1、Y2和Y3里面最大的一个数，记为M，最小的一个数记为N，然后执行下面这条SQL语句：
        select * from t limit N, M-N+1;

18 | 为什么这些SQL语句逻辑相同，性能却差异巨大？
    案例一：条件字段函数操作
        select count(*) from tradelog where month(t_modified)=7;
        对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。
            原因：计算month()函数的话，你会看到传入7的时候，在树的第一层就不知道该怎么办了
                解释说明：放弃了树搜索功能，优化器可以选择遍历主键索引，也可以选择遍历索引t_modified，优化器对比索引大小后发现，索引t_modified更小，遍历这个索引比遍历主键索引来得更快。因此最终还是会选择索引t_modified。
        Extra字段的Using index：表示的是使用了覆盖索引。
        优化方案：
            select count(*) from tradelog where
            -> (t_modified >= '2016-7-1' and t_modified<'2016-8-1') or
            -> (t_modified >= '2017-7-1' and t_modified<'2017-8-1') or 
            -> (t_modified >= '2018-7-1' and t_modified<'2018-8-1');
    案例二：隐式类型转换
        tradeid是字符型号
            select * from tradelog where tradeid=110717;==》字符串转成了数字
            分析数据类型转换规则：
                select "10" > 9 结果是1
                    1。如果规则是“将字符串转成数字”，那么就是做数字比较，结果应该是1；
                    2。如果规则是“将数字转成字符串”，那么就是做字符串比较，结果应该是0。

            优化器相当于：select * from tradelog where  CAST(tradid AS signed int) = 110717;
            缺点：对索引字段做函数操作，优化器会放弃走树搜索功能。

    案例三：隐式字符编码转换
        select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; /*语句Q1*/
            分析计划：
            1。第一行显示优化器会先在交易记录表tradelog上查到id=2的行，这个步骤用上了主键索引，rows=1表示只扫描一行；
            2。第二行key=NULL，表示没有用上交易详情表trade_detail上的tradeid索引，进行了全表扫描。
                    驱动表：因为需要先去从tradelog表中取tradeid字段
                    被驱动表：再去trade_detail表里查询匹配字段
            原因：
                因为这两个表的字符集不同，一个是utf8，一个是utf8mb4，所以做表连接查询的时候用不上关联字段的索引
                字符集不同只是条件之一，连接过程中要求在被驱动表的索引字段上加函数操作，是直接导致对被驱动表做全表扫描的原因。

19 | 为什么我只查一行的语句，也执行这么慢？
    排除情况：如果MySQL数据库本身就有很大的压力，导致数据库服务器CPU占用率很高或ioutil（IO利用率）很高，这种情况下所有语句的执行都有可能变慢
    第一类：查询长时间不返回
            大概率：大概率是表t被锁住了，第一步执行show processlist
            select * from t where id=1;
        等MDL锁
            查找原因流程：
                1。show processlist 查看  Waiting for table metadata lock
            处理：找到谁持有MDL写锁，然后把它kill掉
            对于sleep的，可以通过下面的方式
            select blocking_pid from sys.schema_table_lock_waits;
                可以直接找出造成阻塞的process id
            解决方案：把这个进程idkill
        等flush
            查找
            select * from information_schema.processlist where id=1;
            show processlist
            状态：这个线程的状态是Waiting for table flush
        等行锁
        select * from t where id=1 lock in share mode; 
        查找；用的是MySQL 5.7版本，可以通过sys.innodb_lock_waits 表查到。
            select * from t sys.innodb_lock_waits where locked_table=`'test'.'t'`\G
    第二类：查询慢：
        select * from t where id=1；慢 会滚日志，版本多
        select * from t where id=1 lock in share mode这个反而块
        可能生成了100万个回滚日志(undo log)。

20 | 幻读是什么，幻读有什么问题？
    可重复读的情况下：
        普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现
    幻读是什么？
        1。在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。
        2。上面session B的修改结果，被session A之后的select语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”。
        原因：
            行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙
        解决办法：
            InnoDB只好引入新的锁，也就是间隙锁(Gap Lock)。
        间隙锁：锁的就是两个值之间的空隙。
                例子：比如文章开头的表t，初始化插入了6个记录，这就产生了7个间隙。
            冲突：
                1。跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作
                2。间隙锁之间都不存在冲突关系。
        next-key lock：间隙锁和行锁合并，前开后闭区间
            (25, +supremum]:
            supremum:InnoDB给每个索引加了一个不存在的最大值supremum，这样才符合我们前面说的“都是前开后闭区间”。
            优势：解决了幻读的问题。
            缺点：
                1带来了死锁的问题的问题；
                2。间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的
                案例：
                记住id=9这条记录在表里面是没有的
                sessionA
                    select * from t where id=9 for update;
                    insert into t value(9,9,9);
                sessionB
                    select * from t where id=9 for update;
                    insert into t value(9,9,9);
                分析过程：
                    1。session A 执行select … for update语句，由于id=9这一行并不存在，因此会加上间隙锁(5,10);
                    2。session B 执行select … for update语句，同样会加上间隙锁(5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；
                    3。ssion B 试图插入一行(9,9,9)，被session A的间隙锁挡住了，只好进入等待；
                    4。ssion A试图插入一行(9,9,9)，被session B的间隙锁挡住了。
                结果：两个session进入互相等待状态，形成死锁。当然，InnoDB的死锁检测马上就发现了这对死锁关系，让session A的insert语句报错返回了。
               ** 读提交的话：就没有间隙锁了
                级别：可重复读隔离级别
                解决方案：
                    1。如果读提交隔离级别够用，也就是说，业务不需要可重复读的保证，这样考虑到读提交下操作数据的锁范围更小

    行锁：
            冲突关系：
                跟行锁有冲突关系的是“另外一个行锁”
            读锁：跟另一个读锁兼容，跟另一个写锁冲突
            写锁：跟另一个读锁冲突，跟另一个写锁冲突；
        扩展知识：where条件之后不是索引，锁表，间隙锁也会加上
                where 条件是索引 ，并且有数据，锁记录加间隙锁
                条件之后没有数据，只是加上记录锁；
                （参考下面21课的加锁规则）


21 | 为什么我只改一行的语句，锁这么多？
加锁规则：两个原则，两个优化，和一个bug
    原则：
        1。加锁的基本单位是next-key lock
                next-key lock：前开后闭区间
        2。查找过程中访问到的对象才会加锁
    优化：
        1。索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。（满足条件）
        2。索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。
    bug
        唯一索引上的范围查询会访问到不满足条件的第一个值为止。
    CREATE TABLE `t` (
        `id` int(11) NOT NULL,
        `c` int(11) DEFAULT NULL,
        `d` int(11) DEFAULT NULL,
        PRIMARY KEY (`id`),
        KEY `c` (`c`)
    ) ENGINE=InnoDB;

    insert into t values(0,0,0),(5,5,5),
    (10,10,10),(15,15,15),(20,20,20),(25,25,25);
        案例一：等值查询间隙锁
            session A
                BEGIN ;
                UPDATE t SET d=d+1 where id=7; 加锁(5,10]
            session B
                INSERT INTO t VALUES (8,8,8); blocked
            session C
                update t set d=d+1 where id=10; Success
            注意：
                唯一索引只遍历一次
            分析：
                1。根据原则1，加锁单位是next-key lock，session A加锁范围就是(5,10]；
                2。同时根据优化2，这是一个等值查询(id=7)，而id=10不满足查询条件。
                3。next-key lock退化成间隙锁，因此最终加锁的范围是(5,10)
            结论：
                1。session B要往这个间隙里面插入id=8的记录会被锁住
                2。session C修改id=10这行是可以的。

        案例二：
            session A
                begin;
                select id from t where c=5 LOCK IN SHARE MODE ; 加锁：覆盖索引和(0,5]，(5,10)间隙锁
            session B
                UPDATE t set d=d+1 where id=5; SUCCESS
            session C
                INSERT INTO t VALUES (7,7,7); blocked
            注意
                普通索引终止条件：查询第一个不满足条件终止
            分析
                1。根据原则1，加锁单位是next-key lock，因此会给(0,5]加上next-key lock。
                2。要注意c是普通索引，因此仅访问c=5这一条记录是不能马上停下来的，需要向右遍历，查到c=10才放弃。根据原则2，访问到的都要加锁，因此要给(5,10]加next-key lock。
                3。但是同时这个符合优化2：等值判断，向右遍历，最后一个值不满足c=5这个等值条件，因此退化成间隙锁(5,10)。
                4。根据原则2 ，只有访问到的对象才会加锁，这个查询使用覆盖索引，并不需要访问主键索引，
                    结论
                        1。所以主键索引上没有加任何锁，
                        2。这就是为什么session B的update语句可以执行完成。
            注意：
                1。lock in share mode只锁覆盖索引
                2。for update认为给主键索引上满足条件的行加上行锁。
            提示：
            1。如果你要用lock in share mode来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化

        案例三：主键索引范围锁
            Session A
                begin;
                select * from t where id>=10 and id<11 for UPDATE ;\
                    加锁：id=10和next-key lock(10,15]
            session B
                INSERT INTO t VALUES (8,8,8);SUCCESS
                INSERT INTO t VALUES (13,13,13);blocked
            session C
                UPDATE t SET d=d+1 WHERE id=15;blocked
            分析：
                1。开始执行的时候，要找到第一个id=10的行，因此本该是next-key lock(5,10]，根据优化1， 主键id上的等值条件，退化成行锁，只加了id=10这一行的行锁。
                2。范围查找就往后继续找，找到id=15这一行停下来，因此需要加next-key lock(10,15]。
            注意：
                1。首次session A定位查找id=10的行的时候，是当做等值查询来判断的
                2。而向右扫描到id=15的时候，用的是范围查询判断。

        案例四：非唯一索引范围锁
            Session A
                begin;
                select * from t where c>=10 and c<11 for UPDATE ;(5,10] 和(10,15]
            session B
                INSERT INTO t VALUES (8,8,8);blocked
            session C
                UPDATE t SET d=d+1 WHERE c=15;blocked

            区别：
                案例三使用的是唯一索引，案例四使用的是普通索引
            现象：
                在第一次用c=10定位记录的时候，索引c上加了(5,10]这个next-key lock
            原因：
                由于索引c是非唯一索引，没有优化规则

        案例五：唯一索引范围锁bug
            Session A
                begin;
                select * from t where id> 10 and id<=15 for UPDATE;(10,15]，(15,20]
            session B
                UPDATE t set d=d+1 where id=20;
            session C
                INSERT INTO t VALUES (16,16,16);
            分析：
                1。session A是一个范围查询，按照原则1的话，应该是索引id上只加(10,15]这个next-key lock
                2。因为id是唯一键，所以循环判断到id=15这一行就应该停止了
            现象：
                1。InnoDB会往前扫描到第一个不满足条件的行为止，也就是id=20。
                2。这是个范围扫描，因此索引id上的(15,20]这个next-key lock也会被锁上。
        案例六：非唯一索引上存在"等值"的例子
            insert into t values(30,10,30);
            c=10存在两条记录
                session A
                    BEGIN ;
                    UPDATE t SET d=d+1 where c=7; (c=5,id=5)和(c=15,id=15)
                session B
                    INSERT INTO t VALUES (12,12,12); blocked
                session C
                    update t set d=d+1 where c=15; Success
                分析：
                    1。session A在遍历的时候，先访问第一个c=10的记录，根据原则1，这里加的是(c=5,id=5)到(c=10,id=10)这个next-key lock。
                    2。session A向右查找，直到碰到(c=15,id=15)这一行，循环才结束。根据优化2，这是一个等值查询，向右查找到了不满足条件的行，所以会退化成(c=10,id=10) 到 (c=15,id=15)的间隙锁。
        案例七：limit 语句加锁
            session A
                BEGIN ;
                DELETE FROM t WHERE c=10 LIMIT 2;（c=5,id=5)到（c=10,id=30)
            Session B
                INSERT INTO t VALUES (12,12,12);SUCCESS
            分析：
                1。session A的delete语句加了 limit 2，加不加limit 2，删除的效果都是一样的
                    原因：表t里c=10的记录其实只有两条
                2。加锁的效果却不同session B的insert语句执行通过了
            原因：
                1。遍历到(c=10, id=30)这一行之后，满足条件的语句已经有两条，循环就结束了。
            结论：
                索引c上的加锁范围就变成了从（c=5,id=5)到（c=10,id=30)这个前开后闭区间

        案例八：一个死锁的例子
            Session A
                Begin
                SELECT id FROM t WHERE c=10 LOCK IN SHARE MODE ;
                INSERT INTO t VALUES (8,8,8);（在Session B执行之后）
            Session B
                UPDATE t SET d=d+1 where c=10;（Blokced）
            分析：
                1。session A 启动事务后执行查询语句加lock in share mode，在索引c上加了next-key lock(5,10] 和间隙锁(10,15)；
                2。session B 的update语句也要在索引c上加next-key lock(5,10] ，进入锁等待；
                3。然后session A要再插入(8,8,8)这一行，被session B的间隙锁锁住。由于出现了死锁，InnoDB让session B回滚。
            原因：
                session B的“加next-key lock(5,10] ”操作，实际上分成了两步 
                    1.先是加(5,10)的间隙锁，加锁成功
                    2.然后加c=10的行锁，这时候才被锁住的。

    注意：
        1。加锁规则的时候可以用next-key lock来分析
        2。具体执行的时候，是要分成间隙锁和行锁两段来执行的。


22 | MySQL有哪些“饮鸩止渴”提高性能的方法？
    连接的成本：
        1。MySQL建立连接的过程，成本是很高的
        2。正常的网络连接三次握手外
        3。需要做登录权限判断和获得这个连接的数据读写权限。
    短连接风暴
        概念：正常的短连接模式就是连接到数据库后，执行很少的SQL语句就断开，下次需要的时候再重连
        缺点：
            1。在业务高峰期的时候，就可能出现连接数突然暴涨的情况。
        wait_timeout:一个线程空闲wait_timeout这么多秒之后
        max_connections：
            概念：控制一个MySQL实例同时存在的连接数的上限
            作用：
                1。超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”
                2。对于被拒绝连接的请求来说，从业务角度看就是数据库不可用。
            条件：
                1。在机器负载比较高的时候，处理现有请求的时间变长，每个连接保持的时间也更长
                2。这时，再有新建连接的话，就可能会超过max_connections的限制。
        知识点：
            1。show processlist:查询线程及相关信息
            2.select * from information_schema.innodb_trx;事务具体状态的话,
                1.字段trx_mysql_thread_id表示线程id
                2.字段trx_state 表示事务的状态
        方法一：
            1。断开事务外空闲的连接：show processlist，command是sleep的连接  
            2。断开事务内空闲太久的连接：select trx_mysql_thread_id from information_schema.innodb_trx;
            3。服务端断开命令：kill connection + id
                问题：
                    1。一个客户端处于sleep状态时，它的连接被服务端主动断开后，这个客户端并不会马上知道
                    2。直到客户端在发起下一个请求的时候，才会收到这样的报错“ERROR 2013 (HY000): Lost connection to MySQL server during query”。
                缺点：
                    1。从数据库端主动断开连接可能是有损的
                    2。有的应用端收到这个错误后，不重新连接，而是直接用这个已经不能用的句柄重试查询。这会导致从应用端看上去，“MySQL一直没恢复”。
        方法二：
            跳过权限验证的方法是：–skip-grant-tables
            缺点：风险极高，不建议用
            mysql8.0：启用–skip-grant-tables参数，MySQL会默认把 --skip-networking参数打开，表示这时候数据库只能被本地的客户端连接
        原因：
            1。查询
                1。慢查询性能问题
                    原因：
                        1。索引没有设计好；
                            方案：1。紧急创建索引来解决
                                 2。直接执行alter table 语句。
                                    例子：你现在的服务是一主一备，主库A、备库B，流程
                                        1。在备库B上执行 set sql_log_bin=off，也就是不写binlog，然后执行alter table 语句加上索引；
                                        2。执行主备切换；
                                        3。这时候主库是B，备库是A。在A上执行 set sql_log_bin=off，然后执行alter table 语句加上索引。
                        2。SQL语句没写好；
                            方法
                                1。我们可以通过改写SQL语句来处理（查询重写）
                                2。MySQL 5.7提供了query_rewrite功能，可以把输入的一种语句改写成另外一种模式。
                            例子：
                                1。select * from t where id + 1 = 10000，
                                2。增加一个语句改写规则。
                                    insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values ("select * from t where id + 1 = ?", "select * from t where id = ? - 1", "db1");
                                    call query_rewrite.flush_rewrite_rules();
                        3。MySQL选错了索引。
                            方法
                                1。应急方案就是给这个语句加上force index。
                                2。使用查询重写功能，给原来的语句加上force index，也可以解决这个问题
                    避免：
                        1。上线前，在测试环境，把慢查询日志（slow log）打开，并且把long_query_time设置成0，确保每个语句都会被记录入慢查询日志；
                        2。在测试表里插入模拟线上的数据，做一遍回归测试
                        3。观察慢查询日志里每类语句的输出，特别留意Rows_examined字段是否与预期一致
                2。QPS(每秒查询数)突增问题
                    原因：
                        1。业务突然出现高峰
                        2。应用程序bug
                    问题：
                        1。某个语句的QPS突然暴涨
                        2。MySQL压力过大，影响服务
                    方法
                        1。从应用端：让业务把这个功能下掉，服务自然就会恢复。
                        2。数据库服务端：不同的背景，有不同的方法可用
                            1。一种是由全新业务的bug导致的，从数据库端直接把白名单去掉。
                            2。如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的QPS就会变成0
                            3。如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的SQL语句直接重写成"select 1"返回。
                                缺点：
                                    1。如果别的功能里面也用到了这个SQL语句模板，会有误伤；
                                    2。很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以select 1的结果返回的话，可能会导致后面的业务逻辑一起失败。

            2。更新
23 | MySQL是怎么保证数据不丢的？binlog的写入机制
    1。binlog的写入机制
            前提：一个事务的binlog是不能被拆开的，因此不论这个事务多大，也要确保一次性写入
            依赖：binlog cache的保存问题。
            解决方法：
                1。系统给每个线程binlog cache分配了一片内存，但是共用同一份binlog文件
                2。事务提交的时候，执行器把binlog cache里的完整事务写入到binlog中
                    binlog cache——》binlog过程
                        1write：日志写入到文件系统的page cache，并没有持久化
                        2fsync：将数据持久化到磁盘，这个时候占磁盘的IOPS。
                            write 和fsync的时机，是由参数sync_binlog控制的：
                                1。sync_binlog=0的时候，表示每次提交事务都只write，不fsync；
                                2。sync_binlog=1的时候，表示每次提交事务都会执行fsync；
                                3。sync_binlog=N(N>1)的时候，表示每次提交事务都write，但累积N个事务后才fsync。
                            sync_binlog设置不同
                                1。sync_binlog比较大的值，提升性能；
                                2。考虑到丢失日志量的可控性，一般不建议将这个参数设成0
                                3。常见的是将其设置为100~1000中的某个数值。
                            风险：如果主机发生异常重启，会丢失最近N个事务的binlog日志。
                 binlog_cache_size：用于控制单个线程内binlog cache所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。

    2。redo log的流程。
    1。事务在执行过程中，生成的redo log是要先写到redo log buffer的。
        问题：事务还没提交的时候，redo log buffer中的部分日志被持久化到磁盘？
            redo log的三种状态：
                1。存在redo log buffer中，物理上是在MySQL进程内存中
                2。写到磁盘(write)，但是没有持久化（fsync)，物理上是在文件系统的page cache里面
                3。持久化到磁盘，对应的是hard disk
            写入速度：
                1。写到redo log buffer是很快
                2。wirte到page cache也差不多
                3持久化到磁盘的速度就慢多了。
            写入策略
                控制redo log的写入策略，innodb_flush_log_at_trx_commit不同设置
                    1。置为0的时候，表示每次事务提交时都只是把redo log留在redo log buffer中
                    2。设置为1的时候，表示每次事务提交时都将redo log直接持久化到磁盘
                    3。设置为2的时候，表示每次事务提交时都只是把redo log写到page cache。
            方式
                1。InnoDB有一个后台线程，每隔1秒，就会把redo log buffer中的日志，调用write写到文件系统的page cache，然后调用fsync持久化到磁盘。
                2。redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候，后台线程会主动写盘
                    现象
                        1。由于这个事务并没有提交，所以这个写盘动作只是write
                        2。没有调用fsync，也就是只留在了文件系统的page cache。
                3。另一种是，并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁盘
                    例子：
                        1。假设一个事务A执行到一半，已经写了一些redo log到buffer中
                        2。另外一个线程的事务B提交，如果innodb_flush_log_at_trx_commit设置的是1
                        3。事务B要把redo log buffer里的日志全部持久化到磁盘，也会把A的redo log buffer给带上
            两阶段提交
                1。redo log先prepare
                2。再写binlog
                3。redo log commit
                示例一：
                    1。如果把innodb_flush_log_at_trx_commit设置成1
                    2。那么redo log在prepare阶段就要持久化一次
                        场景：崩溃恢复逻辑，依赖于prepare 的redo log，再加上binlog来恢复
                     条件：每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑
                    推论：InnoDB就认为redo log在commit的时候就不需要fsync了，只会write到文件系统的page cache中就够了。
                示例二：
                    背景：双1配置：sync_binlog（binlog的写入策略）和innodb_flush_log_at_trx_commit（redolog的写入策略）都设置成 1
                    现象：一个事务完整提交前，需要等待两次刷盘，一次是redo log（prepare 阶段），一次是binlog。
                        问题：MySQL看到的TPS是每秒两万的话，每秒就会写四万次磁盘。用工具测试出来，磁盘能力也就两万左右，怎么能实现两万的TPS？
                            解决方案：组提交（group commit）机制
                                前提知识：
                                日志逻辑序列号：（log sequence number，LSN）
                                    概念：
                                        1LSN是单调递增的，用来对应redo log的一个个写入点。每次写入长度为length的redo log， LSN的值就会加上length。
                                        2。LSN也会写到InnoDB的数据页中，来确保数据页不会被多次执行重复的redo log
                                    例子：
                                         1。三个并发事务(trx1, trx2, trx3)在prepare 阶段
                                         2。都写完redo log buffer，持久化到磁盘的过程，对应的LSN分别是50、120 和160。
                                    流程：
                                        1。trx1是第一个到达的，会被选为这组的 leader；
                                        2。等trx1要开始写盘的时候，这个组里面已经有了三个事务，这时候LSN也变成了160；
                                        3。trx1去写盘的时候，带的就是LSN=160，因此等trx1返回时，所有LSN小于等于160的redo log，都已经被持久化到磁盘；
                                        4。这时候trx2和trx3就可以直接返回了。
                                    现象：
                                        1。一次组提交里面，组员越多，节约磁盘IOPS的效果越好
                                        2。如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。
                                        3。并发更新场景下，第一个事务写完redo log buffer以后，接下来这个fsync越晚调用，组员可能越多，节约IOPS的效果就越好。
            提升binlog组提交的效果，设置以下两个参数：
                 1。binlog_group_commit_sync_delay ：表示延迟多少微秒后才调用fsync;
                 2。binlog_group_commit_sync_no_delay_count：表示累积多少次以后才调用fsync。
                两个条件是或的关系只要有一个满足条件就会调用fsync。
            WAL机制主要得益于两个方面：
                1。redo log 和 binlog都是顺序写，磁盘的顺序写比随机写速度要快；
                2。组提交机制，可以大幅度降低磁盘的IOPS消耗。
            问题：如果你的MySQL现在出现了性能瓶颈，而且瓶颈在IO上，可以通过哪些方法来提升性能呢？
                方法：
                    1。设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count参数，减少binlog的写盘次数
                    2。将sync_binlog 设置为大于1的值（比较常见是100~1000）。这样做的风险是，主机掉电时会丢binlog日志。
                    3。将innodb_flush_log_at_trx_commit设置为2。这样做的风险是，主机掉电的时候会丢数据。
            innodb_flush_log_at_trx_commit
                1。设置0表示redo log只保存在内存中，这样的话MySQL本身异常重启也会丢数据，风险太大
                2。而redo log写到文件系统的page cache的速度也是很快的，所以将这个参数设置成2跟设置成0其实性能差不多，但这样做MySQL异常重启时就不会丢数据了，相比之下风险会更小。

24 | MySQL是怎么保证主备一致的？
    MySQL主备的基本原理
        1.主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写binlog。
        2.备库B跟主库A之间维持了一个长连接
        3.主库A内部有一个线程，专门用于服务备库B的这个长连接。
        一个事务日志同步的完整过程是这样的：
            1.备库B上通过change master命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog，这个位置包含文件名和日志偏移量。
            2.在备库B上执行start slave命令，这时候备库会启动两个线程，就是图中的io_thread和sql_thread。其中io_thread负责与主库建立连接。
            3.主库A校验完用户名、密码后，开始按照备库B传过来的位置，从本地读取binlog，发给B。
            4.备库B拿到binlog后，写到本地文件，称为中转日志（relay log）。
            5.sql_thread读取中转日志，解析出日志里的命令，并执行。
    binlog有三种格式，一种是statement，一种是row，mixed（前两种格式的混合）
        mysqlbinlog：
            概念：解析和查看binlog中的内容
            例子：mysqlbinlog  -vv data/master.000001 --start-position=8900;
        statement格式：
            内容：记录到binlog里的是语句原文
            现象：
            1。在主库执行这条SQL语句的时候，用的是索引a
            2。而在备库执行这条SQL语句的时候，却使用了索引t_modified（有风险）
                比如：
                    1。如果delete语句使用的是索引a，那么会根据索引a找到第一个满足条件的行，也就是说删除的是a=4这一行；
                    2。但如果使用的是索引t_modified，那么删除的就是 t_modified='2018-11-09’也就是a=5这一行。
        row格式：（用的多，恢复数据方便）
            内容：
            1。没有了SQL语句的原文，而是替换成了两个event：Table_map和Delete_rows。
            2。binlog里面记录了真实删除行的主键id，这样binlog传到备库去的时候，就肯定会删除id=4的行，不会有主备删除不同行的问题。
                1。Table_map event，用于说明接下来要操作的表是test库的表t;
                2。Delete_rows event，用于定义删除的行为。

        mixed：（用的少）
            背景
                1。因为有些statement格式的binlog可能会导致主备不一致，所以要使用row格式。
                2。但row格式的缺点是，很占空间
                    例子：用一个delete语句删掉10万行数据
                    1。statement格式，占用几十个字节的空间
                    2。row格式，就要把这10万条记录都写到binlog中，不仅会占用更大的空间，同时写binlog也要耗费IO资源，影响执行速度。
            优点：
                可以利用statment格式的优点，同时又避免了数据不一致的风险。
                MySQL自己会判断这条SQL语句是否可能引起主备不一致，如果有可能，就用row格式，否则就用statement格式。
            例子：insert into t values(10,10, now());用的是statement格式
                解析：mysqlbinlog工具解析sql语句
                现象：原来binlog在记录event的时候，多记了一条命令：SET TIMESTAMP=1546103491
                优点：通过这条SET TIMESTAMP命令，MySQL就确保了主备数据的一致性。
                注意：mysqlbinlog解析出日志，然后把里面的statement语句直接拷贝出来执行。（风险，不要这样做），用工具解析在弄。

    数据恢复
        delete语句：
            原因：row格式的binlog也会把被删掉的行的整行信息保存起来
            恢复流程：
                1。把binlog中记录的delete语句转成insert（就可以恢复了）
        insert语句
            原因：row格式下，insert语句的binlog里会记录所有的字段信息，这些信息可以用来精确定位刚刚被插入的那一行
            恢复流程：你直接把insert语句转成delete语句（可以恢复了）
        update语句
            原因：binlog里面会记录修改前整行的数据和修改后的整行数据
            恢复：把这个event前后的两行信息对调一下，再去数据库里面执行（可以恢复了）

    循环复制问题
        双M结构：节点A和B之间总是互为主备关系。这样在切换的时候就不用再修改主备关系。
        问题：
            1。业务逻辑在节点A上更新了一条语句，然后再把生成的binlog 发给节点B，节点B执行完这条更新语句后也会生成binlog
            2。如果节点A同时是节点B的备库，相当于又把节点B新生成的binlog拿过来执行了一次
            3。然后节点A和B间，会不断地循环执行这个更新语句，也就是循环复制了
        方法：server id
            1。规定两个库的server id必须不同，如果相同，则它们之间不能设定为主备关系；
            2。一个备库接到binlog并在重放的过程中，生成与原binlog的server id相同的新的binlog；
            3。每个库在收到从自己的主库发过来的日志后，先判断server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。
        设置了双M结构，日志的执行流就会变成这样
            1。从节点A更新的事务，binlog里面记的都是A的server id；
            2。传到节点B执行一次以后，节点B生成的binlog 的server id也是A的server id；
            3。再传回给节点A，A判断到这个server id与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。

25 | MySQL是怎么保证高可用的？
    主备延迟
    主备切换：
        1。主动操作：比如软件升级、主库所在机器按计划下线等
            同步延迟：
                1。主库A执行完成一个事务，写入binlog，我们把这个时刻记为T1;
                2。之后传给备库B，我们把备库B接收完这个binlog的时刻记为T2;
                3。备库B执行完成这个事务，我们把这个时刻记为T3。
            主备延迟：
                概念：就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是T3-T1。
                show slave status：结果里面会显示seconds_behind_master（当前备库延迟了多少秒）
                    seconds_behind_master的计算方法：（T3-T1）
                        1。每个事务的binlog 里面都有一个时间字段，用于记录主库上写入的时间；
                        2。备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到seconds_behind_master。
                原因：
                    1。有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。
                    2。备库的压力大（备库上的查询耗费了大量的CPU资源，影响了同步速度，造成主备延迟。）
                        方法：
                            1。一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。
                            2。通过binlog输出到外部系统，比如Hadoop这类系统，让外部系统提供统计类查询的能力。
                    3。大事务
                        例子：
                            1。一次性地用delete语句删除太多数据
                            2。就是大表DDL
                    4。库的并行复制能力。
                可靠性优先策略：双M结构下
                    1。判断备库B现在的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则持续重试这一步；
                    2。把主库A改成只读状态，即把readonly设置为true；
                    3。判断备库B的seconds_behind_master的值，直到这个值变成0为止；
                    4。把备库B改成可读写状态，也就是把readonly 设置为false；
                    5。把业务请求切到备库B。
                    优点：seconds_behind_master足够小，不可用的时间越少
                可用性优先策略
                    做法：把上面的步骤4、5调整到最开始执行，不等主备数据同步，直接把连接切到备库B，并且让备库B可以读写，那么系统几乎就没有不可用时间了。
                    binlog_format=mixed时的切换流程和数据结果：
                        流程：
                            1。步骤2中，主库A执行完insert语句，插入了一行数据（4,4），之后开始进行主备切换。
                            2。步骤3中，由于主备之间有5秒的延迟，所以备库B还没来得及应用“插入c=4”这个中转日志，就开始接收客户端“插入 c=5”的命令。
                            3。步骤4中，备库B插入了一行数据（4,5），并且把这个binlog发给主库A。
                            4。步骤5中，备库B执行“插入c=4”这个中转日志，插入了一行数据（5,4）。而直接在备库B执行的“插入c=5”这个语句，传到主库A，就插入了一行新数据（5,5）。
                        结果：
                            1主库A和备库B上出现了两行不一致的数据。
                        原因：
                            这个数据不一致，是由可用性优先流程导致的。
                    inlog_format=row时的切换流程和数据结果
                        背景
                            因为row格式在记录binlog的时候，会记录新插入的行的所有字段值
                        结果：
                            最后只会有一行不一致
                        报错
                            两边的主备同步的应用线程会报错duplicate key error并停止
                    场景：记录操作日志
                结论
                    1。使用row格式的binlog时，数据不一致的问题更容易被发现
                    2。使用mixed或者statement格式的binlog时，数据很可能悄悄地就不一致了（过了很久才能发现）
                    3。主备切换的可用性优先策略会导致数据不一致
                建议：
                    使用可靠性优先策略。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的。
        2。被动操作：比如主库所在机器掉电。
            按照可靠性优先的思路，异常切换会是什么效果？
                主库A和备库B间的主备延迟是30分钟，这时候主库A掉电了，HA系统要切换B作为主库
                做法：采用可靠性优先策略的话，你就必须得等到备库B的seconds_behind_master=0之后，才能切换
                缺点：如果主备延迟时间长，服务恢复需要的时间就越长
        结论：
            1。在满足数据可靠性的前提下，MySQL高可用系统的可用性，是依赖于主备延迟的
            2。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。

26 | 备库为什么会延迟好几个小时？
    原因：
        1。如果备库执行日志的速度持续低于主库生成日志的速度，那这个延迟就有可能成了小时级别
        2。对于一个压力持续比较高的主库来说，备库很可能永远都追不上主库的节奏。
    演进一：官方的5.6版本之前：MySQL只支持单线程复制，由此在主库并发高、TPS高时就会出现严重的主备延迟问题。
        多线程复制机制：一个线程的sql_thread，拆成多个线程
            如：coordinator：原来的sql_thread, 不过现在它不再直接更新数据了，只负责读取中转日志和分发事务
            worker：真正更新日志的，而work线程的个数，就是由参数slave_parallel_workers（8-16）决定的
                多线程复制，都遵循了这两条基本原则：
                    1。不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个worker中
                        原因：
                            1。事务被分发给worker以后，不同的worker就独立执行了。
                            2。由于CPU的调度策略，很可能第二个事务最终比第一个事务先执行
                            3。如果这时候刚好这两个事务更新的是同一行，也就意味着，同一行上的两个事务，在主库和备库上的执行顺序相反，会导致主备不一致的问题。
                    2。同一个事务不能被拆开，必须放到同一个worker中。
                        例子：
                            1。一个事务更新了表t1和表t2中的各一行，如果这两条更新语句被分到不同worker的话
                            2。如果表t1执行完成的瞬间，备库上有一个查询，就会看到这个事务“更新了一半的结果”，破坏了事务逻辑的隔离性。
                案例一：按表分发策略
                    思路：
                        1。如果两个事务更新不同的表，它们就可以并行
                        2。数据是存储在表里的，所以按表分发，可以保证两个worker不会更新同一行。
                    每个事务在分发的时候，跟所有worker的冲突关系包括以下三种情况：
                        1。如果跟所有worker都不冲突，coordinator线程就会把这个事务分配给最空闲的woker;
                        2。如果跟多于一个worker冲突，coordinator线程就进入等待状态，直到和这个事务存在冲突关系的worker只剩下1个；
                        3。如果只跟一个worker冲突，coordinator线程就会把这个事务分配给这个存在冲突关系的worker。
                    优点：
                        这个按表分发的方案，在多个表负载均匀的场景里应用效果很好
                    缺点：
                        如果碰到热点表，比如所有的更新事务都会涉及到某一个表的时候，所有事务都会被分配到同一个worker中，就变成单线程复制了。
                案例二：按行分发策略
                    条件：这个模式要求binlog格式必须是row。
                    原因：果两个事务没有更新相同的行，它们在备库上可以并行执行
                    思路：
                        1。按行复制和按表复制的数据结构差不多，也是为每个worker，分配一个hash表
                        2。只是要实现按行分发，这时候的key，就必须是“库名+表名+唯一键的值”。
                        引入唯一键的原因：
                            1。两个事务要更新的行的主键值不同，但是如果它们被分到不同的worker
                            2。就有可能session B的语句先执行。这时候id=1的行的a的值还是1，就会报唯一键冲突。
                    优点：
                        解决热点表的并行复制问题
                    缺点：
                        1。耗费内存。比如一个语句要删除100万行数据，这时候hash表就要记录100万个项。
                        2。耗费CPU。解析binlog，然后计算hash值，对于大事务，这个成本还是很高的。
                        方法：
                            1。设置一个阈值，单个事务如果超过设置的行数阈值（比如，如果单个事务更新的行数超过10万行）
                            2。暂时退化为单线程模式，退化过程的逻辑大概是这样的：
                                1。coordinator暂时先hold住这个事务；
                                2。等待所有worker都执行完成，变成空队列；
                                3。coordinator直接执行这个事务；
                                4。恢复并行模式。
                两个方案其实都有一些约束条件：
                    1。要能够从binlog里面解析出表名、主键值和唯一索引的值。也就是说，主库的binlog格式必须是row；
                    2。表必须有主键；
                    3。不能有外键。表上如果有外键，级联更新的行不会记录在binlog中，这样冲突检测就不准确。
    演进二：MySQL 5.6版本的并行复制策略
        用于决定分发策略的hash表里，key就是数据库名。（粒度是库）
        相比于按表和按行分发，这个策略有两个优势：
            1。构造hash值的时候很快，只需要库名；而且一个实例上DB数也不会很多，不会出现需要构造100万个项这种情况。
            2。不要求binlog的格式。因为statement格式的binlog也可以很容易拿到库名。
        失效的场景：
            1。主库上的表都放在同一个DB里面
            2。不同DB的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。
        理想的场景：
            1。创建不同的DB，把相同热度的表均匀分到这些不同的DB中
            2。强行使用这个策略。不过据我所知，由于需要特地移动数据，这个策略用得并不多。
    演进三：MariaDB的并行复制策略
        实现：
            1。在一组里面一起提交的事务，有一个相同的commit_id，下一组就是commit_id+1；
            2。commit_id直接写到binlog里面；
            3。传到备库应用的时候，相同commit_id的事务分发到多个worker执行；
            4。这一组全部执行完成后，coordinator再去取下一批。
        思路来源：
            模拟主库的并行模式
        以前版本的的思路
            分析binlog，并拆分到worker
        缺点：
            1。在备库上执行的时候，要等第一组事务完全执行完成后，
            2。第二组事务才能开始执行，这样系统的吞吐量就不够。
            总结：并没有实现“真正的模拟主库并发度”这个目标
                主库并发度：在主库上，一组事务在commit的时候，下一组事务是同时处于“执行中”状态的。
    演进四：MySQL 5.7的并行复制策略
        1。配置为DATABASE，表示使用MySQL 5.6版本的按库并行策略
        2。配置为 LOGICAL_CLOCK，表示的就是类似MariaDB的策略
        并行复制策略的思想是：
            1。同时处于prepare状态的事务，在备库执行时是可以并行的；
            2。处于prepare状态的事务，与处于commit状态的事务之间，在备库执行时也是可以并行的。
        方法：
            配置下面两个参数，提高并发度
                binlog_group_commit_sync_delay参数，表示延迟多少微秒后才调用fsync;
                binlog_group_commit_sync_no_delay_count参数，表示累积多少次以后才调用fsync
                    上面两个参数的作用：
                        拉长binlog从write到fsync的时间，以此减少binlog的写盘次数
                可以用来制造更多的“同时处于prepare阶段的事务”。这样就增加了备库复制的并行度。
            优点：
                1。既可以“故意”让主库提交得慢些
                2。又可以让备库执行得快些
    演进五：MySQL 5.7.22的并行复制策略
        基于WRITESET的并行复制。
            新增了一个参数binlog-transaction-dependency-tracking，可选值：
                1。COMMIT_ORDER，同时进入prepare和commit来判断是否可以并行的策略。
                2。WRITESET：
                        1。表示的是对于事务涉及更新的每一行，计算出这一行的hash值，组成集合writeset
                        2。如果两个事务没有操作相同的行，也就是说它们的writeset没有交集，就可以并行
                3。在WRITESET的基础上多了一个约束，
                        1。即在主库上同一个线程先后执行的两个事务
                        2。在备库执行的时候，要保证相同的先后顺序

            相较按行分发的优势：
                1。writeset是在主库生成后直接写入到binlog里面的
                     这样在备库执行的时候，不需要解析binlog内容（event里的行数据），节省了很多计算量；
                2。不需要把整个事务的binlog都扫一遍才能决定分发到哪个worker，更省内存；
                3。由于备库的分发策略不依赖于binlog内容，所以binlog是statement格式也是可以的。
            缺点：对于“表上没主键”和“外键约束”的场景，WRITESET策略也是没法并行的，也会暂时退化为单线程模型。
27 | 主库出问题了，从库怎么办？
    一主多从的切换正确性
    基于位点的主备切换
    当我们把节点B设置成节点A’的从库的时候，需要执行一条change master命令：
        CHANGE MASTER TO 
        MASTER_HOST=$host_name 
        MASTER_PORT=$port 
        MASTER_USER=$user_name 
        MASTER_PASSWORD=$password 
        MASTER_LOG_FILE=$master_log_name 
        MASTER_LOG_POS=$master_log_pos 
        1。MASTER_HOST、MASTER_PORT、MASTER_USER和MASTER_PASSWORD四个参数，分别代表了主库A’的IP、端口、用户名和密码。
        2。最后两个参数MASTER_LOG_FILE和MASTER_LOG_POS表示，要从主库的master_log_name文件的master_log_pos这个位置的日志继续同步。而这个位置就是我们所说的同步位点，也就是主库对应的文件名和日志偏移量。
        问题：同步位点怎么获取
            方法
                1。等待新主库A’把中转日志（relay log）全部同步完成；
                2。在A’上执行show master status命令，得到当前A’上最新的File 和 Position；
                3。取原主库A故障的时刻T；
                4。用mysqlbinlog工具解析A’的File，得到T时刻的位点。
            位点不准确带来的问题：
                1。在从库B上，由于同步了binlog， R这一行已经存在；
                2。在新主库A’上， R这一行也已经存在，日志是写在123这个位置之后的；
                3。我们在从库B上执行change master命令，指向A’的File文件的123位置，就会把插入R这一行数据的binlog又同步到从库B去执行。
            解决方法：
                1。主动跳过一个事务
                    跳过命令的写法是：
                        set global sql_slave_skip_counter=1;
                        start slave;
                2。通过设置slave_skip_errors参数，直接设置跳过指定的错误
                    比如
                        1。1062错误是插入数据时唯一键冲突；
                        2。1032错误是删除数据时找不到行。
                    解决方法：
                        可以把slave_skip_errors 设置为 “1032,1062”
    GTID：
        背景：上面解决两个解决方法比较复杂
        概念：
            全称是Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成的，是这个事务的唯一标识
        组成：GTID=server_uuid:gno
            1。server_uuid是一个实例第一次启动时自动生成的，是一个全局唯一的值；
            2。gno是一个整数，初始值是1，每次提交事务的时候分配给这个事务，并加1。
        官方：GTID=source_id:transaction_id
        server_uuid就是source_id，gno就是transaction_id
        transaction_id容易误会：
            事务中：指事务id，事务id是在事务执行过程中分配的，这个事务回滚了，事务id也会递增
            提交：gno在事务提交的时候才会分配
        GTID模式的启动：加上参数gtid_mode=on和enforce_gtid_consistency=on就可以了。
        生成方式：
            1。gtid_next=automatic：MySQL就会把server_uuid:gno分配给这个事务。
                1。记录binlog的时候，先记录一行 SET @@SESSION.GTID_NEXT=‘server_uuid:gno’;
                2。把这个GTID加入本实例的GTID集合。
            2。set gtid_next='current_gtid’指定为current_gtid
                1。如果current_gtid已经存在于实例的GTID集合中，接下来执行的这个事务会直接被系统忽略；
                2。如果current_gtid没有存在于实例的GTID集合中，就将这个current_gtid分配给接下来要执行的事务，也就是说系统不需要给这个事务生成新的GTID，因此gno也不用加1。
        基于GTID的主备切换
        备库B要设置为新主库A’的从库的语法如下：
            CHANGE MASTER TO 
            MASTER_HOST=$host_name 
            MASTER_PORT=$port 
            MASTER_USER=$user_name 
            MASTER_PASSWORD=$password 
            master_auto_position=1 
            master_auto_position=1：表示这个主备关系使用的是GTID协议
            实例B上执行start slave命令，取binlog的逻辑是这样的
                1。实例B指定主库A’，基于主备协议建立连接。
                2。实例B把set_b发给主库A’。
                3。例A’算出set_a与set_b的差集，也就是所有存在于set_a，但是不存在于set_b的GITD的集合，判断A’本地是否包含了这个差集需要的所有binlog事务。
                    1。如果不包含，表示A’已经把实例B需要的binlog给删掉了，直接返回错误；
                    2。如果确认全部包含，A’从自己的binlog文件里面，找出第一个不在set_b的事务，发给B；
                4。之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行。
                问题：
                    索引缺失引起的性能问题，
                方法：
                    可以先在备库加索引，然后再切换。
                原因：
                    要避免新增索引对主库性能造成的影响，我们
                GTID和在线DDL
                    在双M结构下
                        方法：
                            备库执行的DDL语句也会传给主库，为了避免传回后对主库造成影响，要通过set sql_log_bin=off关掉binlog。
                        问题：这样操作的话，数据库里面是加了索引，但是binlog并没有记录下这一个更新，是不是会导致数据和日志不一致？
                        例子：
                            这两个互为主备关系的库还是实例X和实例Y，且当前主库是X，并且都打开了GTID模式
                            主备切换的流程：
                                1。在实例X上执行stop slave。
                                2。在实例Y上执行DDL语句。注意，这里并不需要关闭binlog。
                                3。执行完成后，查出这个DDL语句对应的GTID，并记为 server_uuid_of_Y:gno。
                                4。到实例X上执行以下语句序列：
                                    set GTID_NEXT="server_uuid_of_Y:gno";
                                    begin;
                                    commit;
                                    set gtid_next=automatic;
                                    start slave;
                                目的：
                                    1。既可以让实例Y的更新有binlog记录
                                    2。同时也可以确保不会在实例X上执行这条更新。

28 | 读写分离有哪些坑？
    目标：分摊主库的压力
    实现：
        方法一：客户端来选择后端数据库进行查询（share JDBC）
            1。客户端（client）主动做负载均衡
            2。一般会把数据库的连接信息放在客户端的连接层
            优点：
                1。因为少了一层proxy转发，所以查询性能稍微好一点儿
                2。整体架构简单，排查问题更方便
           。 缺点：
                1。要了解后端部署细节，所以在出现主备切换、库迁移等操作的时候，客户端都会感知到，并且需要调整数据库连接信息
                2。信息大量冗余，架构很丑（优化：增加Zookeeper，管理后段的组件，业务端只专注于业务逻辑开发。）
        方法二：Proxy选择后端数据库进行查询（mycat），
            1。在MySQL和客户端之间有一个中间代理层proxy
            2。客户端只连接proxy， 由proxy根据请求类型和上下文决定请求的分发路由。
            优点：
                1。带proxy的架构，对客户端比较友好
                2。客户端不需要关注后端细节，连接维护、后端信息维护等工作，都是由proxy完成的。
            缺点：
                1。对后端维护团队的要求会更高
                2。proxy也需要有高可用架构。因此，带proxy架构的整体就相对比较复杂。
        取舍：取决于数据库团队提供的能力，目前偏向第二种往带proxy的架构方向发展
    过期读：
        概念：在从库上会读到系统的一个过期状态
        原因：
            1。由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询
            2。果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。
        方法：
            1。强制走主库方案；
                流程：将查询分为两类
                    1。对于必须要拿到最新结果的请求，强制将其发到主库上
                        例子：
                            1。在一个交易平台上，卖家发布商品以后，马上要返回主页面，看商品是否发布成功
                            2。这个请求需要拿到最新的结果，就必须走主库。
                    2。对于可以读到旧数据的请求，才将其发到从库上
                        例子：
                            在这个交易平台上，买家来逛商铺页面，就算晚几秒看到最新发布的商品，也是可以接受的。
                问题：有时候你会碰到“所有查询都不能是过期读”的需求，放弃读写分离，所有读写压力都在主库，等同于放弃了扩展性
                    例子：比如一些金融类的业务
            2。sleep方案；
                流程：
                    1。主库更新后，读从库之前先sleep一下
                具体实现：类似于执行一条select sleep(1)命令
                场景
                    1。卖家发布商品为例，商品发布后，用Ajax（Asynchronous JavaScript + XML，异步JavaScript和XML）直接把客户端输入的内容作为“新的商品”显示在页面上，而不是真正地去数据库做查询。
                    2。卖家就可以通过这个显示，来确认产品已经发布成功了
                    3。等到卖家再刷新页面，去查看商品的时候，其实已经过了一段时间，也就达到了sleep的目的，进而也就解决了过期读的问题。
                问题：不精确
                    1。如果这个查询请求本来0.5秒就可以在从库上拿到正确结果，也会等1秒；
                    2。如果延迟超过1秒，还是会出现过期读。
            3。判断主备无延迟方案；
                方法一：
                    1。每次从库执行查询请求
                    2。先判断seconds_behind_master(单位是秒)是否已经等于0
                    3。如果还不等于0 ，那就必须等到这个参数变为0才能执行查询请求。
                方法二：对比位点
                    1。Master_Log_File和Read_Master_Log_Pos，表示的是读到的主库的最新位点；
                    2。Relay_Master_Log_File和Exec_Master_Log_Pos，表示的是备库执行的最新位点。
                    上面两个参数的值完全相同，表示接收到的日志已经同步完成。
                方法三：对比GTID集合
                    1。Auto_Position=1 ，表示这对主备关系使用了GTID协议。
                    2。Retrieved_Gtid_Set，是备库收到的所有日志的GTID集合；
                    3。Executed_Gtid_Set，是备库所有已经执行完成的GTID集合。
                优点：对比位点和对比GTID这两种方法，都要比判断seconds_behind_master是否为0更准确。
                缺点：从库认为已经没有同步延迟，但还是查不到trx3的。严格地说，就是出现了过期读。
                    一个事务的binlog在主备库之间的状态：
                        1。主库执行完成，写入binlog，并反馈给客户端；
                        2。binlog被从主库发送给备库，备库收到；
                        3。在备库执行binlog完成。
                    分析：
                        1。我们上面判断主备无延迟的逻辑，是“备库收到的日志都执行完成了”
                        2。从binlog在主备之间状态的分析中，不难看出还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。
                    例子：
                        1。trx1和trx2已经传到从库，并且已经执行完成了；
                        2。trx3在主库执行完成，并且已经回复给客户端，但是还没有传到从库中。

            4。配合semi-sync方案；
                半同步复制：semi-sync replicatio
                    设计：
                        1。事务提交的时候，主库把binlog发给从库；
                        2。从库收到binlog以后，发回给主库一个ack，表示收到了；
                        3。主库收到这个ack以后，才能给客户端返回“事务完成”的确认。
                    普通的异步复制模式：就可能会丢失
                        比如：如果主库掉电的时候，有些binlog还来不及发给从库
                    解决办法
                        一主一从
                             semi-sync配合前面关于位点的判断，就能够确定在从库上执行的查询请求，可以避免过期读。
                        一主多从
                            在一主多从场景中，主库只要等到一个从库的ack，就开始给客户端返回确认。从库执行查询请求，就有两种情况
                                1。如果查询是落在这个响应了ack的从库上，是能够确保读到最新数据；
                                2。但如果是查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题
                    问题：
                        1。一主多从的时候，在某些从库执行查询请求会存在过期读的现象；
                        2。在持续延迟的情况下，可能出现过度等待的问题。
                            例子：
                                1。如果在业务更新的高峰期，主库的位点或者GTID集合更新很快
                                2。那么上面的两个位点等值判断就会一直不成立，很可能出现从库上迟迟无法响应查询请求的情况。
            5。等主库位点方案；
                命令：select master_pos_wait(file, pos[, timeout]);
                    逻辑：
                        1。它是在从库执行的；
                        2。参数file和pos指的是主库上的文件名和位置；
                        3。timeout可选，设置为正整数N表示这个函数最多等待N秒。
                    概念：正常返回的结果是一个正整数M，表示从命令开始执行，到应用完file和pos表示的binlog位置，执行了多少事务。
                    存在的可能结果
                        1。如果执行期间，备库同步线程发生异常，则返回NULL；
                        2。如果等待超过N秒，就返回-1；
                        3。如果刚开始执行的时候，就发现已经执行过这个位置了，则返回0。
                    例子：先执行trx1，再执行一个查询请求的逻辑：流程
                        1。trx1事务更新完成后，马上执行show master status得到当前主库执行到的File和Position；
                        2。选定一个从库执行查询语句；
                        3。在从库上执行select master_pos_wait(File, Position, 1)；
                        4。如果返回值是>=0的正整数，则在这个从库执行查询语句；
                        5。否则，到主库执行查询语句。
                            假设，这条select查询最多在从库上等待1秒。那么，如果1秒内master_pos_wait返回一个大于等于0的整数，
                            就确保了从库上执行的这个查询结果一定包含了trx1的数据。
                    问题：
                        如果所有的从库都延迟超过1秒了，那查询压力不就都跑到主库上了
                        方法：
                            1。一种是超时放弃
                            2。一种是转到主库查询。
            6。等GTID方案。
                select wait_for_executed_gtid_set(gtid_set, 1);
                    逻辑：
                        1。等待，直到这个库执行的事务中包含传入的gtid_set，返回0；
                        2。超时返回1。
                    背景：
                        1在前面等位点的方案中，我们执行完事务后，还要主动去主库执行show master status
                        2。MySQL 5.7.6版本开始，允许在执行完更新类事务后，把这个事务的GTID返回给客户端，这样等GTID的方案就可以减少一次查询。
                    执行流程：
                        1。trx1事务更新完成后，从返回包直接获取这个事务的GTID，记为gtid1；
                        2。选定一个从库执行查询语句
                        3。在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；
                        4。如果返回值是0，则在这个从库执行查询语句；
                        5。否则，到主库执行查询语句。
                    缺点：跟等主库位点的方案一样，等待超时后是否直接到主库查询
                    问题：怎么能够让MySQL在执行事务后，返回包中带上GTID呢？
                    方法：
                        1。将参数session_track_gtids设置为OWN_GTID
                        2。通过API接口mysql_session_track_get_first从返回包解析出GTID的值即可。

29 | 如何判断一个数据库是不是出问题了？
怎么判断一个主库出问题了
方法一：select 1判断（不行）
    原因：select 1成功返回，只能说明这个库的进程还在，并不能说明主库没问题
    例子
        innodb_thread_concurrency：设置成3，表示InnoDB只允许3个线程并行执行
        innodb_thread_concurrency参数设置为0，表示不限制并发线程数量
        并发连接和并发查询
            并发连接：show processlist的结果里，显示的几千个连接
            并发查询："当前正在执行”的语句
            影响：并发连接数达到几千个影响并不大，就是多占一些内存而已，应该关注的是并发查询，因为并发查询太高才是CPU杀手
        建议把innodb_thread_concurrency设置为64~128
            模拟大查询方法：
                Session A
                    select sleep(1000) from t;
                Session B
                    select sleep(1000) from t;
                Session C
                    select sleep(1000) from t;
                Session D
                    select 1;(Query ok)
                    select * from t(blocked)6
        热点更新和死锁检测的时候，会不会很容易把128消耗完
        解决方案：
            在线程进入锁等待以后，并发线程的计数会减一（说等行锁（也包括间隙锁）的线程是不算在128里面的。）
        优点：
            1。进入锁等待的线程已经不吃CPU了
            2。必须这么设计，才能避免整个系统锁死。
        例子：假设处于锁等待的线程也占并发线程的计数
            1。线程1执行begin; update t set c=c+1 where id=1, 启动了事务trx1， 然后保持这个状态。这时候，线程处于空闲状态，不算在并发线程里面。
            2。线程2到线程129都执行 update t set c=c+1 where id=1; 由于等行锁，进入等待状态。这样就有128个线程处于等待状态；
            3。如果处于锁等待状态的线程计数不减一，InnoDB就会认为线程数用满了，会阻止其他语句进入引擎执行，这样线程1不能提交事务。而另外的128个线程又处于锁等待状态，整个系统就堵住了。
        注意：select sleep(100) from t，还是要算进并发线程的计数的
方法二：查表判断
    做法：
        1。在系统库（mysql库）里创建一个表
        2。比如命名为health_check
        3。里面只放一行数据，然后定期执行：
        4。执行查询：select * from mysql.health_check; 
    优点：可以检测出由于并发线程过多导致的数据库不可用的情况。
    问题：空间满了以后，这种方法又会变得不好使。
    原因：
        1。更新事务要写binlog，而一旦binlog所在磁盘的空间占用率达到100%
        2。那么所有的更新语句和事务提交的commit语句就都会被堵住
        3。系统这时候还是可以正常读数据的。
    解决方法：方法三
    方法三：更新判断
            update mysql.health_check set t_modified=now();
            背景：节点可用性的检测都应该包含主库和备库，如果用更新来检测主库的话，那么备库也要进行更新检测。
            问题：如果主库A和备库B都用相同的更新命令，就可能出现行冲突，也就是可能会导致主备同步停止
                原因：
                    1。备库的检测也是要写binlog的
                    2。我们一般会把数据库A和B的主备关系设计为双M结构
                    3。所以在备库B上执行的检测命令，也要发回给主库A。
            解决方案
                1。mysql.health_check表上存入多行数据，并用A、B的server_id做主键。
                    原因：MySQL规定了主库和备库的server_id必须不同（否则创建主备关系的时候就会报错）
                检测命令：
                insert into mysql.health_check(id, t_modified) values (@@server_id, now()) on duplicate key update t_modified=now();
        问题：
            判定慢
                涉及到：服务器IO资源分配的问题。
                例子：
                    1。设想一个日志盘的IO利用率已经是100%的场景。这时候，整个系统响应非常慢，已经需要做主备切换了。
                           I/O的100%：
                            1。IO利用率100%表示系统的IO是在工作的，每个请求都有机会获得IO资源，执行自己的任务
                            2。使用的update命令，需要的资源很少，所以可能在拿到IO资源的时候就可以提交成功
                            3。并且在超时时间N秒未到达之前就返回给了检测系统。
                    2。执行更新操作，update命令没有超时，于是就得到了“系统正常”的结论。
                    3。也就是说，这时候在业务系统上正常的SQL语句已经执行得很慢了，但是DBA上去一看，HA系统还在正常工作，并且认为主库现在处于可用状态
    外部检测：方法一到方法三
        问题：随机性
            1。外部检测都需要定时轮询，所以系统可能已经出问题了，但是却需要等到下一个检测发起执行语句的时候，我们才有可能发现问题。
            2。如果你的运气不够好的话，可能第一次轮询还不能发现，这就会导致切换慢的问题。

    内部统计
    概念：
        针对磁盘利用率这个问题，如果MySQL可以告诉我们，内部每一次IO请求的时间，那我们判断数据库是否出问题的方法就可靠得多了。
    方法：
        MySQL 5.6版本以后提供的performance_schema库，就在file_summary_by_event_name表里统计了每次IO请求的时间。
        file_summary_by_event_name表里有很多行数据
            参考网址https://www.cnblogs.com/gaosf/p/11149739.html
30 | 答疑文章（二）：用动态的观点看加锁
31 | 误删数据后除了跑路，还能怎么办？
    分类
    1。使用delete语句误删数据行；
        恢复方法：
            可以用Flashback工具通过闪回把数据恢复回来。
        恢复原理：
            1。Flashback恢复数据的原理，是修改binlog的内容，拿回原库重放。
            2。而能够使用这个方案的前提是，需要确保binlog_format=row 和 binlog_row_image=FULL。
            具体恢复数据时，需要对单个数据做如下操作：
                1。对于insert语句，对应的binlog event类型是Write_rows event，把它改成Delete_rows event即可；
                2。同理，对于delete语句，也是将Delete_rows event改为Write_rows event；
                3。而如果是Update_rows的话，binlog里面记录了数据行修改前和修改后的值，对调这两行的位置即可。
            注意一：如果误删数据涉及到了多个事务的话，需要将事务的顺序调过来再执行。
                例子：
                    (A)delete ...
                    (B)insert ...
                    (C)update ...
                    要把数据库恢复回这三个事务操作之前的状态，用Flashback工具解析binlog后，写回主库的命令是：
                    (reverse C)update ...
                    (reverse B)delete ...
                    (reverse A)insert ...
            注意二：不建议你直接在主库上执行这些操作。
                1。恢复数据比较安全的做法，是恢复出一个备份
                2。或者找一个从库作为临时库，在这个临时库上执行这些操作
                3。然后再将确认过的临时库的数据，恢复回主库。
                原因：
                    1。一个在执行线上逻辑的主库，数据状态的变更往往是有关联的
                    2。可能由于发现数据问题的时间晚了一点儿，就导致已经在之前误操作的基础上，业务代码逻辑又继续修改了其他数据
                    3。所以，如果这时候单独恢复这几行数据，而又未经确认的话，就可能会出现对数据的二次破坏。
            安全措施：
                1。sql_safe_updates参数设置为on
                    1。如果我们忘记在delete或者update语句中写where条件
                    2。或者where条件里面没有包含索引字段的话，这条语句的执行就会报错。
                2。代码上线前，必须经过SQL审计。
            性能：
                1。优先考虑使用truncate table或者drop table命令。（可以用Flashback恢复数据）
                2。delete全表是很慢的，需要生成回滚日志、写redo、写binlog（不能用flashback恢复）
                3。而使用truncate /drop table和drop database命令删除的数据，就没办法通过Flashback来恢复了。
                    原因：
                        1。即使我们配置了binlog_format=row，执行这三个命令时
                        2。记录的binlog还是statement格式。binlog里面就只有一个truncate/drop 语句，这些信息是恢复不出数据的
    2。使用drop table或者truncate table语句误删数据表；
        恢复：要想恢复数据，就需要使用全量备份，加增量日志的方式了
        条件：要求线上有定期的全量备份，并且实时备份binlog。
        恢复流程：
            1。取最近一次全量备份，假设这个库是一天一备，上次备份是当天0点；
            2。备份恢复出一个临时库；
            3。从日志备份里面，取出凌晨0点之后的日志
            4。把这些日志，除了误删除数据的语句外，全部应用到临时库。

    3。使用drop database语句误删数据库；
    4。使用rm命令误删整个MySQL实例。
32 | 为什么还有kill不掉的语句？
    两个kill的mysql的命令
        1。kill query +线程id 
            表示终止这个线程中正在执行的语句
        2。kill connection +线程id
            connection可缺省，表示断开这个线程的连接，当然如果这个线程有语句正在执行，也是要先停止正在执行的语句的。
    显示执行语句：
        show processlist
            问题：
                有的时候可以看到执行的线程是command列是killed

    大多数情况下是有效的
        例子一：执行一个查询的过程中，发现执行时间太久，要放弃继续查询
            方法：kill query命令，终止这条查询语句。
        例子二：语句处于锁等待的时候，直接使用kill命令也是有效的
            方法：kill命令也是有效的
    kill的执行逻辑：
        1。kill并不是马上停止的意思，而是告诉执行线程说
            原因：
                1。当对一个表做增删改查操作时，会在表上加MDL读锁。
                2。所以，session B虽然处于blocked状态，但还是拿着一个MDL读锁的
                3。如果线程被kill的时候，就直接终止，那之后这个MDL读锁就没机会被释放了。
        2。这条语句已经不需要继续执行了，可以开始“执行停止的逻辑了”。
            linux中的kill：
                1。Linux的kill命令类似，kill -N pid并不是让进程直接停止
                2。而是给进程发一个信号，然后进程处理这个信号，进入终止逻辑
                3。只是对于MySQL的kill命令来说，不需要传信号量参数，就只有“停止”这个命令。
            mysql的执行的kill命令线程做了两件事：
                1。把session B的运行状态改成THD::KILL_QUERY(将变量killed赋值为THD::KILL_QUERY)；
                2。给session B的执行线程发一个信号。
                    目的：
                        让session B退出等待，来处理这个THD::KILL_QUERY状态。
                        隐含了三层意思：
                            1。一个语句执行过程中有多处“埋点”，在这些“埋点”的地方判断线程状态，如果发现线程状态是THD::KILL_QUERY，才开始进入语句终止逻辑；
                            2。如果处于等待状态，必须是一个可以被唤醒的等待，否则根本不会执行到“埋点”处；
                            3。语句从开始进入终止逻辑，到终止逻辑完全完成，是有一个过程的。
        kill无效的几种情况
            情况一：线程没有执行到判断线程状态的逻辑。
                例子一：set global innodb_thread_concurrency=2
                    执行两个查询线程，session A，Session B 执行Session c阻塞
                        执行命令：
                        kill query C 失败；
                        kill connection 成功；
                        show processlist 还是有killed的线程，没有退出
                            扩展知识：如果一个线程的状态是KILL_CONNECTION，就把Command列显示成Killed。
                            原因：
                                1。等行锁时，使用的是pthread_cond_timedwait函数，这个等待状态可以被唤醒
                                2。12号线程的等待逻辑是这样的：每10毫秒判断一下是否可以进入InnoDB执行，如果不行，就调用nanosleep函数进入sleep状态
                                3。Session C线程的状态已经被设置成了KILL_QUERY，但是在这个等待进入InnoDB的循环过程中，并没有去判断线程的状态，因此根本不会进入终止逻辑阶段。
                                4。当session E执行kill connection 命令时，是这么做的
                                    1。把Session C的线程状态设置为KILL_CONNECTION；
                                    2。关掉Session C线程的网络连接
                例子二：IO压力过大，读写IO的函数一直无法返回，导致不能及时判断线程的状态
            情况二：终止逻辑耗时较长。
                原因：
                    1。从show processlist结果上看也是Command=Killed，需要等到终止逻辑完成，语句才算真正完成
                常见的场景：
                    1。超大事务执行期间被kill
                        原因：回滚操作需要对事务执行期间生成的所有新数据版本做回收操作，耗时很长。
                    2。大查询回滚
                        原因：
                            1。如果查询过程中生成了比较大的临时文件，加上此时文件系统压力大
                            2。删除临时文件可能需要等待IO资源，导致耗时较长。
                    3。DDL命令执行到最后阶段
                        原因：
                            1。如果被kill，需要删除中间过程的临时文件
                            2。也可能受IO资源影响耗时较久。
        关于两个关于客户端的误解
            第一个误解：
                如果库里面的表特别多，连接就会很慢。
                原因：
                    客户端在连接成功后，需要多做一些操作
                        过程：
                            1。执行show databases；
                            2。切到db1库，执行show tables；
                            3。把这两个命令的结果用于构建一个本地的哈希表。
                结论：
                    感知到的连接过程慢，其实并不是连接慢，也不是服务端慢，而是客户端慢。
                方法：
                    连接命令中加上-A，就可以关掉这个自动补全的功能，然后客户端就可以快速返回了。
                        自动补全：
                            在输入库名或者表名的时候，输入前缀，可以使用Tab键自动补全表名或者显示提示。
                    除了加-A以外，加–quick(或者简写为-q)参数，也可以跳过这个阶段
            第二个误解：
                –quick参数应该是一个让服务端加速的参数？
                结论：
                    恰恰相反，设置了这个参数可能会降低服务端的性能
                原因：
                    MySQL客户端发送请求后，接收服务端返回结果的方式有两种
                        1。一种是本地缓存，也就是在本地开一片内存，先把结果存起来
                        2。一种是不缓存，读一个处理一个
                            问题：
                                采用不缓存的方式时，如果本地处理得慢，就会导致服务端发送结果被阻塞
                扩展：
                    1。MySQL客户端默认采用第一种方式
                    2。如果加上–quick参数，就会使用第二种不缓存的方式
                        参数取名叫作quick的原因？
                            1。跳过表名自动补全功能
                            2。mysql_store_result需要申请本地内存来缓存查询结果，如果查询结果太大，会耗费较多的本地内存，可能会影响客户端本地机器的性能；
                            3。不会把执行命令记录到本地的命令历史文件
            思考题：
                问题
                    1。如果一个事务被kill之后，持续处于回滚状态，从恢复速度的角度看
                    2。你是应该重启等它执行结束，还是应该强行重启整个MySQL进程。
                结论：
                    1。重启之后该做的回滚动作还是不能少的，所以从恢复速度的角度来说，应该让它自己结束。
                    2。如果这个语句可能会占用别的锁，或者由于占用IO资源过多，从而影响到了别的语句执行的话，就需要先做主备切换，切到新主库提供服务。
                    3。切换之后别的线程都断开了连接，自动停止执行。接下来还是等它自己执行完成。这个操作属于我们在文章中说到的，减少系统压力，加速终止逻辑。

33 | 我查这么多数据，会不会把数据库内存打爆？
    问题：
        我的主机内存只有100G，现在要对一个200G的大表做全表扫描，会不会把数据库主机的内存用光了
    思考点：
        逻辑备份的时候，可不就是做整库扫描吗？如果这样就会把内存吃光，逻辑备份不是早就挂了？
    全表扫描对server层的影响
        例子：
            对一个200G的InnoDB表db1. t，执行一个全表扫描，把扫描结果保存在客户端
        命令：
            mysql -h$host -P$port -u$user -p$pwd -e "select * from db1.t" > $target_file
        流程：
            1。全表扫描实际上是直接扫描表t的主键索引
                原因：InnoDB的数据是保存在主键索引上的
            2。查到的每一行都可以直接放到结果集里面
                原因：查询语句由于没有其他的判断条件
                结果集：服务端并不需要保存一个完整的结果集
                取数据和发数据的流程是这样的
                    1。获取一行，写到net_buffer中。这块内存的大小是由参数net_buffer_length定义的，默认是16k。
                    2。重复获取行，直到net_buffer写满，调用网络接口发出去。
                    3。如果发送成功，就清空net_buffer，然后继续取下一行，并写入net_buffer。
                    4。如果发送函数返回EAGAIN或WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。
            3。然后返回给客户端。
        重要：
            MySQL是“边读边发的”
            问题：
                如果客户端接收得慢，会导致MySQL服务端由于结果发不出去，这个事务的执行时间变长。
            查看命令：show processlist
                Sending to client：
                    概念：
                        1。线程处于“等待客户端接收结果”的状态
                    问题一：如果一直处于“Sending to client”，表示服务器端的网络栈写满了
                       例如：
                            1。假设有一个业务的逻辑比较复杂，每读一行数据以后要处理的逻辑如果很慢
                            2。就会导致客户端要过很久才会去取下一行数据
                               前提：客户端使用–quick参数，会使用mysql_use_result方法。
                                    mysql_use_result：读一行处理一行
                                        场景：大查询
                                            例子：执行了一个大查询导致客户端占用内存近20G
                        方法：mysql_store_result解决
                            mysql_store_result：
                            场景：
                                一个查询的返回结果不会很多
                    问题二：很多个线程都处于“Sending to client”这个状态，这个没有设置-quick的前提
                        方法：
                            让业务开发同学优化查询结果，并评估这么多的返回结果是否合理
                    注意：
                        如果要快速减少处于这个状态的线程
                        方法：
                            将net_buffer_length参数设置为一个更大的值是一个可选方案。
                Sending data：表示“正在执行”
                    例子：
                        构造一个锁等待的场景，就能看到Sending data状态

    全表扫描对InnoDB的影响
        背景：
        redo log：作用，避免了随机写盘，顺序写盘，
        Buffer Pool ：作用，加快更新和查询
            Buffer Pool对查询效果依赖的指标：内存命中率
                查看命令：show engine innodb status 
            innodb_buffer_pool_size：决定Buffer Pool的大小，
                建议设置物理内存的60%~80%。
                概念：
                    如果一个 Buffer Pool满了，而又要从磁盘读入一个数据页，那肯定是要淘汰一个旧数据页的。
                淘汰算法：
                    最近最少使用 (Least Recently Used, LRU)算法：是淘汰最久未使用的数据。
                例子：
                    1。我们要扫描一个200G的表，而这个表是一个历史数据表，平时没有业务访问它。
                    2。这个算法扫描的话，就会把当前的Buffer Pool里的数据全部淘汰掉，存入扫描过程中访问到的数据页的内容
                问题：
                    1。Buffer Pool里面主要放的是这个历史数据表的数据
                    2。Buffer Pool的内存命中率急剧下降，磁盘压力增加，SQL语句响应变慢。
                方法：InnoDB对LRU算法做了改进。
                    1。在InnoDB实现上，按照5:3的比例把整个LRU链表分成了young区域和old区域
                        对old区的数据页做的判断
                            1。若这个数据页在LRU链表中存在的时间超过了1秒，就把它移动到链表头部；
                            2。如果这个数据页在LRU链表中存在的时间短于1秒，位置保持不变
                                innodb_old_blocks_time；控制的1，单位是毫秒
                        操作逻辑：
                        1。扫描过程中，需要新插入的数据页，都被放到old区域;
                        2。一个数据页里面有多条记录，这个数据页会被多次访问到，但由于是顺序扫描
                        3。这个数据页第一次被访问和最后一次被访问的时间间隔不会超过1秒，因此还是会被保留在old区域
                        4。再继续扫描后续的数据，之前的这个数据页之后也不会再被访问到
                        5。于是始终没有机会移到链表头部（也就是young区域），很快就会被淘汰出去。
                    分析：
                        1。在扫描这个大表的过程中，虽然也用到了Buffer Pool
                        2。对young区域完全没有影响，从而保证了Buffer Pool响应正常业务的查询命中率。

34 | 到底可不可以使用join？
    Index Nested-Loop Join
        前提： join关联字段必须是索引
        select * from t1 straight_join t2 on (t1.a=t2.a);
        流程：
            1。从表t1中读入一行数据 R；
            2。从数据行R中，取出a字段到表t2里去查找；
            3。取出表t2中满足条件的行，跟R组成一行，作为结果集的一部分；
            4。重复执行步骤1到3，直到表t1的末尾循环结束。
            结论：
                1。使用join语句，性能比强行拆成多个单表执行SQL语句的性能要好；
                    例子：
                        使用join：
                            select * from t1 straight_join t2 on (t1.a=t2.a);
                        拆分后：
                            1。执行select * from t1，查出表t1的所有数据，这里有100行；
                            2。循环遍历这100行数据：
                                1。从每一行R取出字段a的值$R.a；
                                2。执行select * from t2 where a=$R.a；
                                3。把返回的结果和R构成结果集的一行。
                            缺点：
                                1。拆分后，也是扫描了200行，但是总共执行了101条语句，比直接join多了100次交互
                                2。客户端还要自己拼接SQL语句和结果。
                2。如果使用join语句的话，需要让小表做驱动表。
                    概念：
                        1。驱动表：全表扫描
                            例子：
                                行数是N，执行过程就要扫描驱动表N行，然后对于每一行，到被驱动表上匹配一次
                                时间复杂度：N
                        2。被驱动表：走树搜索。
                            例子：行数是M。每次在被驱动表查一行数据，要先搜索索引a，再搜索主键索引
                                时间复杂度：2*log2M（涉及到回表，所以乘以2）
                                原因：
                                    每次搜索一棵树近似复杂度是以2为底的M的对数，记为log2M
                    整个执行过程中：
                        时间复杂度是 N + N*2*log2M。
                        结论：N对扫描行数的影响更大，因此应该让小表来做驱动表。
                            原因：
                                1。N扩大1000倍的话，扫描行数就会扩大1000倍
                                2。而M扩大1000倍，扫描行数扩大不到10倍

    Simple Nested-Loop Join
        前提：被驱动表用不上索引
            例子：
                select * from t1 straight_join t2 on (t1.a=t2.b);
                分析：
                    1。表t2的字段b上没有索引
                    2。每次到t2去匹配的时候，就要做一次全表扫描。
                扫描行数：
                    100*1000=10万行
                缺点：这个算法看上去太“笨重”了
                注意：
                    MySQL也没有使用这个Simple Nested-Loop Join算法
            方法：
                使用了另一个叫作“Block Nested-Loop Join”的算法，简称BNL。
    Block Nested-Loop Join
        前提：join条件时，关联的字段不是用的索引
        explain显示结果：
             using join buffer（Block nested loop）
        流程：
            1。把t1中的表中的所有数据放在join_buffer中；
                问题：表t1是一个大表，join_buffer放不下怎么办呢？
                    概念：join_buffer默认是256k
                    方法：分段放
                        执行过程：
                            1。描表t1，顺序读取数据行放入join_buffer中，放完第88行join_buffer满了，继续第2步
                            2。扫描表t2，把t2中的每一行取出来，跟join_buffer中的数据做对比，满足join条件的，作为结果集的一部分返回；
                            3。清空join_buffer；
                            4。继续扫描表t1，顺序读取最后的12行数据放入join_buffer中，继续执行第2步。
                            分析：
                                1。驱动表的数据行数是N，需要分K段才能完成算法流程，被驱动表的数据行数是M
                                    注意：这里的K不是常数，N越大K就会越大，因此把K表示为λ*N，显然λ的取值范围是(0,1)。
                                2。这个算法的执行过程中
                                    1。扫描行数是 N+λ*N*M；
                                    2。内存判断 N*M次。
                            结论：让小表当驱动表。
                                原因
                                    1。内存判断次数是不受选择哪个表作为驱动表影响的
                                    2。而考虑到扫描行数，在M和N大小确定的情况下，N小一些，整个算式的结果会更小。
                                N+λ*N*M：λ才是影响扫描行数的关键因素，这个值越小越好
                                    1。N越大，分段数K越大
                                    2。N固定的时候，什么参数会影响K的大小呢？（也就是λ的大小）
                                        结果：join_buffer_size
                                            1。join_buffer_size越大，一次可以放入的行越多
                                            2。分成的段数也就越少，对被驱动表的全表扫描次数就越少。

            2。描表t2，把表t2中的每一行取出来，跟join_buffer中的数据做对比，满足join条件的，作为结果集的一部分返回。
        分析：
            1。对表t1和t2都做了一次全表扫描，因此总的扫描行数是1100
            2。对表t2中的每一行，都要做100次判断，总共需要在内存中做的判断次数是：100*1000=10万次。
                原因：join_buffer是以无序数组的方式组织的
        与Simple Nested-Loop Join的查询相比：
            时间复杂度都是10万行，但是一个是磁盘操作，一个内存操作
        优点：
            内存操作，速度上会快很多，性能也更好
        整体时间复杂度：
            1。两个表都做一次全表扫描，所以总的扫描行数是M+N；
            2。存中的判断次数是M*N。
        这时候选择大表还是小表做驱动表，执行耗时是一样的。
    问题一：能不能使用join语句？
        1。如果可以使用Index Nested-Loop Join算法，也就是说可以用上被驱动表上的索引，其实是没问题的；
        2。如果使用Block Nested-Loop Join算法，扫描行数就会过多。
            尤其是在大表上的join操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种join尽量不要用。
        判断方法：
            看explain结果里面，Extra字段里面有没有出现“Block Nested Loop”字样。
    第二个问题是：如果要使用join，应该选择大表做驱动表还是选择小表做驱动表？
    1。如果是Index Nested-Loop Join算法，应该选择小表做驱动表；
    2。如果是Block Nested-Loop Join算法：
        1。在join_buffer_size足够大的时候，是一样的；
        2。在join_buffer_size不够大的时候（这种情况更常见），应该选择小表做驱动表。
    什么叫作“小表”。
        例子一：
            select * from t1 straight_join t2 on (t1.b=t2.b) where t2.id<=50;
            select * from t2 straight_join t1 on (t1.b=t2.b) where t2.id<=50;
            分析：
                两条语句的被驱动表都用不上索引
            结论：
                用第二个语句的话，join_buffer只需要放入t2的前50行，显然是更好的
            原因：“t2的前50行”是那个相对小的表
        例子二：
            select t1.b,t2.* from  t1  straight_join t2 on (t1.b=t2.b) where t2.id<=100;
            select t1.b,t2.* from  t2  straight_join t1 on (t1.b=t2.b) where t2.id<=100;
            现象：
                1。表t1 和 t2都是只有100行参加join。
                2。但是，这两条语句每次查询放入join_buffer中的数据是不一样的：
            分析：
                1。表t1只查字段b，因此如果把t1放到join_buffer中，则join_buffer中只需要放入b的值
                2。表t2需要查所有的字段，因此如果把表t2放到join_buffer中的话，就需要放入三个字段id、a和b。
            结论：
                选择表t1作为驱动表
            原因：
                “只需要一列参与join的表t1”是那个相对小的表。
        小表：
            1。决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤
            2。过滤完成之后，计算参与join的各个字段的总数据量，数据量小的那个表，

35 | join语句怎么优化？
    背景：
        1。BNL算法在大表join的时候性能就差多了
        2。比较次数等于两个表参与join的行数的乘积，很消耗CPU资源。
    Multi-Range Read优化
        背景：
            回表：
                概念：
                    1。InnoDB在普通索引a上查到主键id的值后
                    2。再根据一个个主键id的值到主键索引上去查整行数据的过程。
                例子：
                    select * from t1 where a>=1 and a<=100;
                    问题：
                        1。如果随着a的值递增顺序查询的话，id的值就变成随机的
                        2。那么就会出现随机访问，性能相对较差
                        原因：“按行查”这个机制不能改
                    方法：
                        调整查询的顺序，还是能够加速的。
                        背景：
                            1。因为大多数的数据都是按照主键递增顺序插入得到的
                            2。如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。
                    执行流程：
                        1。根据索引a，定位到满足条件的记录，将id值放入read_rnd_buffer中;
                            read_rnd_buffer_size：决定了read_rnd_buffer大小
                            1。这个满了，就会先执行完步骤2和3，
                            2。然后清空read_rnd_buffer。之后继续找索引a的下个记录，并继续循环。
                        2。将read_rnd_buffer中的id进行递增排序；
                        3。排序后的id数组，依次到主键id索引中查记录，并作为结果返回
        开启MRR优化：
            set optimizer_switch="mrr_cost_based=off"
        如何知道查询用了MRR优化：
            explain结果中，我们可以看到Extra字段多了Using MRR，表示的是用上了MRR优化
        场景：
            1。查询语句在索引a上做的是一个范围查询
            2。可以得到足够多的主键id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。
    Batched Key Access
        背景：
            1。其实就是对NLJ算法的优化。
                NLJ算法逻辑：
                    1。从驱动表t1，一行行地取出a的值，再到被驱动表t2去做join。
                    2。对于表t2来说，每次都是匹配一个值。这时，MRR的优势就用不上了
                思路：
                    那怎么才能一次性地多传些值给表t2呢？
                方法：
                    就把表t1的数据取出来一部分，先放到一个临时内存
                    临时内存：就是join_buffer
                        扩展：
                            1。在BNL算法里的作用，是暂存驱动表的数据
                            2。在NLJ算法里并没有用
        概念：
            复用join_buffer到BKA算法
        启用设置：
            set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
            前两个参数的作用是要启用MRR
                原因：BKA算法的优化要依赖于MRR。
        注意：
            1。join_buffer中放入的数据是P1~P100，表示的是只会取查询需要的字段
            2。如果join buffer放不下P1~P100的所有数据，就会把这100行数据分成多段执行上图的流程。

    BNL算法的性能问题
        背景
            1。可能会对被驱动表做多次扫描
            2。Bufffer Pool的LRU算法做了优化
                1。第一次从磁盘读入内存的数据页，会先放在old区域
                2。如果1秒之后这个数据页不再被访问了，就不会被移动到LRU链表头部，这样对Buffer Pool的命中率影响就不大。
                正常情况：冷表的数据量小于整个Buffer Pool的3/8，能够完全放入old区域的情况。
                    例子：
                        1。如果一个使用BNL算法的join语句，多次扫描一个冷表
                        2。而且这个语句执行时间超过1秒，就会在再次扫描冷表的时候，把冷表的数据页移到LRU链表头部。
                特殊情况：超过整个Buffer Pool的3/8
                    例子：如果这个冷表很大
                    问题：
                        业务正常访问的数据页，没有机会进入young区域。
                    原因：
                        1。一个正常访问的数据页，要进入young区域，需要隔1秒后再次被访问到
                        2。但是，由于我们的join语句在循环读磁盘和淘汰内存页，进入old区域的数据页，很可能在1秒之内就被淘汰了
                        3。就会导致这个MySQL实例的Buffer Pool在这段时间内，young区域的数据页没有被合理地淘汰。
                结论：
                    这两种情况都会影响Buffer Pool的正常运作
                注意：
                    1。大表join操作虽然对IO有影响，但是在语句执行结束后，对IO的影响也就结束了
                    2。但是，对Buffer Pool的影响就是持续性的，需要依靠后续的查询请求慢慢恢复内存命中率。
                方法：
                    减少这种影响，考虑增大join_buffer_size的值，减少对被驱动表的扫描次数
        BNL算法对系统的影响主要包括三个方面：
            1。能会多次扫描被驱动表，占用磁盘IO资源；
            2。判断join条件需要执行M*N次对比（M、N分别是两张表的行数），如果是大表就会占用非常多的CPU资源；
            3。可能会导致Buffer Pool的热数据被淘汰，影响内存命中率。
            现象：
                1。通过理论分析和查看explain结果的方式，确认是否要使用BNL算法。
                2。如果确认优化器会使用BNL算法，就需要做优化
            方法：
                给被驱动表的join字段加上索引，把BNL算法转成BKA算法。

    BNL转BKA
        一些情况下：
            可以直接在被驱动表上建索引，这时就可以直接转成BKA算法了。
        不适合加索引的情况：
        例子：
            select * from t1 join t2 on (t1.b=t2.b) where t2.b>=1 and t2.b<=2000;
            原因：
                1。t2表的数据有200万条数据
                2。如果这条语句同时是一个低频的SQL语句
            加索引的缺点：
                在表t2的字段b上创建一个索引就很浪费了。
            执行流程：
                1。把表t1的所有字段取出来，存入join_buffer中。这个表只有1000行，join_buffer_size默认值是256k，可以完全存入
                2。扫描表t2，取出每一行数据跟join_buffer中的数据进行对比，
                    1。如果不满足t1.b=t2.b，则跳过；
                    2。如果满足t1.b=t2.b, 再判断其他条件，也就是是否满足t2.b处于[1,2000]的条件，如果是，就作为结果集的一部分返回，否则跳过。
                        因此判断等值条件的次数是1000*100万=10亿次，这个判断的工作量很大。
            问题
                t2创建索引的问题：创建索引会浪费资源
                不创建索引的问题：不创建索引的话这个语句的等值条件要判断10亿次，想想也是浪费
            方法：考虑使用临时表，大致思路
                1。把表t2中满足条件的数据放在临时表tmp_t中；
                2。为了让join使用BKA算法，给临时表tmp_t的字段b加上索引；
                3。让表t1和tmp_t做join操作。
                对应的sql语句：
                    create temporary table temp_t(id int primary key, a int, b int, index(b))engine=innodb;
                    insert into temp_t select * from t2 where b>=1 and b<=2000;
                    select * from t1 join temp_t on (t1.b=temp_t.b);
                    这个过程的消耗：
                        1。执行insert语句构造temp_t表并插入数据的过程中，对表t2做了全表扫描，这里扫描行数是100万。
                        2。之后的join语句，扫描表t1，这里的扫描行数是1000
                        3。join比较过程中，做了1000次带索引的查询
            优点：
                相比于优化前的join语句需要做10亿次条件判断来说，这个优化效果还是很明显的。
            注意：
                1。不论是在原表上加索引，还是用有索引的临时表
                2。我们的思路都是让join语句能够用上被驱动表上的索引，来触发BKA算法，提升查询性能。

    扩展-hash join
        现象：其实上面计算10亿次那个操作，看上去有点儿傻。
        假设：
            1。如果join_buffer里面维护的不是一个无序数组，而是一个哈希表的话，那么就不是10亿次判断，
            2。而是100万次hash查找。这样的话，整条语句的执行速度就快多了吧？
        mysql并没有支持哈希join
        业务代码实现
            1。select * from t1;取得表t1的全部1000行数据
            2。在业务端存入一个hash结构，比如C++里的set、PHP的dict这样的数据结构。
            3。select * from t2 where b>=1 and b<=2000; 获取表t2中满足条件的2000行数据
            4。这2000行数据，一行一行地取到业务端，到hash结构的数据表中寻找匹配的数据。满足匹配的条件的这行数据，就作为结果集的一行。

36 | 为什么临时表可以重名？
    内存表：
        概念：
            1。指的是使用Memory引擎的表，
            2。建表语法是create table … engine=memory。
        特点：
            1。这种表的数据都保存在内存里
            2。系统重启的时候会被清空，但是表结构还在
    临时表：
        概念：
            1。可以使用各种引擎类型
            2。如果是使用InnoDB引擎或者MyISAM引擎的临时表，写数据的时候是写到磁盘上
            3。当然，临时表也可以使用Memory引擎。
        特点：
            1。建表语法是create temporary table …。
            2。一个临时表只能被创建它的session访问，对其他线程不可见
                session结束的时候，会自动删除临时表
            3。临时表可以与普通表同名。
            4。session A内有同名的临时表和普通表的时候，show create语句，以及增删改查语句访问的是临时表。
            5。show tables命令不显示临时表。
        优点：
            1。不同session的临时表是可以重名的，如果有多个session同时执行join优化，不需要担心表名重复导致建表失败的问题。
            2。不需要担心数据删除问题
                原因：
                    1。如果使用普通表，在流程执行过程中客户端发生了异常断开，或者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。
                    2。而临时表由于会自动回收，所以不需要这个额外的操作。
    临时表的应用
        场景一：分库分表系统的跨库查询
            分库分表：
                概念：
                    把一个逻辑上的大表分散到不同的数据库实例上
                例子：
                    1。将一个大表ht，按照字段f，拆分成1024个分表
                    2。然后分布到32个数据库实例上。
                连接数据库方案：
                    1。中间层proxy：mycat
                    2。让客户端直接连接数据库，也就是没有proxy这一层。：sharde_jdbc
                分区key的选择依据：
                    减少跨库和跨表查询
            情况一：大部分的语句都会用分区键作为等值查询
                例子：
                    select v from ht where f=N;
                        1。大部分的语句都会包含f的等值条件，那么就要用f做分区键
                        2。在proxy这一层解析完SQL语句以后，就能确定将这条语句路由到哪个分表做查询。
            情况二：查询条件里面没有用到分区字段
                例子：
                    select v from ht where k >= M order by t_modified desc limit 100;
                        1。只能到所有的分区中去查找满足条件的所有行
                        2。然后统一做order by 的操作。
                    思路一：在proxy层的进程代码中实现排序。
                        优势一：
                            1。处理速度快，
                            2。拿到分库的数据以后，直接在内存中参与计算
                        缺点：
                            1。需要的开发工作量比较大
                                例子：涉及到复杂的操作，比如group by，甚至join这样的操作，对中间层的开发能力要求比较高；
                            2。对proxy端的压力比较大，尤其是很容易出现内存不够用和CPU瓶颈的问题。
                    思路二：把各个分库拿到的数据，汇总到一个MySQL实例的一个表中，然后在这个汇总实例上做逻辑操作。
                        流程：
                            1。在汇总库上创建一个临时表temp_ht，表里包含三个字段v、k、t_modified；
                            2。在各个分库上执行
                                select v,k,t_modified from ht_x where k >= M order by t_modified desc limit 100;
                            3。把分库执行的结果插入到temp_ht表中
                            4。执行
                                select v from temp_ht order by t_modified desc limit 100; 
                        注意：
                            我们往往会发现每个分库的计算量都不饱和，所以会直接把临时表temp_ht放到32个分库中的某一个上。

    为什么临时表可以重名？
        例子：
            create temporary table temp_t(id int primary key)engine=innodb;
        物理结构上
            表结构定义的存储：
                1。创建一个frm文件保存表结构定义
                2。这个frm文件放在临时文件目录下，文件名的后缀是.frm
                3。前缀是“#sql{进程id}_{线程id}_序列号”。
                查看方式：
                    使用select @@tmpdir命令，来显示实例的临时文件目录
            数据的存储方式：
                mysql5.6之前：
                    在临时文件目录下创建一个相同前缀、以.ibd为后缀的文件，用来存放数据文件；
                mysql5.7版本开始
                    引入了一个临时文件表空间，专门用来存放临时文件的数据。因此，我们就不需要再创建ibd文件了。
        内存结构上：
            概念：每个表都对应一个table_def_key。
            普通表：table_def_key的值是由“库名+表名”得到的
                注意：要在同一个库下创建两个同名的普通表，创建第二个表的过程中就会发现table_def_key已经存在了。
            临时表：table_def_key在“库名+表名”基础上，又加入了“server_id+thread_id”。
                session A和sessionB创建的两个临时表t1，它们的table_def_key不同，磁盘文件名也不同，因此可以并存。
        实现上：
            1。每个线程都维护了自己的临时表链表
            2。这样每次session内操作表的时候，先遍历链表，检查是否有这个名字的临时表
            3。如果有就优先操作临时表，如果没有再操作普通表；
            4。在session结束的时候，对链表里的每个临时表，执行 “DROP TEMPORARY TABLE +表名”操作。
        问题：
            binlog中也记录了DROP TEMPORARY TABLE这条命令，临时表只在线程内自己可以访问，为什么需要写到binlog里面？
    临时表和主备复制
        在主库上执行下面这个语句序列：
            create table t_normal(id int primary key, c int)engine=innodb;/*Q1*/
            create temporary table temp_t like t_normal;/*Q2*/
            insert into temp_t values(1,1);/*Q3*/
            insert into t_normal select * from temp_t;/*Q4*/
            如果关于临时表的操作都不记录
                1。在备库就只有create table t_normal表和insert into t_normal select * from temp_t这两个语句的binlog日志
                2。备库在执行到insert into t_normal的时候，就会报错“表temp_t不存在”。
            情况一：
                把binlog设置为row格式就好了，这是就不会传入临时表的记录，直接记录的是操作的数据
            情况二：
                binlog_format=statment/mixed 
                    1。创建临时表的语句会传到备库执行，因此备库的同步线程就会创建这个临时表
                    2。主库在线程退出的时候，会自动删除临时表，但是备库同步线程是持续在运行的
                    3。这时候我们就需要在主库上再写一个DROP TEMPORARY TABLE传给备库执行。

            问题一：
                1。MySQL在记录binlog的时候，不论是create table还是alter table语句，都是原样记录，甚至于连空格都不变
                2。但是如果执行drop table t_normal，系统记录binlog就会写成：
                    DROP TABLE `t_normal` /* generated by server */
                原因：
                    1。drop table命令是可以一次删除多个表的。
                    例子：
                        1。比如，在上面的例子中，设置binlog_format=row
                        2。如果主库上执行 "drop table t_normal, temp_t"这个命令，那么binlog中就只能记录：
                            DROP TABLE `t_normal` /* generated by server */
                        原因：
                            备库上并没有表temp_t，将这个命令重写后再传到备库执行，才不会导致备库同步线程停止
            问题二：
                主库上不同的线程创建同名的临时表是没关系的，但是传到备库执行是怎么处理的呢？
                例子：
                    主库M上的两个session创建了同名的临时表t1，这两个create temporary table t1 语句都会被传到备库S上。
                    猜测：
                        这会不会导致同步线程报错 ？
                            原因：
                                备库的应用日志线程是共用的，也就是说要在应用线程里面先后执行这个create 语句两次。
                具体实现
                    MySQL在记录binlog的时候，会把主库执行这个语句的线程id写到binlog中
                流程：
                    1。session A的临时表t1，在备库的table_def_key就是：库名+t1+“M的serverid”+“session A的thread_id”
                    2。session B的临时表t1，在备库的table_def_key就是 ：库名+t1+“M的serverid”+“session B的thread_id”。

37 | 什么时候会使用内部临时表？
    背景：
    sort buffer、内存临时表和join buffer，
        作用：
            用来存放语句执行过程中的中间数据，以辅助SQL语句的执行的。
        sort buffer：排序的时候用到了
        join buffer：使用join语句的时候
    内部临时表：
        create table t1(id int primary key, a int, b int, index(a));
        例子一：union 执行流程
            (select 1000 as f) union (select id from t1 order by id desc limit 2);
                explain的结果：
                    1。第二行的key=PRIMARY，说明第二个子句用到了索引id。
                    2。第三行的Extra字段，表示在对子查询的结果集做union的时候，使用了临时表(Using temporary)。
            语句的执行流程是：
                1。创建一个内存临时表，这个临时表只有一个整型字段f，并且f是主键字段。
                2。执行第一个子查询，得到1000这个值，并存入临时表中。
                3。执行第二个子查询：
                    1。拿到第一行id=1000，试图插入临时表中。但由于1000这个值已经存在于临时表了，违反了唯一性约束，所以插入失败，然后继续执行；
                    2。取到第二行id=999，插入临时表成功。
                4。从临时表中按行取出数据，返回结果，并删除临时表，结果中包含两行数据分别是1000和999。
            分析：
                1。内存临时表起到了暂存数据的作用
                2。计算过程还用上了临时表主键id的唯一性约束，实现了union的语义。
            语句变动：
                uinon 变成union all
                过程：
                    1。就没有了“去重”的语义
                    2。依次执行子查询，得到的结果直接作为结果集的一部分，发给客户端
                结果：
                    1。此也就不需要临时表了。
                    2。Extra字段显示的是Using index，表示只使用了覆盖索引，没有用临时表了
    例子二：group by 执行流程
        select id%10 as m, count(*) as c from t1 group by m;
            explain显示的结果：在Extra字段里面，我们可以看到三个信息：
                1。Using index，表示这个语句使用了覆盖索引，选择了索引a，不需要回表；
                2。Using temporary，表示使用了临时表；
                3。Using filesort，表示需要排序。
                    如果需求中没有要排序：
                    方法：在SQL语句末尾增加order by null
                        select id%10 as m, count(*) as c from t1 group by m order by null;
                        就跳过了最后排序的阶段，直接从临时表中取数据返回
                语句的执行流程：
                    1。创建内存临时表，表里有两个字段m和c，主键是m；
                    2。创建内存临时表，表里有两个字段m和c，主键是m；
                        1。如果临时表中没有主键为x的行，就插入一个记录(x,1);
                        2。如果表中有主键为x的行，就将x这一行的c值加1；
                    3。遍历完成后，再根据字段m做排序，得到结果集返回给客户端。
                分析：
                    1。这个例子里由于临时表只有10行，内存可以放得下，因此全程只使用了内存临时表。
                    2。内存临时表的大小是有限制的，参数tmp_table_size就是控制这个内存大小的，默认是16M。
        修改配置和修改语句：
            set tmp_table_size=1024;
            select id%100 as m, count(*) as c from t1 group by m order by null limit 10;
            结果：
                1。返回结果有100行数据，内存临时表不够存下这100行数据
                2。这时候就会把内存临时表转成磁盘临时表，默认使用引擎是InnoDB
            缺点：
                如果这个表t1的数据量很大，很可能这个查询需要的磁盘临时表就会占用大量的磁盘空间。
        group by 优化方法 --索引
            背景：
                1。不论是使用内存临时表还是磁盘临时表，group by逻辑都需要构造一个带唯一索引的表，执行代价都是比较高的
            问题一：执行group by语句为什么需要临时表？
                原因：
                    1。group by的语义逻辑，是统计不同的值出现的个数
                    2。由于每一行的id%100的结果是无序的，所以我们就需要有一个临时表，来记录并统计结果。
                思路：
                    保证扫描过程中是有序的，就不用使用临时表来统计啦
                    假设输入的数据是有序的，
                        1。那么计算group by的时候，就只需要从左到右，顺序扫描，依次累加
                        过程：
                            1。当碰到第一个1的时候，已经知道累积了X个0，结果集里的第一行就是(0,X);
                            2。当碰到第一个2的时候，已经知道累积了Y个1，结果集里的第一行就是(1,Y);
                方法：增加列，并创建索引
                    原因：InnoDB的索引，就可以满足这个输入有序的条件。
                    alter table t1 add column z int generated always as(id % 100), add index(z);
                    group by语句需要改成：
                        select z, count(*) as c from t1 group by z;
        group by优化方法 --直接排序
            背景：磁盘临时表是B+树存储，存储效率不如数组来得高
            前提：不合适增加索引的情况
            数据量大的情况的一般逻辑：
                1。一个group by语句中需要放到临时表上的数据量特别大
                2。插入一部分数据后，发现内存临时表不够用了再转成磁盘临时表”
            优化：直接走磁盘临时表
            实现：
                在group by语句中加入SQL_BIG_RESULT这个提示（hint）
                    SQL_BIG_RESULT作用：
                            可以告诉优化器：这个语句涉及的数据量很大，请直接用磁盘临时表。
                例子：
                    select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;
                    执行流程：
                        1。初始化sort_buffer，确定放入一个整型字段，记为m；
                        2。扫描表t1的索引a，依次取出里面的id值, 将 id%100的值存入sort_buffer中；
                        3。扫描完成后，对sort_buffer的字段m做排序（如果sort_buffer内存不够用，就会利用磁盘临时文件辅助排序）；
                        4。排序完成后，就得到了一个有序数组。

    基于上面的union、union all和group by语句的执行过程的分析，我们来回答文章开头的问题：
        问题：MySQL什么时候会使用内部临时表？
            1。如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果；
            2。join_buffer是无序数组，sort_buffer是有序数组，临时表是二维表结构；
            3。如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表
                例子：
                    1。union需要用到唯一索引约束
                    2。group by还需要用到另外一个字段来存累积计数。

38 | 都说InnoDB好，那还要不要使用Memory引擎？
    问题：
        两个group by 语句都用了order by null，
            1。内存临时表，得到的结果0这个值在最后一行
            2。磁盘临时表，得到的结果0这个第一行
        例子一：t1：Memory
            建表语句：
                create table t1(id int primary key, c int) engine=Memory;
                insert into t1 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);
            执行语句：
                    select * from t1;
            结论：
                返回结果里面0在最后一行
            原因：（跟插入的顺序有关系）
                走的是全表扫描，也就是顺序扫描这个数组，0就是最后一个被读到，并放入结果集的数据

        例子二： t2：InnoDB
            建表语句
                create table t2(id int primary key, c int) engine=innodb;
                insert into t2 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);
            执行：
                select * from t2。
            结论：返回结果里0在第一行
        原因：
            主键索引上的值是有序存储的，会按照叶子节点从左到右扫描
        区别的原因：
            要从这两个引擎的主键索引的组织方式说起
    内存表的数据组织结构
    InnoDB引擎：
        概念：
            1。数据就放在主键索引树上，主键索引是B+树。
            2。主键索引上的值是有序存储的
            3在执行select *的时候，就会按照叶子节点从左到右扫描，所以得到的结果里，0就出现在第一行。
        数据组织方式：索引组织表（Index Organizied Table）
            概念：
                把数据放在主键索引上，其他索引上保存的是主键id
        特点：
            1。InnoDB表的数据总是有序存放
            2。数据文件有空洞，插入保证有序行
            3。删除数据，InnoDB表只需要修改主键索引
            4。InnoDB主键索引查询需要走一次，普通索引查询需要两次查找
            5。InnoDB支持可变长类型，不同记录的长度可能不同
    Memory引擎：
        概念：
            1。数据和索引是分开的
            2。数据部分以数组的方式单独存放
            3。主键id索引里，存的是每个数据的位置
            4。主键id是hash索引，可以看到索引上的key并不是有序的
        现象：
            1。当我执行select *的时候，走的是全表扫描，也就是顺序扫描这个数组（即插入的顺序）
            2。因此，0就是最后一个被读到，并放入结果集的数据。
        数据组织方式：堆组织表（Heap Organizied Table）
            概念：
                采用的是把数据单独存放，索引上保存数据位置的数据组织形式
        特点：
            1。内存表的数据就是按照写入顺序存放
            2。找到空位就可以插入新值
            3。内存表需要修改所有索引
            4。索引查询是，所有索引的“地位”都是相同的。
            5。每行数据长度相同，不支持变长字段Blob 和 Text字段
            基于这些特性
                现象一：
                    1。每个数据行被删除以后，空出的这个位置都可以被接下来要插入的数据复用。
                        例子：
                            delete from t1 where id=5;
                            insert into t1 values(10,10);
                            select * from t1;
                            执行过程
                                就会看到返回结果里，id=10这一行出现在id=4之后，也就是原来id=5这行数据的位置。
                现象二：
                    表t1的这个主键索引是哈希索引，因此如果执行范围查询
                    例子：
                        select * from t1 where id<5;
                        执行过程：
                            用不上主键索引的，需要走全表扫描
                    问题：
                        如果要让内存表支持范围扫描，应该怎么办呢 ？
                    方法：
                        hash索引和B-Tree索引
                        背景：
                            内存表也是支B-Tree索引的
                        具体实现：在id列上创建一个B-Tree索引
                            alter table t1 add index a_btree_index using btree (id);
                            证明：
                                select * from t1 where id<5;
                                    现象：
                                        优化器会选择B-Tree索引，所以返回结果是0到4
                                select * from t1 force index(primary) where id<5;
                                    现象：
                                        使用force index强行使用主键id这个索引，id=0这一行就在结果集的最末尾了。
        优点：
            速度快
                原因：
                    1。Memory引擎支持hash索引
                    2。内存表的所有数据都保存在内存，而内存的读写速度总是比磁盘快。
    生产不建议使用内存表，原因：
        1。锁粒度问题
            概念：
                不支持行锁，只支持表锁
                缺点：
                    一张表只要有更新，就会堵住其他所有在这个表上的读写操作。
            例子：
                sessionA：update set id=sleep(50) where id=1;
                sessionB:select * from t1 where id=2;(wait 50秒)
                sessionC：show prrocesslist;
                问题：
                    1.跟行锁比起来，表锁对并发访问的支持不够好
                    2.内存表的锁粒度问题，决定了它在处理并发事务的时候，性能也不会太好。
        2。数据持久化问题。
            问题：
                1。数据库重启的时候，所有的内存表都会被清空。
                2。高可用架构下，内存表的这个特点简直可以当做bug来看待了
            例子：看看M-S架构下，使用内存表存在的问题
                1。业务正常访问主库
                2。备库硬件升级，备库重启，内存表t1内容被清空；
                3。备库重启后，客户端发送一条update语句，修改表t1的数据行，这时备库应用线程就会报错“找不到要更新的行”。
                后果：
                    主备同步停止。当然，如果这时候发生主备切换的话，客户端会看到，表t1的数据“丢失”了。
                诡异现象：
                    1。由于MySQL知道重启之后，内存表的数据会丢失。
                    2。在数据库重启之后，往binlog里面写入一行DELETE FROM t1。
                        原因：防止主库重启之后，出现主备不一致
                    3。在备库重启的时候，备库binlog里的delete语句就会传到主库
                    4。然后把主库内存表的内容删除。这样你在使用的时候就会发现，主库的内存表数据突然被清空了
        方法：
            普通内存表都用InnoDB表来代替
        注意：
            有一个场景是例外的：
                1。用户临时表：在数据量可控，不会耗费过多内存的情况下，你可以考虑使用内存表。
                2。内存临时表刚好可以无视内存表的两个不足，主要是下面的三个原因：
                    1。临时表不会被其他线程访问，没有并发性的问题；
                    2。临时表重启后也是需要删除的，清空数据这个问题不存在
                    3。备库的临时表也不会影响主库的用户线程。

            例子：join语句优化的例子，当时我建议的是创建一个InnoDB临时表，使用的语句序列是：
                优化前：用的是innodb引擎：
                    create temporary table temp_t(id int primary key, a int, b int, index(b))engine=innodb;
                    insert into temp_t select * from t2 where b>=1 and b<=2000;
                    select * from t1 join temp_t on (t1.b=temp_t.b);
                优化后：

                    create temporary table temp_t(id int primary key, a int, b int, index (b))engine=memory;
                    insert into temp_t select * from t2 where b>=1 and b<=2000;
                    select * from t1 join temp_t on (t1.b=temp_t.b);
                了解了内存表的特性，你就知道了， 其实这里使用内存临时表的效果更好，原因有三个：
                    1。相比于InnoDB表，使用内存表不需要写磁盘，往表temp_t的写数据的速度更快；
                    2。索引b使用hash索引，查找的速度比B-Tree索引快；
                    3。临时表数据只有2000行，占用的内存有限

    两者的区别：
        1。存放数据上：
            InnoDB表的数据总是有序存放；内存表的数据就是按照写入顺序存放
        2。插入逻辑
            前提：数据文件有空洞
                InnoDB表保证有序行，只能在固定的位置写入新值；内存表找到空位就可以插入新值
        3。位置发生变化时
            InnoDB表只需要修改主键索引；内存表需要修改所有索引
        4。索引查询
            InnoDB主键索引查询需要走一次，普通索引查询需要两次查找，内存表没有这个区别，所有索引的“地位”都是相同的。
        5。数据类型
            InnoDB支持可变长类型，不同记录的长度可能不同；内存表不支持Blob 和 Text字段
            并且即使定义了varchar(N)，实际也当作char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。

39 | 自增主键为什么不是连续的？
    自增值：
        概念：
            不同的引擎对于自增值的保存策略不同、
        1。MyISAM：自增值保存在数据文件中。
        2。InnoDB
            1。MySQL 5.7及之前的版本：
                1。自增值保存在内存里，并没有持久化
                2。每次重启后，第一次打开表的时候，都会去找自增值的最大值max(id)
                3。然后将max(id)+1作为这个表当前的自增值。﻿
                例子：
                    1。如果一个表当前数据行里最大的id是10，AUTO_INCREMENT=11。
                    2。这时候，我们删除id=10的行，AUTO_INCREMENT还是11
                    3。如果马上重启实例，重启后这个表的AUTO_INCREMENT就会变成10。
                结论：
                ﻿   MySQL重启可能会修改一个表的AUTO_INCREMENT的值
            2。在MySQL 8.0版本：
                1。将自增值的变更记录在了redo log中
                2。重启的时候依靠redo log恢复重启之前的值。
    自增值修改机制
        背景：
            1。MySQL里面，如果字段id被定义为AUTO_INCREMENT，
            2。在插入一行数据的时候，自增值的行为如下：
        流程：
            1。如果插入数据时id字段指定为0、null 或未指定值，那么就把这个表当前的 AUTO_INCREMENT值填到自增字段
            2。如果插入数据时id字段指定了具体的值，就直接使用语句里指定的值。
                注意：某次要插入的值是X，当前的自增值是Y。（需要比较大小）
                    1。如果X<Y，那么这个表的自增值不变
                    2。如果X≥Y，就需要把当前自增值修改为新的自增值
        新的自增值生成算法：
            概念：
                auto_increment_offset：初始值，默认值是1
                auto_increment_increment：步长，默认值是1
            注意：
                情况一：使用的就不全是默认值。
                    例子：
                        1。双M的主备结构里要求双写的时候，我们就可能会设置成auto_increment_increment=2
                    2。让一个库的自增id都是奇数，另一个库的自增id都是偶数，避免两个库生成的主键发生冲突
                情况二：都是默认值的时候：
                    1。如果准备插入的值>=当前自增值，新的自增值就是“准备插入的值+1”；
                    2。否则，自增值不变。
            过程：
                1。从auto_increment_offset开始
                2。以auto_increment_increment为步长
                3。持续叠加，直到找到第一个大于X的值，作为新的自增值
        自增值的修改时机
        自增主键不连续的原因：
            原因一：唯一键冲突
                例子：表里已经有一条记录
                    insert into t values(null, 1, 1); 
                执行流程：
                    1。执行器调用InnoDB引擎接口写入一行，传入的这一行的值是(0,1,1);
                    2。InnoDB发现用户没有指定自增id的值，获取表t当前的自增值2；
                    3。将传入的行的值改成(2,1,1);
                    4。将表的自增值改成3；
                    5。继续执行插入数据操作，由于已经存在c=1的记录，所以报Duplicate key error，语句返回
                        现象：唯一键发生冲突时，没有把自增值改回去
            原因二：事务回滚也
            原因三：批量插入数据，优化之后的新策略（见下面 情况二：批量插入）
        自增值为什么不能回退
            目的：为了提升性能
            例子：
                1。假设有两个并行执行的事务，在申请自增值的时候
                2。为了避免两个事务申请到相同的自增id，肯定要加锁，然后顺序申请。
            过程：
                1。假设事务A申请到了id=2， 事务B申请到id=3，那么这时候表t的自增值是4，之后继续执行。
                2。事务B正确提交了，但事务A出现了唯一键冲突。
                3。如果允许事务A把自增id回退，也就是把表t的当前自增值改回2，那么就会出现这样的情况：表里面已经有id=3的行，而当前的自增id值是2。
                4。接下来，继续执行的其他事务就会申请到id=2，然后再申请到id=3。这时，就会出现插入语句报错“主键冲突”
                解决主键冲突的两种办法：
                    方法一：
                        过程：
                            1。每次申请id之前，先判断表里面是否已经存在这个id
                            2。如果存在，就跳过这个id。
                        缺点：
                            成本很高
                                原因：
                                    本来申请id是一个很快的操作，现在还要再去主键索引树上判断id是否存在。
                    方法二：
                        过程：
                            1。把自增id的锁范围扩大
                            2。必须等到一个事务执行完成并提交
                            3。下一个事务才能再申请自增id。
                        缺点：
                            锁的粒度太大，系统并发能力大大下降
            问题：
                带来性能问题
            方案：
                InnoDB放弃了这个设计，语句执行失败也不回退自增id
                现象：
                    只保证了自增id是递增的，但不保证是连续的。

        自增锁的优化
            发展：
                MySQL 5.1版本之前：
                    概念：
                        自增锁的范围是语句级别。也就是说，如果一个语句申请了一个表自增锁，这个锁会等语句执行结束以后才释放
                    缺点：
                        影响并发度
                MySQL 5.1.22版本引入了一个新策略：
                概念：
                  新增参数innodb_autoinc_lock_mode，默认值是1
                        innodb_autoinc_lock_mode=0：采用之前MySQL 5.0版本的策略，即语句执行结束后才释放锁；
                        innodb_autoinc_lock_mode=1：默认值
                                1。普通insert语句，自增锁在申请之后就马上释放；
                                2。类似insert … select这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放
                            默认值为什么是1：
                                目的：数据的一致性。
                                原因：主备同步时，binlog_format=statement，会带来主备数据不一致的情况
                                    例子：
                                        1。SessionA往t1中插入了4行数据，
                                        2。SessionB然后创建了一个相同结构的表t2
                                        3。然后两个session同时执行向表t2中插入数据的操作。
                                        可能出现的情况：
                                            1。session B先插入了两个记录，(1,1,1)、(2,2,2)；
                                            2。然后，session A来申请自增id得到id=3，插入了（3,5,5)；
                                            3。之后，session B继续执行，插入两条记录(4,3,3)、 (5,4,4)。
                                            分析：
                                                数据逻辑上是对的，但是如果binlog_format=statement
                                            背景：
                                               1。由于两个session是同时执行插入数据命令的
                                                2。所以binlog里面对表t2的更新日志只有两种情况
                                                3。要么先记session A的，要么先记session B的。
                                            从库恢复过程：
                                                1。但不论是哪一种，这个binlog拿去从库执行，或者用来恢复临时实例，备库和临时实例里面
                                                2。session B这个语句执行出来，生成的结果里面，id都是连续的。
                                            问题：
                                                这时，这个库就发生了数据不一致。
                                                原因：
                                                    1。原库session B的insert语句，生成的id不连续
                                                    2。这个不连续的id，用statement格式的binlog来串行执行，是执行不出来的。
                                                解决思路：
                                                    思路一：
                                                        让原库的批量插入数据语句，固定生成连续的id值。
                                                        目的：自增锁直到语句执行结束才释放
                                                    思路二：
                                                        在binlog里面把插入数据的操作都如实记录进来，到备库执行的时候，不再依赖于自增主键去生成。
                                                        具体实现：nnodb_autoinc_lock_mode设置为2，同时binlog_format设置为row。

                        innodb_autoinc_lock_mode=2：所有的申请自增主键的动作都是申请后就释放锁。

                注意：
                    innodb_autoinc_lock_mode=1
                        情况一：
                            普通的insert语句里面包含多个value值的情况下
                            过程：
                                不会等语句执行完成才释放锁
                            原因：
                                可以精确计算出需要多少个id的，然后一次性申请，申请完成后锁就可以释放了。
                        情况二：insert … select批量插入
                            背景：之所以需要这么设置，是因为“不知道要预先申请多少个id”。
                            过程：
                                1。需要一个时申请一个。但如果一个select … insert语句要插入10万行数据
                                2。按照这个逻辑的话就要申请10万次
                            缺点：
                                这种申请自增id的策略，在大批量插入数据的情况下，不但速度慢，还会影响并发插入的性能。
                            方法：对于批量插入数据的语句，MySQL有一个批量申请自增id的策略：
                                1。语句执行过程中，第一次申请自增id，会分配1个；
                                2。1个用完以后，这个语句第二次申请自增id，会分配2个；
                                3。2个用完以后，还是这个语句，第三次申请自增id，会分配4个；
                                4。依此类推，同一个语句去申请自增id，每次申请到的自增id个数都是上一次的两倍
                            例子：
                                insert into t values(null, 1,1);
                                insert into t values(null, 2,2);
                                insert into t values(null, 3,3);
                                insert into t values(null, 4,4);
                                create table t2 like t;
                                insert into t2(c,d) select c,d from t;
                                insert into t2 values(null, 5,5);
                                分析：
                                    1。insert…select，实际上往表t2中插入了4行数据
                                    2。这四行数据是分三次申请的自增id
                                    3。第一次申请到了id=1
                                    4。第二次被分配了id=2和id=3
                                    5。 第三次被分配到id=4到id=7。
                            现象：
                                主键id出现自增id不连续

40 | insert语句的锁为什么这么多？
    背景：
        1。一般情况下，insert语句是一个很轻量的操作，即普通的sql
        2。特殊情况，在执行过程中需要给其他资源加锁
        3。或者无法在申请id以后立马释放自增锁
    insert … select 语句
        条件：
            1。可重复读隔离级别
            2。binlog_format=statement时执行
        执行语句：
            SessionA
                insert into values();
            SessionB
                insert into t2(c,d)select c,d from t;
        执行过程：
            1。如果session B先执行，由于这个语句对表t主键索引加了(-∞,1]这个next-key lock
            2。会在语句执行完成后，才允许session A的insert语句执行。
        思考：假设没有锁
            可能出现：
                1。session B的insert语句先执行，但是后写入binlog的情况
                2。在binlog_format=statement的情况下，binlog里面就记录了这样的语句序列
                    insert into t values(-1,-1,-1);
                    insert into t2(c,d) select c,d from t;
            问题：
                这个语句到了备库执行，就会把id=-1这一行也写到表t2中，出现主备不一致。
        注意：
            执行insert … select 的时候，对目标表也不是锁全表，而是只锁住需要访问的资源。

    insert 循环写入
        例子一：(3,4]和(4,supremum]这两个next-key lock，
            insert into t2(c,d)  (select c+1, d from t force index(c) order by c desc limit 1);
            分析
                1。加锁范围 ：
                    表t索引c上的(3,4]和(4,supremum]这两个next-key lock，以及主键索引上id=4这一行。
                2。扫描行数为1；
        例子二：锁全表
            insert into t(c,d)  (select c+1, d from t force index(c) order by c desc limit 1);
            分析：
                1。加锁范围，给索引c上的所有间隙都加上共享的next-key lock
                2。扫描行数是5
                explain来查看sql的执行过程：
                    现象：
                        Extra字段可以看到“Using temporary”字样，表示用到了临时表；
                            临时表：执行过程中，需要把表t的内容读出来，写入临时表。
                        使用临时表：
                            原因：
                                1。这类一边遍历数据，一边更新数据的情况
                                2。如果读出来的数据直接写回原表，就可能在遍历过程中，读到刚刚插入的记录
                                3。新插入的记录如果参与计算逻辑，就跟语义不符。
                        优化方法：
                            1。先insert into到临时表temp_t，这样就只需要扫描一行
                            2。然后再从表temp_t里面取出这行数据插入表t1。
                            具体实现：
                                create temporary table temp_t(c int,d int) engine=memory;
                                insert into temp_t  (select c+1, d from t force index(c) order by c desc limit 1);
                                insert into t select * from temp_t;
                                drop table temp_t;
                    猜测流程：
                        1。如果说是把子查询的结果读出来（扫描1行），写入临时表
                        2。然后再从临时表读出来（扫描1行），写回表t中
                        3。那么，这个语句的扫描行数就应该是2，而不是5。
                        猜测不对；
                        证明：
                            show status like '%Innodb_rows_read%'；
                                insert into t(c,d)  (select c+1, d from t force index(c) order by c desc limit 1);
                            show status like '%Innodb_rows_read%'；
                        Innodb_rows_read：查看innodb扫描了多少行；发现了是4行，说明对t表进行了全表扫描
                    正确的执行过程：
                        1。创建临时表，表里有两个字段c和d。
                        2。按照索引c扫描表t，依次取c=4、3、2、1，然后回表，读到c和d的值写入临时表。这时，Rows_examined=4。
                        3。由于语义里面有limit 1，所以只取了临时表的第一行，再插入到表t中。这时，Rows_examined的值加1，变成了5。
    insert 唯一键冲突
        例子一：唯一键冲突会加上next-key lock（读锁
            可重复读（repeatable read）隔离级别下执行的
            sessionA
                insert into t values(10,10,10);
                begin
                insert into t values(11,10,10);
                (Duplicate entry '10' for key 'c')
            sessionB
                insert into t values(12,9,9);blocked
            分析：
                1。session A执行的insert语句，发生唯一键冲突的时候
                2。并不只是简单地报错返回，还在冲突的索引上加了锁
                    背景：一个next-key lock就是由它右边界的值定义的
                    推出：session A持有索引c上的(5,10]共享next-key lock（读锁）。
            注意：主键和唯一键索引冲突都会加入next-key lock
        例子二：死锁：
            1。sessionA
                begin
                insert into t values(null,5,5);
            2。SessionB
                insert into t values(null,5,5);
            3。SessionC
                insert into t values(null,5,5);(DeadLock found)
                在session A执行rollback语句回滚的时候，session C几乎同时发现死锁并返回。
            产生死锁的逻辑：
                1。在T1时刻，启动session A，并执行insert语句，此时在索引c的c=5上加了记录锁
                        注意，这个索引是唯一索引，因此退化为记录锁
                2。T2时刻，session B要执行相同的insert语句，发现了唯一键冲突，加上读锁
                    同样地，session C也在索引c上，c=5这一个记录上，加了读锁。
                3。T3时刻，session A回滚。
                    这时候，session B和session C都试图继续执行插入操作，都要加上写锁；
                    两个session都要等待对方的行锁，所以就出现了死锁。
            原因：
                主键冲突后直接报错
            方法：
                insert into … on duplicate key update
                语义：
                    插入一行数据，如果碰到唯一键约束，就执行后面的更新语句。
                    注意：
                        如果有多个列违反了唯一性约束，就会按照索引的顺序，修改跟第一个索引冲突的行。
                        例子：
                            1。现在表t里面已经有了(1,1,1)和(2,2,2)这两行，
                                执行语句
                                    insert into t values(2,1,10) on duplicate key update d=100; 
                                        过程：主键id是先判断的，MySQL认为这个语句跟id=2这一行冲突，所以修改的是id=2的行
                                            执行这条语句的affected rows返回的是2，insert和update都认为自己成功了，update计数加了1， insert计数也加了1。
                    具体实现
                        insert into t values(11,10,10) on duplicate key update d=100; 

41 | 怎么最快地复制一张表？
    背景：
        1。如果可以控制对源表的扫描行数和加锁范围很小的话，我们简单地使用insert … select 语句即可实现
        2。为了避免对源表加读锁，更稳妥的方案是先将数据写到外部文本文件，然后再写回目标表
    mysqldump方法
        注意：生成临时文件在客户端
        导出命令
            mysqldump -h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction  --set-gtid-purged=OFF db1 t --where="a>900" --result-file=/client_tmp/t.sql
            把结果输出到临时文件
            参数的含义：
                1。–single-transaction作用：
                        1。在导出数据的时候不需要对表db1.t加表锁
                        2。而是使用START TRANSACTION WITH CONSISTENT SNAPSHOT的方法；
                2。–add-locks设置为0，表示在输出的文件结果里，不增加" LOCK TABLES t WRITE;" ；
                3。–no-create-info的意思是，不需要导出表结构；
                4。–set-gtid-purged=off表示的是，不输出跟GTID相关的信息；
                5。–result-file指定了输出文件的路径，其中client表示生成的文件是在客户端机器上的。
            生成的临时文件：
                一条INSERT语句里面会包含多个value对，
                    目的：写入数据的时候，执行速度可以更快
                –skip-extended-insert：一条INSERT语句只插入一行数据
        导入命令：
            mysql -h127.0.0.1 -P13000  -uroot db2 -e "source /client_tmp/t.sql"
            说明：source并不是一条SQL语句，而是一个客户端命令
                流程：
                    1。打开文件，默认以分号为结尾读取一条条的SQL语句；
                    2。将SQL语句发送到服务端执行。
    导出CSV文件
        注意：生成的文件在服务端
        导出命令：
            select * from db1.t where a>900 into outfile '/server_tmp/t.csv';
            注意：
                1。这条语句会将结果保存在服务端，不过在客户端执行，临时目录下是不会生成t.csv文件的。
                2。into outfile指定了文件的生成位置（/server_tmp/）这个位置必须受参数secure_file_priv的限制。
                    secure_file_priv的作用：
                        1。为empty时，表示不限制文件生成的位置，这是不安全的设置；
                        2。字符串的路径时，就要求生成的文件只能放在这个指定的目录，或者它的子目录；
                        3。null时，表示禁止在这个MySQL实例上执行select … into outfile 操作。
                3。不会覆盖文件，如果路径下存在相同的文件，会报错
                4。条命令生成的文本文件中，原则上一个数据行对应文本文件的一行。
                    但是，如果字段中包含换行符，在生成的文本中也会有换行符。不过类似换行符、
                    制表符这类符号，前面都会跟上“\”这个转义符，这样就可以跟字段之间、数据行之间的分隔符区分开。
        导入命令：
            load data infile '/server_tmp/t.csv' into table db2.t;
            执行过程：
                1。开文件/server_tmp/t.csv，以制表符(\t)作为字段间的分隔符，以换行符（\n）作为记录之间的分隔符，进行数据读取；
                2。启动事务。
                3。判断每一行的字段数与表db2.t是否相同：
                    若不相同，则直接报错，事务回滚；
                    若相同，则构造成一行，调用InnoDB引擎接口，写入到表中。
                4。重复步骤3，直到/server_tmp/t.csv整个文件读入完成，提交事务。
            问题：
                如果binlog_format=statement，这个load语句记录到binlog里以后，怎么在备库重放呢？
                因为备库是没有这个目录的，可能会导致的主备同步停止；
                这条语句的的完整流程：
                    1。主库执行完成后，将/server_tmp/t.csv文件的内容直接写到binlog文件中。
                    2。往binlog文件中写入语句load data local infile ‘/tmp/SQL_LOAD_MB-1-0’ INTO TABLE `db2`.`t`。
                        多了一个local：
                            将执行这条命令的客户端所在机器的本地文件/tmp/SQL_LOAD_MB-1-0的内容，加载到目标表db2.t中”
                    3。把这个binlog日志传到备库。
                    4。库的apply线程在执行这个事务日志时：
                        a.先将binlog中t.csv文件的内容读出来，写入到本地临时目录/tmp/SQL_LOAD_MB-1-0 中；
                        b.再执行load data语句，往备库的db2.t表中插入跟主库相同的数据。
        load data命令有两种用法：
            1。加“local”，是读取服务端的文件，这个文件必须在secure_file_priv指定的目录或子目录
            2。加上“local”，读取的是客户端的文件，只要mysql客户端有访问这个文件的权限即可。这时候，MySQL客户端会先把本地文件传给服务端，然后执行上述的load data流程。
        注意：
            1。select …into outfile方法不会生成表结构文件,
            2。mysqldump提供了一个–tab参数，
                mysqldump -h$host -P$port -u$user ---single-transaction  --set-gtid-purged=OFF db1 t --where="a>900" --tab=$secure_file_priv
                这条命令会在$secure_file_priv定义的目录下，创建一个t.sql文件保存建表语句，同时创建一个t.txt文件保存CSV数据。
    物理拷贝方法：
        猜测：
            直接把db1.t表的.frm文件和.ibd文件拷贝到db2目录下，是否可行呢？
        答案：
            不行
        原因：
            1。一个InnoDB表，除了包含这两个物理文件外，还需要在数据字典中注册。
            2。直接拷贝这两个文件的话，因为数据字典中没有db2.t这个表，系统是不会识别和接受它们的。
        注意：在MySQL 5.6版本引入了可传输表空间(transportable tablespace)的方法，
