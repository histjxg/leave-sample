00开篇词 | 为什么你要学习高并发系统设计？
    背景：
        每家公司所处的行业不同，业务场景不同，但是设计和优化的思想却是万变不离其宗。
        知识体系的套路：
            1。理论知识的讲解
            2。问题场景的介绍
            3。问题分析的过程
            4。以及解决问题的思路
        作用：
            能明确地知道，系统处于某一个阶段时，可能会面临的问题
        方案：
            及时找到架构升级优化的思路解决这些问题，提升系统性能。

    为什么要学习高并发系统设计？
        问题一：
            在微博中，明星动辄拥有几千万甚至上亿的粉丝，你要怎么保证明星发布的内容让粉丝实时地看到呢？
        问题二：
            淘宝双十一，当你和上万人一起抢购一件性价比超高的衣服时，怎么保证衣服不会超卖？
        问题三：
            1。春运时我们都会去 12306 订购火车票，以前在抢票时经常遇到页面打不开的情况
            2。那么如果你来设计 12306 系统，要如何保证在千万人访问的同时也能支持正常抢票呢？
        思考：
            这些问题是你在设计和实现高并发系统时经常会遇到的痛点问题，都涉及如何在高并发场景下做到高性能和高可用，
        作用：
            掌握这些内容，你开发的产品可以为用户提供更好的使用体验，你的技术能力也能有一个质的变化。

    1。高并发系统设计知识，是你获取大厂 Offer 必不可少的利器

    2。不要囿于公司现有的业务场景，你的能力，绝不止于此
        案例一：
            电商系统中的下单流程设计技术方案为例。
                流程：
                    1。在每秒只有一次调用的系统中，你只需要关注业务逻辑本身就好了
                    1。查询库存是否充足，如果充足，就可以到数据库中生成订单
                    2。成功后锁定库存，然后进入支付流程。
                场景：
                    如果要做一次秒杀的活动，配合一些运营的推广，你会发现下单操作的调用量可能达到每秒 10000 次！
                    问题一：
                        10000 次请求同时查询库存，是否会把库存系统拖垮？
                    问题二：
                        如果请求全部通过，那么就要同时生成 10000 次订单，数据库能否抗住？
                    问题三：
                        如果抗不住，我们要如何做？
                    思考：
                        这些问题都可能出现，并让之前的方案不再适用，此时你就需要设计新的方案。
        案例二：
            缓存的使用，在低并发下你只需要了解基本的使用方式
            高并发下的问题：
                问题一：
                    要关注缓存命中率，如何应对缓存穿透
                问题二：
                    如何避免雪崩
                问题三：
                    如何解决缓存一致性等问题
                    思考：
                        这就增加了设计方案的复杂度，对设计者能力的要求也会更高
                    做法：
                        必要提前储备足够多的高并发知识，从而具备随时应对可能出现的高并发需求场景的能力。
        注意：
            解决产品问题不应该是你最终的目标，提升技术能力和技术视野才应是你始终不变的追求。
    3。计算机领域里虽然知识点庞杂，但很多核心思想都是相通的
        例子一：
            消息队列
                概念：
                    是高并发系统中常见的一种组件
                作用：
                    可以将消息生产方和消费方解耦，减少突发流量对于系统的冲击
                    问题：
                        但如果你的系统没有那么高的流量，你就永远不会使用消息队列了吗？
                    回答
                        当然不是
                    原因：
                        1。系统模块要做到高内聚、低解耦，这是系统的基本设计思想，和是否高并发无关
                        2。消息队列作为主要的系统解耦方式，应该是你技术百宝囊中一件不可或缺的制胜法宝。
        例子二：
            缓存技术：
                目的：
                    蕴含的是空间换时间的思想
        例子三：
            压缩体现
                目的：
                    时间换空间的思想；
        例子四
            分布式思想
                思考
                    体现在 CPU 的设计和实现上…
    课程的方式：
        1。决定以一个虚拟的系统为主线，讲解在流量和并发不断提升的情况下如何一步步地优化它
        2。并在这个过程中穿插着讲解知识点，这样通过场景、原理、实践相结合的方式，来帮助你更快、更深入地理解和消化
    收获：
        1。掌握高并发系统设计的“套路”；
        2。理解基本的系统设计思想，对新的知识触类旁通，举一反三；
        3。突破技术的瓶颈，突破所处平台的限制，具备一个优秀架构师的资质。

01 | 高并发系统：它的通用设计方法是什么？
    面对高并发下采用高的三种方案：
        方案一：
            Scale-up（纵向扩展）
                概念：
                    类似追逐摩尔定律不断提升 CPU 性能的方案
                实现方式：
                    通过购买性能更好的硬件来提升系统的并发处理能力
                    例子：
                        说目前系统 4 核 4G 每秒可以处理 200 次请求
                        问题：
                            那么如果要处理 400 次请求呢？
                        方法：
                            我们把机器的硬件提升到 8 核 8G（硬件资源的提升可能不是线性的，这里仅为参考）。
                问题：
                    什么时候选择 Scale-up
                    回答：
                        系统设计初期会考虑使用 Scale-up 的方式
                        原因：
                            这种方案足够简单，所谓能用堆砌硬件解决的问题就用硬件来解决
            Scale-out：
                概念：
                    类似 CPU 多核心的方案
                原理：
                    把流量分流开，让每个服务器都承担一部分并发和流量。
                实现方式：
                    通过将多个低性能的机器组成一个分布式集群来共同抵御高并发流量的冲击
                    例子：
                        沿用刚刚的例子，我们可以使用两台 4 核 4G 的机器来处理那 400 次请求。
                问题：
                    什么时候选择 Scale-out 呢？
                    回答：
                        当系统并发超过了单机的极限时
                        新的问题：
                            1。某个节点出现故障如何保证整体可用性？
                            2。当多个节点有状态需要同步时，如何保证状态信息在不同节点的一致性？
                            3。如何做到使用方无感知的增加和删除节点？等等
                应用：
                    1。数据库一主多从
                    2。分库分表
                    3。存储分片

        方案二：
            缓存
                目的：
                    使用缓存来提高系统的性能
                类似：
                    用“拓宽河道”的方式抵抗高并发大流量的冲击
                概念：
                    将任何降低响应时间的中间存储都称为缓存
                    应用：
                        1。在操作系统中 CPU 有多级缓存
                        2。文件有 Page Cache 缓存

        方案三：
            异步
                过程：
                    1。在某些场景下，未处理完成之前，我们可以让请求先返回
                    2。在数据准备好之后再通知请求方，这样可以在单位时间内处理更多的请求。
            方法调用区分：
                同步调用：
                    概念：
                        调用方要阻塞等待被调用方法中的逻辑执行完成
                    缺点：
                        当被调用方法响应时间较长时，会造成调用方长久的阻塞，在高并发下会造成整体系统性能下降甚至发生雪崩。
                异步调用：
                    概念：
                        1。调用方不需要等待方法逻辑执行完成就可以返回执行其他的逻辑
                        2。在被调用方法执行完毕后再通过回调、事件通知等方式将结果反馈给调用方。
                    案例：
                        12306 网站
                        场景一
                            当我们订票时，页面会显示系统正在排队，这个提示就代表着系统在异步处理我们的订票请求。
                        场景二：
                            1。在 12306 系统中查询余票、下单和更改余票状态都是比较耗时的操作
                            2。可能涉及多个内部系统的互相调用
                        问题：
                            如果是同步调用就会像 12306 刚刚上线时那样，高峰期永远不可能下单成功。
                        方法：
                            采用异步的方式
                            具体流程：
                                1。后端处理时会把请求丢到消息队列中，同时快速响应用户
                                2。告诉用户我们正在排队处理，然后释放出资源来处理更多的请求
                                3。订票请求处理完之后，再通知用户订票成功或者失败。
                            优点：
                                系统承受高并发的能力也就提升了
                               原因：
                                    处理逻辑后移到异步处理程序中，Web 服务的压力小了，资源占用的少了

02 | 架构分层：我们为什么一定要这么做？
    问题一：(what)
        什么是分层架构
            背景：
                软件架构分层在软件工程中是一种常见的设计方式
            概念：
                将整体系统拆分成 N 个层次，每个层次有独立的职责，多个层次协同提供完整的功能。
            例子一：
                MVC：
                    概念：
                        1。它将整体的系统分成了 Model（模型），View（视图）和 Controller（控制器）三个层次
                        2。将用户视图和业务处理隔离开，并且通过控制器连接起来
                    作用：
                        很好地实现了表现和逻辑的解耦，是一种标准的软件分层架构
            例子二：
                将整体架构分为表现层、逻辑层和数据访问层
                    表现层：展示数据结果和接受用户指令的，是最靠近用户的一层
                    逻辑层：有复杂业务的具体实现；
                    数据访问层：主要处理和存储之间的交互。
                具体方式：
                    比如在构建项目的时候，我们通常会建立三个目录：
                        Web：表现层
                        Service：逻辑层
                        Dao：数据访问层。
            例子三：
                OSI 网络模型
                    概念：
                        整个网络分了七层，自下而上分别是物理层、数据链路层、网络层、传输层、会话层、表示层和应用层。
            例子四：
                TCP/IP 协议
                    概念：
                        1。把网络简化成了四层，即链路层、网络层、传输层和应用层。
                        2。每一层各司其职又互相帮助，网络层负责端到端的寻址和建立连接
                        3。传输层负责端到端的数据传输等，同时呢相邻两层还会有数据的交互
                    作用：
                        这样可以隔离关注点，让不同的层专注做不同的事情。
            例子五：
                Linux 文件系统也是分层设计
                    概念：
                        1。文件系统的最上层是虚拟文件系统（VFS）
                            作用：
                                用来屏蔽不同的文件系统之间的差异，提供统一的系统调用接口
                        2。虚拟文件系统的下层是 Ext3、Ext4 等各种文件系统
                        3。通用块设备层
                            作用：
                                为了屏蔽不同硬件设备的实现细节
                        4。然后就是不同类型的磁盘了。


    问题二：(why)
        分层有什么好处
            1。分层的设计可以简化系统设计，让不同的人专注做某一层次的事情。
                案例：
                    如果你要设计一款网络程序却没有分层，该是一件多么痛苦的事情。
                原因：
                    1。你必须是一个通晓网络的全才，要知道各种网络设备的接口是什么样的，以便可以将数据包发送给它
                    2。还要关注数据传输的细节，并且需要处理类似网络拥塞，数据超时重传这样的复杂问题
                    3。更需要关注数据如何在网络上安全传输，不会被别人窥探和篡改
                方法：
                    分层
                优点：
                    只需要专注设计应用层的程序就可以了，其他的，都可以交给下面几层来完成。
            2。分层之后可以做到很高的复用
                案例：
                    1。我们在设计系统 A 的时候，发现某一层具有一定的通用性，那么我们可以把它抽取独立出来
                    2。在设计系统 B 的时候使用起来
                优点：
                    可以减少研发周期，提升研发的效率。
            3。分层架构可以让我们更容易做横向扩展。
                案例：
                    如果系统没有分层，当流量增加时我们需要针对整体系统来做扩展。
                    方法：
                        如果我们按照上面提到的三层架构将系统分层后
                    优点：
                        就可以针对具体的问题来做细致的扩展。
                        比如说：
                            1。业务逻辑里面包含有比较复杂的计算，导致 CPU 成为性能的瓶颈
                            2。那这样就可以把逻辑层单独抽取出来独立部署，然后只对逻辑层来做扩展
                            优势：
                                相比于针对整体系统扩展所付出的代价就要小的多了。
    问题三：(how)
        如何来做系统分层
        问题：
            当我们要做分层设计的时候，需要考虑哪些关键因素呢？
                1。首要需要理清楚每个层次的边界是什么。
                    问题：
                        如果按照三层架构来分层的话，每一层的边界不是很容易就界定吗？”
                    答案：
                        没错
                            前提：当业务逻辑简单时，层次之间的边界的确清晰，开发新的功能时也知道哪些代码要往哪儿写
                        问题点：
                            但是当业务逻辑变得越来越复杂时，边界就会变得越来越模糊
                    例子：
                        1。任何一个系统中都有用户系统，最基本的接口是返回用户信息的接口
                        2。它调用逻辑层的 GetUser 方法，GetUser 方法又和 User DB 交互获取数据
                            参考图片：
                                com/suixingpay/profit/document/高并发系统设计40问(PDF+HTML+MP3更新至17课)/图片/第02讲用户信息接口的进化.png
                        3。新的需求：
                            1。在 APP 中展示用户信息的时候，如果用户不存在，那么要自动给用户创建一个用户。
                            2。同时，要做一个 HTML5 的页面，HTML5 页面要保留之前的逻辑，也就是不需要创建用户。
                            分析：
                                1。这时逻辑层的边界就变得不清晰，表现层也承担了一部分的业务逻辑
                                    原因：（将获取用户和创建用户接口编排起来）
                            问题：
                                那我们要如何做呢？
                            方法：
                                1。参照阿里发布的《阿里巴巴 Java 开发手册 v1.4.0（详尽版）》
                                    参考：com/suixingpay/profit/document/高并发系统设计40问(PDF+HTML+MP3更新至17课)/图片/第2讲阿里系统分层的规约.png
                                2。我们可以将原先的三层架构细化成下面的样子：
                                    1。终端显示层：各端模板渲染并执行显示的层。
                                        说明：
                                            当前主要是 Velocity 渲染，JS 渲染， JSP 渲染，移动端展示等。
                                    2。开放接口层：将 Service 层方法封装成开放接口，同时进行网关安全控制和流量控制等。
                                    3。Web 层：主要是对访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。
                                    4。Service 层：业务逻辑层。
                                    5。Manager 层：通用业务处理层
                                        作用：
                                            1。可以将原先 Service 层的一些通用能力下沉到这一层，比如与缓存和存储交互策略，中间件的接入
                                            2。也可以在这一层封装对第三方接口的调用，比如调用支付服务，调用审核服务等
                                    6。DAO 层：数据访问层，与底层 MySQL、Oracle、Hbase 等进行数据交互
                                    7。外部接口或第三方平台：包括其它部门 RPC 开放接口，基础平台，其它公司的 HTTP 接口。
                                分析：
                                    1。这个分层架构中主要增加了 Manager 层
                                    2。它与 Service 层的关系是：
                                        1。Manager 层提供原子的服务接口
                                        2。Service 层负责依据业务逻辑来编排原子接口。
                                具体实现过程：
                                    1。Manager 层提供创建用户和获取用户信息的接口，
                                    2。而 Service 层负责将这两个接口组装起来
                                优点：
                                    这样就把原先散布在表现层的业务逻辑都统一到了 Service 层，每一层的边界就非常清晰了。
                2。是层次之间一定是相邻层互相依赖，数据的流转也只能在相邻的两层之间流转。
                    案例：
                        1。以三层架构为例，数据从表示层进入之后一定要流转到逻辑层，做业务逻辑处理
                        2。然后流转到数据访问层来和数据库交互
                        问题：
                            如果业务逻辑很简单的话可不可以从表示层直接到数据访问层，甚至直接读数据库呢？
                        回答：
                            从功能上是可以的，但是从长远的架构设计考虑，这样会造成层级调用的混乱
                            原因：
                                1。如果表示层或者业务层可以直接操作数据库，那么一旦数据库地址发生变更
                                2。就需要在多个层次做更改，这样就失去了分层的意义
                                3。并且对于后面的维护或者重构都会是灾难性的。并且对于后面的维护或者重构都会是灾难性的。
    分层架构的不足
        背景：
            任何事物都不可能是尽善尽美的，分层架构虽有优势也会有缺陷：
        缺陷一
            增加了代码的复杂度。
            例如：
                1。明明可以在接收到请求后就可以直接查询数据库获得结果
                2。却偏偏要在中间插入多个层次，并且有可能每个层次只是简单地做数据的传递
        缺陷二：
            如果我们把每个层次独立部署，层次间通过网络来交互，那么多层的架构在性能上会有损耗
                也就是所谓的“多一跳”问题。
        问题：
            那我们是否要选择分层的架构呢？
        答案：
            当然是肯定的。
            原因：
                1。分层架构固然会增加系统复杂度，也可能会有性能的损耗
                2。但是相比于它能带给我们的好处来说，这些都是可以接受的，或者可以通过其它的方案解决的
                3。我们在做决策的时候切不可以偏概全，因噎废食。

03 | 系统设计目标（一）：如何提升系统性能？
    高并发：
        概念：
            1。指运用设计手段让系统能够处理更多的用户并发请求，也就是承担更大的流量
            2。它是一切架构设计的背景和前提，脱离了它去谈性能和可用性是没有意义的。
            3。性能和可用性，是我们实现高并发系统设计必须考虑的因素。
                原因：
                    1。在每秒一次请求和每秒一万次请求，两种不同的场景下，分别做到毫秒级响应时间和五个九（99.999%）的可用性
                    2。无论是设计难度还是方案的复杂度，都不是一个级别的
        考虑的因素
                性能：
                    概念：
                        反应了系统的使用体验，是系统设计成功与否的关键
                    案例：
                        同样承担每秒一万次请求的两个系统，一个响应时间是毫秒级，一个响应时间在秒级别
                        问题：
                            带给用户的体验相同吗？
                        答案：
                            用户的体验肯定是不同的。
                    优化原则：
                        1。一定不能盲目，一定是问题导向的
                            原因：
                                1。盲目地提早优化会增加系统的复杂度，浪费开发人员的时间
                                2。某些优化可能会对业务上有些折中的考虑，所以也会损伤业务。
                        2。遵循“八二原则”
                            过程：
                                在优化过程中一定要抓住主要矛盾，优先优化主要的性能瓶颈点
                                原因：
                                    可以用 20% 的精力解决 80% 的性能问题
                        3。要有数据支撑
                            注意：
                                时刻了解你的优化让响应时间减少了多少，提升了多少的吞吐量。
                        4。过程是持续的
                            概念：
                                需要持续不断地寻找性能瓶颈，制定优化方案，直到达到目标为止。
                            原因：
                                1。高并发的系统通常是业务逻辑相对复杂的系统
                                2。那么在这类系统中出现的性能问题通常也会有多方面的原因
                            例子：
                                1。我们在做性能优化的时候要明确目标
                                2。比方说，支撑每秒 1 万次请求的吞吐量下响应时间在 10ms
                    度量指标：
                        1。平均值
                            概念：
                                平均值是把这段时间所有请求的响应时间数据相加，再除以总请求数
                            作用：
                                在一定程度上反应这段时间的性能，但它敏感度比较差
                            缺点：
                                如果这段时间有少量慢请求时，在平均值上并不能如实的反应。
                            案例：
                                1。假设我们在 30s 内有 10000 次请求，每次请求的响应时间都是 1ms，那么这段时间响应时间平均值也是 1ms
                                2。这时，当其中 100 次请求的响应时间变成了 100ms，那么整体的响应时间是 (100 * 100 + 9900 * 1) / 10000 = 1.99ms
                                分析：
                                    1。从平均值上来看仅仅增加了不到 1ms
                                    2。但是实际情况是有 1% 的请求（100/10000）的响应时间已经增加了 100 倍
                                推论：
                                    平均值在这个时候并没有作如实的标准
                        2。最大值
                            概念：
                                这段时间内所有请求响应时间最长的值，但它的问题又在于过于敏感了。
                            案例：
                                1。如果 10000 次请求中只有一次请求的响应时间达到 100ms
                                2。那么这段时间请求的响应耗时的最大值就是 100ms，性能损耗为原先的百分之一
                                3。这种说法明显是不准确的。
                        3。分位值
                            概念：
                                1。排除了偶发极慢请求对于数据的影响，能够很好地反应这段时间的性能情况
                                2。分位值越大，对于慢请求的影响就越敏感。
                                3。分位值是最适合作为时间段内，响应时间统计值来使用的，在实际工作中也应用最多
                            案例：
                                1。分位值有很多种，比如 90 分位、95 分位、75 分位。以 90 分位为例
                                2。我们把这段时间请求的响应时间从小到大排序，假如一共有 100 个请求
                                3。那么排在第 90 位的响应时间就是 90 分位值。
                        4。吞吐量(同时在线用户数)或者响应时间
                            概念：
                                1。度量并发和流量，使用吞吐量的情况会更多一些
                                2。这两个指标是呈倒数关系的。
                            案例：
                                1。响应时间 1s 时，吞吐量是每秒 1 次，响应时间缩短到 10ms，那么吞吐量就上升到每秒 100 次
                                2。一般我们度量性能时都会同时兼顾吞吐量和响应时间，比如我们设立性能优化的目标时通常会这样表述
                                3。在每秒 1 万次的请求量下，响应时间 99 分位值在 10ms 以下。
                            问题：
                                响应时间究竟控制在多长时间比较合适呢？
                                答案：
                                    这个不能一概而论
                                    分析：
                                        从用户使用体验的角度来看：
                                            1。200ms 是第一个分界点
                                                现象：
                                                    用户是感觉不到延迟的，就像是瞬时发生的一样
                                            2. 1s 是另外一个分界点
                                                现象：
                                                    用户可以感受到一些延迟，但却是可以接受的
                                            3。超过 1s 之后：
                                                现象：
                                                    用户就会有明显等待的感觉，等待时间越长，用户的使用体验就越差
                                            好的现象：
                                                1。健康系统的 99 分位值的响应时间通常需要控制在 200ms 之内
                                                2。而不超过 1s 的请求占比要在 99.99% 以上
                    优化思路：
                        案例：
                            1。你现在有一个系统，这个系统中处理核心只有一个
                            2。执行的任务的响应时间都在 10ms，它的吞吐量是在每秒 100 次
                        问题：
                            如何来优化性能从而提高系统的并发能力呢？
                                思路：
                                    1。提高系统的处理核心数
                                        概念：
                                            就是增加系统的并行处理能力
                                        案例：
                                            把系统的处理核心数增加为两个，并且增加一个进程，让这两个进程跑在不同的核心上
                                        分析：
                                            1。理论上：系统的吞吐量可以增加一倍
                                            2。吞吐量和响应时间就不是倒数关系了：
                                                关系为：吞吐量 = 并发进程数 / 响应时间
                                        阿姆达尔定律
                                            概念：
                                                1。吉恩·阿姆达尔在 1967 年提出的
                                                2。并发进程数与响应时间之间的关系
                                                3。是在固定负载下，并行计算的加速比，也就是并行化之后效率提升情况
                                                公式：
                                                    (Ws + Wp) / (Ws + Wp/s)
                                                        描述：
                                                            1。Ws 表示任务中的串行计算量
                                                            2。Wp 表示任务中的并行计算量
                                                            3。s 表示并行进程数
                                                    推导出：
                                                        1/(1-p+p/s)
                                                        描述：
                                                            1。s 还是表示并行进程数
                                                            2。p 表示任务中并行部分的占比
                                                            3。当 p 为 1 时，也就是完全并行时，加速比与并行进程数相等；
                                                            4。当 p 为 0 时，即完全串行时，加速比为 1，也就是说完全无加速
                                                            5。当 s 趋近于无穷大的时候，加速比就等于 1/(1-p)，你可以看到它完全和 p 成正比
                                                            6。特别是，当 p 为 1 时，加速比趋近于无穷大。
                                                            问题：
                                                                是不是无限制地增加处理核心数就能无限制地提升性能，从而提升系统处理高并发的能力呢？
                                                                答案：
                                                                    1。随着并发进程数的增加，并行的任务对于系统资源的争抢也会愈发严重。
                                                                    2。在某一个临界点上继续增加并发进程数，反而会造成系统性能的下降，这就是性能测试中的拐点模型
                                                                    参考：com/suixingpay/profit/document/高并发系统设计40问/图片/第03讲性能测试中的拐点模型.png
                                                                        分析：
                                                                            1。并发用户数处于轻压力区时，响应时间平稳，吞吐量和并发用户数线性相关
                                                                            2。当并发用户数处于重压力区时，系统资源利用率到达极限，吞吐量开始有下降的趋势，响应时间也会略有上升
                                                                            3。再对系统增加压力，系统就进入拐点区，处于超负荷状态，吞吐量下降，响应时间大幅度上升。
                                                                    性能测试的目的：
                                                                        找到系统的“拐点”，从而知道系统的承载能力，也便于找到系统的瓶颈，持续优化系统性能。

                                    2。减少单次任务的响应时间
                                        概念：
                                            想要减少任务的响应时间，首先要看你的系统是 CPU 密集型还是 IO 密集型的
                                                原因：
                                                    不同类型的系统性能优化方式不尽相同。
                                            CPU密集型：
                                                概念：
                                                    需要处理大量的 CPU 运算
                                                优化手段：
                                                    1。更高效的算法
                                                    2。减少运算次数
                                                案例：
                                                    如果系统的主要任务是计算 Hash 值，那么这时选用更高性能的 Hash 算法就可以大大提升系统的性能
                                                如何发现问题：
                                                    是通过一些 Profile 工具来找到消耗 CPU 时间最多的方法或者模块
                                                    方法：
                                                        Linux 的 perf、eBPF 等。
                                            IO密集型：
                                                概念：
                                                    指的是系统的大部分操作是在等待 IO 完成，这里 IO 指的是磁盘 IO 和网络 IO。
                                                例子：
                                                    数据库系统、缓存系统、Web 系统
                                                问题点：
                                                    1。可能出在系统内部
                                                    2。也可能是依赖的其他系统
                                                发现手段：
                                                    1。采用工具
                                                        例如：
                                                            网络协议栈、网卡、磁盘、文件系统、内存，等等
                                                        用法：
                                                            排查问题的过程中逐渐积累
                                                        语言特性的分析工具：
                                                            Java 语言就有其专属的内存分析工具。
                                                    2。通过监控来发现性能问题
                                                        过程：
                                                            1。可以对任务的每一个步骤做分时的统计
                                                            2。从而找到任务的哪一步消耗了更多的时间
                    如何优化：
                        概念：
                            优化方案会随着问题的不同而不同
                            场景一：
                                数据库访问慢
                                分析：
                                    1。是不是有锁表的情况
                                    2。是不是有全表扫描
                                    3。索引加得是否合适
                                    4。是否有 JOIN 操作
                                    5。需不需要加缓存，等等
                            场景二：
                                网络的问题
                                分析：
                                    1。看网络的参数是否有优化的空间
                                    2。抓包来看是否有大量的超时重传，网卡是否有大量丢包等
                可用性：
                    概念：
                        表示系统可以正常服务用户的时间
                    案例：
                        两个承担每秒一万次的系统，一个可以做到全年不停机、无故障，一个隔三差五宕机维护
                    问题：
                        如果你是用户，你会选择使用哪一个系统呢？
                    答案：
                        选择前者
                可扩展性：
                    案例：
                        1。流量分为平时流量和峰值流量两种，峰值流量可能会是平时流量的几倍甚至几十倍
                        2。在应对峰值流量的时候，我们通常需要在架构和方案上做更多的准备
                        具体例子：
                            1。淘宝会花费大半年的时间准备双十一，也是在面对“明星离婚”等热点事件时
                            2。看起来无懈可击的微博系统还是会出现服务不可用的原因
                            3。易于扩展的系统能在短时间内迅速完成扩容，更加平稳地承担峰值流量。

04 | 系统设计目标（二）：系统怎样做到高可用？
    高可用性：(High Availability，HA)
        概念：
            1。指的是系统具备较高的无故障运行的能力。
        案例一：
            1。Hadoop 1.0 中的 NameNode 是单点的，一旦发生故障则整个集群就会不可用；
            2。在 Hadoop2 中提出的 NameNode HA 方案就是同时启动两个 NameNode
            3。一个处于 Active 状态，另一个处于 Standby 状态，两者共享存储
            4。一旦 Active NameNode 发生故障，则可以将 Standby NameNode 切换成 Active 状态继续提供服务
            优点：
                就增强了 Hadoop 的持续无故障运行的能力，也就是提升了它的可用性。
        案例二：
            1。一个高并发大流量的系统，系统出现故障比系统性能低更损伤用户的使用体验
            2。一个日活用户过百万的系统，一分钟的故障可能会影响到上千的用户
            3。随着系统日活的增加，一分钟的故障时间影响到的用户数也随之增加，
            4。系统对于可用性的要求也会更高。
        可用性的度量
            1。MTBF：(Mean Time Between Failure)
                概念：
                    平均故障间隔的意思，代表两次故障的间隔时间，也就是系统正常运转的平均时间
                特点：
                    时间越长，系统稳定性越高。
            2。MTTR：(Mean Time To Repair)
                概念：
                    表示故障的平均恢复时间，也可以理解为平均故障时间
                特点：
                    值越小，故障对于用户的影响越小。
            关系：
                Availability = MTBF / (MTBF + MTTR)
                比例代表系统的可用时间：
                    参考：
                        com/suixingpay/profit/document/高并发系统设计40问/图片/第04讲不同可用标准下允许的故障时间.png
                    分析：
                        1。一个九和两个九的可用性是很容易达到的
                        2。三个九之后，系统的年故障时间从 3 天锐减到 8 小时
                        3。到了四个九之后，年故障时间缩减到 1 小时之内。
                            思路：
                                1。可能需要建立完善的运维值班体系、故障处理流程和业务变更流程
                                2。你可能还需要在系统设计上有更多的考虑
                            具体例子：
                                1。在开发中你要考虑，如果发生故障，是否不用人工介入就能自动恢复
                                2。在工具建设方面，你也需要多加完善，以便快速排查故障原因，让系统快速恢复
                        4。到达五个九之后，故障就不能靠人力恢复了
                            现象：
                                从故障发生到你接收报警，再到你打开电脑登录服务器处理问题，时间可能早就过了十分钟了
                            实现
                              考察的是系统的容灾和自动恢复的能力，让机器来处理故障，才会让可用性指标提升一个档次。
                    现象：
                        不同级别，不同业务场景的系统对于可用性要求是不一样的。
        设计的思路
            1。系统设计
                概念：
                    “Design for failure”是我们做高可用系统设计时秉持的第一原则
                    原因：
                        1。在承担百万 QPS 的高并发系统中，集群中机器的数量成百上千台
                        2。单机的故障是常态，几乎每一天都有发生故障的可能。
                思路：
                    1。预先考虑如何自动化地发现故障
                    2。发生故障之后要如何解决
                具体方法：
                    1。failover（故障转移）:
                        情况一：
                            是在完全对等的节点之间做 failover
                            概念：
                                1。这类系统中所有节点都承担读写流量，并且节点中不保存状态
                                2。每个节点都可以作为另一个节点的镜像
                            方法：
                                如果访问某一个节点失败，那么简单地随机访问另一个节点就好了。
                            例子：
                                Nginx 可以配置当某一个 Tomcat 出现大于 500 的请求的时候，重试请求另一个 Tomcat 节点
                                参考：
                                    com/suixingpay/profit/document/高并发系统设计40问/图片/第04讲Nginx的upstream的failover的机制.png
                        情况二：
                            是在不对等的节点之间，即系统中存在主节点也存在备节点
                            例子：
                                我们有一个主节点，有多台备用节点，这些备用节点可以是热备（同样在线提供服务的备用节点）也可以是冷备（只作为备份使用）
                                问题一：
                                    如何检测主备机器是否故障
                                    方法：
                                        故障检测机制是“心跳”
                                        具体流程：
                                            1。可以在客户端上定期地向主节点发送心跳包
                                            2。也可以从备份节点上定期发送心跳包。
                                            3。当一段时间内未收到心跳包，就可以认为主节点已经发生故障，可以触发选主的操作。
                                问题二：
                                    如何做主备切换。
                                    方法：
                                        使用某一种分布式一致性算法Paxos，Raft。
                                    目的：
                                        多个备份节点上达成一致
                    2。超时控制:
                        背景：
                            1。复杂的高并发系统通常会有很多的系统模块组成，同时也会依赖很多的组件和服务
                                例子：
                                    缓存组件，队列服务
                                问题：
                                    之间的调用最怕的就是延迟而非失败，因为失败通常是瞬时的，
                                    方法：
                                        可以通过重试的方式解决
                                    缺点：
                                        1。一旦调用某一个模块或者服务发生比较大的延迟
                                        2。调用方就会阻塞在这次调用上，它已经占用的资源得不到释放
                                        3。当存在大量这种阻塞请求时，调用方就会因为用尽资源而挂掉。
                                案例：
                                    1。模块之间通过 RPC 框架来调用，超时时间是默认的 30 秒
                                    2。平时系统运行得非常稳定，可是一旦遇到比较大的流量，RPC 服务端出现一定数量慢请求的时候
                                    3。RPC 客户端线程就会大量阻塞在这些慢请求上长达 30 秒，造成 RPC 客户端用尽调用线程而挂掉。
                                    方法：
                                        调整了 RPC，数据库，缓存以及调用第三方服务的超时时间
                                    目的：
                                        出现慢请求的时候可以触发超时，就不会造成整体系统雪崩。
                        概念：
                            1。不让请求一直保持，而是在经过一定时间之后让请求失败，释放资源给接下来的请求使用
                            2。这对于用户来说是有损的，但是却是必要的
                                原因：
                                    牺牲了少量的请求却保证了整体系统的可用性

                        问题：
                            怎么来确定超时时间呢？
                        回答：
                            困难。
                            原因：
                                1。超时时间短了，会造成大量的超时错误，对用户体验产生影响
                                2。超时时间长了，又起不到作用
                            方法一：
                                1。通过收集系统之间的调用日志，统计比如说 99% 的响应时间是怎样的
                                2。然后依据这个时间来指定超时时间。
                            方法二：
                                如果没有调用的日志，那么你只能按照经验值来指定超时时间
                            注意：
                                1。无论你使用哪种方式，超时时间都不是一成不变的，
                                2。需要在后面的系统维护过程中不断地修改。
                    3。降级：
                        概念：
                            为了保证核心服务的稳定而牺牲非核心服务的做法
                        案例：
                            我们发一条微博会先经过反垃圾服务检测，检测内容是否是广告，通过后才会完成诸如写数据库等逻辑。
                        分析：
                            反垃圾的检测是一个相对比较重的操作，日常流量下虽然会比较耗时却还能正常响应
                                原因：
                                    涉及到非常多的策略匹配
                            问题
                                但是当并发较高的情况下，它就有可能成为瓶颈，而且它也不是发布微博的主体流程
                            方法：
                                可以暂时关闭反垃圾服务检测，这样就可以保证主体的流程更加稳定。

                    4。限流：
                        概念：
                            通过对并发的请求进行限速来保护系统。
                        案例：
                            对于 Web 应用，我限制单机只能处理每秒 1000 次的请求，超过的部分直接返回错误给客户端
                        缺点：
                            损害了用户的使用体验，但是它是在极端并发下的无奈之举，是短暂的行为，因此是可以接
            2。系统运维
                从下面两个角度提升系统的可用性
                    1。灰度发布
                        案例一：
                            1。在业务平稳运行过程中，系统是很少发生故障的，90% 的故障是发生在上线变更阶段的
                            2。比方说，你上了一个新的功能，由于设计方案的问题
                            3。数据库的慢请求数翻了一倍，导致系统请求被拖慢而产生故障。
                            问题：
                                如果没有变更，数据库怎么会无缘无故地产生那么多的慢请求呢？
                                方法一：
                                    出现问题时快速回滚恢复
                                方法二：
                                    灰度发布。
                        概念：
                            1。灰度发布指的是系统的变更不是一次性地推到线上的，而是按照一定比例逐步推进的
                            2。一般情况下，灰度发布是以机器维度进行的
                        案例二：
                            1。我们先在 10% 的机器上进行变更，同时观察 Dashboard 上的系统性能指标以及错误日志
                            2。如果运行了一段时间之后系统指标比较平稳并且没有出现大量的错误日志，那么再推动全量变更。
                    2。故障演练
                        概念：
                            1。对系统进行一些破坏性的手段，观察在出现局部故障时
                            2。整体的系统表现是怎样的，从而发现系统中存在的，潜在的可用性问题。
                        原因：
                            1。一个复杂的高并发系统依赖了太多的组件，比方说磁盘，数据库，网卡等
                            2。这些组件随时随地都可能会发生故障，而一旦它们发生故障
                            3。会不会如蝴蝶效应一般造成整体服务不可用呢？
                        方法：
                            1。搭建一套和线上部署结构一模一样的线下系统
                            2。然后在这套系统上做故障演练，从而避免对生产系统造成影响。

05 | 系统设计目标（三）：如何让系统易于扩展？
    背景：
        可以通过增加机器的方式来线性提高系统的处理能力，从而承担更高的流量和并发。
        问题：
            在架构设计之初，为什么不预先考虑好使用多少台机器，支持现有的并发呢？
        回答：
            峰值的流量不可控。
        现象：
            基于成本考虑，在业务平稳期，我们会预留 30%～50% 的冗余以应对运营活动或者推广可能带来的峰值流量
        缺点：
            当有一个突发事件发生时，流量可能瞬间提升到 2～3 倍甚至更高

        案例：
            1。鹿晗和关晓彤互圈公布恋情，大家会到两个人的微博下面，或围观，或互动
            2。微博的流量短时间内增长迅速，微博信息流也短暂出现无法刷出新的消息的情况。
            问题：
                那我们要如何应对突发的流量呢？
                方法：
                    最快的方式就是堆机器。
                猜测：
                   扩容了三倍的机器之后，相应的我们的系统也能支撑三倍流量（不是）
                原因：
                    1。不同的系统分层上可能存在一些“瓶颈点”
                    2。这些瓶颈点制约着系统的横线扩展能力
                    案例：
                        系统的流量是每秒 1000 次请求，对数据库的请求量也是每秒 1000 次
                        情况一：
                            如果流量增加 10 倍，系统可以通过扩容正常服务
                            问题：
                                数据库却成了瓶颈。
                        情况二：
                            单机网络带宽是 50Mbps，那么如果扩容到 30 台机器
                            问题：
                                前端负载均衡的带宽就超过了千兆带宽的限制，也会成为瓶颈点
    问题一：
        为什么提升系统扩展性会很复杂
        原因：
            1。无状态的服务和组件更易于扩展，而像 MySQL 这种存储服务是有状态的，比较难以扩展
            2。向存储集群中增加或者减少机器时，会涉及大量数据的迁移，而一般传统的关系型数据库都不支持
    考虑的因素
        1。数据库
        2。缓存
        3。依赖的第三方
        4。负载均衡
        5。交换机带宽等等
    设计思路：
        拆分：
            概念：
                1。会把庞杂的系统拆分成独立的，有单一职责的模块。
                2。相对于大系统来说，考虑一个一个小模块的扩展性当然会简单一些。
                3。将复杂的问题简单化
            注意：
                但对于不同类型的模块，我们在拆分上遵循的原则是不一样的
            案例：
                假如你要设计一个社区，那么社区会有几个模块呢？可能有 5 个模块。
                1。用户：负责维护社区用户信息，注册，登陆等；
                2。关系：用户之间关注、好友、拉黑等关系的维护；
                3。内容：社区发的内容，就像朋友圈或者微博的内容；
                4。评论、赞：用户可能会有的两种常规互动操作；
                5。搜索：用户的搜索，内容的搜索。
                系统：
                    1。而部署方式遵照最简单的三层部署架构，负载均衡负责请求的分发
                    2。应用服务器负责业务逻辑的处理，数据库负责数据的存储落地。
                    3。这时，所有模块的业务代码都混合在一起了，数据也都存储在一个库里。
                参考：
                    com/suixingpay/profit/document/高并发系统设计40问/图片/第05讲简单社区部署图.png
                思路：
                    1。存储层的扩展性：
                        概念：
                            1。无论是存储的数据量，还是并发访问量，不同的业务模块之间的量级相差很大
                                例子：
                                    1。成熟社区中，关系的数据量是远远大于用户数据量的
                                    2。用户数据的访问量却远比关系数据要大
                                分析：
                                    假如存储目前的瓶颈点是容量，那么我们只需要针对关系模块的数据做拆分就好了，而不需要拆分用户模块的数据
                                    参考：
                                        com/suixingpay/profit/document/高并发系统设计40问/图片/第05讲按照数据库业务拆分后的部署图.png
                                思路：
                                    首先考虑的维度是业务维度。
                                具体方法：
                                    将社区系统拆分：用户库、内容库、评论库、点赞库和关系库
                                优点：
                                    能隔离故障，某一个库“挂了”不会影响到其它的数据库
                                    问题：
                                        1。按照业务拆分，在一定程度上提升了系统的扩展性，但系统运行时间长了之后
                                        2。单一的业务数据库在容量和并发请求量上仍然会超过单机的限制
                                    方法：
                                        按照数据特征做水平的拆分
                                        例子：
                                            可以给用户库增加两个节点，然后按照某些算法将用户的数据拆分到这三个库里面
                                        优点：
                                            可以让数据库突破单机的限制了
                                        注意：
                                            基于长远的考虑，我们最好一次性增加足够的节点以避免频繁地扩容
                                            原因：
                                                不能随意地增加节点，因为一旦增加节点就需要手动地迁移数据，成本还是很高的

                    2。业务层的扩展性：
                        思路：
                            一般会从三个维度考虑业务层的拆分方案
                            1。业务维度
                                概念：
                                    1。把相同业务的服务拆分成单独的业务池
                                    2。每个业务依赖独自的数据库资源，不会依赖其它业务的数据库资源
                                优点：
                                    大大减少了扩容的复杂度。
                                    原因：
                                        当某一个业务的接口成为瓶颈时，我们只需要扩展业务的池子，以及确认上下游的依赖方可以了
                                例子：
                                    1。说上面的社区系统中，我们可以按照业务的维度拆分成
                                    2。用户池、内容池、关系池、评论池、点赞池和搜索池
                                参考：
                                    com/suixingpay/profit/document/高并发系统设计40问/图片/第05讲业务纬度拆分之后的部署图.png
                            2。重要性维度
                                方法：
                                    把业务分为核心池和非核心池。
                                例子：
                                    1。就关系池而言，关注、取消关注接口相对重要一些，可以放在核心池里面
                                    2。拉黑和取消拉黑的操作就相对不那么重要，可以放在非核心池里面
                                优点：
                                    1。优先保证核心池的性能，当整体流量上升时优先扩容核心池
                                    2。降级部分非核心池的接口，从而保证整体系统的稳定性
                                参考：
                                    com/suixingpay/profit/document/高并发系统设计40问/图片/第05讲业务重要程度关系池拆分示意图.png
                            3。请求来源维度。
                                方法：
                                    根据接入客户端类型的不同做业务池的拆分
                                例子：
                                    1。服务于客户端接口的业务可以定义为外网池
                                    2。服务于小程序或者 HTML5 页面的业务可以定义为 H5 池
                                    3。服务于内部其它部门的业务可以定义为内网池，等等

07 | 池化技术：如何减少频繁创建数据库连接的性能损耗？
    案例：
        连接池；
            带领一名兄弟，迅速研发出一套面向某个垂直领域的电商系统
                开发流程：
                    前端一台 Web 服务器运行业务代码，后端一台数据库服务器存储业务数据。
                    原因：
                        人手紧张，时间不足的情况下，为了能够完成任务，你毫不犹豫地采用了最简单的架构
                    现象：
                        1。系统一开始上线之后，虽然用户量不大，但运行平稳
                        2。推广很快带来了一大波流量
                    问题：
                        系统的访问速度开始变慢。
                        方法：
                            分析程序的日志之后，你发现系统慢的原因出现在和数据库的交互上
                            原因：
                                1。数据库的调用方式是先获取数据库的连接
                                2。然后依靠这条连接从数据库中查询数据
                                3。最后关闭连接释放数据库资源。
                            缺点：
                                每次执行 SQL 都需要重新建立连接
                            猜测：
                                是不是频繁地建立数据库连接耗费时间长导致了访问慢的问题。
                                问题：
                                    为什么频繁创建连接会造成响应时间慢呢？
                                方法：
                                    "tcpdump -i bond0 -nn -tttt port 4490"
                                    表示抓取了线上 MySQL 建立连接的网络包来做分析
                                分析：
                                    1。第一部分是前三个数据包
                                        流程：(三次握手)
                                            1。第一个数据包是客户端向服务端发送的一个“SYN”包
                                            2。第二个包是服务端回给客户端的“ACK”包以及一个“SYN”包
                                            3。第三个包是客户端回给服务端的“ACK”包
                                    2。第二部分是 MySQL 服务端校验客户端密码的过程
                                        流程：
                                            1。第一个包是服务端发给客户端要求认证的报文
                                            2。第二和第三个包是客户端将加密后的密码发送给服务端的包
                                            3。最后两个包是服务端回给客户端认证 OK 的报文
                                            4。看到整个连接过程大概消耗了 4ms（969012-964904）
                                    问题：
                                        单条 SQL 执行时间是多少呢？
                                        方法：
                                            统计了一段时间的 SQL 执行时间，发现 SQL 的平均执行时间大概是 1ms
                                        缺点：
                                            MySQL 建立连接的过程是比较耗时的
                                        现象：
                                            1。如果按照原来的方式建立一次连接只执行一条 SQL 的话
                                            2。1s 只能执行 200 次数据库的查询，而数据库建立连接的时间占了其中 4/5。
                                            方法：
                                                数据库连接池
                                                概念：
                                                    1。数据库连接池有两个最重要的配置
                                                    2。最小连接数和最大连接数，它们控制着从连接池中获取连接的流程：
                                                流程：
                                                    1。如果当前连接数小于最小连接数，则创建新的连接处理数据库请求；
                                                    2。如果连接池中有空闲连接则复用空闲连接；
                                                    3。   ，则创建新的连接处理请求；
                                                    4。如果当前连接数已经大于等于最大连接数，则按照配置中设定的时间，等待旧的连接可用；
                                                    5。如果等待超过了这个设定时间则向用户抛出错误。
                                                出现故障的原因：
                                                    1。数据库的域名对应的 IP 发生了变更，池子的连接还是使用旧的 IP
                                                        现象：
                                                            当旧的 IP 下的数据库服务关闭后，再使用这个连接查询就会发生错误
                                                    2。MySQL 有个参数是“wait_timeout”，控制着当数据库连接闲置多长时间后，数据库会主动的关闭这条连接
                                                        现象：
                                                            使用这个被关闭的连接时就会发生错误。
                                                    方法：
                                                        1。启动一个线程来定期检测连接池中的连接是否可用（推荐）
                                                            具体流程：
                                                                1。使用连接发送“select 1”的命令给数据库看是否会抛出异常
                                                                2。如果抛出异常则将这个连接从连接池中移除，并且尝试关闭
                                                                3。目前 C3P0 连接池可以采用这种方式来检测连接是否可用，也是我比较推荐的方式。
                                                        2。在获取到连接之后，先校验连接是否可用，如果可用才会执行 SQL 语句
                                                            例子：
                                                                DBCP 连接池的 testOnBorrow 配置项，就是控制是否开启这个验证
                                                                注意：
                                                                    这种方式在获取连接时会引入多余的开销，在线上系统中还是尽量不要开启，在测试服务上可以使用
        线程池：
            需求：
                一个非常重要的接口中，你需要访问 3 次数据库
            分析：
                根据经验判断，你觉得这里未来肯定会成为系统瓶颈。
            思路：
                可以创建多个线程来并行处理与数据库之间的交互，这样速度就能快了。
                问题：
                    在高并发阶段，频繁创建线程的开销也会很大
                方法：
                    用线程池预先创建线程
                        两个重要的参数：
                            coreThreadCount 和 maxThreadCount，这两个参数控制着线程池的执行过程
                    流程：
                        1。如果线程池中的线程数少于 coreThreadCount 时，处理新的任务时会创建新的线程；
                        2。如果线程数大于 coreThreadCount 则把任务丢到一个队列里面，由当前空闲的线程执行；
                        3。当队列中的任务堆积满了的时候，则继续创建线程，直到达到 maxThreadCount；
                        4。当线程数达到 maxTheadCount 时还有新的任务提交，那么我们就不得不将它们丢弃了。
                        参考：
                            com/suixingpay/profit/document/高并发系统设计40问/图片/第07讲线程池提交示意图.png
                            注意：
                                1。JDK 实现的这个线程池优
                                    1。先把任务放入队列暂存起来，而不是创建更多的线程
                                        原因：
                                            1。执行 CPU 密集型的任务时 CPU 比较繁忙，因此只需要创建和 CPU 核数相当的线程就好了
                                            2。多了反而会造成线程上下文切换，降低任务执行效率
                                        场景：
                                            适用于执行 CPU 密集型的任务，也就是需要执行大量 CPU 运算的任务
                                    2。当当前线程数超过核心线程数时，线程池不会增加线程，而是放在队列里等待核心线程空闲下来。
                                2。Tomcat 使用的线程池
                                    背景
                                        1。平时开发的 Web 系统通常都有大量的 IO 操作，比方说查询数据库、查询缓存等等。
                                        2。任务在执行 IO 操作的时候 CPU 就空闲了下来，这时如果增加执行任务的线程数而不是把任务暂存在队列中
                                        3。就可以在单位时间内执行更多的任务，大大提高了任务执行的吞吐量。
                                    方法：
                                        Tomcat 使用的线程池就不是 JDK 原生的线程池，而是做了一些改造
                                        具体：
                                            1。当线程数超过 coreThreadCount 之后会优先创建线程
                                            2。直到线程数到达 maxThreadCount，这样就比较适合于 Web 系统大量 IO 操作的场景了
                                3。线程池中使用的队列的堆积量也是我们需要监控的重要指标
                                    扩展：
                                        对于实时性要求比较高的任务来说，这个指标尤为关键。
                                    案例：
                                        实际项目中就曾经遇到过任务被丢给线程池之后，长时间都没有被执行的诡异问题
                                        思考：
                                            认为这是代码的 Bug 导致的
                                            方法：
                                                经过排查发现
                                                原因：
                                                    线程池的 coreThreadCount 和 maxThreadCount 设置的比较小，导致任务在线程池里面大量的堆积
                                                具体方案：
                                                    调大了这两个参数之后问题就解决了
                                4。如果你使用线程池请一定记住不要使用无界队列（即没有设置固定大小的队列）
                                    乐观思考：
                                        任务就永远不会被丢弃，只要任务对实时性要求不高，反正早晚有消费完的一天。
                                    理性分析：
                                        大量的任务堆积会占用大量的内存空间，一旦内存空间被占满就会频繁地触发 Full GC，造成服务不可用

    汇总：
        1。连接池，线程池它们都有一个共同点：
            它们所管理的对象，无论是连接还是线程，它们的创建过程都比较耗时，也比较消耗系统资源
            方法：
                我们把它们放在一个池子里统一管理起来
            优点：
                达到提升性能和资源复用的目的。
        2。这是一种常见的软件设计思想，叫做池化技术
            核心：
                1。核心思想是空间换时间，期望使用预先创建好的对象来减少频繁创建对象的性能开销
                2。同时还可以对对象进行统一的管理，降低了对象的使用的成本，总之是好处多多。
            缺点：
                1。说存储池子中的对象肯定需要消耗多余的内存，如果对象没有被频繁使用，就会造成内存上的浪费
                2。池子中的对象需要在系统启动的时候就预先创建完成，这在一定程度上增加了系统启动时间。
        问题：
            为什么还有这种思想：
                原因：
                    1。相比池化技术的优势来说就比较微不足道了
                    2。只要我们确认要使用的对象在创建时确实比较耗时或者消耗资源
                    3。并且这些对象也确实会被频繁地创建和销毁，我们就可以使用池化技术来优化。

08 | 数据库优化方案（一）：查询请求增加时，如何做主从分离？
    主从读写分离：
        背景：
            大部分系统的访问模型是读多写少，读写请求量的差距可能达到几个数量级
        例子：
            1。刷朋友圈的请求量肯定比发朋友圈的量大
            2。淘宝上一个商品的浏览量也肯定远大于它的下单量。
            问题：
                如何抗住更高的查询请求
                思考：
                    需要把读写流量区分开，读写分离
                    原因：
                        方便针对读流量做单独的扩展
                案例：
                    前端流量突增导致从库负载过高的问题
                    处理流程：
                        1。DBA 兄弟会优先做一个从库扩容上去
                        2。这样对数据库的读流量就会落入到多个从库上，从库的负载就降了下来
                        3。然后研发同学再考虑使用什么样的方案将流量挡在数据库层之上。
    主从读写的两个技术关键点
        1。主从复制
            背景：
                1。MySQL 的主从复制是依赖于 binlog 的
                    说明：
                        记录 MySQL 上的所有变化并以二进制形式保存在磁盘上二进制日志文件
                2。主从复制就是将 binlog 中的数据从主库传输到从库上
                3。一般这个过程是异步的，即主库上的操作不会等待 binlog 同步的完成。
            流程：
                1。首先从库在连接到主节点时会创建一个 IO 线程，用以请求主库更新的 binlog
                2。并且把接收到的 binlog 信息写入一个叫做 relay log 的日志文件中
                3。而主库也会创建一个 log dump 线程来发送 binlog 给从库；
                4。同时，从库还会创建一个 SQL 线程读取 relay log 中的内容，并且在从库中做回放，最终实现主从的一致性
                分析：
                    1。使用独立的 log dump 线程是一种异步的方式（主库）
                    优点：
                        可以避免对主库的主体更新流程产生影响
                    2。从库在接收到信息后并不是写入从库的存储中，是写入一个 relay log（从库）
                    优点：
                        是避免写入从库实际存储会比较耗时，最终造成从库和主库延迟变长。
                        参考：com/suixingpay/profit/document/高并发系统设计40问/图片/第08讲mysql主从复制的过程.png
                特殊的现象：
                    1。基于性能的考虑，主库的写入流程并没有等待主从同步完成就会返回结果
                    情况一：
                        主从数据的不一致
                        原因：
                            说主库上 binlog 还没有来得及刷新到磁盘上就出现了磁盘损坏或者机器掉电
                        容忍：
                            这种情况出现的概率很低，对于互联网的项目来说是可以容忍的。
            应用：
                1。Redis 也是通过主从复制实现读写分离；
                2。Elasticsearch 中存储的索引分片也可以被复制到多个节点中；
                3。写入到 HDFS 中文件也会被复制到多个 DataNode 中。
                扩展：
                    1。不同的组件对于复制的一致性、延迟要求不同，采用的方案也不同
                    2。这种设计的思想是通用的，是你需要了解的，这样你在学习其他存储组件的时候就能够触类旁通了
            优点：
                1。写请求会锁表或者锁记录，也不会影响到读请求的执行
                    原因：
                        写入时只写主库，在读数据时只读从库
                2。抵御较高的并发读流量
                    方法：
                        在读流量比较大的情况下，我们可以部署多个从库共同承担读流量（一主多从）
                    问题：
                        是不是我无限制地增加从库的数量就可以抵抗大量的并发呢？
                    回答：
                        并不是，一般一个主库最多挂 3～5 个从库。
                        原因：
                            1。随着从库数量增加，从库连接上来的 IO 线程比较多
                            2。主库也需要创建同样多的 log dump 线程来处理复制的请求，对于主库资源消耗比较高
                            3。同时受限于主库的网络带宽，

                3。从库也可以当成一个备库来使用
                    优点：
                        避免主库故障导致数据丢失。
            缺点：
                1。部署上的复杂度
                2。主从同步的延迟，这种延迟有时候会对业务产生一定的影响
                    例子：
                        1。将微博的信息同步给审核系统，所以我们在更新完主库之后
                        2。会将微博的 ID 写入消息队列，再由队列处理机依据 ID 在从库中获取微博信息再发送给审核系统
                        问题：
                            如果主从数据库存在延迟，会导致在从库中获取不到微博信息，整个流程会出现异常。
                        现象：
                            1。我们遇到从数据库中获取不到信息的诡异问题时，会纠结于代码中是否有一些逻辑会把之前写入的内容删除
                            2。但是你又会发现，过了一段时间再去查询时又可以读到数据了
                        措施：
                            1。把从库落后的时间作为一个重点的数据库指标做监控和报警
                            2。正常的时间是在毫秒级别，一旦落后的时间达到了秒级别就需要告警了。
                        思路：
                            尽量不去从库中查询信息
                        解决方案：
                            1。数据的冗余
                                流程：
                                    1。可以在发送消息队列时不仅仅发送微博 ID
                                    2。而是发送队列处理机需要的所有微博信息
                                目的：
                                    避免从数据库中重新查询数据
                                优点：
                                    这种方式足够简单（优先采用）
                                缺点：
                                    可能造成单条消息比较大，从而增加了消息发送的带宽和时间。
                            2。使用缓存
                                流程：
                                    1。同步写数据库的同时，也把微博的数据写入到 Memcached 缓存里面
                                    2。队列处理机在获取微博信息的时候会优先查询缓存
                                目的：
                                    可以保证数据的一致性。
                                场景：
                                    比较适合新增数据的场景
                                缺点：
                                    在更新数据的场景下，先更新缓存可能会造成数据的不一致
                                例子：
                                    1。两个线程同时更新数据，线程 A 把缓存中的数据更新为 1
                                    2。此时另一个线程 B 把缓存中的数据更新为 2，然后线程 B 又更新数据库中的数据为 2
                                    3。此时线程 A 更新数据库中的数据为 1，这样数据库中的值（1）和缓存中的值（2）就不一致了。
                            3。查询主库
                                方法：
                                    在队列处理机中不查询从库而改为查询主库
                                注意：
                                    1。使用起来要慎重，要明确查询的量级不会很大
                                    2。是在主库的可承受范围之内，否则会对主库造成比较大的压力
                                    3。一般不采用：
                                        原因：
                                            1。提供一个查询主库的接口，在团队开发的过程中，你很难保证其他同学不会滥用这个方法
                                            2。一旦主库承担了大量的读请求导致崩溃，那么对于整体系统的影响是极大
        2。如何访问数据库：
            背景：
               1。使用主从复制的技术将数据复制到了多个节点，也实现了数据库读写的分离，对于数据库的使用方式发生了变化
                2。以前只需要使用一个数据库地址就好了，现在需要使用一个主库地址和多个从库地址，并且需要区分写入操作和查询操作
            方案一：
                以代码形式内嵌运行在应用程序内部
                原理：
                    1。它看成是一种数据源的代理，它的配置管理着多个数据源
                    2。每个数据源对应一个数据库，可能是主库，可能是从库
                    3。当有一个数据库请求时，中间件将 SQL 语句发给某一个指定的数据源来处理，然后将处理结果返回。
                例子：
                    1。以淘宝的 TDDL（ Taobao Distributed Data Layer）为代表，
                    2。早期的网易 DDB，它们都是 Java 语言开发的
                    3。Sharding-JDBC 这样的嵌入应用内部的方案
                优点：
                    优点是简单易用，没有多余的部署成本
                    原因：
                        它是植入到应用程序内部，与应用程序一同运行的
                场景：
                    比较适合运维能力较弱的小团队使用
                缺点：
                    缺乏多语言的支持
            方案二：
                单独部署的代理层方案
                原理：
                    1。中间件部署在独立的服务器上，业务代码如同在使用单一数据库一样使用它
                    2。实际上它内部管理着很多的数据源
                    3。当有数据库请求时，它会对 SQL 语句做必要的改写，然后发往指定的数据源。
                例子：
                    1。早期阿里巴巴开源的 Cobar，基于 Cobar 开发出来的 Mycat
                    2。360 开源的 Atlas，美团开源的基于 Atlas 开发的 DBProxy 等等。
                优点：
                    1。可以很好地支持多语言
                        原因：
                            一般使用标准的 MySQL 通信协议
                    2。比较方便进行维护升级
                        原因：
                            它是独立部署的
                场景：
                    比较适合有一定运维能力的大中型团队使用
                缺点：
                    性能上会有一些损耗。
                        原因：
                            所有的 SQL 语句都需要跨两次网络：从应用到代理层和从代理层到数据源
                    参考：
                        com/suixingpay/profit/document/高并发系统设计40问/图片/第08讲数据库代理层.png

            注意：
                1。使用任何中间件的时候一定要保证对于中间件有足够深入的了解
                2。否则一旦出了问题没法快速地解决就悲剧了。

09 | 数据库优化方案（二）：写入数据量增加时，如何实现分库分表？
    案例：
        所设计的电商系统的订单量突破了五千万，订单数据都是单表存储的
        现象：
            无论是数据库的查询还是写入性能都在下降，数据库的磁盘空间也在报警
            问题一：
                如何提升查询性能呢？
                背景：
                    1。系统正在持续不断地的发展，注册的用户越来越多，产生的订单越来越多
                    2。数据库中存储的数据也越来越多，单个表的数据量超过了千万甚至到了亿级别
                分析：
                    1。即使你使用了索引，索引占用的空间也随着数据量的增长而增大
                    2。数据库就无法缓存全量的索引信息，那么就需要从磁盘上读取索引数据，就会影响到查询的性能了
            问题二：
                如何让数据库系统支持如此大的数据量呢？
                现象：
                    数据量的增加也占据了磁盘的空间，数据库在备份和恢复的时间变长
            问题三：
                如何做到不同模块的故障隔离呢？
                背景：
                    1。不同模块的数据，比如用户数据和用户关系数据，全都存储在一个主库中
                    2。一旦主库发生故障，所有的模块儿都会受到影响
            问题四：
                数据库系统如何来处理更高的并发写入请求呢？
                背景：
                    1。在 4 核 8G 的云服务器上对 MySQL5.7 做 Benchmark，大概可以支撑 500TPS 和 10000QPS
                    2。数据库对于写入性能要弱于数据查询的能力，那么随着系统写入请求量的增长
            注意：
                数据库的写入请求量大造成的性能和可用性方面的问题
                措施：
                    对数据进行分片，分库分表
                    概念：
                        基本思想是依照某一种策略将数据尽量平均的分配到多个数据库节点或者多个表中。
                    优点：
                        1。解决了数据存储瓶颈的同时也能有效的提升数据查询的性能
                            原因：
                                每个节点只保存部分的数据，这样可以有效地减少单个数据库节点和单个数据表中存储的数据量
                        2。一定程度上也会提升并发写入的性能。
                            原因：
                                数据被分配到多个数据库节点上，那么数据的写入请求也从请求单一主库变成了请求多个数据分片节点
                忽视的点：
                    1。对如何使用正确的分库分表方式一知半解，没有明白使用场景和方法
                        例子：
                            查询时不使用分区键；
                                问题一：
                                    如何对数据库做垂直拆分(关注业务)
                                    概念：
                                        对数据库竖着拆分，也就是将数据库的表拆分到多个不同的数据库中。
                                    原则：
                                        按照业务类型来拆分，核心思想是专库专用，将业务耦合度比较高的表拆分到单独的库中。
                                    案例一：
                                        在整理衣服的时候，将羽绒服、毛衣、T 恤分别放在不同的格子里
                                        目的：
                                            实现了数据层面的故障隔离（解决上面问题三的问题）
                                            原因：
                                                1。把不同的业务的数据分拆到不同的数据库节点上
                                                2。这样一旦数据库发生故障时只会影响到某一个模块的功能，不会影响到整体功能
                                    案例二；
                                        1。微博系统中有和用户相关的表，有和内容相关的表，有和关系相关的表
                                        2。这些表都存储在主库中
                                        流程：
                                            1。用户相关的表分拆到用户库中
                                            2。内容相关的表分拆到内容库中
                                            3。关系相关的表分拆到关系库中。
                                    优点：
                                        可以暂时缓解存储容量的瓶颈
                                    缺点：
                                        不能解决某一个业务模块的数据大量膨胀的问题，一旦你的系统遭遇某一个业务库的数据量暴增
                                        例子：
                                            微博关系量早已经过了千亿，单一的数据库或者数据表已经远远不能满足存储和查询的需求了
                                        方法：
                                            对数据库和数据表做水平拆分了。

                                问题二：
                                    如何对数据库做水平拆分(关注数据)
                                    概念：
                                        指的是将单一数据表按照某一种规则拆分到多个数据库和多个数据表中，关注点在数据的特点。
                                    规则：
                                        1。按照某一个字段的哈希值做拆分
                                            场景：
                                                适用于实体表
                                            例子：
                                                用户表，内容表，我们一般按照这些实体表的 ID 字段来拆分
                                                流程：
                                                    1。把用户表拆分成 16 个库，64 张表，那么可以先对用户 ID 做哈希
                                                        目的：
                                                            哈希的目的是将 ID 尽量打散
                                                    2。然后再对 16 取余，这样就得到了分库后的索引值
                                                    3。对 64 取余，就得到了分表后的索引值
                                                        参考：
                                                            com/suixingpay/profit/document/高并发系统设计40问/图片/第09讲hash分表的示意图.png
                                        2。按照某一个字段的区间来拆分，比较常用的是时间字段
                                            例子一：
                                                1。在内容表里面有“创建时间”的字段，而我们也是按照时间来查看一个人发布的内容
                                                2。可能会要看昨天的内容，也可能会看一个月前发布的内容
                                                思考：
                                                    1。可以按照创建时间的区间来分库分表
                                                具体做法：
                                                    比如说可以把一个月的数据放入一张表中
                                                    现象：
                                                        查询时就可以根据创建时间先定位数据存储在哪个表里面，再按照查询条件来查询。
                                            缺点：
                                                1。会存在明显的热点，查询的 QPS 也会更多一些，对性能有一定的影响。
                                                2。数据表要提前建立好，否则如果时间到了 2020 年元旦，忘记了建表，就会发生故障了。
                                变化：
                                    分库分表前：
                                        只需要根据查询条件到从库中查询数据即可
                                    分库分表：
                                        需要先确认数据在哪一个库表中，再到那个库表中查询数据
                                        方法：
                                            可以通过数据库中间件来解决
                    2。分库分表引入了一些问题后，没有找到合适的解决方案
                      问题一：
                        引入了分库分表键，也叫做分区键
                            概念：
                                对数据库做分库分表所依据的字段。
                            分析：
                                1。无论是哈希拆分还是区间段的拆分
                                2。我们首先都需要选取一个数据库字段
                            现象：
                                1。我们之后所有的查询都需要带上这个字段，才能找到数据所在的库和表
                                2。否则就只能向所有的数据库和数据表发送查询命令
                                    例子：
                                        上面说的要拆分成 16 个库和 64 张表，那么一次数据的查询会变成 16*64=1024 次查询
                                        缺点：
                                            查询的性能肯定是极差的。
                            例子一：
                                在用户库中我们使用 ID 作为分区键，这时如果需要按照昵称来查询用户时
                                方法一：
                                    按照昵称作为分区键再做一次拆分
                                    缺点：
                                        1。会极大的增加存储成本
                                        2。如果以后我们还需要按照注册时间来查询时要怎么办呢，再做一次拆分吗？
                                方法二：
                                    建立一个昵称和 ID 的映射表
                                    查询流程：
                                        先通过昵称查询到 ID，再通过 ID 查询完整的数据
                                    注意：
                                        这个表也可以是分库分表的，也需要占用一定的存储空间
                                    优点：
                                        表中只有两个字段，所以相比重新做一次拆分还是会节省不少的空间的。
                        问题二：
                            一些数据库的特性在实现时可能变得很困难
                            例子一：
                                1。多表的 join 在单库时是可以通过一个 SQL 语句完成的
                                2。拆分到多个数据库之后就无法跨库执行 SQL 了
                                情况：
                                    我们对于 join 的需求不高
                                方法：
                                    把两个表的数据取出后在业务代码里面做筛选，复杂是有一些，不过是可以实现的
                            例子二：
                                要在 SQL 中执行 count()
                                单库：
                                    只需要在 SQL 中执行 count() 即可
                                多库：
                                    将计数的数据单独存储在一张表中或者记录在 Redis 里面
                            例子三：
                                分页查询：
                                    通过数据中心同步的方式来解决
                        问题三：(下一讲讲)
                            主键的全局唯一性的问题。
                优点：
                    很好地分摊数据库的读写压力，也可以突破单机的存储瓶颈
                注意 ：
                    1。使用一个方案解决一个问题的时候一定要弄清楚原理
                    2。搞清楚这个方案会带来什么问题，要如何来解决
                    3。要知其然也知其所以然，这样才能在解决问题的同时避免踩坑。

10 | 发号器：如何保证分库分表后ID的全局唯一性？
    背景：
        1。面临高并发的查询数据请求时，可以使用主从读写分离的方式，部署多个从库分摊读压力
        2。当存储的数据量达到瓶颈时，我们可以将数据分片存储在多个节点上，降低单个存储节点的存储压力
        3。通过分库分表和主从读写分离的方式解决了数据库的扩展性问题
        参考：
            com/suixingpay/profit/document/高并发系统设计40问/图片/第10讲读写分离分库分表系统图.png
    问题一：
        数据库的主键要如何选择？
        背景：
            1。数据库中的每一条记录都需要有一个唯一的标识
            2。依据数据库的第二范式，数据库中每一个表中都需要有一个唯一的主键，其他数据元素和主键一一对应。
        选择方式：
            1。使用业务字段作为主键
                例子：
                    对于用户表来说，可以使用手机号，email 或者身份证号作为主键。
                场景：
                    很少用
                原因：
                    1。在评论表中，你很难找到一个字段唯一标识一条评论
                    2。一个人可以有多个 email 和手机号，一旦出现变更 email 或者手机号的情况，就需要变更所有引用的外键信息
                    3。身份证号码确实是用户的唯一标识，它的隐私属性，并不是一个用户系统的必须属性
                    情况一：
                        系统如果没有要求做实名认证，那么肯定不会要求用户填写身份证号码的。
                    情况二：
                        并且已有的身份证号码是会变更的，比如在 1999 年时身份证号码就从 15 位变更为 18 位
                缺点：
                    主键一旦变更，以这个主键为外键的表也都要随之变更，这个工作量是巨大的
            2。使用生成的唯一 ID 作为主键。（推荐）
                原因：
                    一旦生成就不会变更，可以随意引用
                单库单表：
                    使用数据库的自增字段作为 ID
                    原因：
                        对于开发人员来说也是透明的
                分库分表：
                    用自增字段就无法保证 ID 的全局唯一性了。
                    方法：
                        你搭建发号器服务来生成全局唯一的 ID。
                    具体：
                        基于 Snowflake 算法搭建发号器
                            问题：
                                为什么不用UUID来做主键
                                    优点：
                                        不依赖于任何第三方系统，所以在性能和可用性上都比较好
                                    场景：
                                        使用它生成 Request ID 来标记单次请求
                                    缺点：
                                        1。不具备生成的 ID 做好具有单调递增性，也就是有序的
                                            问题：
                                                为什么 ID 要是有序的呢？
                                                原因：
                                                    在系统设计时，ID 有可能成为排序的字段
                                                例子：
                                                    1。实现一套评论的系统时，你一般会设计两个表
                                                        一张评论表，存储评论的详细信息
                                                            1。其中有 ID 字段，有评论的内容，还有评论人 ID，被评论内容的 ID 等等
                                                            2。以 ID 字段作为分区键；
                                                        一个是评论列表
                                                            存储着内容 ID 和评论 ID 的对应关系，以内容 ID 为分区键
                                                    2。在获取内容的评论列表时，需要按照时间序倒序排列
                                                现象：
                                                    1。如果评论 ID 不是在时间上有序的话，我们就需要在评论列表中再存储一个多余的创建时间的列用作排序
                                                    2。假设内容 ID、评论 ID 和时间都是使用 8 字节存储
                                                    缺点：
                                                        就要多出 50% 的存储空间存储时间字段，造成了存储空间上的浪费。
                                                        方法：
                                                            可以按照评论 ID 的倒序排列
                                                            原因：
                                                                ID 是时间上有序的

                                        2。在于 ID 有序也会提升数据的写入性能
                                            背景：
                                                MySQL InnoDB 存储引擎使用 B+ 树存储索引数据，而主键也是一种索引
                                            插入流程：
                                                有序：
                                                    1。当插入的下一条记录的 ID 是递增的时候
                                                    2。比如插入 30 时，数据库只需要把它追加到后面就好了
                                                无序：
                                                    1。如果插入的数据是无序的，比如 ID 是 13
                                                    2。那么数据库就要查找 13 应该插入的位置
                                                    3。再挪动 13 后面的数据
                                                    缺点：
                                                        造成了多余的数据移动的开销
                                                        原因：
                                                            1。机械磁盘在完成随机的写时，需要先做“寻道”找到要写入的位置
                                                            2。也就是让磁头找到对应的磁道，这个过程是非常耗时的
                                                            3。顺序写就不需要寻道，会大大提升索引的写入性能
                                        3。不能作为 ID 的另一个原因是它不具备业务含义
                                            例子一：
                                                1。我们使用的身份证的前六位是地区编号；
                                                2。7～14 位是身份证持有人的生日
                                            例子二：
                                                1。不同城市电话号码的区号是不同的
                                                2。你从手机号码的的前三位就可以看出这个手机号隶属于哪一个运营商
                                            思路：
                                                如果生成的 ID 可以被反解，那么从反解出来的信息中我们可以对 ID 来做验证
                                                优点：
                                                    1。可以从中知道这个 ID 的生成时间，从哪个机房的发号器中生成的
                                                    2。为哪个业务服务的，对于问题的排查有一定的帮助。
                                        4。UUID 是由 32 个 16 进制数字组成的字符串
                                            缺点：
                                              如果作为数据库主键使用比较耗费空间。
                            原理：
                                1。将 64bit 的二进制数字分成若干部分，
                                2。每一部分都存储有特定含义的数据，比如说时间戳、机器 ID、序列号等等，最终生成全局唯一的有序 ID
                                参考：
                                    com/suixingpay/profit/document/高并发系统设计40问/图片/第10讲Snowflake算法示意图.png
                                    分析：
                                        1。41 位的时间戳大概可以支撑69年：
                                            n=pow(2,41)/1000/60/60/24/365
                                        2。如果你的系统部署在多个机房
                                            1。10 位的机器 ID 可以继续划分为 2～3 位的 IDC 标示（可以支撑 4 个或者 8 个 IDC 机房）
                                            2。7～8 位的机器 ID（支持 128-256 台机器）
                                        3。12 位的序列号代表着每个节点每毫秒最多可以生成 4096 的 ID。
                            注意：
                                不同公司也会依据自身业务的特点对 Snowflake 算法做一些改造
                                情况一：
                                    减少序列号的位数增加机器 ID 的位数以支持单 IDC 更多的机器
                                情况二：
                                    加入业务 ID 字段来区分不同的业务
                            案例：
                                1 位兼容位恒为 0 + 41 位时间信息 + 6 位 IDC 信息（支持 64 个 IDC）+ 6 位业务信息（支持 64 个业务）+ 10 位自增信息（每毫秒支持 1024 个号）
                                设计原因：
                                    1。单机房只部署一个发号器的节点，并且使用 KeepAlive 保证可用性
                                    2。业务信息指的是项目中哪个业务模块使用
                                        例如：
                                            1。用户模块生成的 ID
                                            2。内容模块生成的 ID
                                        作用：
                                            1。一是希望不同业务发出来的 ID 可以不同
                                            2。在出现问题时可以反解 ID，知道是哪一个业务发出来的 ID。
                            实现方式：
                                1。嵌入到业务代码里，也就是分布在业务服务器中
                                    优点：
                                        业务代码在使用的时候不需要跨网络调用，性能上会好一些
                                    缺点：
                                        1。需要更多的机器 ID 位数来支持更多的业务服务器
                                        2。由于业务服务器的数量很多，我们很难保证机器 ID 的唯一性
                                            方法：
                                                需要引入 ZooKeeper 等分布式一致性组件来保证每次机器重启时都能获得唯一的机器 ID。
                                2。作为独立的服务部署，这也就是我们常说的发号器服务（推荐）
                                    缺点：
                                        业务在使用发号器的时候就需要多一次的网络调用，但是内网的调用对于性能的损耗有限
                                    优点：
                                        可以减少机器 ID 的位数
                                    例子一：
                                        1。如果发号器以主备方式部署，同时运行的只有一个发号器，那么机器 ID 可以省略
                                        2。可以留更多的位数给最后的自增信息位
                                    例子二：
                                        需要机器 ID，发号器部署实例数有限，那么就可以把机器 ID 写在发号器的配置文件里
                                        优点：
                                            即可以保证机器 ID 唯一性，也无需引入第三方组件了
                                    应用：
                                        微博和美图都是使用独立服务的方式来部署发号器的，性能上单实例单 CPU 可以达到两万每秒。
                            优点：
                                1。Snowflake 算法设计的非常简单且巧妙，性能上也足够高效
                                2。生成具有全局唯一性、单调递增性和有业务含义的 ID
                            缺点：
                                1。它依赖于系统的时间戳，一旦系统时间不准，就有可能生成重复的 ID。
                                    方法：
                                        如果我们发现系统时钟不准，就可以让发号器暂时拒绝发号，直到时钟准确为止。
                                2。分库分表时如果使用 ID 作为分区键就会造成库表分配的不均匀
                                    前提：
                                        如果请求发号器的 QPS 不高
                                            现象：
                                              比如说发号器每毫秒只发一个 ID就会造成生成 ID 的末位永远是 1
                                    方法：
                                        1。时间戳不记录毫秒而是记录秒，这样在一个时间区间里可以多发出几个号
                                            作用：
                                                避免出现分库分表时数据分配不均。
                                        2。生成的序列号的起始号可以做一下随机，这一秒是 21，下一秒是 30
                                            作用：
                                                这样就会尽量的均衡了。
                            扩展：
                                1。如滴滴和美团都有提出基于数据库生成 ID 的方案
                                2。这些方法根植于公司的业务，同样能解决分布式环境下 ID 全局唯一性的问题。
                                3。可以多角度了解不同的方法，这样能够寻找到更适合自己业务目前场景的解决方案
                                4。方案不在多，而在精，方案没有最好，只有最适合，真正弄懂方法背后的原理，并将它落地，才是你最佳的选择。

11 | NoSQL：在高并发场景下，数据库和NoSQL如何做到互补？
    问题一：
        如何将传统的关系型数据库改造成分布式存储服务，以抵抗高并发和大流量的冲击。
        思考：
            1。提升它的读写性能，尤其是读性能，因为我们面对的多是一些读多写少的产品
                例子：
                    离不开的微信朋友圈、微博和淘宝，都是查询 QPS 远远大于写入 QPS。
            2。增强它在存储上的扩展能力，从而应对大数据量的存储需求。
        实现方式：
            读写分离和分库分表就是从这两方面出发，改造传统的关系型数据库的
    问题二：
        传统数据库很难解决的
        案例：
            1。微博项目中关系的数据量达到了千亿，那么即使分隔成 1024 个库表，每张表的数据量也达到了亿级别
            2。并且关系的数据量还在以极快的速度增加，即使你分隔成再多的库表，数据量也会很快增加到瓶颈
            难点：
                这个问题用传统数据库很难根本解决
                原因：
                    在扩展性方面是很弱的
            方法：
                可以利用 NoSQL
                原因：
                    1。有着天生分布式的能力，能够提供优秀的读写性能
                    2。补充传统关系型数据库的短板
    NoSQL 数据库
        概念：
            1。不同于传统的关系型数据库的其他数据库系统的统称，它不使用 SQL 作为查询语言
            2。提供优秀的横向扩展能力和读写性能，非常契合互联网项目高并发大数据的特点
        应用：
            小米、微博、陌陌都很倾向使用它来作为高并发大容量的数据存储服务。
        类型：
            1。Redis、LevelDB 这样的 KV 存储
                优点：
                    这类存储相比于传统的数据库的优势是极高的读写性能
                场景：
                    对性能有比较高的要求的场景会使用。
            2。Hbase、Cassandra 这样的列式存储数据库
                特点：
                    是数据不像传统数据库以行为单位来存储，而是以列来存储
                场景：
                    适用于一些离线数据统计的场景
            3。像 MongoDB、CouchDB 这样的文档型数据库
                特点：
                    是 Schema Free（模式自由），数据表中的字段可以任意扩展
                例子：
                    1。电商系统中的商品有非常多的字段，并且不同品类的商品的字段也都不尽相同
                    2。使用关系型数据库就需要不断增加字段支持，而用文档型数据库就简单很多了。
        可以替代关系型数据库的银弹原因：（误区）
            1。弥补了传统数据库在性能方面的不足；
            2。数据库变更方便，不需要更改原先的数据结构；
            3。适合互联网项目常见的大数据量的场景；
            误区：
                1。业务开发的场景下还是需要利用 SQL 语句的强大的查询功能
                2。以及传统数据库事务和灵活的索引等功能
                3。NoSQL 只能作为一些场景的补充。
        使用 NoSQL 提升写入性能
            背景：
                1。数据库系统大多使用的是传统的机械磁盘
                2。对于机械磁盘的访问方式有两种
                    1。随机 IO；
                        缺点：
                            1。需要花费时间做昂贵的磁盘寻道
                            2。读写效率要比顺序 IO 小两到三个数量级
                        思路：
                            提升写入的性能就要尽量减少随机 IO。
                        例子一：
                            更新 datafile 和索引文件则是在做随机 IO
                            目的：
                                为了减少随机 IO 的发生
                            优化：
                                写入时先写入内存，然后批量刷新到磁盘上
                            缺点：
                                随机 IO 还是会发生
                        例子二：
                            1。索引在 InnoDB 引擎中是以 B+ 树方式来组织的，而 MySQL 主键是聚簇索引（一种索引类型，数据与索引数据放在一起）
                            2。既然数据和索引数据放在一起，那么在数据插入或者更新的时候
                            3。我们需要找到要插入的位置，再把数据写到特定的位置上，这就产生了随机的 IO
                            缺点：
                                一旦发生了页分裂，就不可避免会做数据的移动，也会极大地损耗写入性能。
                            问题：
                                NoSQL 数据库是怎么解决这个问题的呢？
                                方案一:(提升性能)
                                    很多 NoSQL 数据库都在使用的基于 LSM 树的存储引擎，这种算法使用最多，
                                    LSM 树：
                                        参考：com/suixingpay/profit/document/高并发系统设计40问/图片/第11讲LSM树示意图.png
                                        概念：
                                            牺牲了一定的读性能来换取写入数据的高性能
                                        应用：
                                            Hbase、Cassandra、LevelDB 都是用这种算法作为存储的引擎
                                        原理：
                                            写数据：
                                                1。数据首先会写入到一个叫做 MemTable 的内存结构中
                                                    说明：
                                                        在 MemTable 中数据是按照写入的 Key 来排序的
                                                2。一般会通过写 Write Ahead Log 的方式将数据备份在磁盘上
                                                    目的：
                                                        防止 MemTable 里面的数据因为机器掉电或者重启而丢失
                                                3。MemTable 在累积到一定规模时，它会被刷新生成一个新的文件
                                                    文件：SSTable（Sorted String Table）
                                                4。当 SSTable 达到一定数量时，我们会将这些 SSTable 合并，减少文件的数量
                                                    扩展：
                                                        因为 SSTable 都是有序的，所以合并的速度也很快
                                            读数据：
                                                1。当从 LSM 树里面读数据时，我们首先从 MemTable 中查找数据
                                                2。如果数据没有找到，再从 SSTable 中查找数据
                                                    优点：
                                                        查找的效率是很高的
                                                        原因：
                                                            存储的数据都是有序的
                                                    缺点：
                                                        读取的效率会低于 B+ 树索引
                                                        原因：
                                                            数据被拆分成多个 SSTable
                                        类似的算法：
                                            TokuDB 使用的名为 Fractal tree 的索引结构
                                            共同点：
                                                核心思想就是将随机 IO 变成顺序的 IO，从而提升写入的性能
                                方案二：（作为传统关系型数据库的补充）
                                    垂直电商项目规划搜索的功能，需要支持按照商品的名称模糊搜索到对应的商品
                                        在数据库里面执行一条类似：
                                            命令：
                                                “select * from product where name like ‘%***%’”的语句吗？
                                        问题：
                                            并不是都能使用到索引只有后模糊匹配的语句才能使用索引
                                                例子一：
                                                    “select * from product where name like ‘% 电冰箱’”
                                                    缺点：
                                                        没有使用到字段“name”上的索引，全表扫描
                                                例子二：
                                                    “select * from product where name like ‘索尼 %’”
                                                    优点：
                                                        使用了“name”上的索引
                                            解决途径：
                                                谷歌上搜索了一下解决方案
                                            方法：
                                                使用开源组件 Elasticsearch 来支持搜索的请求
                                                    核心思想：
                                                        基于“倒排索引”来实现的
                                                            倒排索引：
                                                                例子：
                                                                    1。指将记录中的某些列做分词，然后形成的分词与记录 ID 之间的映射关系
                                                                        参考：
                                                                            com/suixingpay/profit/document/高并发系统设计40问/图片/第11讲倒排索引.png
                                                                    2。我们将商品名称做简单的分词，然后建立起分词和商品 ID 的对应关系
                                                                    3。如果用户搜索电冰箱，就可以给他展示商品 ID 为 1 和 3 的两件商品了
                                                    概念：
                                                        1。Elasticsearch 作为一种常见的 NoSQL 数据库
                                                        2。就以倒排索引作为核心技术原理，为你提供了分布式的全文搜索服务
                                                    优点：
                                                        1。在传统的关系型数据库中使用 SQL 语句是很难实现的
                                                        2。NoSQL 可以在某些业务场景下代替传统数据库提供数据存储服务
                                方案三：(扩展性)
                                    例子：
                                        1。电商系统增加了评论系统，开始你的评估比较乐观，觉得电商系统的评论量级不会增长很快
                                        2。所以就为它分了 8 个库，每个库拆分成 16 张表。
                                        3。评论系统上线之后，存储量级增长的异常迅猛，你不得不将数据库拆分成更多的库表，
                                        问题：
                                            数据也要重新迁移到新的库表中，过程非常痛苦，而且数据迁移的过程也非常容易出错。
                                        思路：
                                            1。考虑使用 NoSQL 数据库来彻底解决扩展性的问题
                                            2。经过调研你发现它们在设计之初就考虑到了分布式和大数据存储的场景
                                            比如：
                                                MongoDB 就有三个扩展性方面的特性。
                                                1。Replica
                                                    概念：
                                                        1。也叫做副本集，你可以理解为主从分离，也就是通过将数据拷贝成多份来保证当主挂掉后数据不会丢失
                                                        2。Replica 还可以分担读请求。Replica 中有主节点来承担写请求，并且把对数据变动记录到 oplog 里（类似于 binlog）
                                                        3。从节点接收到 oplog 后就会修改自身的数据以保持和主节点的一致
                                                        4。一旦主节点挂掉，MongoDB 会从从节点中选取一个节点成为主节点，可以继续提供写数据服务。

                                                2。Shard
                                                    概念：
                                                        也叫做分片，你可以理解为分库分表，即将数据按照某种规则拆分成多份，存储在不同的机器上
                                                    一般需要三个角色来支持：
                                                        1。Shard Server：实际存储数据的节点，是一个独立的 Mongod 进程
                                                        2。Config Server：是一组 Mongod 进程，主要存储一些元信息
                                                            例子：
                                                                哪些分片存储了哪些数据等；
                                                        3。Route Server：不实际存储数据，仅仅作为路由使用，它从 Config Server 中获取元信息后，将请求路由到正确的 Shard Server 中。

                                                3。负载均衡
                                                    概念：
                                                        1。当 MongoDB 发现 Shard 之间数据分布不均匀，会启动 Balancer 进程对数据做重新的分配
                                                        2。最终让不同 Shard Server 的数据可以尽量的均衡。
                                                        3。当我们的 Shard Server 存储空间不足需要扩容时，数据会自动被移动到新的 Shard Server 上
                                                    优点：
                                                        减少了数据迁移和验证的成本。
                                        优点：
                                            1。内置的扩展性方面的特性可以让我们不再需要对数据库做分库分表和主从分离
                                            2。也是对传统数据库一个良好的补充


                    2。顺序 IO：
                        例子：
                            MySQL 的 InnoDB 存储引擎来说，更新 binlog、redolog、undolog 都是在做顺序 IO

12 | 缓存：数据库成为瓶颈后，动态数据的查询要如何加速？
    背景：
        1。数据库分了主库和从库，数据也被切分到多个数据库节点上
        2。但随着并发的增加，存储数据量的增多，数据库的磁盘 IO 逐渐成了系统的瓶颈
        思考：
            需要一种访问更快的组件来降低请求响应时间，提升整体系统性能
        方法：
            使用缓存
    问题一：
        1。什么是缓存
            概念：
                1。是一种存储数据的组件，它的作用是让对数据的请求更快地返回。
                    误解：
                        经常会把缓存放在内存中来存储， 所以有人就把内存和缓存画上了等号
                        原因：
                            某些场景下我们可能还会使用 SSD 作为冷数据的缓存
                            例子：
                                360 开源的 Pika 就是使用 SSD 存储数据解决 Redis 的容量瓶颈的。
                2。位于速度相差较大的两种硬件之间，用于协调两者数据传输速度差异的结构
                    参考：
                        com/suixingpay/profit/document/高并发系统设计40问/图片/第12讲访问磁盘内存寻址的时间.png
                        分析：
                            做一次内存寻址大概需要 100ns，而做一次磁盘的查找则需要 10ms。
                            类似：
                                一次内存寻址的时间类比为一个课间，那么做一次磁盘查找相当于度过了大学的一个学期
                            优点：
                                1。使用内存作为缓存的存储介质相比于以磁盘作为主要存储介质的数据库来说，性能上会提高多个数量级
                                2。也能够支撑更高的并发量
                                3。内存是最常见的一种缓存数据的介质。
            例子一：
                TLB：（Translation Lookaside Buffer）
                    背景：
                        1。Linux 内存管理是通过一个叫做 MMU（Memory Management Unit）的硬件
                        2。来实现从虚拟地址到物理地址的转换的，但是如果每次转换都要做这么复杂计算的话
                            缺点：
                                会造成性能的损耗
                            方法：
                                TLB
                    概念：
                        一种缓存组件，缓存复杂运算的结果
                    思想：
                        来缓存最近转换过的虚拟地址，和物理地址的映射
            例子二：
                平时经常刷的抖音
                1。如果我们在打开一个视频的时候才开始下载数据的话，无疑会增加视频的打开速度
                    缺点：
                        播放过程中会有卡顿
                        优化：
                            播放器中通常会设计一些缓存的组件，在未打开视频时缓存一部分视频数据
                        具体：
                            1。服务端可能一次会返回三个视频信息，我们在播放第一个视频的时候
                            2。播放器已经帮我们缓存了第二、三个视频的部分数据
                            3。这样在看第二个视频的时候就可以给用户“秒开”的感觉。
            例子三：
                HTTP 协议也是有缓存机制的。
                流程：
                    1。当我们第一次请求静态的资源时，比如一张图片，服务端除了返回图片信息，在响应头里面还有一个“Etag”的字段
                    2。浏览器会缓存图片信息以及这个字段的值
                    3。当下一次再请求这个图片的时候，浏览器发起的请求头里面会有一个“If-None-Match”的字段，
                    4。并且把缓存的“Etag”的值写进去发给服务端。
                    5。服务端比对图片信息是否有变化，如果没有，则返回浏览器一个 304 的状态码，浏览器会继续使用缓存的图片信息
                方式：
                    缓存协商
                优点：
                    可以减少网络传输的数据大小，从而提升页面展示的性能。
                    参考：
                        com/suixingpay/profit/document/高并发系统设计40问/图片/第12讲http缓存机制.png

        2。缓存与缓冲区
            缓存：
                作用：
                    1。可以提高低速设备的访问速度
                    2。减少复杂耗时的计算带来的性能问题。
                理想：
                    理论上说，我们可以通过缓存解决所有关于“慢”的问题
                    例子：
                        比如从磁盘随机读取数据慢，从数据库查询数据慢，只是不同的场景消耗的存储成本不同。

            缓冲区：
                概念：
                    是一块临时存储数据的区域，这些数据后面会被传输到其他设备上。
                类似：
                    缓冲区更像“消息队列篇”中即将提到的消息队列，用以弥补高速设备和低速设备通信时的速度差
                    例子：
                        1。我们将数据写入磁盘时并不是直接刷盘，而是写到一块缓冲区里面，内核会标识这个缓冲区为脏
                        2。当经过一定时间或者脏缓冲区比例到达一定阈值时，由单独的线程把脏块刷新到硬盘上
                    优点：
                        避免了每次写数据都要刷盘带来的性能问题

    缓存分类
        1。静态缓存
            web1.0时期：
                流程：
                    1。通过生成 Velocity 模板或者静态 HTML 文件来实现静态缓存
                    2。在 Nginx 上部署静态缓存可以减少对于后台应用服务器的压力
                例子：
                    1。新浪，网易这种门户网站一样
                    2。我们在做一些内容管理系统的时候，后台会录入很多的文章，前台在网站上展示文章内容
                        通过数据库存储的缺点：
                            这样会对数据库造成很大的压力
                    3。用户在访问的时候会优先访问 Web 服务器上的静态页面
                    4。在对旧的文章执行一定的清理策略后，依然可以保证 99% 以上的缓存命中率。
            场景：
                静态数据访问

        2。分布式缓存
            例子：
                Memcached、Redis 就是分布式缓存
            优点：
                一些分布式的方案组成集群可以突破单机的限制
            场景：
                动态请求

        3。热点本地缓存
            场景：
                遇到极端的热点数据查询的时候。
            概念：
                主要部署在应用服务器的代码中
            优点：
                阻挡热点查询对于分布式缓存节点或者数据库的压力。
            例子：
                某一位明星在微博上有了热点话题，“吃瓜群众”会到他 (她) 的微博首页围观，这就会引发这个用户信息的热点查询。
                现象：
                    通常会命中某一个缓存节点或者某一个数据库分区，短时间内会形成极高的热点查询。
                方法：
                    会在代码中使用一些本地缓存方案
                    如：HashMap，Guava Cache 或者是 Ehcache 等
                优点：
                    1。不需要跨网络调度，速度极快
                    2。可以来阻挡短时间内的热点查询
                    案例：
                        垂直电商系统的首页有一些推荐的商品，这些商品信息是由编辑在后台录入和变更
                    分析：
                        1。编辑录入新的商品或者变更某个商品的信息后，在页面的展示是允许有一些延迟的
                        2。比如说 30 秒的延迟，并且首页请求量最大，即使使用分布式缓存也很难抗住
                    方法：
                        1。使用 Guava Cache 来将所有的推荐商品的信息缓存起来
                        2。并且设置每隔 30 秒重新从数据库中加载最新的所有商品。
                    代码：
                        CacheBuilder<String, List<Product>> cacheBuilder = CacheBuilder.newBuilder().maximumSize(maxSize).recordStats(); // 设置缓存最大值
                        cacheBuilder = cacheBuilder.refreshAfterWrite(30, TimeUnit.Seconds); // 设置刷新间隔

                        LoadingCache<String, List<Product>> cache = cacheBuilder.build(new CacheLoader<String, List<Product>>() {
                            @Override
                            public List<Product> load(String k) throws Exception {
                            return productService.loadAll(); // 获取所有商品
                            }
                        });
                    过程：
                        1。获取所有商品信息的时候可以调用 Loading Cache 的 get 方法，就可以优先从本地缓存中获取商品信息
                        2。如果本地缓存不存在，会使用 CacheLoader 中的逻辑从数据库中加载所有的商品。
            注意：
                1。本地缓存是部署在应用服务器中，而我们应用服务器通常会部署多台
                2。当数据更新时，我们不能确定哪台服务器本地中了缓存，更新或者删除所有服务器的缓存不是一个好的选择，通常会等待缓存过期
                3。这种缓存的有效期很短，通常为分钟或者秒级别，以避免返回前端脏数据。
    缓存的优点：
        提升访问速度，从而能够抗住更高的并发
    缓存的缺点：
        1。缓存比较适合于读多写少的业务场景，并且数据最好带有一定的热点属性
            原因：
                缓存毕竟会受限于存储介质不可能缓存所有数据，那么当数据有热点属性的时候才能保证一定的缓存命中率
                例子一：
                    微博、朋友圈这种 20% 的内容会占到 80% 的流量。
                例子二：
                    当业务场景读少写多时或者没有明显热点时
                    在搜索的场景下，每个人搜索的词都会不同，没有明显的热点，那么这时缓存的作用就不明显了。


        2。缓存会给整体系统带来复杂度，并且会有数据不一致的风险
            原因：
                当更新数据库成功，更新缓存失败的场景下，缓存中就会存在脏数据
                方法：
                    考虑使用较短的过期时间或者手动清理的方式来解决。
        3。之前提到缓存通常使用内存作为存储介质，但是内存并不是无限的
            措施：
                1。在使用缓存的时候要做数据存储量级的评估，对于可预见的需要消耗极大存储成本的数据，要慎用缓存方案
                2。缓存一定要设置过期时间，这样可以保证缓存中的会是热点数据。
        4。缓存会给运维也带来一定的成本
            成本：
                需要对缓存组件有一定的了解，在排查问题的时候也多了一个组件需要考虑在内。

13 | 缓存的使用姿势（一）：如何选择缓存的读写策略？
    猜测流程：
        1。缓存的读写很简单，只需要优先读缓存
        2。缓存不命中就从数据库查询，查询到了就回种缓存
        实际情况：
            针对不同的业务场景，缓存的读写策略也是不同的。
    选择策略考虑的因素：
        1。缓存中是否有可能被写入脏数据
        2。策略的读写性能如何
        3。是否存在缓存命中率下降的情况等等
    Cache Aside（旁路缓存）策略
        案例一：
            电商系统中有一个用户表，表中只有 ID 和年龄两个字段，缓存中我们以 ID 为 Key 存储用户的年龄信息。
            问题：
                当我们要把 ID 为 1 的用户的年龄从 19 变更为 20，要如何做呢？
                思路一：(直接更新缓存)
                    先更新数据库中 ID 为 1 的记录，再更新缓存中 Key 为 1 的数据。
                    问题一：(数据不一致)
                        造成缓存和数据库中的数据不一致
                        例子：（并发问题）
                            1。A 请求将数据库中 ID 为 1 的用户年龄从 19 变更为 20
                            2。请求 B 也开始更新 ID 为 1 的用户数据，它把数据库中记录的年龄变更为 21
                            3。然后变更缓存中的用户年龄为 21。
                            4。紧接着，A 请求开始更新缓存数据，它会把缓存中的年龄变更为 20。
                            问题：
                                数据库中用户年龄是 21，而缓存中的用户年龄却是 20。
                                原因：
                                    1。变更数据库和变更缓存是两个独立的操作，而我们并没有对操作做任何的并发控制
                                    2。当两个线程并发更新它们的时候，就会因为写入顺序的不同造成数据的不一致。
                    问题二：(丢失更新)
                        另外一个问题就是丢失更新。
                        例子
                            1。假如电商系统中的账户表有三个字段：ID、户名和金额，
                            2。这个时候缓存中存储的就不只是金额信息，而是完整的账户信息了
                            3。当更新缓存中账户金额时，你需要从缓存中查询完整的账户数据，把金额变更后再写入到缓存中。
                        分析：
                            过程中存在并发问题；
                            情况一：
                                1。原有金额是 20，A 请求从缓存中读到数据，并且把金额加 1，变更成 21
                                2。在未写入缓存之前又有请求 B 也读到缓存的数据后把金额也加 1，也变更成 21
                                3。两个请求同时把金额写回缓存，这时缓存里面的金额是 21
                                现象：
                                    但是我们实际上预期是金额数加 2，这也是一个比较大的问题。
                    方法：（旁路缓存策略）
                        1。更新数据时不更新缓存，而是删除缓存中的数据
                        2。在读取数据时，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中
                        参考：
                            com/suixingpay/profit/document/高并发系统设计40问/图片/第13讲缓存读写过程.png
                        思想
                            策略数据以数据库中的数据为准，缓存中的数据是按需加载的
                        读策略：
                            1。从缓存中读取数据；
                            2。如果缓存命中，则直接返回数据；
                            3。如果缓存不命中，则从数据库中查询数据
                            4。查询到数据后，将数据写入到缓存中，并且返回给用户。
                        写策略：
                            1。更新数据库中的记录；
                            2。删除缓存记录。
                           问题一：
                                为什么要更新后删除；
                                回答：
                                    在理论上还是有缺陷的。几率不高
                                    例子：
                                        1。假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20
                                        2。在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存
                                        3。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中，造成缓存和数据库数据不一致。
                                        com/suixingpay/profit/document/高并发系统设计40问/图片/第13讲Cache Aside 策略变更图.png
                                    原因：
                                        1。缓存的写入通常远远快于数据库的写入
                                        2。实际中很难出现请求 B 已经更新了数据库并且清空了缓存，请求 A 才更新完缓存的情况
                                        3。请求 A 早于请求 B 清空缓存之前更新了缓存，那么接下来的请求就会因为缓存为空而从数据库中重新加载数据
                                        4。不会出现数据不一致的情况

                            问题二：
                                在写策略中，能否先删除缓存，后更新数据库呢？
                                回答：
                                    不行的
                                    原因：
                                        可能出现缓存数据不一致的问题
                                        例子：
                                            1。假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。
                                            2。这时，另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后
                                            3。会从数据库中读取到年龄为 20，并且写入到缓存中
                                            4。然后请求 A 继续更改数据库，将用户的年龄更新为 21
                                            结果：
                                                造成了缓存和数据库的不一致。
                                                参考：
                                                    com/suixingpay/profit/document/高并发系统设计40问/图片/第13讲缓存错误变更图.png
                            Cache Aside 缺点：
                                当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响
                                例子：
                                    1。当新注册一个用户，按照这个更新策略，你要写数据库，然后清理缓存
                                    2。可当我注册用户后立即读取用户信息，并且数据库主从分离时，会出现因为主从延迟所以读不到用户信息的情况。
                                    分析：
                                        1。插入新数据到数据库之后写入缓存，这样后续的读请求就会从缓存中读到数据了
                                        2。因为是新注册的用户，所以不会出现并发更新用户信息的情况
                                    方案一：
                                        在更新数据时也更新缓存，只是在更新缓存前先加一个分布式锁
                                        原因：
                                            这样在同一时间只允许一个线程更新缓存，就不会产生并发问题了
                                        缺点：
                                            对于写入的性能会有一些影响；

                                    方案二：
                                        在更新数据时更新缓存，只是给缓存加一个较短的过期时
                                        原因：
                                            出现缓存不一致的情况，缓存的数据也会很快地过期，对业务的影响也是可以接受
    Read/Write Through（读穿 / 写穿）策略
        核心原则：
            用户只与缓存打交道，由缓存和数据库通信，写入或者读取数据
        Write Through 的策略：
            1。先查询要写入的数据在缓存中是否已经存在
                1。存在，更新缓存中的数据，并且由缓存组件同步更新到数据库中
                2。不存在“Write Miss（写失效）”
                    方式一：Write Allocate（按写分配）
                        流程
                            写入缓存相应位置，再由缓存组件同步更新到数据库中
                    方式二：No-write allocate（不按写分配）(推荐)
                        流程：
                            不写入缓存中，而是直接更新到数据库中。
                        优点：
                            减少了一次缓存的写入，能够提升写入的性能
                            原因：
                                无论采用哪种“Write Miss”方式，我们都需要同步将数据更新到数据库中
        Read Through 策略
            步骤：
                1。先查询缓存中数据是否存在，如果存在则直接返回
                2。如果不存在，则由缓存组件负责从数据库中同步加载数据。
        参考：
            com/suixingpay/profit/document/高并发系统设计40问/图片/第13讲Read:Write Through（读穿 : 写穿）策略.png
        特点：
            1。是由缓存节点而非用户来和数据库打交道
            2。使用场景比较少见；
                原因：
                    使用的分布式缓存组件，无论是 Memcached 还是 Redis 都不提供写入数据库，自动加载数据库中的数据的功能
        场景：
            本地缓存的时候可以考虑使用这种策略
            上一节的：Guava Cache 中的 Loading Cache 就有 Read Through 策略的影子
        缺点：
            Write Through 策略中写数据库是同步的，这对于性能来说会有比较大的影响
            原因：
                相比于写缓存，同步写数据库的延迟就要高很多了
            思考：
                可否异步地更新数据库？
            回答：
                “Write Back”策略

    Write Back（写回）策略
        原理：
            1。在写入数据时只写入缓存，并且把缓存块儿标记为“脏”的
            2。而脏块儿只有被再次使用时才会将其中的数据写入到后端存储中。
        Write Back写策略：
            1。在“Write Miss”的情况下，我们采用的是“Write Allocate”的方式
            2。写入后端存储的同时要写入缓存
            3。在之后的写请求中都只需要更新缓存即可，而无需更新后端存储了
            参考：com/suixingpay/profit/document/高并发系统设计40问/图片/第13讲Write Back写策略示意图.png
        Write Back读策略：
            1。缓存命中则直接返回缓存数据
            2。如果缓存不命中则寻找一个可用的缓存块儿
                1。如果这个缓存块儿是“脏”的，就把缓存块儿中之前的数据写入到后端存储中，从后端存储加载数据到缓存块儿
                2。如果不是脏的，则由缓存组件将后端存储中的数据加载到缓存中
            3。最后我们将缓存设置为不是脏的，返回数据就好了。
            参考：
                com/suixingpay/profit/document/高并发系统设计40问/图片/第13讲Write Back读策略示意图.png

        应用场景：
            1。在向磁盘中写数据时采用的就是这种策略
            2。操作系统层面的 Page Cache
            3。日志的异步刷盘
            4。消息队列中消息的异步写入磁盘
            5。不能被应用到我们常用的数据库和缓存的场景中
        优点：
            避免了直接写磁盘造成的随机写问题
            原因：
                内存和写磁盘的随机 I/O 的延迟相差了几个数量级
        缺点：
            缓存中的脏块儿数据丢失
            原因：
                缓存一般使用内存，而内存是非持久化的，所以一旦缓存机器掉电
        建议：
            1。在向低速设备写入数据的时候，可以在内存里先暂存一段时间的数据
            2。甚至做一些统计汇总，然后定时地刷新到低速设备上
            例子：
                1。你在统计你的接口响应时间的时候，需要将每次请求的响应时间打印到日志中，然后监控系统收集日志后再做统计
                2。但是如果每次请求都打印日志无疑会增加磁盘 I/O，那么不如把一段时间的响应时间暂存起来
                3。经过简单的统计平均耗时，每个耗时区间的请求数量等等，然后定时地，批量地打印到日志中。

14 | 缓存的使用姿势（二）：缓存如何做到高可用？
    背景：
        1。Web 层和数据库层之间增加了缓存层，请求会首先查询缓存
        2。只有当缓存中没有需要的数据时才会查询数据库。
    缓存命中率：
        公式：
            缓存命中率 = 命中缓存的请求数 / 总请求数
            核心缓存的命中率需要维持在 99% 甚至是 99.9%；，哪怕下降 1%，系统都会遭受毁灭性的打击。
        例子：
            1。假设系统的 QPS 是 10000/s，每次调用会访问 10 次缓存或者数据库中的数据
            2。那么当缓存命中率仅仅减少 1%，数据库每秒就会增加 10000 * 10 * 1% = 1000 次请求
            3。我们单个 MySQL 节点的读请求量峰值就在 1500/s 左右
            现象
                增加的这 1000 次请求很可能会给数据库造成极大的冲击
    思考：
        命中率仅仅下降 1% 造成的影响就如此可怕，更不要说缓存节点故障了
    问题：
        如何来解决这个问题，提升缓存的可用性呢？(单点部署)
            方案一：
                客户端方案
                概念：
                    在客户端配置多个缓存的节点，通过缓存写入和读取算法策略来实现分布式，提高缓存的可用性
                关注点：
                    写数据：
                        概念：
                            把被写入缓存的数据分散到多个节点中，即进行数据分片
                    读数据：
                        概念：
                            可以利用多组的缓存来做容错，提升缓存系统的可用性
                        策略：
                            1。主从
                            2。多副本
                    1。缓存数据如何分片
                        思路：
                            将数据分片，依照分片算法将数据打散到多个不同的节点上，每个节点上存储部分数据。
                            原因：
                                单一的缓存节点受到机器内存、网卡带宽和单节点请求量的限制，不能承担比较高的并发
                            优点：
                                在某个节点故障的情况下，其他节点也可以提供服务，保证了一定的可用性
                        分片算法：
                            1。Hash 分片算法
                                原理：
                                    对缓存的 Key 做哈希计算，然后对总的缓存节点个数取余
                                例子：
                                    1。比如说，我们部署了三个缓存节点组成一个缓存的集群，当有新的数据要写入时
                                    2。我们先对这个缓存的 Key 做比如 crc32 等 Hash 算法生成 Hash 值
                                    3。然后对 Hash 值模 3，得出的结果就是要存入缓存节点的序号。
                                优点：
                                    简单易理解
                                缺点：
                                    当增加或者减少缓存节点时，缓存总的节点个数变化造成计算出来的节点发生变化，从而造成缓存失效不可用
                                    优化方法：
                                        一致性 Hash 算法
                                场景：
                                    缓存命中率下降不敏感

                            2。一致性 Hash 分片算法
                                原理：
                                    写数据：
                                        1。我们将整个 Hash 值空间组织成一个虚拟的圆环
                                        2。然后将缓存节点的 IP 地址或者主机名做 Hash 取值后，放置在这个圆环上
                                    读数据：
                                        1。先对这个 Key 做同样的 Hash 取值，确定在环上的位置
                                        2。确定在环上的位置，然后按照顺时针方向在环上“行走”
                                        3。遇到的第一个缓存节点就是要访问的节点
                                优点：
                                    1。在增加和删除节点时，只有少量的 Key 会“漂移”到其它节点上
                                    2。大部分的 Key 命中的节点还是会保持不变，从而可以保证命中率不会大幅下降。
                                缺点：
                                    1。缓存节点在圆环上分布不平均，会造成部分缓存节点的压力较大
                                        例子：
                                            1。有三个节点 A、B、C 承担整体的访问，每个节点的访问量平均
                                            2。A 故障后，B 将承担双倍的压力（A 和 B 的全部请求）
                                            3。当 B 承担不了流量 Crash 后，C 也将因为要承担原先三倍的流量而 Crash
                                            现象：
                                                整体缓存系统的雪崩。
                                                方法：
                                                    虚拟节点：
                                                        参考：https://www.cnblogs.com/cherish010/p/9662746.html
                                                    原理：
                                                        将一个缓存节点计算多个 Hash 值分散到圆环的不同位置
                                                    优点：
                                                        1。既实现了数据的平均，而且当某一个节点故障或者退出的时候
                                                        2。原先承担的 Key 将以更加平均的方式分配到其他节点上，从而避免雪崩的发生。
                                    2。一致性 Hash 算法的脏数据问题
                                        例子：
                                            1。在集群中有两个节点 A 和 B，客户端初始写入一个 Key 为 k，值为 3 的缓存数据到 Cache A 中
                                            2。更新K值时，客户端和缓存A发生了故障，写入请求到CacheB中
                                            3。缓存 A 和客户端的连接恢复，客户端获取k值时，
                                            现象：
                                                获取到存在 Cache A 中的脏数据 3，而不是 Cache B 中的 4。
                                            方法：
                                                设置缓存的过期时间，当发生漂移时，之前存储的脏数据可能已经过期，就可以减少存在脏数据的几率。

                        优点：
                            缓解缓存节点的存储和访问压力
                        缺点：
                            让缓存的使用更加复杂
                            例子：
                                1。在 MultiGet（批量获取）场景下，单个节点的访问量并没有减少
                                2。同时节点数太多会造成缓存访问的 SLA（即“服务等级协议”，SLA 代表了网站服务可用性）得不到很好的保证
                                    原因：
                                        根据木桶原则，SLA 取决于最慢、最坏的节点的情况，节点数过多也会增加出问题的概率
                                    方法：
                                        推荐 4 到 6 个节点为佳。

                    2。Memcached 的主从机制
                        背景：
                            Redis 本身支持主从的部署方式，但是 Memcached 并不支持
                        问题：
                            Memcached 的主从机制是如何在客户端实现的
                            案例：
                                单个主节点故障导致数据穿透的问题
                                1。我为每一组 Master 配置一组 Slave，更新数据时主从同步更新
                                2。读取时，优先从 Slave 中读数据，如果读取不到数据就穿透到 Master 读取
                                3。并且将数据回种到 Slave 中以保持 Slave 数据的热度。
                        优点：
                            1。当某一个 Slave 宕机时，还会有 Master 作为兜底
                            2。不会有大量请求穿透到数据库的情况发生，提升了缓存系统的高可用性

                    3。多副本
                        场景：
                            一组 Slave 通常来说并不能完全承担所有流量，Slave 网卡带宽可能成为瓶颈。
                        流程：
                            1。当客户端发起查询请求时，请求首先会先从多个副本组中选取一个副本组发起查询
                            2。如果查询失败，就继续查询 Master/Slave，并且将查询的结果回种到所有副本组中，避免副本组中脏数据的存在。
                        特点：
                            1。只存储了更加热的数据
                                原因：
                                    基于成本的考虑，每一个副本组容量比 Master 和 Slave 要小
                            2。Master 和 Slave 的请求量会大大减少，为了保证它们存储数据的热度，
                    缺点：
                        只能在单一语言系统之间复用

            方案二：
                中间代理层方案
                概念：
                    1。在应用代码和缓存节点之间增加代理层，客户端所有的写入和读取的请求都通过代理层
                    2。而代理层中会内置高可用策略，帮助提升缓存系统的高可用。
                优点：
                    跨语言：
                应用：
                    1。 Facebook 的Mcrouter
                    2。Twitter 的Twemproxy
                    3。豌豆荚的Codis
                    参考：
                        com/suixingpay/profit/document/高并发系统设计40问/图片/第14讲中间代理层方案示意图.png
                    分析：
                        1。缓存的读写请求都是经过代理层完成的
                        2。代理层是无状态的，主要负责读写请求的路由功能
                        3。并且在其中内置了一些高可用的逻辑，不同的开源中间代理层方案中使用的高可用策略各有不同
            方案三：
                服务端方案
                例子：
                    Redis 2.4 版本后提出的 Redis Sentinel 方案。
                优点：
                    在主节点挂了以后自动将从节点提升为主节点，保证整体集群的可用性，
                概念：
                    1。Redis Sentinel 也是集群部署的
                        原因：
                            避免 Sentinel 节点挂掉造成无法自动故障恢复的问题
                    2。每一个 Sentinel 节点都是无状态的
                原理：
                    1。在 Sentinel 中会配置 Master 的地址，Sentinel 会时刻监控 Master 的状态
                    2。当发现 Master 在配置的时间间隔内无响应，就认为 Master 已经挂了
                    3。Sentinel 会从从节点中选取一个提升为主节点，并且把所有其他的从节点作为新主的从节点
                    4。Sentinel 集群内部在仲裁的时候，会根据配置的值来决定当有几个 Sentinel 节点认为主挂掉可以做主从切换的操作
                    5。集群内部需要对缓存节点的状态达成一致才行。
                    参考：
                        com/suixingpay/profit/document/高并发系统设计40问/图片/第14讲Redis Sentinel部署架构图.png

15 | 缓存的使用姿势（三）：缓存穿透了怎么办？
    背景：
        1。一般来说，我们的核心缓存的命中率要保持在 99% 以上
        2。非核心缓存的命中率也要尽量保证在 90%
        3。如果低于这个标准，那么你可能就需要优化缓存的使用方式了
    什么是缓存穿透
        概念：
            1。从缓存中没有查到数据，而不得不从后端系统（比如数据库）中查询的情况。
            2。少量的缓存穿透不可避免，对系统也是没有损害的
                原因：
                    1。缓存系统在容量上是有限的，不可能存储系统所有的数据，那么在查询未缓存数据的时候就会发生缓存穿透。
                    2。互联网系统的数据访问模型一般会遵从“80/20 原则”
                        1。经常访问 20% 的热点数据
                        2。另外的 80% 的数据则不会被经常访问
                理论：
                    1。在有限的缓存空间里存储 20% 的热点数据就可以有效地保护脆弱的后端系统了
                    2。放弃缓存另外 80% 的非热点数据了
                    优点：
                        少量的缓存穿透是不可避免的，但是对系统是没有损害的。

        问题：
            那么什么样的缓存穿透对系统有害呢？
            答案：
                大量的穿透请求超过了后端系统的承受范围，造成了后端系统的崩溃
            类似：
                少量的请求比作毛毛细雨，那么一旦变成倾盆大雨，引发洪水，冲倒房屋，肯定就不行了。

    缓存穿透的解决方案
        案例：
            1。你的电商系统的用户表中，我们需要通过用户 ID 查询用户的信息
            2。缓存的读写策略采用 Cache Aside 策略
        问题：
            如果要读取一个用户表中未注册的用户，会发生什么情况呢？
            流程：
                1。我们会先读缓存，再穿透读数据库。
                2。由于用户并不存在，所以缓存和数据库中都没有查询到数据，因此也就不会向缓存中回种数据
                3。这样当再次请求这个用户数据的时候还是会再次穿透到数据库
            缺点：
                缓存并不能有效地阻挡请求穿透到数据库上，它的作用就微乎其微了。
                方法：
                    回种空值
        方案一：
            回种空值
                例子一：
                    1。数据库中并不存在用户的数据，这就造成无论查询多少次
                    2。数据库中永远都不会存在这个用户的数据，穿透永远都会发生。
                例子二：
                    1。由于代码的 bug 导致查询数据库的时候抛出了异常
                    2。这样可以认为从数据库查询出来的数据为空，同样不会回种缓存。
                实现：
                    1。从数据库中查询到空值或者发生异常时，我们可以向缓存中回种一个空值。
                    2。给这个空值加一个比较短的过期时间，让空值在短时间之内能够快速过期淘汰
                        原因：
                            空值并不是准确的业务数据，并且会占用缓存的空间
                    伪代码：
                        Object nullValue = new Object();
                        try {
                            Object valueFromDB = getFromDB(uid); // 从数据库中查询数据
                            if (valueFromDB == null) {
                                cache.set(uid, nullValue, 10);   // 如果从数据库中查询到空值，就把空值写入缓存，设置较短的超时时间
                            } else {
                                cache.set(uid, valueFromDB, 1000);
                            }
                        } catch(Exception e) {
                            cache.set(uid, nullValue, 10);
                        }
                优点：
                    能够阻挡大量穿透的请求
                场景：
                    情况一：
                        如果有大量获取未注册用户信息的请求，缓存内就会有有大量的空值缓存
                        缺点：
                            也就会浪费缓存的存储空间
                    情况二：
                        如果缓存空间被占满了，还会剔除掉一些已经被缓存的用户信息
                        缺点：
                            造成缓存命中率的下降
                分析：
                    1。使用的时候应该评估一下缓存容量是否能够支撑
                    2。如果需要大量的缓存节点来支持，那么就无法通过通过回种空值的方式来解决
                    考虑使用布隆过滤器
        方案二
            使用布隆过滤器
                概念：
                    1。用来判断一个元素是否在一个集合中
                    2。这种算法由一个二进制数组和一个 Hash 算法组成
                原理：
                    1。把集合中的每一个值按照提供的 Hash 算法算出对应的 Hash 值
                    2。然后将 Hash 值对数组长度取模后得到需要计入数组的索引
                    3。并且将数组这个位置的值从 0 改成 1
                        说明：
                            在判断一个元素是否存在于这个集合中，这个元素按照相同的算法计算出索引值
                                1。位置的值为 1 就认为这个元素在集合中
                                2。否则则认为不在集合中
                                参考：
                                    com/suixingpay/profit/document/高并发系统设计40问/图片/第15讲布隆过滤器示意图.png
                问题：
                    如何使用布隆过滤器来解决缓存穿透的问题呢？
                案例：
                    1。以存储用户信息的表为例进行讲解。首先，我们初始化一个很大的数组
                    2。比方说长度为 20 亿的数组，接下来我们选择一个 Hash 算法
                    3。然后我们将目前现有的所有用户的 ID 计算出 Hash 值并且映射到这个大数组中
                    4。映射位置的值设置为 1，其它值设置为 0。
                    注意：
                        1。新注册的用户除了需要写入到数据库中之外
                        2。它也需要依照同样的算法更新布隆过滤器的数组中，相应位置的值
                查询过程：
                    参考：
                        com/suixingpay/profit/document/高并发系统设计40问/图片/第15讲查询场景下使用的布隆过滤器.png
                    1。查询某一个用户的信息时，我们首先查询这个 ID 在布隆过滤器中是否存在
                    2。如果不存在就直接返回空值，而不需要继续查询数据库和缓存
                    优点：
                        极大地减少异常查询带来的缓存穿透。
                优点：
                    1。极高的性能，无论是写入操作还是读取操作，时间复杂度都是 O(1)，是常量值
                    2。在空间上，相对于其他数据结构它也有很大的优势
                        例子：
                            1。20 亿的数组需要 2000000000/8/1024/1024 = 238M 的空间
                            2。如果使用数组来存储，假设每个用户 ID 占用 4 个字节的空间，
                                那么存储 20 亿用户需要 2000000000 * 4 / 1024 / 1024 = 7600M，是布隆过滤器的 32 倍。
                缺点：
                    1。在判断元素是否在集合中时是有一定错误几率的
                        例子：
                            它会把不是集合中的元素判断为处在集合中；
                        问题
                            主要是 Hash 算法的问题
                            原因：
                                1。布隆过滤器是由一个二进制数组和一个 Hash 算法组成的
                                2。Hash 算法存在着一定的碰撞几率。
                                    碰撞的含义：
                                        不同的输入值经过 Hash 运算后得到了相同的 Hash 结果。
                                  思考：
                                    为什么不映射成更长的 Hash 值呢？
                                        原因：
                                            更长的 Hash 值会带来更高的存储成本和计算成本
                                        例子：
                                            1。即使使用 32 位的 Hash 算法，它的值空间长度是 2 的 32 次幂减一，约等于 42 亿
                                            2。用来映射 20 亿的用户数据，碰撞几率依然有接近 50%。
                            现象：
                                产生了误判
                                    例子：
                                        1。Hash 的碰撞就造成了两个用户 ID ，A 和 B 会计算出相同的 Hash 值
                                        2。那么如果 A 是注册的用户，它的 Hash 值对应的数组中的值是 1
                                        3。那么 B 即使不是注册用户，它在数组中的位置和 A 是相同的，对应的值也是 1
                                    特点：
                                        1。当布隆过滤器判断元素在集合中时，这个元素可能不在集合中
                                        2。但是一旦布隆过滤器判断这个元素不在集合中时，它一定不在集合中。
                                    思路：
                                        1。布隆过滤器虽然存在误判的情况，但是还是会减少缓存穿透的情况发生
                                        2。只是我们需要尽量减少误判的几率，这样布隆过滤器的判断正确的几率更高，对缓存的穿透也更少
                                    方法：
                                        1。使用多个 Hash 算法为元素计算出多个 Hash 值
                                        2。只有所有 Hash 值对应的数组中的值都为 1 时，才会认为这个元素在集合中。
                    2。不支持删除元素。
                        背景：
                            布隆过滤器不支持删除元素的缺陷也和 Hash 碰撞有关
                        例子：
                            1。假如两个元素 A 和 B 都是集合中的元素，它们有相同的 Hash 值，它们就会映射到数组的同一个位置
                            2。这时我们删除了 A，数组中对应位置的值也从 1 变成 0
                                现象：
                                    那么在判断 B 的时候发现值是 0，也会判断 B 是不在集合中的元素，就会得到错误的结论。
                                方案：
                                    数组中不再只有 0 和 1 两个值，而是存储一个计数
                                    例子：
                                        1。比如如果 A 和 B 同时命中了一个数组的索引，那么这个位置的值就是 2，
                                        2。如果 A 被删除了就把这个值从 2 改为 1
                                        2。这个方案中的数组不再存储 bit 位，而是存储数值
                                    缺点：
                                        会增加空间的消耗
                        注意：
                            依据业务场景来选择是否能够使用布隆过滤器
                            例子：
                                1。像是注册用户的场景下，因为用户删除的情况基本不存在
                                2。所以还是可以使用布隆过滤器来解决缓存穿透的问题的。
                建议：
                    1。选择多个 Hash 函数计算多个 Hash 值，这样可以减少误判的几率；
                    2。使用时需要评估你的业务场景下需要多大的内存，存储的成本是否可以接受。
                        原因：
                            布隆过滤器会消耗一定的内存空间
                扩展：
                    1。回种空值和布隆过滤器是解决缓存穿透问题的两种最主要的解决方案
                    2。它们也有各自的适用场景，并不能解决所有问题。
                        例子：
                            “dog-pile effect”（狗桩效应）
                                1。当有一个极热点的缓存项，它一旦失效会有大量请求穿透到数据库


                            方案一：
                                流程：
                                    1。控制在某一个热点缓存项失效之后启动一个后台线程
                                    2。穿透到数据库，将数据加载到缓存中，在缓存未加载之前
                                    3。所有访问这个缓存的请求都不再穿透而直接返回
                            方案二：
                                流程
                                    1。通过在 Memcached 或者 Redis 中设置分布式锁，
                                    2。只有获取到锁的请求才能够穿透到数据库。
                                优点：
                                    简单
                                例子：
                                    比方说 ID 为 1 的用户是一个热点用户，当他的用户信息缓存失效后，我们需要从数据库中重新加载数据时
                                    具体实现：
                                        1。先向 Memcached 中写入一个 Key 为"lock.1"的缓存项
                                        2。然后去数据库里面加载数据，当数据加载完成后再把这个 Key 删掉
                                        3。这时，如果另外一个线程也要请求这个用户的数据，它发现缓存中有 Key 为“lock.1”的缓存
                                        4。就认为目前已经有线程在加载数据库中的值到缓存中了，它就可以重新去缓存中查询数据
                                    优点：
                                        不再穿透数据库了。

16 | CDN：静态资源如何加速？
    静态资源请求:
        1.对于移动 APP 来说，这些静态资源主要是图片、视频和流媒体信息。
        2.对于 Web 网站来说，则包括了 JavaScript 文件，CSS 文件，静态 HTML 文件等等。
    背景:
        1。商品的图片，介绍商品使用方法的视频等等静态资源，现在都放 在了 Nginx 等 Web 服务器上
        2。它们的读请求量极大，并且对访问速度的要求很高
        3。并且占据了很高的带宽，这时会出现访问速度慢，带宽被占满影响动态请求的问题
        4。那么你就需 要考虑如何针对这些静态资源进行读加速了。
    静态资源加速的考虑点
        问题：
            我们是否也可以使用分布式缓存来解决这个问题呢?
        答案：
            否定的。
            原因：
                1。一般来说，图片和视频的大小会在几兆到几百兆之间不等，如果我们的应用服务器和分布式缓存都部署在北京的机房里
                2。这时一个杭州的用户要访问缓存中的一个视频，那这个视频文件就需要从北京传输到杭州
                3。期间会经过多个公网骨干网络，延迟很高，会让用户感觉视频打开很慢，严重影响到用户的使用体验。
                方法：(不采用)
                    那我们在杭州也自建一个机房，让用户访问杭州机房的数据就好了呀
                    缺点：
                        1。用户遍布在全国各地，有些应用可能还有国外的用户
                        2。不可能在每个地域都自建机房，这样成本太高了。

        方法：
            就近访问：
                解释：
                    北京用户访问北京的数据，杭州用户访问杭州的数据，这样才可以达到性能的最优。
            具体实现：
                在业务服务器的上层，增加一层特殊的缓存
                作用：
                    用来承担绝大部分对于静态资源的访问
                特点：
                    这一层特殊缓存的节点需要遍布在全国各地，这样可以让用户选择最近的节点访问。
                要求：
                    缓存的命中率也需要一定的保证，尽量减少访问资源存储源站的请求数量

    CDN 的关键技术
        概念：
            将静态的资源分发到，位于多个地理位置机房中的服务器上
        作用：
            很好地解决数据就近访问的问题，也就加快了静态资源的访问速度。
        考虑点：
            1。如何将用户的请求映射到 CDN 节点上;
                DNS：(Domain Name System，域名系统)
                    概念：
                        一个存储域名和 IP 地址对应关系 的分布式数据库
                    域名解析结果：
                        1。一种叫做“A 记录”，返回的是域名对应 的 IP 地址;
                        2。另一种是“CNAME 记录”，返回的是另一个域名，也就是说当前域名的解析 要跳转到另一个域名的解析上
                            例子：
                                www.baidu.com 域名的解析结果就是一个 CNAME 记录，域名的解析被跳转到 www.a.shifen.com 上了
                        问题：
                            利用 CNAME 记 录来解决域名映射问题的，具体是怎么解决的呢
                        例子：
                            1。比如你的公司的一级域名叫做 example.com，那么你可以给你的图片服务的域名定义 为“img.example.com”
                            2。然后将这个域名的解析结果的 CNAME 配置到 CDN 提供的域 名上
                            3。比如 uclound 可能会提供一个域名是“80f21f91.cdn.ucloud.com.cn”这个域名。
                            4。这样你的电商系统使用的图片地址可以是“http://img.example.com/1.jpg”。
                        解释：
                            1。用户在请求这个地址时，DNS 服务器会将域名解析到 80f21f91.cdn.ucloud.com.cn 域名 上
                            2。然后再将这个域名解析为 CDN 的节点 IP，这样就可以得到 CDN 上面的资源数据了。
                    域名分级：
                        1。根 DNS
                        2。顶级 DNS
                        3。Local DNS：
                            概念：
                                由你的运营商提供的 DNS，一般域名解析的第一站会到这里;
                        4。权威 DNS：
                            概念：
                                是自身数据库中存 储了这个域名对应关系的 DNS。
                    案例：
                        www.baidu.com 这个域名的解析过程：
                    过程：
                        1。一开始，域名解析请求先会检查本机的 hosts 文件，查看是否有 www.baidu.com 对应 的 IP;
                        2。如果没有的话，就请求 Local DNS 是否有域名解析结果的缓存，如果有就返回，标识是 从非权威 DNS 返回的结果;
                        3。如果没有，就开始 DNS 的迭代查询。
                            1。先请求根 DNS，根 DNS 返回顶级 DNS(.com) 的地址;
                            2。再请求.com 顶级 DNS，得到 baidu.com 的域名服务器地址;
                            3。再从 baidu.com 的域名服务器中查询到 www.baidu.com 对应的 IP 地址，返回这个 IP 地址 的同时，标记这个结果是来自于权威 DNS 的结果，
                            4。同时写入 Local DNS 的解析结果缓 存，这样下一次的解析同一个域名就不需要做 DNS 的迭代查询了。
                        缺点：
                            经过了向多个 DNS 服务器做查询之后，整个 DNS 的解析的时间有可能会到秒级别
                            解决思路：
                                1。在 APP 启动时，对需要解析的域名做预先解析，然后把解析的结果缓 存到本地的一个 LRU 缓存里面
                                2。同时，为 了避免 DNS 解析结果的变更造成缓存内数据失效，我们可以启动一个定时器，定期地更新 缓存中的数据。


            2。如何根据用户的地理位置信息选择到比较近的节点。
            GSLB(Global Server Load Balance，全局负载均衡)：
                概念：
                    对于部署在不同地域的服务器之间做负载均衡
                作用：
                    1。一种负载均衡服务器，让流量平均分配使得下面管理的服务器的负载更平均;
                    2。保证流量流经的服务器与流量源头在地缘上是比较接近的。

17 | 消息队列:秒杀时如何处理每秒上万次的下单请求?
    背景：
        数据库的分布式改造，各类缓存的原理和使用技巧,我们遇到的大部分场景都是读多写少
        例子：
            1。一个社区的系统初期一定是只有少量的种子用户在生产内容，而大部分的用户都 在“围观”别人在说什么
            2。此时，整体的流量比较小，而写流量可能只占整体流量的百分之 一
            3。那么即使整体的 QPS 到了 10000 次 / 秒，写请求也只是到了每秒 100 次
            4。如果要对 写请求做性能优化，它的性价比确实不太高。
    问题：
        面对的依旧是读请求过高，那么应对的措施有哪些呢?
        例子：
            1。其中秒杀抢购就是最典型的场景，假设你的商城策划了一期秒杀活动，活动在第五天的 00:00 开始，仅限前 200 名
            2。那么秒杀即将开始时，后台会显示用户正在疯狂地刷新 APP 或者浏览器来保证自 己能够尽量早的看到商品。
    分析：
        1。用户查询的是少量的商品数据，属于查询的热点数据，你可以采用缓存策略
            作用：
                将请求尽量挡在上层的缓存中
        2。能被静态化的数据，比如说商城里的图片和视频数据，尽量做到静态化，这样就可以命中 CDN 节点缓存
            作用：
                减少 Web 服务器的查询量和带宽负担
        3。Web 服务 器比如 Nginx 可以直接访问分布式缓存节点
            作用：
                避免请求到达 Tomcat 等业务服务 器。
        4。可以加上一些限流的策略
            例子：
                对于短时间之内来自某一个用户、某一个 IP 或 者某一台设备的重复请求做丢弃处理。
        优点：
            通过这几种方式，你发现自己可以将请求尽量挡在数据库之外了。
        现象：
            1。稍微缓解了读请求之后，00:00 分秒杀活动准时开始，用户瞬间向电商系统请求生成订单
            2。扣减库存，用户的这些写操作都是不经过缓存直达数据库的
            3。1 秒钟之内，有 1 万个数据 库连接同时达到，系统的数据库濒临崩溃
            方法：
                消息队列
                概念：
                    1。暂时存储数据的一个容器
                    2。是一个平衡低速系统和高速系统处理任务时间差的工具
                应用的影子：
                    1。在Java 线程池中我们就会使用一个队列来暂时存储提交的任务，等待有空闲的线程处理 这些任务;
                    2。操作系统中，中断的下半部分也会使用工作队列来实现延后执行;
                    3。在实现一个 RPC 框架时，也会将从网络上接收到的请求写到队列里，再启动若干个 工作线程来处理。
                问题：
                    如何用消息队列解决秒杀场景下的问题呢?
                分析：
                    在秒杀场景下，短时间之内数据库的写流量会很高
                思路一：
                    1。应该对数据做分库分表
                    2。如果已经做了分库分表，那么就需要扩展更多的数据库来应对更高的写流量
                    缺点：
                        无论是分库分表，还是扩充更多的数据库，都会比较复杂
                    原因：
                        你需要将数据库中的数据做迁移，这个时间就要按天甚至按周来计算了。
                    分析：
                        1。在秒杀场景下，高并发的写请求并不是持续的，也不是经常发生的
                        2。只有在秒杀活动开 始后的几秒或者十几秒时间内才会存在。
                        3。为了应对这十几秒的瞬间写高峰，就要花费几天甚 至几周的时间来扩容数据库
                        4。再在秒杀之后花费几天的时间来做缩容，这无疑是得不偿失的。
                思路二：
                    1。将秒杀请求暂存在消息队列中
                    2。然后业务服务器会响应用户“秒杀结果正在计算中”
                    3。释放了系统资源之后再处理其它用户的请求。
                    具体实现：
                        1。在后台启动若干个队列处理程序，消费消息队列中的消息
                        2。再执行校验库存、下单等逻辑
                            原因：
                                1。只有有限个队列处理线程在执行，所以落入后端数据库上的并发请求是有限的。
                        3。而请求是可以在消息队列中被短暂地堆积，当库存被消耗完之后
                        4。消息队列中堆积的请求就可以被丢弃了。
                作用一：
                    削峰填谷
                    解释：
                        1。可以削平短暂的流量高峰，虽说堆积会造成请求被短暂延迟处理
                        2。只要我们时刻监控消息队列中的堆积长度，在堆积量超过一定量时
                        3。增加队列处理机数量，来提升消息的处理能力就好了
                        4。而且秒杀的用户对于短暂延迟知晓秒杀的结果，也是有一定容忍度的。
                    注意：
                        短暂”延迟，如果长时间没有给用户公示秒杀结果，那么 用户可能就会怀疑你的秒杀活动有猫腻了
                        思路：
                            1。在使用消息队列应对流量峰值时，需要对 队列处理的时间、前端写入流量的大小
                            2。数据库处理能力做好评估，然后根据不同的量级来 决定部署多少台队列处理程序。
                        例子：
                            1。比如你的秒杀商品有 1000 件，处理一次购买请求的时间是 500ms，那么总共就需要 500s 的时间
                            2。你部署 10 个队列处理程序，那么秒杀请求的处理时间就是 50s，用户需要等待 50s 才可以看到秒杀的结果，这是可以接受的
                            3。这时会并发 10 个请求到达数 据库，并不会对数据库造成很大的压力。

                作用二：
                    异步处理
                    解释：
                        异步处理来简化秒杀请求中的业务流程，提升系统的性能。
                    例子：
                        1。秒杀场景下，我们在处理购买请求时，需要 500ms
                        2。分析了 一下整个的购买流程，发现这里面会有主要的业务逻辑，也会有次要的业务逻辑
                            1。主要的流程是生成订单、扣减库存;
                            2。次要的流程可能是我们在下单购买成功之后会给用户发 放优惠券，会增加用户的积分。
                        具体实现：
                            1。假如发放优惠券的耗时是 50ms，增加用户积分的耗时也是 50ms
                            2。那么如果我们将发放优 惠券、增加积分的操作放在另外一个队列处理机中执行
                            3。那么整个流程就缩短到了400ms，性能提升了 20%，处理这 1000 件商品的时间就变成了 400s。
                            4。如果我们还是希望 能在 50s 之内看到秒杀结果的话，只需要部署 8 个队列程序就好了。
                作用三：
                    解耦合。
                    案例：
                        1。比如数据团队对你说，在秒杀活动之后想要统计活动的数据
                        2。借此来分析活动商品的受欢迎程度、购买者人群的特点以及用户对于秒杀互动的满意程度等等指标
                    问题：
                        我们需要将大量的数据发送给数据团队，那么要怎么做呢?
                    思路一：
                        可以使用 HTTP 或者 RPC 的方式来同步地调用，也就是数据团队这边提供一 个接口，我们实时将秒杀的数据推送给它
                        缺点：
                            1。整体系统的耦合性比较强，当数据团队的接口发生故障时，会影响到秒杀系统的可用性。
                            2。当数据系统需要新的字段，就要变更接口的参数，那么秒杀系统也要随着一起变更。
                    思路二：
                        使用消息队列降低业务系统和数据系统的直接耦合度。
                        具体实现：
                            1。秒杀系统产生一条购买数据后，我们可以先把全部数据发送给消息队列
                            2。然后数据团队再订阅这个消息队列的话题，这样它们就可以接收到数据，然后再做过滤和处理了。
                        优点：
                            1。秒杀系统在这样解耦合之后，数据系统的故障就不会影响到秒杀系统了
                            2。当数据系统需要新的字段时，只需要解析消息队列中的消息，拿到需要的数据就好了。
        总结：
            1。异步处理
                作用：
                    可以简化业务流程中的步骤，提升系统性能
            2。解耦合
                作用：
                    可以削去到达秒杀系统的峰值流量，让业务逻辑的处理更加缓和
            3。削峰填谷
                作用：
                    可以将秒杀系统和数据系统解耦开，这样两个系统的任何变更都不会影响到另一个系统，

18 | 消息投递:如何保证消息仅仅被消费一次?
    背景
        1。随着业务逻辑越来越复杂，会引入更多的外部系统和服务来解决业务上的问题
            例子：
                我们会引入 Elasticsearch 来解决商品和店铺搜索的问题，也会引入审核系统
                作用：
                    来对售卖的商品、用户的评论做自动的和人工的审核
        2。你会越来越多地使用消息队列与外部系统解耦合，以及提升系统性能。
    案例：
        1。电商系统需要上一个新的红包功能:用户在购买一定数量的商品之后
        2。由你的系统给用户发一个现金的红包，鼓励用户消费
        3。由于发放红包的过程不应该在购买商品的主流程之内，所以你考虑使用消息队列来异步处理
    问题一：
        如果消息在投递的过程中发生丢失，那么用户就会因为没有得到红包而投诉
        思路：
            消息为什么会丢失
        分析：
            1。如果要保证消息只被消费一次，首先就要保证消息不会丢失。
            2。那么消息从被写入到消息队列，到被消费者消费完成，这个链路上会有哪些地方存在丢失消息的可能呢?
            3。主要存在三个场景:
                场景一：
                    在消息生产的过程中丢失消息
                    情形一：(消息丢失)
                        1。消息的生产者一般是我们的业务服务器，消息队列是独立部署在单独的服务器上的。
                        2。两者之间的网络虽然是内网，但是也会存在抖动的可能
                        3。而一旦发生抖动，消息就有可能因为网络的错误而丢失。
                        方法：
                            消息重传
                            解释：
                                1。当你发现发送超时后你就将消息重新发一次，但是你也不能无限制地重传消息
                                2。一般来说，如果不是消息队列发生故障，或者是到消息队列的网络断开了，重试 2~3 次就可以了。
                    情形二：(消息重复)
                        可能会造成消息的重复，从而导致在消费的时候会重复消费同样的消息
                        例子：
                            1。消息生产时由于消息队列处理慢或者网络的抖动，导致虽然最终写入消息队列成功
                            2。但在生产端却超时了，生产者重传这条消息就会形成重复的消息
                            3。那么针对上面的例子，直观显示在你面前的就会是你收到了两个现金红包。
                场景二：
                    在消息队列中丢失消息
                    例子：
                        1。消息在 Kafka 中是存储在本地磁盘上的，而为了减少消息存储时对磁盘的 随机 I/O
                        2。我们一般会将消息先写入到操作系统的 Page Cache 中，然后再找合适的时机刷 新到磁盘上。
                        3。Kafka 可以配置当达到某一时间间隔，或者累积一定的消息数量的时候再刷盘，也就 是所说的异步刷盘。
                        缺点：
                            如果发生机器掉电或者机器异常重启，那么 Page Cache 中还没有来得及刷盘的消息就会丢失了
                    方法一：(不建议采纳)
                        1。把刷盘的间隔设置很短，或者设置累积一条消息就就刷盘
                        2。这样频繁刷盘会对性 能有比较大的影响，而且从经验来看，出现机器宕机或者掉电的几率也不高
                    方法二：
                        以集群方式部署 Kafka 服务，通过部署多个副本备份数据，保证消息尽量不丢失。
                        具体实现：
                            1。Kafka 集群中有一个 Leader 负责消息的写入和消费，可以有多个 Follower 负责数据的备份
                            2。Follower 中有一个特殊的集合叫做 ISR(in-sync replicas)，当 Leader 故障时
                            3。新选举出来的 Leader 会从 ISR 中选择，默认 Leader 的数据会异步地复制给 Follower
                            优点：
                                在Leader 发生掉电或者宕机时，Kafka 会从 Follower 中消费消息，减少消息丢失的可能。
                            分析：
                                1。由于默认消息是异步地从 Leader 复制到 Follower 的，所以一旦 Leader 宕机
                                2。那些还没有来得及复制到 Follower 的消息还是会丢失
                                3。为了解决这个问题，Kafka 为生产者提供一 个选项叫做“acks”，当这个选项被设置为“all”时
                                4。生产者发送的每一条消息除了发给Leader 外还会发给所有的 ISR，并且必须得到 Leader 和所有 ISR 的确认后才被认为发送 成功
                                5。只有 Leader 和所有的 ISR 都挂了，消息才会丢失。
                    建议：
                        情形一：
                           如果你需要确保消息一条都不能丢失
                            方法：
                                1。建议不要开启消息队列的同步刷盘
                                2。使用集群的方式来解决，可以配置当所有 ISR Follower 都接收到消息才返回成功
                        情形二：
                            如果对消息的丢失有一定的容忍度
                            方法：
                                1。建议不部署集群，即使以集群方式部署
                                2。也建议配置只发送给一个 Follower 就可以返回成功了。
                        情形三：
                            如果我们的业务系统一般对于消息的丢失有一定的容忍度
                            方法：
                                后续补充丢失的数据
                            例子：
                                1。上面的红包系统为例，如果红包消息丢失了
                                2。我们只要后续给没有发送红包的用户补发红包就好了。
                场景三：
                    在消费的过程中存在消息丢失的可能
                    例子：
                        以 Kafka 为例来说明。一个消费者消费消息的进度是记录在消息队列集群中的
                        消费的过程：
                            1。接收消息
                            2。处理消息
                            3。更新消费进度
                    分析：
                        接收消息和处理消息的过程都可能会发生异常或者失败
                        情形一：
                            消息接收时网络发生抖动，导致消息并没有被正确的接收到
                        情形二：
                            1。处理消息时可能发生一些业务的异常导致处理流程未执行完成，这时如果更新消费进度
                            2。那么这条失败的消息就永远不会被处理了，也可以认为是丢失了。
                    方法：
                        一定要等到消息接收和处理完成后才能更新消费进度
                        缺点：
                            会造成消息重复的问题
                        例子：
                            1。比方说某一条消息在处理之后，消费者恰好宕机了
                            2。那么因为没有更新消费进度，所以当这个消费者重启之后，还会重复地消费这条消息。
    问题二：
        如何保证消息只被消费一次
        背景：
            1。为了避免消息丢失，我们需要付出两方面的代价:一方面是性能的损耗;一方面可能造成消息重复消费。
            2。想要完全的避免消息重复的发生是很难做到的
                原因：
                    为网络的抖动、机器的宕机和处理的异常都是比较难以避免的
            3。在工业上并没有成熟的方法，因此我们会把要求放宽，只要保证即使消费到了重复的消息
            4。从消费的最终结果来看和只消费一次是等同的就好了，也就是保证在消息的生产和消费的过程是“幂等”的。
        幂等：
            概念：
                多次执行同一个操作和执行一次操作，最终得到的结果是相同的
            例子一：
                1。如果我们消费一条消息的时候，要给现有的库存数量减 1
                2。如果消费两条相同的消息就 会给库存数量减 2，这就不是幂等的
            例子二：
                1。如果消费一条消息后，处理逻辑是将库存的数量设 置为 0
                2。如果当前库存数量是 10 时则减 1，这样在消费多条消息时，所得到的结果 就是相同的，这就是幂等的。
            解释：
                一件事儿无论做多少次都和做一次产生的结果是一样 的，那么这件事儿就具有幂等性。
        生产过程消息幂等性的保证
            特点：
                保证消息虽然可能在生产端产生重复，但是最终在消息队列存储时只会存储一份。
            具体实现：
                1。给每一个生产者一个唯一的 ID，并且为生产的每一条消息赋予一个唯一 ID
                2。消息队列的服务端会存储 < 生产者 ID，最后一条消息 ID> 的映射
                3。当某一个生产者产生新的消息时，消息队列服务端会比对消息 ID 是否与存储的最后一条 ID 一致
                4。如果一致，就认为是重复的消息，服务端会自动丢弃。
            消费端：
                分析：
                    幂等性的保证会稍微复杂一些，你可以从通用层和业务层两个层面来考虑。
                    通用层：
                        1。可以在消息被生产的时候，使用发号器给它生成一个全局唯一的消息 ID
                        2。消息被处理之后，把这个 ID 存储在数据库中，在处理下一条消息之前
                        3。先从数据库里面查询这个全局 ID 是否被消费过，如果被消费过就放弃消费。
                    问题：
                        1。如果消息在处理之后，还没有来得及写入数据库，
                        2。消费者宕机了重启之后发现数据库中并没有这条消息，还是会重复执行两次消费逻辑
                        方法：
                            需要引入事务机制，保证消息处理和写入数据库必须同时成功或者同时失败
                        缺点：
                            消息处理的成本就更高了
                        注意：
                            如果对于消息重复没有特别严格的要求，可以直接使用这种通用的方案， 而不考虑引入事务。
            业务层：
                这里有很多种处理方式，其中有一种是增加乐观锁的方式
                例子：
                    你的消息处理程序需要给一个人的账号加钱，那么你可以通过乐观锁的方式来解决
                具体实现：
                    1。给每个人的账号数据中增加一个版本号的字段，在生产消息时 先查询这个账户的版本号
                    2。并且将版本号连同消息一起发送给消息队列
                    3。消费端在拿到消息和版本号后，在执行更新账户金额 SQL 的时候带上版本号

19 | 消息队列:如何降低消息队列系统中消息的延迟?
    场景一：
        1。垂直电商项目中，你会在用户下单支付之后，向消息队列里面发送一条消息
        2。队列处理程序消费了消息后，会增加用户的积分，或者给用户发送优惠券
        3。那么用户在下单之后，等待几分钟或者十几分钟拿到积分和优惠券是可以接受的
        4。但是一旦消息队列出现大量堆积，用户消费完成后几小时还拿到优惠券，那就会有用户投诉了。
    分析：
        消息队列中，消息的延迟了，这其实是消费性能的问题
    问题：
        你要如何提升消费性能，保证更短的消息延迟呢？
    思路：
        1。首先需要掌握如何来监控消息的延迟
            原因：
                有了数据之后，你才可以知道目前的延迟数据是否满足要求，也可以评估优化之后的效果。
            方式：
                1。使用消息队列提供的工具，通过监控消息的堆积来完成;
                    思路一：
                        1。首先需要从原理上了解，在消息队列中消费者的消费进度是多少
                            原因：
                                这样才方便计算当前的消费延迟是多少
                            例子：
                                1。生产者向队列中一共生产了 1000 条消息，某 一个消费者消费进度是 900 条
                                2。那么这个消费者的消费延迟就是 100 条消息
                            扩展：
                                1。在 Kafka 中，消费者的消费进度在不同的版本上是不同的。
                                    情形一：
                                        1。在 Kafka0.9 之前的版本中，消费进度是存储在 ZooKeeper 中的，消费者在消费消息的时候
                                        2。先要从 ZooKeeper 中获取最新的消费进度，再从这个进度的基础上消费后面的消息
                                    情形二：
                                        1。在 Kafka0.9 版本之后，消费进度被迁入到 Kakfa 的一个专门的 topic 叫“__consumer_offsets”里面。
                                2。如果你了解 kafka 的原理，你可以依据不同的版 本，从不同的位置，获取到这个消费进度的信息。
                            方法：(通过工具)
                                1。Kafka 提供了工具叫做“kafka-consumer-groups.sh”
                                2。第二个工具是 JMX。(推荐)
                    思路二
                        2。通过生成监控消息的方式来监控消息的延迟情况。
                            具体实现：
                                1。先定义一种特殊的消息，然后启动一个监控程序，将这个消息定时地循环写入到消息队列中
                                2。消息的内容可以是生成消息的时间戳，并且也会作为队列的消费者消费数据
                                3。业务处理程序消费到这个消息时直接丢弃掉，而监控程序在消费到这个消息时
                                4。就可以和这个消息的生成时间做比较，如果时间差达到某一个阈值就可以向我们报警。
                            优点：
                                对于消费延迟的监控则更加直观，而且从时间的维度来做监控也比较容易确定报警阈值。
                    推荐：
                        推荐两种方式结合来使用
                        例子：
                            1。实际项目中，我会优先在监控程序中获取 JMX 中的队列堆积数据，做到 dashboard 报表中
                            2。同时也会启动探测进程，确认消息的延迟情况是怎样的。
        2。然后，你要掌握使用消息队列的正确姿势
            需要在消费端和消息队列两个层面来完成：
                消费端：
                    1。优化消费代码提升性能;
                    2。增加消费者的数量(这个方式比较简单)。
                        缺点：
                            受限于消息队列的实现
                            例子：
                                如果消息队列使用的是 Kafka 就无 法通过增加消费者数量的方式，来提升消息处理能力。
                                原因：
                                    1。在 Kafka 中，一个 Topic(话题)可以配置多个 Partition(分区)，数据会被平均或者按照生产者指定的方式
                                    2。写入到多个分区中，那么在消费的时候，Kafka 约定一个分区只 能被一个消费者消费
                                    问题一：
                                        为什么这么设计？
                                        答案：
                                            1。如果有多个consumer(消费者)可以消费一个分区的数据
                                            2。那么在操作这个消费进度的时候就需要加锁，可能会对性能有一定的影响。
                                            3。话题的分区数量决定了消费的并行度，增加多余的消费者也是没有用处的
                                        方法：
                                            可以通过增加分区来提高消费者的处理能力。
                                    问题二：
                                        如何在不增加分区的前提下提升消费能力呢?
                                        分析：
                                            既然不能增加 consumer，那么你可以在一个 consumer 中提升处理消息的并行度
                                        方法：
                                            可以考虑使用多线程的方式来增加处理能力
                                        具体流程：
                                            1。可以预先创建一个或者多个线程池，在接收到消息之后，把消息丢到线程池中来异步地处理
                                            2。原本串行的消费消息的流程就变成了并行的消费
                                            优点：
                                                1。可以提高消息消费的吞吐量，在并行处理的前提下
                                                2。我们就可以在一次和消息队列的交互中多拉取几条数据，然后分配给多个线程来处理。
                                            缺点：
                                                消费线程空转的问题。
                                                例子：
                                                    消费客户端的进程会偶发地出现 CPU 跑满的情况
                                                    方法：
                                                        打印了 JVM 线程堆栈，找到了那个跑满 CPU 的线 程
                                                    结论：
                                                        1。原来是消息队列中，有一段时间没有新的消息
                                                        2。于是消费客户端拉取 不到新的消息就会不间断地轮询拉取消息，这个线程就把 CPU 跑满了。
                                            方法：
                                                拉取不到消息可以等待一段时间再来拉取，等待的时间不宜过长，否则会增加消息的延迟
                                                建议：
                                                    1。固定的 10ms~100ms，也 可以按照一定步长递增
                                                    2。比如第一次拉取不到消息等待 10ms，第二次 20ms，最长可以到 100ms，直到拉取到消息再回到 10ms。


                消息队列：
                    主要从两方面考虑读取性能问题:
                        1。消息的存储：
                            过程：
                                1。在设计的时候为了实现简单，使用了普通的数据库来存储消息
                                    缺点：
                                        但是受 限于数据库的性能瓶颈，读取 QPS 只能到 2000
                                    方法：
                                        后面我重构了存储模块，使用本地磁盘作为存储介质
                                2。Page Cache 的存在就可以提升消息的读取速度，即使要读取磁盘中的数据
                                    优点：
                                        由于消息的读取是顺序的，并且不需要跨网络读取数据，所以读取消息的 QPS 提升了 一个数量级。

                        2。零拷贝技：
                            分析：
                                1。我们不可能消灭数据的拷贝，只是尽量 减少拷贝的次数
                                2。在读取消息队列的数据的时候，其实就是把磁盘中的数据通过网络发送给消费客户端
                                3。在实现上会有四次数据拷贝的步骤:
                                    1。数据从磁盘拷贝到内核缓冲区;
                                    2。系统调用将内核缓存区的数据拷贝到用户缓冲区;
                                    3。用户缓冲区的数据被写入到 Socket 缓冲区中;
                                    4。操作系统再将 Socket 缓冲区的数据拷贝到网卡的缓冲区中。
                                方法：
                                    1。操作系统提供了 Sendfile 函数，可以减少数据被拷贝的次数
                                    2。使用了 Sendfile 之后，在内 核缓冲区的数据不会被拷贝到用户缓冲区，而是直接被拷贝到 Socket 缓冲区，
                                优点：
                                    节省了一次 拷贝的过程，提升了消息发送的性能。
                                应用：
                                    高级语言中对于 Sendfile 函数有封装，比如说在 Java 里面的 java.nio.channels.FileChannel 类就提供了 transferTo 方法提供了 Sendfile 的功能。
        3。以及关注消息队列本身是如何保证消息尽快被存储和投递的。

21 | 系统架构:每秒1万次请求的系统要做服务化拆分吗?
    背景：
        1。怎么通过技术上的 优化改造，来支撑更高的并发流量，比如支撑过百万的 DAU。
        2。目前来看，工程的部署方式还是采用一体化架构，也就是说所有的功能模块
        3。比方说电商系 统中的订单模块、用户模块、支付模块、物流模块等等
        4。都被打包到一个大的 Web 工程 中，然后部署在应用服务器上。
    方法：
        我们将一体化架构，拆分成微服务化架构
    问题：
        我们为什么需要做拆分？
        一体化架构
            优点：
                1。开发简单直接，代码和项目集中式管理;
                2。只需要维护一个工程，节省维护系统运行的人力成本;
                3。排查问题的时候，只需要排查这个应用进程就可以了，目标性强。
            缺点：
                1。在技术层面上，数据库连接数可能成为系统的瓶颈。
                    案例：
                        连接 MySQL 的客户端数量有限制，最多可以设置为 16384
                        例子：
                            1。数据库的最大连接数设置为 8000，应用服务器部署在虚拟机 上，数量大概是 50 个
                            2。每个服务器会和数据库建立 30 个连接，但是数据库的连接数，却 远远大于 30 * 50 = 1500。
                            现象：
                                1。因为你不仅要支撑来自客户端的外网流量，还要部署单独的应用服务
                                2。支撑来自其它部门的 内网调用，也要部署队列处理机，处理来自消息队列的消息
                                3。这些服务也都是与数据库直接 连接的，林林总总加起来，在高峰期的时候，数据库的连接数要接近 3400。
                2。增加了研发的成本，抑制了研发效率的提升。
                3。一体化架构对于系统的运维也会有很大的影响。

    如何使用微服务化解决这些痛点
        背景：
            1。之前，我在做一个社区业务的时候，开始采用的架构也是一体化的架构
            2。数据库已经做了垂直分库，分出了用户库、内容库和互动库
            3。并且已经将工程拆分了业务池，拆分成了用户池、内容池和互动池。
        现象：
            当前端的请求量越来越大时，我们发现，无论哪个业务池子，用户模块都是请求量最大的模块儿，用户库也是请求量最大的数据库
            原因：
                1。无论是内容还是互动，都会查询用户库获取用户数据
                2。即使我们做了业务池的拆分，但实际上，每一个业务池子都需要连接用户库，并且请求量都很大
                3。这就造成了用户库的连接数比其它都要多一些，容易成为系统的瓶颈。
        方法一：
            按照业务做横向拆分的方式，解决了数据库层面的扩展性问题。
            具体实现：
                1。可以把与用户相关的逻辑，部署成一个单独的服务
                2。其它无论是用户池、内容池还是互动池，都连接这个服务来获取和更改用户信息
                3。只有这个服务可以连接用户库，其它的业务池都不直连用户库获取数据。
                4。如此一来，我们也可以将内容和互动相关的逻辑，都独立出来，形成内容服务和互动服务
            优点：
                不需要部署太多的实例就可以承担流量，这样就可以有效地控制用户库的连接数，提升了系统的可扩展性。
        方法二：
            将与业务无关的公用服务抽取出来，下沉成单独的服务。
        总结：
            1。按照以上两种拆分方式将系统拆分之后，每一个服务的功能内聚，维护人员职责明确
            2。增加了新的功能只需要测试自己的服务就可以了，而一旦服务出了问题
            3。也可以通过服务熔断、降级的方式减少对于其他服务的影响

22 | 微服务架构:微服务化后，系统架构要如何改造?
    背景：
        1。微服务化之后，垂直电商系统的架构会将变成下面这样:
            参考：
                第22讲微服务拆分之后的系统架构图.png
        2。在这个架构中，我们将用户、订单和商品相关的逻辑，抽取成服务独立的部署
        3。原本的 Web 工程和队列处理程序，将不再直接依赖缓存和数据库
        4。而是通过调用服务接口，查询存储中的信息。
    1。微服务拆分的原则
        一体化架构：
            概念：
                像是一个大的蜘蛛网，不同功能模块，错综复杂地交织在一起
            缺点：
                1。方法之间调用关系非常的复杂
                2。导致你修复了一个 Bug，可能会引起另外多个 Bug
                3。整体的维护成本非常高
                4。数据库较弱的扩展性，也限制了服务的扩展能力
        原则一：
            做到单一服务内部功能的高内聚，和低耦合
            解释：
                每个服务只完成自己职责之内的任务，对于不是自己职责的功能，交给其它服务来完成。
        原则二：
            你需要关注服务拆分的粒度，先粗略拆分，再逐渐细化
            做法：
                1。拆分初期可以把服务粒度拆的粗一些
                2。后面随着团队对于业务和微服务理解的加深，再考虑把服务粒度细化
            例子：
                1。对于一个社区系统来说，你可以先把和用户关系相关的业务逻辑
                2。都拆分到用户关系服务中，之后，再把比如黑名单的逻辑独立成黑名单服务。
        原则三：
            拆分的过程，要尽量避免影响产品的日常功能迭代
            解释：
                要一边做产品功能迭代，一边完成服务化拆分。
            做法：
                我们的拆分只能在现有一体化系统的基础上，不断剥离业务独立部署，剥离的顺序
            考虑点一：
                1。优先剥离比较独立的边界服务(比如短信服务、地理位置服务)
                2。从非核心的服务出发，减少拆分对现有业务的影响，也给团队一个练习、试错的机会;
            考虑点二：
                当两个服务存在依赖关系时，优先拆分被依赖的服务
                例子：
                    1。内容服务依赖于用户服务获取用户的基本信息
                    2。那么如果先把内容服务拆分出来，内容服务就会依赖于一体化架构中的用户模块
                    缺点：
                        这样还是无法保证内容服务的快速部署能力。
                    方法：
                        1。理清服务之间的调用关系，比如说，内容服务会依赖用户服务获取用户信息
                        2。互动服务会依赖内容服务，所以要按照先用户服务，再内容服务
                        3。最后互动服务的顺序来进行拆分。
        原则四：
            服务接口的定义要具备可扩展性
            分析：
                1。服务拆分之后，由于服务是以独立进程的方式部署
                2。所以服务之间通信，就不再是进程内部的方法调用，而是跨进程的网络通信了
                3。在这种通信模型下需要注意，服务接口的定义要具备可扩展性
                4。否则在服务变更时，会造成意想不到的错误。
            例子：
                1。在之前的项目中，某一个微服务的接口有三个参数
                2。在一次业务需求开发中，组内的一个同学将这个接口的参数调整为了四个
                3。接口被调用的地方也做了修改，结果上线这个服务后，却不断报错，无奈只能回滚。

    2。微服务化带来的问题和解决思路
        问题一：
            服务接口的调用，不再是同一进程内的方法调用，而是跨进程的网络调用，这会增加接口响应时间的增加
            分析：
                1。选择高效的服务调用框架
                2。接口调用方需要知道服务部署在哪些机器的哪个端口上
                3。这些信息需要存储在一个分布式一致性的存储中
            解决思路：
                需要引入服务注册中心
        问题二：
            多个服务之间有着错综复杂的依赖关系。
            分析：
                1。一个服务会依赖多个其它服务，也会被多个服务所依赖
                2。那么一旦被依赖的服务的性能出现问题，产生大量的慢请求
                3。就会导致依赖服务的工作线程池中的线程被占满，那么依赖的服务也会出现性能问题
                4。接下来，问题就会沿着依赖网，逐步向上蔓延，直到整个系统出现故障为止。
            解决思路：
                引入服务治理体系
                解释：
                    1。针对出问题的服务，采用熔断、降级、限流、超时控制的方法
                    2。使得问题被限制在单一服务中，保护服务网络中的其它服务不受影响。
        问题三：
            1。服务拆分到多个进程后，一条请求的调用链路上，涉及多个服务
            2.那么一旦这个请求的响应时间增长，或者是出现错误，我们就很难知道，是哪一个服务出现的问题。
            3。整体系统一旦出现故障，很可能外在的表现是所有服务在同一时间都出现了问题
            4。在问题定位时，很难确认哪一个服务是源头
            解决思路：
                引入分布式追踪工具，以及更细致的服务端监控报表。

23 | RPC框架:10万QPS下如何实现毫秒级的服务调用?
    背景：
        1。服务拆分单独部署后，引入的服务跨网络通信的问题;
        2。在拆分成多个小服务之后，服务如何治理的问题。
    解决第一个问题的方案：
        RPC 框架。
            场景：
                1。你的垂直电商系统的 QPS 已经达到了每秒 2 万次
                2。在做了服务化拆分之后，由于我们把业务逻辑，都拆分到了单独部署的服务中
                3。那么假设你在完成一次完整的请求时，需要调用 4~5 次服务
                4。算下来，RPC 服务需要承载大概每秒 10 万次的请求。
                问题：
                    该如何设计 RPC 框架，来承载如此大的请求量呢?
                思路：
                    1。选择合适的网络模型，有针对性地调整网络参数，以优化网络传输性能;
                    2。选择合适的序列化方式，以提升封包、解包的性能。
    RPC（Remote Procedure Call，远程过程调用)
        概念：
            指的是通过网络，调用另一台计算机上部署服务的技术。
        特点：
            封装了网络调用的细节，让你像调用本地服务一样，调用远程部署的服务。
        应用一：
            RMI(Remote Method Invocation)
            概念：
                是一种远程调用的 方法，也是 J2EE 时代大名鼎鼎的 EJB 的实现基础。
            作用：
                可以让 Java 程序通过网络，调用另一台机器上的 Java 对象的方法
            缺点：
                1。使用专为 Java 远程对象定制的协议 JRMP(Java Remote Messaging Protocol) 进行通信，这限制了它的通信双方，
                2。只能是 Java 语言的程序，无法实现跨语言通信;
                2。使用Java 原生的对象序列化方式，生成的字节数组空间较大，效率很差。
        应用二：
            Web Service
            概念：
                是 RPC 的一种实现方式
            优点：
                使用 HTTP+SOAP 协议，保证了调用可以跨语言，跨平台
            缺点：
                使用 XML 封装数 据，数据包大，性能还是比较差。
        注意：
            1。RPC 并不是互联网时代的产物，也不是服务化之后 才衍生出来的技术，而是一种规范
            2。只要是封装了网络调用的细节，能够实现远程调用其他服务，就可以算作是一种 RPC 技术了。
        问题：
            垂直电商项目在使用 RPC 框架之后，会产生什么变化呢?
            例子：
                你的电商系统中，商品详情页面需要商品数据、评论数据还有店铺数据
                    情形一：
                        1。如果在一体化的架构中，你只需要从商品库，评论库和店铺库获取数据就可以了
                        2。不考虑缓存的情况下有三次网络请求。
                    情形二：
                        1。如果独立出商品服务、评论服务和店铺服务之后，那么就需要分别调用这三个服务
                        2。而这三个服务又会分别调用各自的数据库，这就是六次网络请求
                    情形三：
                        1。如果你服务拆分的更细粒度，那么多出的网络调用就会越多
                        2。请求的延迟就会更长，而这就是你为了提升系统的扩展性，在性能上所付出的代价。
        分析：
            如果优化 RPC 的性能，从而尽量减少网络调用
            问题一：
                对于性能的影响呢?
                思路：
                    首先需要了解一次 RPC 的调用都经过了哪些步骤
                        原因：
                            因为这样，你才可以针对这些步骤中可能存在的性能瓶颈点提出优化方案
                        步骤：
                            1。在一次 RPC 调用过程中，客户端首先会将调用的类名、方法名、参数名、参数值等信息，序列化成二进制流;
                            2。然后客户端将二进制流，通过网络发送给服务端;
                            3。服务端：
                                1。服务端接收到二进制流之后，将它反序列化，得到需要调用的类名、方法名、参数名和参数值
                                2。再通过动态代理的方式，调用对应的方法得到返回值;
                            4。服务端将返回值序列化，再通过网络发送给客户端;
                            5。客户端对结果反序列化之后，就可以得到调用的结果了。
                            分析：
                                有网络传输的过程，也有将请求序列化和反序列化的过程
                            思路
                                如果要提升 RPC 框架的性能，需要从网络传输和序列化两方面来优化
            问题二：
                如何提升网络传输性能
                思路：
                    1。在网络传输优化中，你首要做的，是选择一种高性能的 I/O 模型
                        分析：
                            一般单次 I/O 请求会分为两个阶段，每个阶段对于 I/O 的处理方式 是不同的。
                        阶段一：
                            I/O 会经历一个等待资源的阶段
                                例子：
                                    等待网络传输数据可用
                                处理方式一：
                                    阻塞
                                        概念：
                                            指的是在数据不可用时，I/O 请求一直阻塞，直到数据返回;
                                处理方式二：
                                    非阻塞：
                                        概念：
                                            指的是数据不可用时，I/O 请求立即返回，直到被通知资源可用为止。
                        阶段二：
                            然后是使用资源的阶段
                            例子：
                                从网络上接收到数据，并且拷贝到应用程序的缓冲区里面
                            处理方式一：
                                同步处理：
                                    概念：
                                        指的是 I/O 请求在读取或者写入数据时会阻塞，直到读取或者写入数据完成;
                            处理方式二：
                                异步处理：
                                    概念：
                                        1。指的是 I/O 请求在读取或者写入数据时立即返回，当操作系统处理完成 I/O 请求
                                        2。并且将数据拷贝到用户提供的缓冲区后，再通知应用 I/O 请求执行完成。
                        常见的五种 I/O 模型:
                            前提：
                                把 I/O 过程比喻成烧水倒水的过程，等待资源(就是烧水的过程)，使用资源(就 是倒水的过程):
                            1。同步阻塞 I/O
                                例子：
                                    1。如果你站在炤台边上一直等着(等待资源)水烧开
                                    2。然后倒水(使用资源)
                            2。同步非阻塞 I/O
                                例子：
                                    1。如果你偷点儿懒，在烧水的时候躺在沙发上看会儿电视(不再时时刻刻等待资源)
                                    2。但是还是要时不时的去看看水开了没有，一旦水开了，马上去倒水(使用资源)
                            3。同步多路 I/O 复用(应用最广)
                                例子：
                                    1。如果你想要洗澡，需要同时烧好多壶水，那你就在看电视的间隙去看看哪壶水开了(等待多个资源)
                                    2。哪一壶开了就先倒哪一壶，这样就加快了烧水的速度，这就是同步多路 I/O 复用;
                                应用：
                                    1。Linux 系统中的 select、epoll 等系统 调用都是支持多路 I/O 复用模型的
                                    2。Java 中的高性能网络框架 Netty 默认也是使用这种模 型

                            4。信号驱动 I/O
                                例子：
                                    1。不过你发现自己总是跑厨房去看水开了没，太累了
                                    2。于是你考虑给你的水壶加一个报警器(信号)，只要水开了就马上去倒水
                            5。异步 I/O
                                例子：
                                    你发明了一个智能水壶，在水烧好后自动就可以把水倒好
                    2。不可忽视的一项就是网络参数的调优
                        例子：
                            1。曾经写过一个简单的 RPC 通信框架
                            2。在进行测试的时候发现， 远程调用一个空业务逻辑的方法时，平均响应时间居然可以到几十毫秒
                            3。这明显不符合我们的预期，在我们看来，运行一个空的方法，应该在 1 毫秒之内可以返回
                            方法：
                                1。我先在测试的时候使用 tcpdump 抓了包
                            现象：
                                2。发现一次请求的 Ack 包竟然要经过 40ms 才返回
                            解决思路：
                                google搜索原因，发现原因和一个叫做 tcp_nodelay 的参数有关
                                背景：
                                    1。tcp 协议的包头有 20 字节，ip 协议的包头也有 20 字节，如果仅仅传输 1 字节的数据
                                    2。在 网络上传输的就有 20 + 20 + 1 = 41 字节，其中真正有用的数据只有 1 个字节
                                缺点：
                                    这对效率和带宽是极大的浪费
                                    优化算法：
                                        在 1984 年的时候，John Nagle 提出了以他的名字命名的 Nagle`s 算法
                                        具体内容：
                                            1。如果是连续的小数据包，大小没有一个 MSS(Maximum Segment Size，最大分段大小)
                                            2。并且还没有收到之前发送的数据包的 Ack 信息，那么这些小数据包就会在发送端暂存起来
                                            3。直到小数据包累积到一个 MSS，或者收到一个 Ack 为止。
                            分析：
                                1。原本是为了减少不必要的网络传输，但是如果接收端开启了 DelayedACK(延迟 ACK 的 发送，这样可以合并多个 ACK，提升网络传输效率)
                                2。那就会发生，发送端发送第一个数据包后，接收端没有返回 ACK，这时发送端发送了第二个数据包
                                    原因：
                                        Nagle`s 算法的存 在，并且第一个发送包的 ACK 还没有返回，所以第二个包会暂存起来
                                3。而 DelayedACK 的超时时间，默认是 40ms
                                4。所以一旦到了 40ms，接收端回给发送端 ACK，那么发送端 才会发送第二个包，这样就增加了延迟。
                            解决办法：
                                1。只要在 socket 上开启 tcp_nodelay 就好了，这个参数关闭了 Nagle`s 算法
                                2。这样发送端就不需要等到上一个发送包的 ACK 返回，直接发送新的数据包 就好了
                            注意：
                                1。对于强网络交互的场景来说非常的适用
                                2。基本上，如果你要自己实现一套网络框架，tcp_nodelay 这个参数最好是要开启的。
            问题三：
                选择合适的序列化方式
                序列化：
                    概念：
                        将传输对象转换成二进制串的过程
                反序列化：
                    概念：
                        将二进制串转换成对象的过程。
                背景：
                    一次 RPC 调用需要经历两次数据序列化的过程，和两次数据反序列化的过程
                考虑因素：
                    1。性能
                        时间上的开销：
                            概念：
                                序列化和反序列化的速度
                        空间上的开销：
                            概念：
                                序列化后的二进制串的大小，过大的二进制串也会占据传输带宽，影响传输效率
                    2。跨语言，跨平台
                        原因：
                            1。为一般的公司的技术体系都不是单一的，使用的语言也不是单一的
                            2。那么如果你的 RPC 框架中 传输的数据只能被一种语言解析，那么这无疑限制了框架的使用。
                    3。扩展性
                        例子：
                            如果对象增加了一个字段就会造成传输协议的不兼容，导致服务调用失败，这会是多么可怕的事情。
                备选方案：
                    1。JSON
                        概念：
                            它起源于 JavaScript，是一种最广泛使用的序列化协议
                        优点：
                            简单易用，人言可读，同时在性能上相比 XML 有比较大的优势
                    2。Thrift
                        概念：
                            是 Facebook 开源的高性能的序列化协议，也是一个轻量级的 RPC 框架;
                        优点：
                            无论在空间上还是时间上都有着很高的性能
                        缺点：
                            由于 IDL 存在带来一些使用上的不方便。
                    3。Protobuf
                        概念：
                            是谷歌开源的序列化协议
                        优点：
                            无论在空间上还是时间上都有着很高的性能
                        缺点：
                            由于 IDL 存在带来一些使用上的不方便。
                建议一：
                    如果对于性能要求不高，在传输数据占用带宽不大的场景下，可以使用 JSON 作为序列化协议;
                建议二：
                    1。如果对于性能要求比较高，那么使用 Thrift 或者 Protobuf 都可以
                    2。而 Thrift 提供了配 套的 RPC 框架，所以想要一体化的解决方案，你可以优先考虑 Thrift;
                建议三：
                    1。在一些存储的场景下，比如说你的缓存中存储的数据占用空间较大
                    2。那么你可以考虑使用Protobuf 替换 JSON，作为存储数据的序列化方式。

24 | 注册中心:分布式系统如何寻址?
    问题一：
        如何让 RPC 客户端知道服务端部署的地址
        例子：
            1。你知道 Nginx 是一个反向代理组件，那么 Nginx 需要知道
            2。这样才能够将流量透传到应用服务器上，这就是服务发现的过程。
        思考：
            那么 Nginx 是怎么实现的呢
        方法一：
            它是把应用服务器的地址配置在了文件中。
            缺点：
                1。在紧急扩容的时候，就需要修改客户端配置后，重启所有的客户端进程，操作时比较长;
                2。一旦某一个服务器出现故障时，也需要修改所有客户端配置后重启，无法快速修复，更无法做到自动恢复;
                3。RPC服务端上线无法做到提前摘除流量
                    例子：
                        在重启服务端的时候，客户端发往被重启服务端的请求还没有返回，会造成慢请求甚至请求失败。
        方法二：
            注册中心
                实现的组件：
                    1。老派的 ZooKeeper
                    2。Kubernetes使用的 ETCD
                    3。阿里的微服务注册中心 Nacos
                    4。Spring Cloud 的 Eureka 等等
                基本功能：
                    1。提供了服务地址的存储;
                    2。当存储内容发生变化时，可以将变更的内容推送给客户端。(使用注册中心的主要原因)
                        原因：
                            当我们需要紧急扩容，还是在服务器发生故障时，需要快速摘除节点，都不用重启服务器就可以实现了
                服务注册和发现的过程:
                    1。客户端会与注册中心建立连接，并且告诉注册中心，它对哪一组服务感兴趣;
                    2。服务端向注册中心注册服务后，注册中心会将最新的服务注册信息通知给客户端;
                    3。客户端拿到服务端的地址之后就可以向服务端发起调用请求了。
                    优点：
                        1。服务节点的增加和减少对于客户端就是透明的
                        2。可以实现不重启客户端，就能动态地变更服务节点以外，
                        3。还可以实现优雅关闭的功能。
                    优雅关闭考虑点：
                        如果暴力地停止服务，那么已经发送给服务端的请求，来不及处理服务就被杀掉了
                        现象：
                            就会造成这部分请求失败，服务就会有波动。
                            方法：
                                服务在退出的时候，都需要先停掉流量，再停止服务，这样服务的关闭才会更平滑
                            例子一：
                                消息队列处理器就是要将所有，已经从消息队列中读出的消息，处理完之后才能退出。
                            例子二：
                                1。我们可以先将 RPC 服务从注册中心的服务列表中删除掉
                                2。然后观察 RPC 服务端没有流量之后，再将服务端停掉

                            优点：
                                RPC 服务端再重启的时 候，就会减少对客户端的影响。
    服务状态管理如何来做
        情形一：
            正常的流程中：
                服务的上线和下线是由服务端主动向注册中心注册、和取消注册来实现的，是没有问题的
        情形二：
            某一个服务端意外故障
            1。比如说机器掉电，网络不通等情况，服务端就没有办法向注册中心通信
            2。将自己从服务列表中删除，那么客户端也就不会得到通知
            3。它就会继续向一个故障的服务端发起请求，也就会有错误发生了
        思路一：(主动探测)
            1。你的 RPC 服务要打开一个端口，然后由注册中心每隔一段时间(比如 30 秒)探测这些端口是否可用
            2。如果可用就认为服务仍然是正常的，否则就可以认为服务不可用
            3。那么注册中心就可以把服务从列表里面删除了。
            应用：
                微博早期的注册中心就是采用这种方式
            缺点：
                问题一：
                    1。所有的 RPC 服务端都需要，开放一个统一的端口给注册中心探测，那时候还没有容器化
                    2。一台物理机上会混合部署很多的服务，你需要开放的端口很可能已经被占用，这样会造成 RPC 服务启动失败。
                问题二：
                    1。如果 RPC 服务端部署的实例比较多，那么每次探测的成本也会比较高，探测的时间也比较长
                    2。这样当一个服务不可用时，可能会有一段时间的延迟，才会被注册中心探测到。
        思路二：(心跳模式)推荐
            应用：
                1。Eureka
                2。ZooKeeper
            具体实现：
                1。注册中心为每一个连接上来的 RPC 服务节点，记录最近续约的时间，RPC 服务节点在启动注册到注册中心后
                2。就按照一定的时间间隔(比如 30 秒)，向注册中心发送心跳包
                3。注册中心在接受到心跳包之后，会更新这个节点的最近续约时间
                4。然后，注册中心会启动一个定时器，定期检测当前时间和节点
                5。最近续约时间的差值，如果达到一个阈值(比如说 90 秒)，那么认为这个服务节点不可用。
            优点：
                1。心跳机制相比主动探测的机制，适用范围更广
                2。有了心跳机制之后，注册中心就可以管理注册的服务节点的状态了
                3。也让你的注册中心成为了整体服务最重要的组件
            缺点
                问题一：
                    一旦它出现问题或者代码出现Bug，那么很可能会导致整个集群的故障
                    案例：
                        项目：
                            1。工程是以“混合云”的方式部署的，也就是一部分节点部署在自建机房中
                            2。一部分节点部署在云服务器上，每一个机房都部署了自研的一套注册中心
                            3。每套注册中心中都保存了全部节点的数据。
                        注册中心：
                            1。这套自研的注册中心使用 Redis 作为最终的存储，而在自建机房和云服务器上的注册中心，共用同一套 Redis 存储资源
                            2。由于“混合云”还处在测试阶段，所以，所有的流量还都在自建机房
                            3。自建机房和云服务器之前的专线带宽还比较小
                        现象：
                            1。在测试的过程中，系统运行稳定，但是某一天早上五点，我突然发现，所有的服务节点都被 摘除了
                            2。客户端因为拿不到服务端的节点地址列表全部调用失败，整体服务宕机
                        思路：
                            1。经过排查我发现，云服务器上部署的注册中心，竟然将所有的服务节点全部删除了
                            2。进一步排查之后，原来是自研注册中心出现了 Bug。
                        分析：
                            1。在正常的情况下，无论是自建机房，还是云服务器上的服务节点，都会向各自机房的注册中心注册地址信息，并且发送心跳
                            2。而这些地址信息，以及服务的最近续约时间，都是存储在Redis主库中，各自机房的注册中心
                            3。会读各自机房的从库来获取最近续约时间，从而判断服务节点是否有效。
                            4。Redis的主从同步数据是通过专线来传输的，出现故障之前，专线带宽被占满，导致主从同步延迟。
                            5。这样一来，云上部署的Redis从库中存储的最近续约时间，就没有得到及时更新，随着主从同步延迟越发严重
                            6。最终，云上部署的注册中心发现了，当前时间与最近续约时间的差值，超过了摘除的阈值，所以将所有的节点摘除，从而导致了故障
                        方法：
                            1。我们给注册中心增加了保护的策略:如果摘除的节点占到了服务集群节点数的 40%，就停止摘除服务节点
                            2。并且给服务的开发同学和，运维同学报警处理
                        扩展一：
                            1。Eureka也采用了类似的策略，来避免服务节点被过度摘除
                            2。导致服务集群不足以承担流量的问题
                        扩展二：
                            1。如果你使用的是 ZooKeeper 或者 ETCD 这种无保护策略的分布式一致 性组件
                            2。那你可以考虑在客户端，实现保护策略的逻辑，比如说当摘除的节点超过一定比例时
                            3。你在 RPC 客户端就不再处理变更通知，你可以依据自己的实际情况来实现。
        问题二：
            通知风暴
            例子：
                1。你想一想，变更一个服务的一个节点，会产生多少条推送消息?
                2。假如你的服务有 100 个调用 者，有 100 个节点，那么变更一个节点会推送 100 * 100 = 10000 个节点的数据
            现象：
                1。如果多个服务集群同时上线或者发生波动时，注册中心推送的消息就会更多
                2。会严重占用机器的带宽资源，这就是我所说的“通知风暴”
            思路：
                1。要控制一组注册中心管理的服务集群的规模，具体限制多少没有统一的标准
                    1。结合你的业务以及注册中心的选型来考虑
                    2。主要考察的指标就是注册中心服务器的峰值带宽;
                2。其次，你也可以通过扩容注册中心节点的方式来解决;
                3。再次，你可以规范一下对于注册中心的使用方式，如果只是变更某一个节点，那么只需要通知这个节点的变更信息即可;
                4。最后，如果是自建的注册中心，你也可以在其中加入一些保护策略，比如说如果通知的消息量达到某一个阈值就停止变更通知
            总结：
                服务治理：
                    概念：
                        服务的注册和发现，归根结底是服务治理中的一环
                    解释：
                        服务的管理，也就是解决多个服务节点，组成集群的时候，产生的一些复杂的问题。
                        集群：
                            看作是一个微型的城市
                        集群的服务：
                            看作道路
                        流量：
                            行走在道路上的车
                        服务治理：
                            对于整个城市道路的管理。
                服务的注册和发现例子：
                    1。如果你新建了一条街道(相当于启动了一个新的服务节点)，那么就要通知所有的车辆(流量)有新的道路可以走了
                    2。你关闭了一条街道，你也要通知所有车辆不要从这条路走了，这就是服务的注册和发现。
                服务的监控：
                    我们在道路上安装监控，监视每条道路的流量情况，
                熔断以及引流：
                    1。道路一旦出现拥堵或者道路需要维修，那么就需要暂时封闭这条道路
                    2。由城市来统一调度车辆，走不堵的道路
                分布式追踪：
                    1。道路之间纵横交错四通八达，一旦在某条道路上出现拥堵
                    2。但是又发现这条道路从头堵到尾，说明事故并不是发生在这条道路上
                    3。那么就需要从整体链路上来排查事故究竟处在哪个位置
                负载均衡：
                    不同道路上的车辆有多有少，那么就需要有一个警察来疏导，在某一个时间走哪一条路会比较快

25 | 分布式Trace:横跨几十个分布式组件的慢请求要如何排查?
    背景：
        1。在经过了服务化拆分之后，服务的可扩展性增强了很多
        2。可以通过横向扩展服务节点的方式，进行平滑地扩容了，对于应对峰值流量也更有信心了。
        现象：
            1。你通过监控发现，系统的核心下单接口在晚高峰的时候，会有少量的慢请求
            2。用户也投诉在 APP 上下单时，等待的时间比较长
        问题：
            一时之间，你很难快速判断，究竟是哪个服务或者资源出了问题，从而导致整体流程变慢
    情形一：
    一体化架构中的慢请求排查
        思路：
            1。打印下单操作的每一个步骤的耗时情况，然后通过比较这些耗时的数据
            2。找到延迟最高的一步，然后再来看看这个步骤要如何的优化
            3。如果有必要的话，你还需要针 对步骤中的子步骤，再增加日志来继续排查
                代码如下：
                    long start = System.currentTimeMillis();
                    processA();
                    Logs.info("process A cost " + (System.currentTimeMillis() - start));// 打印 A 步
                    start = System.currentTimeMillis();
                    processB();
                    Logs.info("process B cost " + (System.currentTimeMillis() - start));// 打印 B 步
                    start = System.currentTimeMillis();
                    processC();
                    Logs.info("process C cost " + (System.currentTimeMillis() - start));// 打印 C 步
            4。打印出日志后，我们可以登录到机器上，搜索关键词来查看每个步骤的耗时情况。
            问题一：
                1。由于同时会有多个下单请求并行处理，所以，这些下单请求的每个步骤的耗时日志，是相互穿插打印的
                2。你无法知道这些日志，哪些是来自于同一个请求，也就不能很直观地看到，某一次请求耗时最多的步骤是哪一步了。
                3。你要如何把单次请求，每个步骤的耗时情况串起来呢?
                方法：
                    1。给同一个请求的每一行日志，增加一个相同的标记。
                    2。只要拿到这个标记就可以查询到这个请求链路上，所有步骤的耗时了，我们把这个标记叫做 requestId
                    3。我们可以在程序的入口处生成一个 requestId，然后把它放在线程的上下文 中
                        优点：
                            这样就可以在需要时，随时从线程上下文中获取到 requestId 了
                        代码：
                            String requestId =UUID.randomUUID.toString();
                            ThreadLocal<String> tl = new ThreadLocal<String>(){
                                @Override
                                protected String initialValue(){
                                    return requestId;
                                }

                              };//requestId 存储在线程上下文中

                            long start = System.currentTimeMillis();
                            processA();
                            Logs.info("rid : " + tl.get() + ", process A cost " + (System.currentTimeMillis() - start));// 打印 A 步
                            start = System.currentTimeMillis();
                            processB();
                            Logs.info("rid : " + tl.get() + ", process B cost " + (System.currentTimeMillis() - start));// 打印 B 步
                            start = System.currentTimeMillis();
                            processC();
                            Logs.info("rid : " + tl.get() + ", process C cost " + (System.currentTimeMillis() - start));// 打印 C 步
                    4.有了 requestId，你就可以清晰地了解一个调用链路上的耗时分布情况了。
                定位问题：
                    1。增加了大量的日志，来排查下单操作缓慢的问题
                    2。发现是某一个数据库查询慢了才导致了下单缓慢，然后你优化了数据库索引，问题最终得到了解决
            问题二：
                又有用户反馈某些商品业务打开缓慢，商城首页打开缓慢
                方法
                    开始焦头烂额地给代码中增加耗时日志
                缺点：
                    1。每次排查一个接口就需要增加日志、重启服务
                    2。这并不是一个好的办法，于是你开始思考解决的方案。
                经验：
                    1。一个接口响应时间慢，一般是出在跨网络的调用上
                        例子：
                            1。请求数据库
                            2。缓存
                            3。依赖的第三方服务
                    2。只需要针对这些调用的客户端类，做切面编程，通过插入一些代码打印它们的耗时就好了。
                        切面编程(AOP)
                            概念：
                                面向对象编程的一种延伸，可以在不修改源代码的前提下，给应用程序添加功能
                            应用：
                                鉴权，打印日志
                            实现分两类：
                                1。一类是静态代理
                                    代表：
                                        AspectJ
                                    特点：
                                        在编译期做切面代码注入
                                2。另一类是动态代理
                                    代表：
                                        Spring AOP
                                    特点：
                                        在运行期做切面代码注入。
                                区别：
                                    例子：
                                        1。以 Java 为例，源代码 Java 文件先被 Java 编译器，编译成 Class 文件
                                        2。然后 Java 虚拟机将 Class 装载进来之后，进行必要的验证和初始化后就可以运行了。
                                        静态代理：
                                            1。在编译期插入代码，增加了编译的时间，给你的直观感觉就是启动的时间变长了
                                            2。但是一旦在编译期插入代码完毕之后，在运行期就基本对于性能没有影响。
                                        动态代理：
                                            1。不会去修改生成的 Class 文件，而是会在运行期生成一个代理对象，这个代理对象对源对象做了字节码增强，来完成切面所要执行的操作
                                            2。由于在运行期需要生成代理对象，所以动态代理的性能要比静态代理要差。
                原因：
                    1。想生成一些调试的日志
                    2。我们期望尽量减少对于原先接口性能的影响
                    思路：
                        推荐采用静态代理的方式，实现切面编程。
                    代码：
                        com/suixingpay/profit/jikeshijian/bingfaxitong40wen/Tracer.java:
                        优点：
                            系统的每个接口中，打印出了所有访问数据库、缓存、外部接口的耗时情况
                        现象：
                            一次请求可能要打印十几条日志，如果你的电商系统的 QPS 是 10000 的话，就是每秒钟会产生十几万条日志
                        缺点：
                            对于磁盘 I/O 的负载是巨大的，
                            问题：
                                你就要考虑如何减少日志的数量。
                            方法一：
                                采样
                                    例子：
                                        比如你想采样 10% 的日志，那么你可以只 打印“requestId%10==0”的请求。
                                    分析：
                                        1。有了这些日志之后，当给你一个 requestId 的时候，你发现自己并不能确定这个请求到了 哪一台服务器上
                                        2。所以你不得不登陆所有的服务器，去搜索这个 requestId 才能定位请求
                                    缺点：
                                        无疑会增加问题排查的时间。
                            方法二：
                                把日志不打印到本地文件中，而是发送到消息队列里，再由消息处理程序写入到集中存储中
                                例如：
                                    Elasticsearch
                                优点：
                                    你在排查问题的时候，只需要拿 着 requestId 到 Elasticsearch 中查找相关的记录就好了
                总结：
                    1。在记录打点日志时，我们使用 requestId 将日志串起来，这样方便比较一次请求中的多个步骤的耗时情况;
                    2。我们使用静态代理的方式做切面编程，避免在业务代码中，加入大量打印耗时的日志的代码，减少了对于代码的侵入性，同时编译期的代码注入可以减少;
                    3。我们增加了日志采样率，避免全量日志的打印;
                    4。最后为了避免在排查问题时，需要到多台服务器上搜索日志，我们使用消息队列，将日志集中起来放在了 Elasticsearch 中。

    如何来做分布式 Trace
        问题：
            为什么要花费大量的篇幅，来说明在一体化架构中如何排查问题呢
            原因：
                为在分布式环境下，你基本上也是依据上面，我提到的这几点来构建分布式追踪的中间件的。
        分析：
            1。在一体化架构中，单次请求的所有的耗时日志，都被记录在一台服务器上
            2。而在微服务的场景下，单次请求可能跨越多个 RPC 服务
                现象：
                    单次的请求的日志会分布在多个服务器上。
        方法一：
            可以通过 requestId 将多个服务器上的日志串起来
            缺点：
                1。仅仅依靠 requestId 很难表达清楚服务之间的调用关系
                2。从日志中，就无法了解服务之间是谁在调用谁

        方法二：
            采用 traceId + spanId 这两个数据维度来记录服务之间的调用关系(这里 traceId 就是 requestId)
                解释：
                    1。使用 traceId 串起单次请求，
                    2。用 spanId 记录每一次 RPC 调用
            例子：
                1。你的请求从用户端过来，先到达 A 服务
                2。A 服务会分别调用 B 和 C 服务，B 服务又 会调用 D 和 E 服务。
                参考：
                    第25讲RPC调用关系图.png
                    图中的内容：
                        1。用户到 A 服务之后会初始化一个 traceId 为 100，spanId 为 1;
                        2。A 服务调用 B 服务时，traceId 不变，而 spanId 用 1.1 标识，代表上一级的 spanId 是 1，这一级的调用次序是 1;
                        3。A 调用 C 服务时，traceId 依然不变，spanId 则变为了 1.2，代表上一级的 spanId 还 是 1，而调用次序则变成了 2，以此类推。
            优点：
                1。清晰地看出服务的调用关系是如何的
                2。方便在后续计算中调整日志顺序，打印出完整的调用链路。
                问题：
                    那么 spanId 是何时生成的，又是如何传递的呢?
                    原理：
                        A 服务：
                            1。A 服务在发起 RPC 请求服务 B 前，先从线程上下文中获取当前的 traceId 和 spanId
                            2。然后，依据上面的逻辑生成本次 RPC 调用的 spanId
                            3。将 spanId 和 traceId 序列化后，装配到请求体中，发送给服务方 B。
                        服务方 B：
                            1。服务方 B 获取请求后，从请求体中反序列化出 spanId 和 traceId
                            2。同时设置到线程上下文中，以便给下次 RPC 调用使用
                        3。在服务 B 调用完成返回响应前，计算出服务 B 的执行时间 发送给消息队列。
                    扩展：
                        1。在服务 B 中，你依然可以使用切面编程的方式，得到所有调用的数据库、缓存、HTTP 服务的响应时间
                        2。只是在发送给消息队列的时候，要加上当前线程上下文中的 spanId 和 traceId。
                    注意：
                        1。无论是数据库等资源的响应时间，还是 RPC 服务的响应时间就都汇总到了消息队列 中
                        2。在经过一些处理之后，最终被写入到 Elasticsearch 中以便给开发和运维同学查询使用。
                        3。因为引入了分布式追踪中间件，导致对于磁盘 I/O 和网络 I/O 的影响
                            指南：
                                1。如果你是自研的分 布式 trace 中间件，那么一定要提供一个开关，方便在线上随时将日志打印关闭;
                                2。如果使用 开源的组件，可以开始设置一个较低的日志采样率，观察系统性能情况再调整到一个合适的数值。

26 | 负载均衡:怎样提升系统的横向扩展能力?
    高并发系统设计的三个通用方法：
        1。缓存
            缓存的使用姿势
        2。异步
            异步处理业务逻辑
        3。横向扩展
            如何提升系统的横向扩展能力。
        方法：
            1。通过部署多个从库的方式，来提升数据库的扩展能力，从而提升数据库的查询性能
            2。借助组件，将查询数据库的请求，按照一些既定的策略分配到多个从库上
            注意：
                这是负载均衡服务器所起的作用，而我们一般使用 DNS 服务器来承担这个角色。
    负载均衡：
        作用：
            1。承接前端的 HTTP 请求，然后将它们按照多种策略，分发给后端的多个业务服务器上。
            2。我们可以随时通过扩容业务服务器的方式，来抵挡突发的流量高峰
            3。可以在域名和请求 URL 地址的层面做更细致的流量分配
        概念：
            将负载(访问的请求)“均衡”地分配到多个处理节点上。
        优点
            1。可以减少单个处理节点的请求量，提升整体系统的性能。
            2。负载均衡服务器作为流量入口，可以对请求方屏蔽服务节点的部署细节，实现对于业务方无感知的扩容
            内容：
                它就像交通警察，不断地疏散交通，将汽车引入合适的道路上。
        服务分类：
            1。代理类的负载均衡服务
                概念：
                    1。以单独的服务方式部署，所有的请求都要先经过负载均衡服务
                    2。在负载均衡服务中，选出一个合适的服务节点后，再由负载均衡服务，调用这个服务节点来实现流量的分发。
                实现的组件：
                    1。Nginx：
                        概念：
                            运行在OSI网络模型中的第七层，应用层，所以又可以称为七层负载
                    2。LVS：
                        概念：
                            在OSI网络模型中的第四层，传输层工作，所以LVS又可以称为四层负载
                实践中：
                    1。项目架构中，一般会同时部署 LVS 和 Nginx 来做 HTTP 应用服务的负载均衡
                    2。在入口处部署 LVS，将流量分发到多个Nginx 服务器上，再由 Nginx 服务器分发 到应用服务器上
                问题：
                    为什么这么做？
                    原因：
                        LVS：
                            1。主要和 LVS 和 Nginx 的特点有关，LVS 是在网络栈的四层做请求包的转发
                            2。请求包转发之后，由客户端和后端服务直接建立连接，后续的响应包不会再经过 LVS 服务器
                            3。所以相比 Nginx，性能会更高，也能够承担更高的并发。
                            缺点：
                                1。LVS 缺陷是工作在四层，而请求的 URL 是七层的概念
                                2。不能针对 URL 做更细致地请求 分发，而且 LVS 也没有提供探测后端服务是否存活的机制
                        Nginx：
                            1。Nginx 虽然比 LVS 的性能 差很多，但也可以承担每秒几万次的请求，
                            2。并且它在配置上更加灵活，还可以感知后端服务是否出现问题。
                        因此
                            1。LVS 适合在入口处，承担大流量的请求分发
                            2。Nginx 要部署在业务服务器之前做 更细维度的请求分发。
                    建议：
                        1。如果你的 QPS 在十万以内，那么可以考虑不引入 LVS 而直接使用 Nginx 作为唯一的负载均衡服务器
                            优点：
                                这样少维护一个组件，也会减少系统的维护成本。
                        2。这两个负载均衡服务适用于普通的 Web 服务，对于微服务架构来说，它们是不合适的。
                            原因：
                                1。微服务架构中的服务节点存储在注册中心里，使用 LVS 就很难和注册中心交互，获取全量的服务节点列表。
                                2。一般微服务架构中，使用的是 RPC 协议而不是 HTTP 协 议，所以 Nginx 也不能满足要求。
            2。客户端负载均衡服务
                概念：
                    1。就是把负载均衡的服务内嵌在 RPC 客户端中。
                    2。一般和客户端应用，部署在一个进程中，提供多种选择节点的策略，最终为客户端应用提供一个最佳的，可用的服务端节点
                实现方式：
                    1。一般会结合注册中心来使用，注册中心提供服务节点的完整列表
                    2。客户端拿到列表之后使用负载均衡服务的策略选取一个合适的节点
                    3。然后将请求发到这个节点上。
            负载均衡策略分类：
                1。静态策略
                    概念：
                        负载均衡服务器在选择服务节点时，不会参考后端服务的实际运行的状态。
                    应用：
                        1。轮询的策略
                            概念：
                                1。会记录上次请求后端服务的地址或者序号，然后在请求时
                                2。按照服务列表的顺序，请求下一个后端服务节点
                            代码：
                                 AtomicInteger lastCounter = getLastCounter();// 获取上次请求的服务节点的序号
                                 List<String> serverList = getServerList(); // 获取服务列表
                                 int currentIndex = lastCounter.addAndGet(); // 增加序列号
                                 if(currentIndex >= serverList.size()) {
                                     currentIndex = 0;
                                    }
                                setLastCounter(currentIndex);
                                return serverList.get(currentIndex);
                            范围：
                                一种通用的策略，基本上，大部分的负载均衡服务器都支持
                            优点：
                                可以做到将请求尽量平均地分配到所有服务节点上
                            缺点：
                                它没有考虑服务节点的具体配置情况
                            例子：
                                1。你有三个服务节点，其中一个服务节点的配置是 8 核 8G，另外两个节点的配置是 4 核 4G
                                2。那么如果使用轮询的方式来平均分配请求的话，8 核 8G 的节点分到的请求数量和 4 核 4G 的一样多
                                缺点：
                                    不能发挥性能上的优势了
                        2。带有权重的轮询策略
                            概念：
                                给节点加上权重值，比如给 8 核 8G 的机器配置权重为 2，那么就会给它分 配双倍的流量，这种策略就是带
                        3。Nginx 提供了 ip_hash 和 url_hash 算法;
                        4。LVS 提供了按照请求的源地址，和目的地址做 hash 的策略;
                        5。Dubbo 也提供了随机选取策略，以及一致性 hash 的策略。

                2。动态策略
                    概念：
                        负载均衡服务器会依据后端服务的一些负载特性，来决定要选择哪一个服务节点。
                        解释：
                            1。从负载均衡端到后端服务的活跃连接数，或者是调用的响应时间
                            2。然后从中选择连接数最少的服务，或者响应时间最短的后端服务
                    例子一：
                        Dubbo 提供的 LeastAcive 策略，就是优先选择活跃连接数最少的服务
                    例子二：
                        1。Spring Cloud 全家桶中的 Ribbon 提供了 WeightedResponseTimeRule 是使用响应 时间
                        2。给每个服务节点计算一个权重，然后依据这个权重，来给调用方分配服务节点
                    策略的思考点：
                        1。从调用方的角度出发，选择负载最小、资源最空闲的服务来调用
                        2。以期望能得到更高的服务调用性能，也就能最大化地使用服务器的空闲资源，请求也会响应地更 迅速
                        建议：
                            在实际开发中，优先考虑使用动态的策略。
    问题点：
        1。你怎么保证选择出来的这个节点，一定是一个可以正常服务的节点呢?
        2。如果你采用的是轮询的策略，选择出来的，是一个故障节点又要怎么办呢?
        参照24讲：
            1。在微服务化架构中，服务节点会定期地向注册中心发送心跳包
            2。这样注册中心就能够知晓服务节点是否故障，也就可以确认传递给负载均衡服务的节点，一定是可用的。
        思考：
            我们要如何保证配置的服务节点是可用的呢?
        具体实现：
            1。淘宝开源的 Nginx 模块nginx_upstream_check_module了，这个模块可以 让 Nginx 定期地探测后端服务的一个指定的接口
            2。然后根据返回的状态码，来判断服务是否还存活
            3。当探测不存活的次数达到一定阈值时，就自动将这个后端服务从负载均衡服务器中摘除
                代码参考26讲
            4。Nginx 按照上面的方式配置之后，你的业务服务器也要实现一个“/health_check”的接口
            5。在这个接口中返回的 HTTP 状态码，这个返回的状态码可以存储在配置中心中
            6。这样在变更状态码时，就不需要重启服务了
            优点：
                节点检测的功能，还能够帮助我们实现 Web 服务的优雅关闭。
                    服务的优雅关闭：
                        1。需要先切除流量再关闭服务，使用了注册中心之后
                        2。就可以先从注册中心中摘除节点，再重启服务，以便达到优雅关闭的目的
                    问题：
                        Web 服务要如何实现优雅关闭呢?
                        答案：
                            刚启动时：
                                1。可以初始化默认的 HTTP 状态码是 500，这样 Nginx 就不会很快将这个服务节点标记为可用
                                2。也就可以等待服务中，依赖的资源初始化完成，避免服务初始启动时的波动。
                            在完全初始化后：
                                1。再将 HTTP 状态码变更为 200，Nginx 经过两次探测后，就会标记服务为可用。
                                2。在服务关闭时，也应该先将 HTTP 状态码变更为 500，等待 Nginx 探测将服务标记为不可用后
                                3。前端的流量也就不会继续发往这个服务节点。在等待服务正在处理的请求全部处理完毕之后
                                4。再对服务做重启，可以避免直接重启导致正在处理的请求失败的问题。

27 | API网关:系统的门面要如何做呢?
    情形一：
        1。随着自己的电商网站知名度越来越高，系统迎来了一些“不速之客”
        2。在凌晨的时候，系统中的搜索商品和用户接口的调用量，会有激剧的上升，持续一段时间之后又回归正常。
        搜索特征：
            来自固定的几台设备
            方法：
                当你在搜索服务上加一个针对设备 ID 的限流功能之后，凌晨的高峰搜索请求不见了
    情形二：
        但是不久之后，用户服务也出现了大量爬取用户信息的请求，商品接口出现了大量爬取商品信息的请求
        方法：
            不得不在这两个服务上也增加一样的限流策略。
    问题：
        1。不同的三个服务上使用同一种策略，在代码上会有冗余，无法做到重用
        2。如果其他服务上也出现类似的问题，还要通过拷贝代码来实现，肯定是不行的。
        思路：
            将限流的功能独立成一个单独的 jar 包，给这三个服务来引用
        缺点：
            忽略了一种情况，那就是你的电商团队使用的除了Java，还有 PHP 和 Golang 等多种语言。
        优化方法：
            需要引入 API 网关。

    API 网关
        概念：
            1。API 网关(API Gateway)不是一个开源组件，而是一种架构模式
            2。它是将一些服务共有的功能整合在一起，独立部署为单独的一层，用来解决一些服务治理的问题
            3。可以把它看作系统的边界，它可以对出入系统的流量做统一的管控。
        分类：
            1。入口网关
                概念：
                    我们经常使用的网关种类，它部署在负载均衡服务器和应用服务器之间
                作用：
                    1。一方面：
                        它提供客户端一个统一的接入地址，API 网关可以将用户的请求动态路由到不同的业务服务上，并且做一些必要的协议转换工作
                            例子：
                                1。在你的系统中，你部署的微服务对外暴露的协议可能不同:
                                    1。有些提供的是 HTTP 服务
                                    2。有些已经完成 RPC 改造，对外暴露 RPC 服 务
                                    3。有些遗留系统可能还暴露的是 Web Service 服务。
                                2。API 网关可以对客户端屏蔽这些服务的部署地址，以及协议的细节
                            优点：给客户端的调用带来很大的便捷。
                    2。另一方面：
                        在 API 网关中，我们可以植入一些服务治理的策略
                        例子：
                            1。服务的熔断
                            2。降级
                            3。流量控制和分流等等
                    3。再有：
                        1。客户端的认证和授权的实现，也可以放在 API 网关中
                        2。不同类型的客 户端使用的认证方式是不同的
                            例子：
                                1。手机 APP 使用 Oauth 协议认证，HTML5 端和 Web 端使用 Cookie 认证
                                2。部服务使用自研的 Token 认证方式
                        3。这些认证方式在 API 网关上，可以得到统一处理，应用服务不需要了解认证的细节。
                    4。另外：
                        API 网关还可以做一些与黑白名单相关的事情
                        例子：
                            比如针对设备 ID、用户 IP、用户 ID 等维度的黑白名单。
                    5。最后：
                        在 API 网关中也可以做一些日志记录的事情
                        例子：
                            比如记录 HTTP 请求的访问日志，讲述分布式追踪系统时，提到的标记一次请求的 requestId，也可以在网关 中来生成。

            2。出口网关
                背景：
                    在系统开发中，会依赖很多外部的第三方系统
                    例子：
                        第三方账户登录、使用第三方工具支付等等
                    方法：
                        在应用服务器和第三方系统之间，部署出口网关
                作用：
                    对调用外部的 API 做统一的认证、授权，审计以及访问控制。
        实现：
            考虑点：
                1。首先是性能：
                    原因：
                        API 入口网关承担从 客户端的所有流量
                        例子：
                            1。假如业务服务处理时间是 10ms，而 API 网关的耗时在 1ms
                            2。那么相 当于每个接口的响应时间都要增加 10%，这对于性能的影响无疑是巨大的
                            3。而提升 API 网 关性能的关键还是在 I/O 模型上
                        例子：
                            1。Netfix 开源的 API 网关 Zuul，在 1.0 版本的时候使用的是同步阻塞 I/O 模型
                    2。整体系统其 实就是一个 servlet，在接收到用户的请求
                    3。然后执行在网关中配置的认证、协议转换等逻辑之后，调用后端的服务获取数据返回给用户。
                    优化后：
                        1。而在 Zuul2.0 中，Netfix 团队将 servlet 改造成了一个 netty server(netty 服务)
                        2。采用 I/O 多路复用的模型处理接入的 I/O 请求，并且将之前同步阻塞调用后端服务的方式
                        3。改造成使用 netty client(netty 客户端)非阻塞调用的方式
                    优点：
                        改造之后，Netfix 团队经过测试 发现性能提升了 20% 左右。
        2。扩展性：
            概念：
                可以随时在网关的执行链路上，增加一些逻辑，也可以随时下掉一些逻辑(所谓的热插拔)
            原因：
                API 网关中执行的动作有些是可以预先定义好的
            例子：
                1。黑白名单的设置，接口动态路由;
                2。有些则是需要业务方依据自身业务来定义
    具体流程：
        1。我们可以把每一个操作定义为一个 filter(过滤器)
        2。然后使用“责任链模式”将这些 filter 串起来
        优点：
            1。责任链可以动态地组织这些 filter，解耦 filter 之间的关系，
            2。无论是增加还是减少 filter，都不会对其他的 filter 有任何的影响。
        应用：
            Zuul 就是采用责任链模式：
                原理：
                    1。Zuul1 中将 filter 定义为三类
                        1。pre routing filter(路由前过 滤器)
                        2。routing filter(路由过滤器)
                        3。after routing filter(路由后过滤器)
                    2。每一个filter 定义了执行的顺序，在 filter 注册时，会按照顺序插入到 filter chain(过滤器链) 中。
                优点：
                    这样 Zuul 在接收到请求时，就会按照顺序依次执行插入到 filter chain 中的 filter了。
    注意：
        为了提升网关对于请求的并行处理能力，我们一般会使用线程池来并行的执行请求
        问题：
            1。如果商品服务出现问题，造成响应缓慢，那么调用商品服务的线程就会被阻塞无法释放
            2。久而久之，线程池中的线程就会被商品服务所占据，那么其他服务也会受到级联的影响
            分析：
                我们需要针对不同的服务做线程隔离，或者保护
            思路一：
                1。如果你后端的服务拆分得不多，可以针对不同的服务
                2。采用不同的线程池，这样商品服务的故障就不会影响到支付服务和用户服务了;
            思路二：
                在线程池内部可以针对不同的服务，甚至不同的接口做线程的保护
                例子：
                    线程池的最大线程数是 1000，那么可以给每个服务设置一个最多可以使用的配额。
            实际应用：
                你在实际应用中也可以将这两种方式结合
            例子：
                针对不同的服务使用不同的线程池，在线程池内部针对不同的接口设置配额。
    开源实现：
        1。Kong是在 Nginx 中运行的 Lua 程序
            优点：
                得益于 Nginx 的性能优势，Kong 相比于其它 的开源 API 网关来说，性能方面是最好的
            范围：
                由于大中型公司对于 Nginx 运维能力都比较强，所以选择 Kong 作为 API 网关
                原因：
                    无论是在性能还是在运维的把控力上，都是比较好的选择;
        2。Zuul是 Spring Cloud 全家桶中的成员，如果你已经使用了 Spring Cloud 中的其他 组件，那么也可以考虑使用 Zuul 和它们无缝集成。
            缺点：
                1。Zuul1 因为采用同步阻塞模 型，所以在性能上并不是很高效
                2。Zuul2 推出时间不长，难免会有坑
            优点
                1。Zuul 的 代码简单易懂，可以很好的把控
                2。并且你的系统的量级很可能达不到 Netfix 这样的级别，所以对于 Java 技术栈的团队，使用 Zuul 也是一个不错的选择;
        3。Tyk是一种 Go 语言实现的轻量级 API 网关，有着丰富的插件资源，对于 Go 语言栈 的团队来说，也是一种不错的选择。
    使用与选择：
        案例：
            以电商系统为例，带你将 API 网关引入我们的系统之中。
        背景：
            1。我们的电商系统已经经过了服务化改造，在服务层和客户端之间有一层薄薄的Web 层
            2。这个 Web 层做的事情主要有两方面:
                一方面：
                    对服务层接口数据的聚合
                    例子：
                        1。商品详情页的接口，可能会聚合服务层中
                        2。获取商品信息、用户信息、店铺信息以及用户评论等多个服务接口的数据;
                另一方面：
                    1。Web 层还需要将 HTTP 请求转换为 RPC 请求
                    2。并且对前端的流量做一些限制，对于某些请求添加设备 ID 的黑名单等等。
        分析：
            1。我们在做改造的时候，可以先将 API 网关从 Web 层中独立出来
            2。将协议转换、限流、黑白名单等事情，挪到 API 网关中来处理，形成独立的入口网关层;
            3。针对服务接口数据聚合的操作，一般有两种解决思路:
                思路一：
                    1。再独立出一组网关专门做服务聚合、超时控制方面的事情
                    2。我们一般把前一种网关叫做流量网关，后一种可以叫做业务网关;

                思路二：
                    1。抽取独立的服务层，专门做接口聚合的操作
                    2。这样服务层就大概分为原子服务层和聚合服务层。
            4。我们可以在系统和第三方支付服务，以及登陆服务之间部署出口网关服务。
                原先：
                    1。你会在拆分出来的支付服务中，完成对于第三方支付接口所需要数据的加密、签名等操作
                    2。再调用第三方支付接口，完成支付请求
                现在：
                    1。你把对数据的加密、签名的操作放在出口网关中
                    2。这样一来，支付服务只需要调用出口网关的统一支付接口就可以了。

28 | 多机房部署:跨地域的分布式系统如何做?
    案例：
        1。你的垂直电商系统部署的 IDC 机房，在某一天发布了公告说
        2。机房会在第二天凌晨做一次网络设备的割接，在割接过程中会不定时出现瞬间，或短时间网络中断。
    分析：
        1。机房网络的中断，肯定会对业务造成不利的影响，即使割接的时间在凌晨
        2。作为技术负责人的你，也要尽量思考方案来规避隔离的影响
        3。在现有的技术架构下，电商业务全都部署在一个 IDC 机房中，你并没有好的解决办法。
    单一机房：
        缺点：
            系统可用性受制于机房的可用性，也就是机房掌控了系统的生命线
        思考：
            1。如何通过架构的改造，来进一步提升系统的可用性
            2。在网上搜索解决方案和学习一些大厂的经验后，你发现“多机房部署”可以解决这个问题。
    多机房部署：
        概念：
            在不同的 IDC 机房中，部署多套服务，这些服务共享同一份业务数据，并且都可以承接来自用户的流量。
        优点：
            1。当其中某一个机房出现网络故障、火灾，甚至整个城市发生地震、洪水等大的不可抗的灾难时
            2。可以随时将用户的流量切换到其它地域的机房中，从而保证系统可以不间断地持续运行
        例子：
            假如我们有两个机房 A 和 B 都部署了应用服务，数据库的主库和从库部署在 A 机房
            问题：
                机房 B 的应用如何访问到数据呢?
                思路一：
                    直接跨机房读取 A 机房的从库
                思路二：
                    1。在机房 B 部署一个从库，跨机房同步主库的数据
                    2。然后机房 B 的应用就可以 读取这个从库的数据了
                分析：
                    1。无论是哪一种思路，都涉及到跨机房的数据传输
                    2。这就对机房之间延迟情况有比较高的要求了。而机房之间的延迟，和机房之间的距离息息相关
                    情形一：
                        北京同地双机房之间的专线延迟一般在 1ms~3ms。
                        问题：
                            这个延迟会造成怎样的影响呢?
                        分析：
                            1。一个接口的调用
                                1。我们的接口响应时间需要控制在 200ms 之内，而一个接口可能会调用几次第三方 HTTP 服务，或者 RPC 服务
                                2。如果这些服务部署在异地机房，那么接口响应时间就会增加几毫秒，是可以接受的。
                            2。一次接口可能会涉及几次的数据库写入：
                                那么如果数据库主库在异地机房，那么接口的响应时间也会因为写入异地机房的主库，增加几毫秒到十几毫秒，也是可以接受的。
                            3。接口读取缓存和数据库的数量：
                                可能会达到十几次甚至几十次，那么这就会增加几十毫秒甚至上百毫秒的延迟，就不能接受了
                    情形二：
                        国内异地双机房之间的专线延迟会在 50ms 之内。
                        分析：
                            1。具体的延迟数据依据距离的不同而不同。
                                例子：
                                    1。北京到天津的专线延迟，会在 10ms 之内;
                                    2。而北京到上海的延迟就会提高到接近 30ms
                                    3。如果想要在北京和广州部署双机房，那么延迟就会到达 50ms 了。
                            2。在这个延迟数据下，要想保证接口的响应时间在 200ms 之内，就要尽量减少跨机房的服务调用，更要避免跨机房的数据库和缓存操作了。
                    情形三：
                        如果你的业务是国际化的服务，需要部署跨国的双机房，那么机房之间的延迟就更高了
                        分析：
                            1。依据各大云厂商的数据来看，比如，从国内想要访问部署在美国西海岸的服务，这个延迟会在 100ms~200ms 左右
                            2。在这个延迟下，就要避免数据跨机房同步调用，而只做异步的数据同步。
                    注意：
                        1。如果你正在考虑多机房部署的架构，那么这些数字都是至关重要的基础数据
                        2。你需要牢牢记住，避免出现跨机房访问数据造成性能衰减问题。
                        3。机房之间的数据延迟，在客观上是存在的，你没有办法改变，你可以做的，就是尽量避免数据延迟对于接口响应时间的影响

    逐步迭代多机房部署方案：
        1。同城双活
            特点：
                1。同城机房之间的延时在 1ms~3ms 左右，对于跨机房调用的容忍度比较高
                2。只能做到机房级别的容灾，无法做到城市级别的容灾
            优点：
                使用了同城双活架构之后，可以实现机房级别的容灾，服务的部署也能够突破单一机房的限制
            缺点：
                会存在跨机房写数据的问题，不过鉴于写数据的请求量不高，所以在性能上是可以容忍的。
            应用：
                如果你的系统不需要考虑城市级别的容灾，一般做到同城双活就足够了
                原因：
                    相比于城市发生地震、洪水等自然灾害来说，机房网络故障、掉电出现的概率要大的多
            案例：
                1。你在北京有 A 和 B 两个机房，A 是联通的机房，B 是电信的机房
                2。机房之间以专线连接，方案设计时，核心思想是，尽量避免跨机房的调用
            方案：
                数据库:
                    数据库的主库可以部署在一个机房中
                        例子：
                            1。比如部署在 A 机房中，那么 A 和 B 机房数据都会被写入到 A 机房中。
                            2。然后，在 A、B 两个机房中各部署一个从库，通过主从复制的方式，从主库中同步数据，这样双机房的查询请求可以查询本机房的从库
                                优点：
                                    一旦 A 机房发生故障，可以通过主从切换的方式，将 B 机房的从库提升为主库，达到容灾的目的。
                缓存
                    缓存也可以部署在两个机房中，
                        1。查询请求也读取本机房的缓存，如果缓存中数据不存在，就穿透到本机房的从库中，加载数据
                        2。数据的更新可以更新双机房中的数据，保证数据的一致性。
                RPC 服务：
                    1。不同机房的 RPC 服务会向注册中心，注册不同的服务组
                    2。而不同机房的 RPC 客户端， 也就是 Web 服务，只订阅同机房的 RPC 服务组
                    3。这样就可以实现 RPC 调用尽量发生在本机房内，避免跨机房的 RPC 调用。
                web服务：
                    1。你的系统肯定会依赖公司内的其他服务
                    2。比如审核，搜索等服务，如果这些服务也是双机房部署的
                    3。那么也需要尽量保证只调用本机房的服务，降低调用的延迟。
        2。异地多活
            背景：
                1。电商系统的流量达到了京东或者淘宝的级别，那么你就要考虑，即使机房所在的城市发生重大的自然灾害，也要保证系统的可用性。
            考虑点：
                1。首先要考虑异地机房的部署位置
                    原因：
                        它部署的不能太近，否则发生自然灾害时，很可能会波及
                    例子：
                        如果你的主机房在北京，那么异地机房就尽量不要建设在天津，而是可以选择上海、广州这样距离较远的位置
                    缺点：
                        会造成更高的数据传输延迟
                        例子：
                            同城双活中，使用的跨机房写数据库的方案，就不合适了。

                2。在数据写入时，你要保证只写本机房的数据存储服务
                    方案一：
                        基于存储系统的主从复制
                        概念：
                            也就是在一个机房部署主库，在异地机房部署从库，两者同步主从复制, 实现数据的同步。
                        例子：
                            比如 MySQL 和 Redis
                    方案二：
                        基于消息队列的方式
                        概念：
                            1。一个机房产生写入请求后，会写一条消息到消息队列
                            2。另一个机房的应用消费这条消息后，再执行业务处理逻辑，写入到存储服务中
            实践：
                采用两种同步相结合的方式
            例子：
                1。你可以基于消息的方式，同步缓存的数据、HBase 数据等。
                2。然后基于存储，主从复制同步 MySQL、Redis 等数据。

29 | Service Mesh:如何屏蔽服务化系统的服务治理细节?
    背景：
        哪些中间件解决服务之间通信和服务治理的问题
        1。用 RPC 框架解决服务通信的问题;
        2。用注册中心解决服务注册，和发现的问题;
        3。使用分布式 Trace 中间件，排查跨服务调用慢请求;
        4。使用负载均衡服务器，解决服务扩展性的问题;
        5。在 API 网关中植入服务熔断、降级和流控等服务治理的策略。
        现象：
            系统使用的语言还是以 Java 为主，之前提到的服务治理的策略，和服务之间 通信协议也是使用 Java 语言来实现的。
        问题点：
            1。一旦你的团队中，有若干个小团队开始尝试使用 Go 或者 PHP
            2。来开发新的微服务，那么在微服务化过程中，一定会受到挑战。
    跨语言体系带来的挑战
        背景：
            一个公司的不同团队，使用不同的开发语言是比较常见的。
            例子：
                1。微博的主要开发语 言是 Java 和 PHP，近几年也有一些使用 Go 开发的系统。
                2。而使用不同的语言开发出来的微服务，在相互调用时会存在两方面的挑战:
        挑战一：
            1。服务之间的通信协议上，要对多语言友好，要想实现跨语言调用，关键点是选择合适的序列化方式
            例子：
                你用 Java 开发一个 RPC 服务，使用的是 Java 原生的序列化方式
                    缺点：
                        这种序列化方式 对于其它语言并不友好
                    原因：
                        你使用其它语言，调用这个 RPC 服务时，就很难解析序列 化之后的二进制流。
                    方法：
                        选择序列化协议时，考虑序列化协议是否对多语言友好
                        例子：
                            1。Protobuf
                            2。Thrift
        挑战二：
            使用新语言开发的微服务，无法使用之前积累的，服务治理的策略
            例子一：
                1。RPC 客户端在使用注册中心，订阅服务的时候，为了避免每次 RPC 调用都要与注册中心交互
                2。一般会在 RPC 客户端，缓存节点的数据。
                3。如果注册中心中的服务节点发生了变更，那么 RPC 客户端的节点缓存会得到通知，并且变更缓存数据
                4。为了减少注册中心的访问压力，在 RPC 客户端上，我们一般会考虑使用多级缓存(内存缓存和文件缓存)来保证节点缓存的可用性
                分析：
                    1。这些策略在开始的时候，都是使用 Java 语言来实现的，并且封装在注册中心客户端里，提供给 RPC 客户端使用。
                    2。如果更换了新的语言，这些逻辑就都要使用新的语言实现一套。
            例子二：
                1。负载均衡、熔断降级、流量控制、打印分布式追踪日志等等，这些服务治理的策略都需要重新实现
                2。而使用其它语言重新实现这些策略无疑会带来巨大的工作量，也是中间件研发中，一个很大的痛点。
        问题：
            如何屏蔽服务化架构中，服务治理的细节，或者说，如何让服务治理的策略在多语言之间复用呢?
            思路：
                1。可以考虑将服务治理的细节，从 RPC 客户端中拆分出来，形成一个代理层单独部署
                2。这个代理层可以使用单一的语言实现，所有的流量都经过代理层，来使用其中的服务治理策略
                3。这是一种“关注点分离”的实现方式，也是 Service Mesh 的核心思想。
    Service Mesh：
        概念：
            1。主要处理服务之间的通信，它的主要实现形式就是在应用程序同主机上部署一个代理程序
            2。一般来讲，我们将这个代理程序称为“Sidecar(边车)”
            3。服务之间的通 信也从之前的，客户端和服务端直连
        流程：
            1。在这种形式下，RPC 客户端将数据包先发送给，与自身同主机部署的 Sidecar
            2。在 Sidecar 中经过服务发现、负载均衡、服务路由、流量控制之后
            3。再将数据发往指定服务节点的 Sidecar，在服务节点的 Sidecar 中
            4。经过记录访问日志、记录分布式追踪日志、限流之后，再将数据发送给 RPC 服务端。
        分析：
            这种方式，可以把业务代码和服务治理的策略隔离开，将服务治理策略下沉，让它成为独立的基础模块。
            优点：
                1。不仅可以实现跨语言，服务治理策略的复用
                2。还能对这些 Sidecar 做统一的管理。
        方案：
            istio
            解释：
                1。它将组件分为数据平面和控制平面
                    1.数据平面:
                        就是我提到的 Sidecar(Istio 使用Envoy 作为 Sidecar 的实现)
                    2.控制平面:
                        1.主要负责服务治理策略的执行，在 Istio 中，主要分为 Mixer、Pilot 和 Istio-auth 三部分。
                        2.在 Istio 中，每次请求都需要经过控制平面
                            解释：
                                每次请求都需要跨网络的调用 Mixer
                            缺点：
                              这会极大地影响性能。
                            实践思路：
                                1。国内大厂开源出来的 Service Mesh 方案中，一般只借鉴 Istio 的数据平面和控制平面的思路
                                2。然后将服务治理策略做到了 Sidecar 中，控制平面只负责策略的下发
                                3。这样就不需要每次请求都经过控制平面，性能上会改善很多。
        问题：
            如何将流量转发到 Sidecar 中
            背景：
                1。在 Service Mesh 的实现中，一个主要的问题，是如何尽量无感知地引入 Sidecar 作为网络代理
                2。无论是数据流入还是数据流出时，都要将数据包重定向到 Sidecar 的端口上
            实现思路一：
                使用 iptables 的方式来实现流量透明的转发，而 Istio 就默认了，使用 iptables 来实现数据包的转发
                    iptables：
                        概念：
                            1。是 Linux 内核中，防火墙软件 Netfilter 的管理工具
                            2。它位于用户空间，可以控制 Netfilter，实现地址转换的功能
                            3。在iptables 中默认有五条链，你可以把这五条链，当作 数据包流转过程中的五个步骤
                                1。PREROUTING
                                2。INPUT
                                3。FORWARD
                                4。OUTPUT
                                5。POSTROUTING
                                参考：
                                    第29讲数据包在iptables五条默认链中流转的示意图.png
                                解释：
                                    数据包以 PREROUTING 链作为入口，当数据包目的地为本机时，它们 也都会流经到 OUTPUT 链
                                例子
                                    参考第29讲
                        优点：
                            对于业务完全透明，业务甚至不知道有 Sidecar 存在，这样会 减少业务接入的时间
                        缺点：
                            在高并发下，性能上会有损耗
            实现思路二：(轻量级客户端)
                1。RPC 客户端会通过配置的方式，知道 Sidecar 的部署端口
                2。然后通过一个 轻量级客户端，将调用服务的请求发送给 Sidecar
                3。Sidecar 在转发请求之前，先执行一些服务治理的策略
                    例子：
                        1。从注册中心中，查询到服务节点信息并且缓存起来
                        2。然后从服务节点中，使用某种负载均衡的策略选出一个节点等等。
                4.请求被发送到服务端的 Sidecar 上后，然后在服务端记录访问日志，和分布式追踪日志，再把请求转发到真正的服务节点上
                5。服务节点在启动时，会委托服务端 Sidecar，向注册中心注册节点，Sidecar 也就知道了真正服务节点部署的端口是多少
            探索方案三：
                目前在探索的方案还有Cilium
                优点：
                    可以从 Socket 层面实现请求的转发，也就可以避免 iptables 方式在性能上的损耗。
        建议：
            使用轻量级客户端的方式，
                缺点：
                    会有一些改造成本
                优点：
                    实现上最简单，可以快速的让 Service Mesh 在你的项目中落地
    比较成熟的 Service Mesh 框架：
        1。Istio：
            概念：
                这个框架在业界最为著名，它提出了数据平面和控制平面的概念，是 Service Mesh 的先驱
            缺点：
                就是刚才提到的 Mixer 的性能问题。
        2。Linkerd：
            概念：
                第一代的 Service Mesh，使用 Scala 语言编写
            缺点：
                是内存的占用。
        3。SOFAMesh：
            概念：
                蚂蚁金服开源的 Service Mesh 组件，在蚂蚁金服已经有大规模落地的经验。

30 | 给系统加上眼睛:服务端监控要怎么做?
    背景：
        在一个项目的生命周期里，运行维护占据着很大的比重，在重要性上，它几乎与项目研发并驾齐驱
        原因：
            在系统运维过程中，能够及时地发现问题并解决问题，是每一个团队的本职工作
        例子：
            1。你的垂直电商系统在搭建之初，运维团队肯定完成了对于机器 CPU、内存、磁 盘、网络等基础监控
            2。期望能在出现问题时，及时地发现并且处理。
            现象：
                系统在运行过程中，频频得到用户的投诉
            原因：
                1。使用的数据库主从延迟变长，导致业务功能上出现了问题;
                2。接口的响应时间变长，用户反馈商品页面出现空白页;
                3。系统中出现大量错误，影响了用户的正常使用。
            意识：
                要想快速地发现和定位业务系统中出现的问题，必须搭建一套完善的服务端监控体系。
            困境：
    1。首先，监控的指标要如何选择呢?
        谷歌针对分布式系统监 控的经验总结，四个黄金信号
            1。延迟：
                概念：
                    请求的响应时间
                例子：
                    接口的响应时间、访问数据库和缓存的响应时间
            2。通信量：
                概念：
                    理解为吞吐量，也就是单位时间内，请求量的大小。
                例子：
                    访问第三方服务的请求量，访问消息队列的请求量。
            3。错误：
                概念：
                    表示当前系统发生的错误数量
                注意：
                    显示的错误：
                        比如在监控 Web 服务时，出现 4 * * 和 5 * * 的响应码
                    隐式的错误：
                        比如，Web 服务虽然返回的响应码是 200，但是却发生了一些和业务相关的错误(出现了数组越界 的异常或者空指针异常等)
                    这些都是错误的范畴。
            4。饱和度：
                概念：
                    指的是服务或者资源到达上限的程度(也可以说是服务或者资源的利用率
                例子：
                    CPU 的使用率，内存使用率，磁盘使用率，缓存数据库的连接数等等
        可以借鉴 RED 指标体系：
            背景：
                是四个黄金信号中衍生出来的
                R：
                    概念：
                        代表请求量(Request rate)
                E：
                    概念：
                        代表错误 (Error)
                D：
                    概念：
                        代表响应时间(Duration)，少了饱和度的指标

        一些组件或者服务还有独特的指标，这些指标也是需要你特殊关注的：
            例子：
                1。数据库主从延迟数据
                2。消息队列的堆积情况
                3。缓存的命中率等等
            参考：
                第30讲高并发系统中常见组件的监控指标.png
    2。采集这些指标可以有哪些方法和途径呢?
        分析：
            依据采集数据源的不同，选用不同的采集方式
            采集方式一：
                Agent
                    概念：
                        是一种比较常见的，采集数据指标的方式。
                    具体实现：
                        1。通过在数据源的服务器上，部署自研或者开源的 Agent
                        2。来收集收据，发送给监控系统，实现数据的采集
                        3。在采集数据源上的信息时，Agent 会依据数据源上，提供的一些接口获取数据
                    例子一：
                        1。你要从 Memcached 服务器上，获取它的性能数据
                        2。你就可以在 Agent 中，连接这个 Memcached 服务器，并且发送一个 stats 命令，获取服务器的统计信息
                        3。你就可以从返回的信息中，挑选重要的监控指标，发送给监控服务器，形成 Memcached 服务的监控报表
                        4。你也可以从这些统计信息中，看出当前 Memcached 服务器，是否存在潜在的问题
                            状态项：
                                STAT cmd_get 201809037423      // 计算查询的 QPS
                                STAT cmd_set 16174920166      // 计算写入的 QPS
                                STAT get_hits 175226700643    // 用来计算命中率，命中率 = get_hits/cmd_get
                                STAT curr_connections 1416    // 当前连接数
                                STAT bytes 3738857307         // 当前内存占用量
                                STAT evictions 11008640149    // 当前被 memcached 服务器剔除的 item 数量，
                                                              //如果这个数量过大 (比如例子中的这个数值)，那么代表当前 Memcached 容量不足或者 Memcache
                        5。如果你是 Java 的开发者，那么一般使用 Java 语言开发的中间件，或者组件，都可 以通过 JMX 获取统计或者监控信息
                采集方式二：
                    在代码中埋点
                    与 Agent 的不同之处在于：
                        Agent：
                            主要收集的是组件服务端的信息
                        埋点：
                            从客户端的角度，来描述所使用的组件，和服务的性能和可用性
                    问题：
                        那么埋点的方式怎么选择呢?
                        答案：
                            1。你可以使用25 讲分布式 Trace 组件中，提到的面向切面编程的方式
                            2。也可以在资源客户端中，直接计算调用资源或者服务的耗时、调用量、慢请求数，并且发送给监控服务器
                                注意：
                                    1。由于调用缓存、数据库的请求量会比较高，一般会单机也会达到每秒万次
                                    2。如果不经过任何优化，把每次请求耗时都发送给监控服务器，那么，监控服务器会不堪重负
                                        方法：
                                            1。我们一般会在埋点时，先做一些汇总。比如，每隔 10 秒汇总这 10 秒内，
                                            2。对同一个资源的请求量总和、响应时间分位值、错误数等，然后发送给监控服务器
                                            3。这样，就可以大大减少发往监控服务器的请求量了。
                            3。日志也是你监控数据的重要来源之一。
                                例子：
                                    所熟知的 Tomcat 和 Nginx 的访问日志，都是重要的监控日志
                                    方法：
                                        你可以通过开源的日志采集工具，将这些日志中的数据发送给监控服务器。
                                        日志采集工具：
                                            1。Apache Flume
                                            2。Fluentd
                                            3。Filebeat

    3。指标采集到之后又要如何处理和展示呢?
        流程：
            1。在采集到监控数据之后，你就可以对它们进行处理和存储了
            2。我们一般会先用消息队列来承接数据
                作用：
                    主要的作用是削峰填谷，防止写入过多的监控数据，让监控服务产生影响。
            3。与此同时，我们一般会部署两个队列处理程序，来消费消息队列中的数据
                一个消息对列：
                    1。处理程序接收到数据后，把数据写入到 Elasticsearch
                    2。然后通过 Kibana 展示数据，这份数据主要是用来做原始数据的查询;
                另一个消息队列：
                    1。处理程序是一些流式处理的中间件
                        例子：
                            1。Spark
                            2。Storm
                    2。它们从消息队列里，接收数据后会做一些处理，这些处理包括:
                        1。解析数据格式，尤其是日志格式。
                            内容：
                                从里面提取诸如请求量、响应时间、请求 URL 等数 据;
                        2。对数据做一些聚合运算
                            例子：
                                比如，针对 Tomcat 访问日志，可以计算同一个 URL 一段时间 之内的请求量、响应时间分位值、非 200 请求量的大小等等。
                        3。将数据存储在时间序列数据库中
                            这类数据哭的特点：
                                1。可以对带有时间标签的数据，做 更有效的存储
                                2。而我们的监控数据恰恰带有时间标签，并且按照时间递增
                                    时序数据库：
                                        1。InfluxDB
                                        2。OpenTSDB
                                        3。Graphite
                        4。就可以通过 Grafana 来连接时序数据库，将监控数据绘制成报表，呈现给开发 和运维的同学了。
            4。在监控系统中一般会形成以下几个报表
                1。访问趋势报表
                    概念：
                        1。这类报表接入的是 Web 服务器，和应用服务器的访问日志
                        2。展示了服 务整体的访问量、响应时间情况、错误数量、带宽等信息
                    作用：
                        主要反映的是，服务的整体运 行情况，帮助你来发现问题。
                2。性能报表
                    概念：
                        这类报表对接的是资源和依赖服务的埋点数据，展示了被埋点资源的访问量和响应时间情况
                    作用：
                        1。反映了资源的整体运行情况，当你从访问趋势报表发现问题后
                        2。可以先从性能报表中，找到究竟是哪一个资源或者服务出现了问题。
                3。资源报表
                    概念：
                        这类报表主要对接的是，使用 Agent 采集的，资源的运行情况数据。
                    作用：
                        1。当你从性能报表中，发现某一个资源出现了问题
                        2。那么就可以进一步从这个报表中，发现资源究竟出现了什么问题，是连接数异常增高，还是缓存命中率下降
                        3。这样可以进一步帮你分析问题的根源，找到解决问题的方案。

31 | 应用性能管理:用户的使用体验应该如何监控?
    背景：
        有一些问题，服务端的监控报表无法排查，甚至无法感知
        例子一：
            1。有用户反馈创建订单失败，但是从服务端的报表来看，并没有什么明显的性能波动
            2。从存储在 Elasticsearch 里的原始日志中，甚至没有找到这次创建订单的请求
            分析：
                这有可能是客户端有 Bug，或者网络抖动导致创建订单的请求并没有发送到服务端。
        例子二：
            1。有些用户会反馈，使用长城宽带打开商品详情页面特别慢
            2。甚至出现 DNS 解析失败的情况
    问题一：
        当我们遇到这类问题时，要如何排查和优化呢?
        方法：
            应用性能管理
                概念：
                    1。对应用各个层面做全方位的监测，期望及时发现可能存在的问题
                    2。并加以解决，从而提升系统的性能和可用性。
                与服务端监控的区别：
                    服务端监控：
                        核心关注点是后端服务的性能和可用性
                    应用性能管理：
                        1。核心关注点是终端用户的使用体验，也就是你需要衡量
                        2。从客户端请求发出开始，到响应数据返回到客户端为止，这个端到端的整体链路上的性能情况。
    问题二：
        如何搭建这么一套端到端的监控体系呢?
        目的：
            无论是订单创建问题的排查，还是长城宽带用户页面打开缓慢的问题，都可以通过这套监控来发现和排查
        分析：
            1。与搭建服务端监控系统类似，在搭建端到端的，应用性能管理系统时
            2。我们也可以从数据的采集、存储和展示几个方面来思考。
        采集：
            流程：
                1。在数据采集方面，我们可以采用类似 Agent 的方式，在客户端上植入 SDK
                2。由 SDK 负责采集信息，并且经过采样之后，通过一个固定的接口，定期发送给服务端
                3。这个 固定接口和服务端，我们可以称为 APM 通道服务。
            指标：
                1。监控网络情况
                2。监控客户端卡顿情况
                3。垃圾收集数据等等
            通用的数据采集格式：
                1。采集的数据包含下面几个部分，SDK 将这几部分数据转换成JSON 格式后，就可以发送给 APM 通道服务了
                2。这几部分数据格式，你可以在搭建自己的 APM 系统时，直接拿来参考。
                    1。系统部分：
                        概念：
                            包括数据协议的版本号，以及下面提到的消息头、端消息体、业务消息体的长度;
                    2。消息头：
                        概念：
                            主要包括应用的标识(appkey)，消息生成的时间戳，消息的签名以及消息体加密的秘钥;
                    3。端消息体：
                        概念：
                            主要存储客户端的一些相关信息
                        例子：
                            1。客户端版本号、SDK 版本号、 IDFA、IDFV、IMEI、机器型号
                            2。渠道号、运营商、网络类型、操作系统类型、国家
                            3。地区、经纬度等等
                            注意：
                                由于这些信息有些比较敏感，所以我们一般会对信息加密;
                    4。业务消息体：
                        概念：
                            也就是真正要采集的数据，这些数据也需要加密。
                            加密方法：
                                1。首先会分配给这个应用，一对 RSA 公钥和私钥
                                2。然后 SDK 在 启动的时候，先请求一个策略服务，获取 RSA 公钥
                                3。在加密时，客户端会随机生成一个对称加密的秘钥 Key，端消息体和业务消息体，都会使用这个秘钥来加密
                                    问题：
                                        那么数据发到 APM 通道服务后，要如何解密呢?
                                        答案：
                                            1。客户端会使用 RSA 的公钥对秘钥加密，存储在消息头里面(也就是上面提到的，消息体加密秘钥)
                                            2。然后 APM 通道服务使用 RSA 秘钥，解密得到秘钥
                                            3。就可以解密得到端消息体和业务消息体的内容了。
                                            4。最后：
                                                1。我们把消息头、端消息体、业务消息体还有消息头中的时间戳组装起来，
                                                2。用MD5 生 成摘要后，存储在消息头中(也就是消息的签名)
                                                优点：
                                                    1。APM 通道服务在接收到消息 后，可以使用同样的算法生成摘要
                                                    2。并且与发送过来的摘要比对，以防止消息被篡改。
                3。数据被采集到 APM 通道服务之后，我们先对 JSON 消息做解析，得到具体的数据，然后 发送到消息队列里面
                4。从消息队列里面消费到数据之后，会写一份数据到 Elasticsearch 中，作为原始数据保存起来，再写一份到统计平台，以形成客户端的报表

    需要监控用户的哪些信息
        背景：
            搭建端到端的监控体系的首要目标，是解决如何监控客户端网络的问题
            原因：
                我们遇到的客户端问题，大部分的原因还是出在客户端网络上
        案例：
            参考第31讲：
                1。等待时间：
                    概念：
                        1。异步调用时，请求会首先缓存在本地的队列里面，由专门的 I/O 线程负责
                        2。那么在 I/O 线程真正处理请求之前，会有一个等待的时间。
                2。DNS 时间:域名解析时间。
                3。握手时间:TCP 三次握手的时间。
                4。SSL 时间:如果服务是 HTTPS 服务，那么就会有一个 SSL 认证的时间。
                5。发送时间:请求包被发送出去的时间。
                6。首包时间:服务端处理后，客户端收到第一个响应包的时间。
                7。包接收时间:我们接收到所有数据的时间。
            流程：
                1。有了这些数据之后，我们可以通过上面提到的 APM 通道服务，发送给服务端
                2。这样服务端和客户端的同学，就可以从 Elasticsearch 中，查询到原始的数据
                3。也可以对数据做一些聚 合处理、统计分析之后，形成客户端请求监控的报表。
                4。我们就可以有针对性地对 HTTP 请求的某一个过程做优化了。
        三方面的价值
            首先：
                1。这种用户网络监控的所有监控数据均来自客户端，是用户访问数据实时上报
                2。因此能够准确、真实、实时地反应用户操作体验。
            再者：
                1。它是我们性能优化的指向标，当做业务架构改造、服务性能优化
                2。网络优化等任何优化行为时，可以反馈用户性能数据，引导业务正向优化接口性能、可用性等指标。
            最后：
                1。它也能帮助我们监控 CDN 链路质量。
                2。之前的 CDN 的监控，严重依赖 CDN 厂商， 这有一个问题是
                    1。CDN 无法从端上获取到全链路的监控数据，有些时候，客户端到 CDN 的链路出了问题
                    2。CDN 厂商是感知不到的，而客户端监控弥补了这方面的缺陷，并且可以 通过告警机制督促 CDN 及时优化调整问题线路

32 | 压力测试:怎样设计全链路压力测试平台?
    背景：
        1。我们已经搭建了服务端和客户端的监控，通过监控的报表和一些报警规则的设置
        2。你可以实时地跟踪和解决垂直电商系统中出现的问题了
        现象：
            1。不能掉以轻心，因为监控只能发现目前系统中已经存在的问题
            2。对于未来可能发生的性能问题是无能为力的。
        方法：
            1。需要了解在流量增长若干倍的时候，系统的哪些组件或者服务会成为整体系统的瓶颈点
            2。这时你就需要做一次全链路的压力测试
    压力测试：
        概念：
            在高并发大流量下，进行的测试，测试人员可以通过观察系统在峰值负载下的表现，从而找到系统中存在的性能隐患。
        测试流程：
            首先：
                做压力测试时，最好使用线上的数据和线上的环境
                原因：
                    无法确定自己搭建的测试环境与正式环境的差异，是否会影响到压力测试的结果;
            其次：
                1。压力测试时不能使用模拟的请求，而是要使用线上的流量
                2。可以通过拷贝流量的方式，把线上流量拷贝一份到压力测试环境
                原因：
                    模拟流量的访问模型，和线上流量相差很大，会对压力测试的结果产生比较大的影响。
                    例子：
                        1。在获取商品信息的时候，线上的流量会获取不同商品的数据，这些商品的数据有的命中了缓存，有的没有命中缓存
                        2。如果使用同一个商品 ID 来做压力测试，那么只有第一次请求没有命中缓存
                        3。而在请求之后会将数据库中的数据回种到缓存，后续的请求就一定会命中缓存了
                    现象：
                        这种压力测试的数据就不具备参考性了。
            最后：
                不要从一台服务器发起流量，这样很容易达到这台服务器性能瓶颈，从而导致压力测试的 QPS 上不去
                缺点：
                    最终影响压力测试的结果
                例子：
                    比如放在 CDN 节点上。如果没有这个条 件，那么可以放在不同的机房中，这样可以尽量保证压力测试结果的真实性。
        作用：
            1。发现系统中存在问题的方式
            2。也是保障系统可用性和稳定性的重要手段。
        测试范围：
            1。不能只针对某一个核心模块来做压测
            2。需要将接入层、所有后端服务、数据库、缓存、消息队列、中间件以及依赖的第三方服务系统及其资源，都纳入压力测试的目标之中
            原因：
                1。一旦用户的访问行为增加，包含上述组件服务的整个链路都会受到不确定的大流量的冲击
                2。们都需要依赖压力测试来发现可能存在的性能瓶颈，
        方法：
            针对整个调用链路执行的压力测试也称为“全链路压测”
            投入：
                联合 DBA、运维、依赖服务方、中间件架构等多 个团队，一起协调进行

    全链路压测平台
        搭建的主要的两个关键点：
            关键点一：
                是流量的隔离
                    原因：
                        1。由于压力测试是在正式环境进行，所以需要区分压力测试流量和正式流量
                        2。这样可以针对压力测试的流量做单独的处理。
            关键点二：
                是风险的控制
                    原因：
                        尽量避免压力测试对于正常访问用户的影响
        模块：
            1。流量构造和产生模块;
                系统的入口流量来源：
                    客户端的 HTTP 请求
                具体做法：
                    1。在系统高峰期时，将这些入口流量拷贝一份，在经过一些流量清洗的工作之后（比如过滤一些无效的请求)
                    2。将数据存储在像是 HBase、MongoDB 这些 NoSQL 存储组件
                    3。或者亚马逊 S3 这些云存储服务中，我们称之为流量数据工厂。
                注意点：
                    参考第32讲
            2。压测数据隔离模块;
            3。系统健康度检查和压测流量干预模块。

33 | 配置管理:成千上万的配置项要如何管理?
    背景：
        1。实际上有些性能优化可能只需要调整一些配置参数就可以搞定了
            例子一：
                可以调整配置的超时时间，让请求快速失败，防止系统的雪崩，提升系统的可用性;
            例子二：
                可以调整 HTTP 客户端连接池的大小，来提升调用第三方 HTTP 服务的并行处理能力，从而提升系统的性能。
        2。可以认为，配置是管理你系统的工具，在你的垂直电商系统中，一定会有非常多的配置项
            例子：
                数据库的地址、请求 HTTP 服务的域名、本地内存最大缓存数量等等。
    配置管理：
        例子：
            在 Linux 系统中就提供了大量的配置项，可以依据自身业务的 实际情况，动态地对系统功能做调整
            如：
                1。修改 dirty_writeback_centisecs 参数 的数值，就可以调整 Page Cache 中脏数据刷新到磁盘上的频率
                2。也可以通过修改 tcp_max_syn_backlog 参数置的值，来调整未建立连接队列的长度
            方法一：
                修改这些参数既可以 通过修改配置文件并且重启服务器来配置生效
            方法二：
                也可以通过 sysctl 命令来动态地调整，让 配置即时生效。
        方式：
            1。通过配置文件来管理
            2。使用配置中心来管理
        问题：
            1。虽然把配置拆分了出来，但是由于配置还是和代码打包在一起
            2。如果要更改一个配置，还是需要重新打包，这样无疑会增加打包的时间
            方法：
                通常会把配置文件存储的目录，标准化为特定的目录
                例子：
                    都配置成 /data/confs 目录，然后把配置项使用 Git 等代码仓库管理起来。
    配置中心：
        概念：
            微服务架构中的一个标配组件了
        开源方案：
            1。比较出名的有携程开源的 Apollo(推荐)
                特点：
                    支持不同环境，不同集群的配置，有完善的管理功能，支持灰度发布、 更改热发布等功能
            2。百度开源的 Disconf
            3。360 开源的 QConf
            4。Spring Cloud 的组件 Spring Cloud Config 等等。
        存储：
            概念：
                配置中心和注册中心非常类似，其核心的功能就是对于配置项的存储和读取
            思路：
                1。在设计配置中心的服务端时，我们需要选择合适的存储组件
                2。来存储大量的配置信息，这里可选择的组件有很多。
            例子：
                不同的开源配置中心也使用了不同的组件
                1。Disconf、Apollo 使用的是 MySQL;
                2。QConf 使用的是 ZooKeeper。
                3。微博的配置中心使用 Redis 来存储信息
                4。美图的则使用 Etcd
            注意：
                无论使用哪一种存储组件，你所要做的就是规范配置项在其中的存储结构
        变更推送：
            目的：
                实现配置的动态变更，不需要重启服务器就能让配置生效了
            思路一：
                是轮询查询的方式
                做法：
                    1。应用程序向配置中心客户端注册一个监听器，
                    2。配置中心的客户端定期地(比如 1 分钟)查询所需要的配置是否有变化，如果有变化则通知触发监听器，让应用程序得到变更通知。
                问题点：
                    1。如果有很多应用服务器都去轮询拉取配置
                    2。由于返回的配置项可能会很大，那么配置中心服务的带宽就会成为瓶颈。
                    方法：
                        1。给配置中心的每一个配置项，多存储一个根据配置项计算出来的 MD5 值。
                        2。配置项一旦变化，这个 MD5 值也会随之改变
                        3。配置中心客户端在获取到配置的同时，也会获取到配置的 MD5 值，并且存储起来
                        4。那么在轮询查询的时候，需要先确认存储的 MD5 值，和配置中心的 MD5 是不是一致的
                        5。如果不一致，这就说明配置中心中，存储的配置项有变化，然后才会从配置中心拉取最新的配置。
                    分析：
                        由于配置中心里存储的配置项变化的几率不大，所以使用这种方式后，每次轮询请求就只是返回一个 MD5 值
                        优点：
                            可以大大地减少配置中心服务器的带宽。
            思路二：
                长连推送的方式。
                做法：
                    在配置中心服务端保存每个连接关注的配置项列表。
                流程：
                    配置中心感知到配置变化后，就可以通过这个连接，把变更的配置推送给客户端
                缺点：
                    1。需保持长连，也需要保存连接和配置的对应关系
                    2。实现上要比轮询的方式复杂一些
                优点：
                    相比轮询方式来说，能够更加实时地获取配置变更的消息。
        高可用：
            概念：
                可用性的重要程度要远远大于性能
            原因：
                1。我们一般会在服务器启动时，从配置中心中获取配置，
                2。如果配置获取的性能不高，那么外在的表现也只是应用启动时间慢了，对于业务的影响不大
                3。如果获取不到配置，很可能会导致启动失败。
                例子：
                    我们把数据库的地址存储在了配置中心里，如果配置中心宕机导致我们无法获取数据库的地址，那么自然应用程序就会启动失败。
                目标：
                    让配置中心“旁路化”。
                解释：
                    即使配置中心宕机，或者配置中心依赖的存储宕机，我们仍然能够保证应用程序是可以启动的
                方法：
                    1。一般会在配置中心的客户端上，增加两级缓存
                        1。第一级缓存是内存的缓存
                            作用：
                                降低客户端和配置中心的交互频率，提升配置获取的性能
                        2。另外一级缓存是文件的缓存。
                            作用：
                                1。就是灾备，当应用程序重启时，一旦配置中心发生故障
                                2。应用程序就会优先使用文件中的配置
                            缺点：
                                无法得到配置的变更消息(因为配置中心已经宕机了)
                            优点：
                                但是应用程序还是可以启动起来的，算是一种降级的方案。
                    2。配置中心客户端在获取到配置信息后，会同时把配置信息同步地写入到内存缓存，并且异步地写入到文件缓存中。


34 | 降级熔断:如何屏蔽非核心系统故障的影响?
    背景：
        1。电商系统已经搭建了完善的服务端和客户端监控系统，并且完成了全链路压测
    案例：
        1。对于应对“双十一”的考验信心满满，但因为欠缺了一些面对巨大流量的经验
        2。在促销过程中出现了几次短暂的服务不可用，这给部分用户造成了不好的使用体验
    过程：
        事后，你们进行了细致的复盘，追查出现故障的根本原因
        原因：
            一类是：
                依赖的资源或者服务不可用，最终导致整体服务宕机
                例子：
                    电商系统中就可能由于数据库访问缓慢，导致整体服务不可用
                方法：
                    降级、熔断
            另一类是：
                乐观地预估了可能到来的流量，当有超过系统承载能力的流量到来时，系统不堪重负，从而出现拒绝服务的情况。
                方法：
                    限流
    雪崩：
        概念：
            局部故障最终导致全局故障
        扩展：
            1。系统在运行的时候是需要消耗一些资源的，包括 CPU、内存等 系统资源
            2。也包括执行业务逻辑的时候，需要的线程资源。
        案例：
            1。一般在业务执行的容器内，都会定义一些线程池来分配执行任务的线程
                1。比如在 Tomcat 这种 Web 容器的内部，定义了线程池来处理 HTTP 请求
                2。RPC 框架也给 RPC 服 务端初始化了线程池来处理 RPC 请求。
            2。这些线程池中的线程资源是有限的，如果这些线程资源被耗尽，那么服务自然也就无法处理新的请求，服务提供方也就宕机了
            例子：
                1。你的垂直电商系统有四个服务 A、B、C、D，A 调用 B，B 调用 C 和 D。
                2。其中，A、B、D 服务是系统的核心服务(像是电商系统中的订单 服务、支付服务等等)
                3。C 是非核心服务(像反垃圾服务、审核服务)。
                情形一：
                    一旦作为入口的 A 流量增加，你可能会考虑把 A、B 和 D 服务扩容，忽略 C
                    分析：
                        1。那么 C 就有可能因为无法承担这么大的流量，导致请求处理缓慢
                        2。进一步会让 B 在调用 C 的时 候，B 中的请求被阻塞，等待 C 返回响应结果
                        3。B 服务中被占用的线程资源就 不能释放。
                    现象：
                        1。久而久之，B 就会因为线程资源被占满，无法处理后续的请求
                        2。那么从 A 发往 B 的请求， 就会被放入 B 服务线程池的队列中
                        3。然后 A 调用 B 响应时间变长，进而拖垮 A 服务。
                    原因：
                        1。因为非核心服务 C 的响应时间变长，就可以导致整体服务宕机，
                        2。因为服务调用方等待服务提供方的响应时间过长，它的资源被耗尽，才引发了级联反应，发生雪崩。
                解决思路：(降级和熔断机制)
                    1。在检测到某一个服务相应时间出现异常时，切断调用它的服务与它之间的关系，
                    2。让服务的调用快速返回失败，从而释放这次请求持有的资源
    熔断：
        实现方式：(物理中)
            1。这个机制参考的是电路中保险丝的保护机制，当电路超负荷运转的时候
            2。保险丝会断开电路，保证整体电路不受损害
        实现方式(服务治理中)
            1。而服务治理中的熔断机制指的是在发起服务调用的时候，如果返回错误或者超时的次数超过一定阈值
            2。则后续的请求不再发向远程服务而是暂时返回错误。
            断路器模式：
        概念：
            这种实现方式在云计算领域又称为断路器模式
            特点：
                1。在这种模式下，服务调用方为每一个调用的服务维护一个有限状态机
                2。在这个状态机中会有三种状态:关闭(调用远程服务)、半打开(尝试调用远程服务)和打开(返回错误)
                3。这三种状态之间切换的过程是下面这个样子。
                关闭态-》打开态
                    情形：
                        当调用失败的次数累积到一定的阈值时，熔断状态从关闭态切换到打开态。
                    实现方式：
                        一般在实现时，如果调用成功一次，就会重置调用失败次数。
                打开状态-》半打开态
                    情形：
                        当熔断处于打开状态时，我们会启动一个超时计时器，当计时器超时后，状态切换到半打开态
                    实现方式：
                        可以通过设置一个定时器，定期地探测服务是否恢复。
                半打开状态-》关闭态
                    情形：
                        1。在熔断处于半打开状态时，请求可以达到后端服务
                        2。如果累计一定的成功次数后，状态切换到关闭态
                半打开状态-》打开：
                    情形：
                        1。在熔断处于半打开状态时，请求可以达到后端服务，如果出现调用失败的情况，则切换到打开态。
            扩展：
                1。不仅仅微服务之间调用需要熔断的机制
                2。在调用 Redis、Memcached 等资源 的时候也可以引入这套机制
                例子：
                    1。我的团队自己封装的 Redis 客户端中，就实现了一套简单 的熔断机制。
                    2。在系统初始化的时候，我们定义了一个定时器，当熔断器处于 Open 状态时，定期地检测 Redis 组件是否可用
                    3。代码参考第34讲
    降级：
        概念：
            1。相比熔断来说，降级是一个更大的概念
                原因：
                    1。它是站在整体系统负载的角度上，放弃部分非核心功能或者服务
                    2。保证整体的可用性的方法，是一种有损的系统容错方式
            2。熔断也是降级的一种，除此之外还有限流降级、开关降级等等
        开关降级：
            概念：
                指的是在代码中预先埋设一些“开关”，用来控制服务调用的返回值
                解释：
                    1。开关关闭的时候正常调用远程服务，开关打开时则执行降级的策略
                    2。这些开关的值可以存储在配置中心中，当系统出现问题需要降级时
                    3。只需要通过配置中心动态更改开关的值，就可以实现不重启服务快速地降级远程服务了。
            案例：
                1。以电商系统为例，你的电商系统在商品详情页面除了展示商品数据以外，还需要展示评论的数据，
                2。但是主体还是商品数据，在必要时可以降级评论数据
                3。所以，你可以定义这个开关为“degrade.comment”，写入到配置中心中，具体的代码也比较简单
                    代码参考第34讲
                注意：
                    我们在设计开关降级预案的时候，首先要区分哪些是核心服务，哪些是非核心服务
                    原因：
                        我们只能针对非核心服务来做降级处理，然后就可以针对具体的业务，制定不同的降级策略了
                    场景一：(降级数据)
                        针对读取数据的场景，我们一般采用的策略是直接返回降级数据
                        具体做法：
                            1。如果数据库的压力比较大，我们在降级的时候，可以考虑只读取缓存的数据，而不再读取数据库中的数据
                            2。如果非核心接口出现问题，可以直接返回服务繁忙或者返回固定的降级数据。
                    场景二：(降频)
                        对于一些轮询查询数据的场景
                        做法：
                            比如每隔 30 秒轮询获取未读数，可以降低获取数据的频率(将获取频率下降到 10 分钟一次)
                    场景三：(异步)
                        而对于写数据的场景
                        做法：
                            一般会考虑把同步写转换成异步写，这样可以牺牲一些数据一致性和实效性来保证系统的可用性。
            注意：
                1。你在为系统增加降级开关时，一定要在流量低峰期的时候做验证演练
                2。也可以在不定期的压力测试过程中演练，保证开关的可用性。
    应用：
        电商系统在双十一、618 大促的场景。

35 | 流量控制:高并发系统中我们如何操纵流量?
背景：
    1。熔断和降级通过暂时关闭某些非核心服务或者组件从而保护核心系统的可用性
    2。电商系统在双十一、618 大促的场景。系统的峰值流量会超过了预估的峰值
    3。对于核心服务也产生了比较大的影响，而你总不能把核心服务整体降级吧?
    4。那么在这个时候要如何保证服务的稳定性呢?
    方法：
        使用限流的方案
        容易出错：
            1。限流算法选择不当，导致限流效果不好;
            2。开启了限流却发现整体性能有损耗;
            3。只实现了单机的限流却没有实现整体系统的限流。
限流：
    概念：
        1。通过限制到达系统的并发请求数量，保证系统能够正常响应部分用户请求
        2。而对于超过限制的流量，则只能通过拒绝服务的方式保证整体系统的可用性。
    部署方式：
        限流策略一般部署在服务的入口层
        情形一：
            API 网关中，这样可以对系统整体流量做塑形
        情形二：
            在微服务架构中，你也可以在 RPC 客户端中引入限流的策略，来保证单个服务不会被过大的流量压垮
    例子一：
        1。到了十一黄金周的时候你想去九寨沟游玩，结果到了九寨沟才发现景区有了临时的通知
        2。每天仅仅售卖 10 万张门票，而当天没有抢到门票的游客就只能第二天起早继续来抢了
        实现思路：
            对一段时间内(在这里是一天)流量做整体的控制
        作用：
            以避免出现游客过多导致的景区环境受到影响的情况，也能保证游客的安全
    例子二：
        1。如果你挤过地铁，就更能感同身受了。
        2。北京早高峰的地铁都会限流，想法很直接，就是控制进入地铁的人数
        作用：
            保证地铁不会被挤爆，也可以尽量保障人们的安全。
    例子三：
        1。在 TCP 协议中有一个滑动窗口的概念，可以实现对网络传输流量的控制
            情形一：
                如果没有流量控制，当流量接收方处理速度变慢而发送方还是继续以之前的速率发送数据
                现象：
                    那么必然会导致流量拥塞。
                TCP 的滑动窗口：
                概念：
                    理解为接收方所能提 供的缓冲区的大小。
                应用：
                    在接收方回复发送方的 ACK 消息中，会带上这个窗口的大小
                作用：
                    发送方就可以通过这个滑动窗口的大小决定发送数据的速率了。
                        场景一
                            如果接收方处理了一些缓冲区的数据，那么这个滑动窗口就会变大，发送方发送数据的速率就会提升
                        场景二：
                            如果接收方接收了一些数据还没有来得及处理，那么这个滑动窗口就会减小，发送方发送数据的速率就会减慢。
    注意：
        无论是在一体化架构还是微服务化架构中，我们也可以在多个维度上对到达系统的流量做控制
            做法：
                1。你可以对系统每分钟处理多少请求做限制;
                2。可以针对单个接口设置每分钟请求流量的限制;
                3。可以限制单个 IP、用户 ID 或者设备 ID 在一段时间内发送请求的数量;
                4。对于服务于多个第三方应用的开放平台来说，每一个第三方应用对于平台方来说都有一 个唯一的 appkey 来标识，你也可以限制单个 appkey 的访问接口的速率。
限流算法：
    限流目的：
        限制一段时间内发向系统的总体请求量
    固定窗口算法：
        例子
            1。限制一分钟之内系统只能承接 1 万次请求，那么最暴力的一种方式就是记录这一分钟之内访问系统的请求量有多少
            2。如果超过了 1 万次的限制，那么就触发限流的策略返回请求失败的错误
            3。如果这一分钟的请求量没有达到限制，那么在下一分钟到来的时候先重置请求量的计数
            4。再统计这一分钟的请求量是否超过限制。
        实现方式：
            1。首先要启动一个定时器定期重置计数
                例子：
                    你需要限制每秒钟访问次数
            2。而限流的逻辑就非常简单了，只需要比较计数值是否大于阈值就可以了:
        缺点：
            无法限制短时间之内的集中流量。
            例子：
                1。假如我们需要限制每秒钟只能处理 10 次请求，如果前一秒钟产生了 10 次请求
                2。这 10次请求全部集中在最后的 10 毫秒中，而下一秒钟的前 10 毫秒也产生了 10 次请求
                3。那么在这 20 毫秒中就产生了 20 次请求，超过了限流的阈值
                4。但是因为这 20 次请求分布在两 个时间窗口内，所以没有触发限流，这就造成了限流的策略并没有生效。
            方法：
                滑动窗口算法
    滑动窗口算法：
        原理：
            将时间的窗口划分为多个小窗口，每个小窗口中都有单独的请求计数。
        例子：
            1。我们将 1s 的时间窗口 划分为 5 份，每一份就是 200ms
            2。那么当在 1s 和 1.2s 之间来了一次新的请求时，我们就 需要统计之前的一秒钟内的请求量，
            3。也就是 0.2s~1.2s 这个区间的总请求量，如果请求量超过了限流阈值那么就执行限流策略。
        优点：
            解决了临界时间点上突发流量无法控制的问题
        缺点：
            1。要存储每个小的时间窗口内的计数，所以空间复杂度有所增加。
            2。还是无法限制短时间之内的集中流量，也就是说无法控制流量让它们更加平滑
        实践中：
            1。很少使用基于时间窗口的限流算法，而是使用其他限流的算法
            2。一种算法叫做漏桶算法，一种叫做令牌筒算法。

    漏桶算法：
        原理：
            1。它就像在流量产生端和接收端之间增加一个漏桶，流量会进入和暂存到漏桶里面
            2。漏桶的出口处会按照一个固定的速率将流量漏出到接收端(也就是服务接口)。
            3。如果流入的流量在某一段时间内大增，超过了漏桶的承受极限，那么多余的流量就会触发限流策略，被拒绝服务。
        优点：
            1。经过了漏桶算法之后，随机产生的流量就会被整形成为比较平滑的流量到达服务端
            2。从而避免了突发的大流量对于服务接口的影响
        实现：
            1。一般会使用消息队列作为漏桶的实现，流量首先被放入到消息队列中排队
            2。由固定的几个队列处理程序来消费流量，如果消息队列中的流量溢出，那么后续的流量就会被拒绝
    令牌桶算法：
        原理：
            1。如果我们需要在一秒内限制访问次数为 N 次，那么就每隔 1/N 的时间，往桶内放入一个令牌;
            2。在处理请求之前先要从桶中获得一个令牌，如果桶中已经没有了令牌，那么就需要等待新的令牌或者直接拒绝服务
            3。桶中的令牌总数也要有一个限制，如果超过了限制就不能向桶中再增加新的令牌了
        优点：
            这样可以限制令牌的总数，一定程度上可以避免瞬时流量高峰的问题。
        推荐：
            倾向于使用令牌桶算法
            原因：
                漏桶算法在面对突发流量的时候
                情形一
                    采用的解决方式是缓存在漏桶中，这样流量的响应时间就会增长，这就与互联网业务低延迟的要求不符
                情形二：
                    而令牌桶算法可以在令牌中暂存一定量的令牌，能够应对一定的突发流量
        应用：
            Guava 中的限流方案就是使 用令牌桶算法来实现的。
        扩展：
            单机：
                令牌桶算法就需要存储令牌的数量，如果是单机上实现限流的话，可以在 进程中使用一个变量来存储
            分布式：
                但是如果在分布式环境下，不同的机器之间无法共享进程中的变量，我们就一般会使用 Redis 来存储这个令牌的数量
            缺点：
                每次请求的时候都需 要请求一次 Redis 来获取一个令牌，会增加几毫秒的延迟，性能上会有一些损耗
            折中的思路是：
                1。我们可以在每次取令牌的时候，不再只获取一个令牌
                2。而是获取一批令牌，这样可以尽量减少请求 Redis 的次数。
37 | 计数系统设计(一):面对海量数据的计数器要如何做?
    案例：
        设计一个支持高并发大存储量的计数系统。
        场景：
            1。在地铁上，你也许会经常刷微博、点赞热搜，如果有抽奖活动
            2。再转发一波，而这些与微博息息相关的数据，其实就是微博场景下的计数数据
            分类：
                1。微博的评论数、点赞数、转发数、浏览数、表态数等等;
                2。用户的粉丝数、关注数、发布微博数、私信数等等。
            分析：
                1。微博维度的计数代表了这条微博受欢迎的程度
                2。用户维度的数据(尤其是粉丝数)，代表了这个用户的影响力
            现象：
                1。大家会普遍看重这些计数信息
                2。并且在很多场景下，我们都需要查询计数数据(比如首页信息流页面、个人主页面)
                3。计数数据访问量巨大，所以需要设计计数系统维护它。
        设计计数系统的问题：
            在设计计数系统时，不少人会出现性能不高、存储成本很大的问题
            例子：
                把计数与微博数据存储在一起
                缺点：
                    这样每次更新计数的时候都需要锁住这一行记录，降低了写入的并发
                原因：
                    对计数系统的设计和优化不甚了解
                思路：
                    要想解决痛点，你有必要形成完备的设计方案。
                    1。首先了解计数在业务上的特点
    计数在业务上的特点：
        特点一：
            数据量巨大：
            现象：
                1。微博系统中微博条目的数量早已经超过了千亿级别
                2。仅仅计算微博的转发、评论、点赞、浏览等核心计数，其数据量级就已经在几千亿的级别
                3。更何况微博条目的数量还在不断高速地增长，并且随着微博业务越来越复杂
                4。微博维度的计数种类也可能会持续扩展(比如说增加了表态数)，因此，仅仅是微博维度上的计数量级就已经过了万亿级别
                5。除此之外，微博的用户量级已经超过了 10 亿，用户维度的计数 量级相比微博维度来说虽然相差很大，但是也达到了百亿级别
            问题：
                那么如何存储这些过万亿级别的数字，对我们来说就是一大挑战。
        特点二：
            访问量大，对于性能的要求高
            现象；
                1。微博的日活用户超过 2 亿，月活用户接近 5 亿
                2。核心服 务(比如首页信息流)访问量级到达每秒几十万次
                3。计数系统的访问量级也超过了每秒百万级别，而且在性能方面，它要求要毫秒级别返回结果。
        特点三：
            对于可用性、数字的准确性要求高
            现象：
                一般来讲，用户对于计数数字是非常敏感的
                例子：
                    1。比如你直播了好几个月，才涨了 1000 个粉，突然有一天粉丝数少了几百个
                    2。那么你是不是会琢磨哪里出现问题，或者打电话投诉直播平台?
        思考：
            1。面临着高并发、大数据量、数据强一致要求的挑战
            2。微博的计数系统是如何设计和演进的呢?你又能从中借鉴什么经验呢?

    支撑高并发的计数系统要如何设计
        一开始的设计：
            1。微博的流量还没有现在这么夸张，我们本着 KISS(Keep It Simple and Stupid)原则
            2。尽量将系统设计的简单易维护，所以，我们使用 MySQL 存储 计数的数据
                原因：
                    它是我们最熟悉的，团队在运维上经验也会比较丰富
                例子：
                    1。假如要存储微博维度(微博的计数，转发数、赞数等等)的数据
                    2。你可以这么设计表结构: 以微博 ID 为主键，转发数、评论数、点赞数和浏览数分别为单独一列
                    3。这样在获取计数时用一个 SQL 语句就搞定了。
                    参考sql
                        select repost_count, comment_count, praise_count, view_count from t_weibo_count
                分析：
                    在数据量级和访问量级都不大的情况下，这种方式最简单，所以如果你的系统量级不大，你可以直接采用这种方式来实现。
                问题：
                    随着微博的不断壮大，之前的计数系统面临了很多的问题和挑战。
                    现象：
                        1。比如微博用户量和发布的微博量增加迅猛，计数存储数据量级也飞速增长
                        2。而 MySQL 数据库单表的存储量级达到几千万的时候，性能上就会有损耗
                    方法：
                        考虑使用分库分表的 方式分散数据量，提升读取计数的性能。
                    具体实现：
                        我们用“weibo_id”作为分区键，在选择分库分表的方式时，考虑了下面两种:
                        方式一：
                            1。选择一种哈希算法对 weibo_id 计算哈希值，然后依据这个哈希值计算出需要存储到哪一个库哪一张表中
                            2。具体的方式你可以回顾一下第 9 讲数据库分库分表的内容;

                        方式二：
                            1。按照 weibo_id 生成的时间来做分库分表，我们在第 10 讲谈到发号器的时候曾经提到
                            2。ID 的生成最好带有业务意义的字段
                                例子：
                                    比如生成 ID 的时间戳
                                优点：
                                    在分库分表的时候，可以先依据发号器的算法反解出时间戳
                            3。然后按照时间戳来做分库分表
                                例子：
                                    比如，一天一张表或者一个月一张表等等。
                        分析：
                            1。因为越是最近发布的微博，计数数据的访问量就越大
                            2。所以虽然我考虑了两种方案，按照时间来分库分表会造成数据访问的不均匀
                            3。最后用了哈希的方式来做分库分表。
                        原有需求：
                            1。与此同时，计数的访问量级也有质的飞越
                            2。在微博最初的版本中，首页信息流里面是不展示计数数据的，那么使用 MySQL 也可以承受当时读取计数的访问量。
        新增需求：(读需求)
            1。后来在首页信息流中也要展示转发、评论和点赞等计数数据了
            2。信息流的访问量巨大，仅仅靠数据库已经完全不能承担如此高的并发量了
            方法一：
                1。考虑使用 Redis 来加速读请求，通过部署多个 从节点来提升可用性和性能
                2。并且通过 Hash 的方式对数据做分片，也基本上可以保证计数的读取性能
                缺点：(数据库 + 缓存的方式)
                    无法保证数据的一致性
                    例子：
                        比如，如果数据库写入成功而缓存更新失败，就会导致数据的不一致，影响计数的准确性
            方法二：
                完全抛弃了 MySQL，全面使用 Redis 来作为计数的存储组件。
        注意(考虑写需求)
            除了考虑计数的读取性能之外，由于热门微博的计数变化频率相当快，也需要考虑如何提升计数的写入性能
            例子：
                1。每次在转发一条微博的时候，都需要增加这条微博的转发数
                2。那么如果明星发布结婚、离婚的微博，瞬时就可能会产生几万甚至几十万的转发
            问题：
                如果是你的话，要如何降低写压力呢?
            方法：
                用消息队列来削峰填谷了
                例子：
                    在转发微博的时候向消息队列写入一条消息，然后在消息处理程序中给这条微博的转发计数加 1
                优化：
                    我们可以通过批量处理消息的方式进一步减小 Redis 的写压力
                    例子：
                        1。比如像下面这样连续更改 三次转发数(我用 SQL 来表示来方便你理解):
                            UPDATE t_weibo_count SET repost_count = repost_count + 1 WHERE weibo_id = 1;
                            UPDATE t_weibo_count SET repost_count = repost_count + 1 WHERE weibo_id = 1;
                            UPDATE t_weibo_count SET repost_count = repost_count +1 WHERE weibo_id = 1;
                        2。这个时候，你可以把它们合并成一次更新:
                            UPDATE t_weibo_count SET repost_count = repost_count + 3 WHERE weibo_id = 1;
    如何降低计数系统的存储成本：
        背景：
            1。在微博的场景下，计数的量级是万亿的级别，这也给我们提了更高的要求，
            2。就是如何在有限的存储成本下实现对于全量计数数据的存取。
        分析：
            Redis 是使用内存来存储信息，相比于使用磁盘存储数据的 MySQL 来说，存储的成本不可同日而语
        现象：
            1。比如一台服务器磁盘可以挂载到 2 个 T，但是内存可能只有 128G，，这样磁盘的存储空间就是内存的 16 倍
            2。而 Redis 基于通用性的考虑，对于内存的使用比较粗放，存在大量的指针以及额外数据结构的开销
                例子：
                    1。如果要存储一个 KV 类型的计数信息，Key 是 8 字节 Long 类型的 weibo_id，Value 是 4 字节 int 类型的转发数
                    2。存储在 Redis 中之 后会占用超过 70 个字节的空间，
                缺点：
                    空间的浪费是巨大的
                方法：
                    对原生 Redis 做一些改造，采用新的数据结构和数据类型来存储计数数据
                    具体做法
                        1。在改造时，主要涉及了两点:
                            第一：
                                原生的 Redis 在存储 Key 时是按照字符串类型来存储的
                                例子：
                                    1。比如一个 8 字节的 Long 类型的数据
                                    2。需要 8(sdshdr 数据结构长度)+ 19(8 字节数字的长度)+1(’\0’) =28 个字节
                                    3。如果我们使用 Long 类型来存储就只需要 8 个字节，会节省 20 个字节的 空间;
                            第二：
                                1。去除了原生 Redis 中多余的指针，如果要存储一个 KV 信息就只需要 8(weibo_id)+4(转发数)=12 个字节
                                2。相比之前有很大的改进。
                        2。我们也会使用一个大的数组来存储计数信息，存储的位置是基于 weibo_id 的哈希值来计算出来的
                            算法参考第37讲
                        3。在对原生的 Redis 做了改造之后，你还需要进一步考虑如何节省内存的使用
                            例子：
                                1。比如，微博的计数有转发数、评论数、浏览数、点赞数等等
                                2。如果每一个计数都需要存储 weibo_id， 那么总共就需要 8(weibo_id)*4(4 个微博 ID)+4(转发数) + 4(评论数) + 4(点 赞数) + 4(浏览数)= 48 字节
                                3。但是我们可以把相同微博 ID 的计数存储在一起，这样就只需要记录一个微博 ID，省掉了多余的三个微博 ID 的存储开销，存储空间就进一步减少 了。
                        4。即使经过上面的优化，由于计数的量级实在是太过巨大，并且还在以极快的速度增长
                            方法：
                                如果我们以全内存的方式来存储计数信息，就需要使用非常多的机器来支撑。
                        5。然而微博计数的数据具有明显的热点属性:越是最近的微博越是会被访问到，时间上久远的微博被访问的几率很小
                            目的：
                                尽量减少服务器的使用
                            方法：
                                1。我们考虑给计数服务增加 SSD 磁盘，然后将时间上比较久远的数据 dump 到磁盘上，内存中只保留最近的数据
                                2。当我们要读取冷数据的时候，使用单独的 I/O 线程异步地将冷数据从 SSD 磁盘中加载到一块儿单 独的 Cold Cache 中。
    总结：
        1。经过了上面这些优化之后，我们的计数服务就可以支撑高并发大数据量的考验
        2。无论是在性能上、成本上和可用性上都能够达到业务的需求了。

38 | 计数系统设计(二):50万QPS下如何设计未读数系统?
    背景：
        1。通过缓存技术、消息队列技术以及对于 Redis 的深度改造，就能够支撑万亿级计数数据存储以及每秒百万级别读取请求了
        2。然而有一类特殊的计数并不能完全使用我们提到的方案，那就是未读数。
    未读数：
        概念：
            系统中一个常见的模块
        例子：
            1。以微博系统为例，你可看到有多个未读计数的场景
            2。当有人 @你、评论你、给你的博文点赞或者给你发送私信的时候，你会收到相应的未读提醒;
            早期的微博系统：
                1。在早期的微博版本中有系统通知的功能，也就是系统会给全部用户发送消息
                2。通知用户有新的版本或者有一些好玩的运营活动
                3。如果用户没有看，系统就会给他展示有多少条未读的提醒。
                4。我们在浏览信息流的时候，如果长时间没有刷新页面，那么信息流上方就会提示你在这段时间有多少条信息没有看。
    需求一：
        要如何记录未读数呢?
        分析：
            这个需求可以用上节课提到的通用计数系统来实现，因为二者的场景非常相似。
        思路：
            1。可以在计数系统中增加一块儿内存区域，以用户 ID 为 Key 存储多个未读数
            2。当有人 @ 你时，增加你的未读 @的计数
            3。当有人评论你时，增加你的未读评论的计数，以此类推。
            3。当你点击了未读数字进入通知页面，查看 @ 你或者评论你的消息时，重置这些未读计数为零
    需求二：
        那么系统通知的未读数是如何实现的呢?
        分析：
            我们能用通用计数系统实现吗?答案是不能的，因为会出现一些问题。
        做法一：
            1。假如你的系统中只有 A、B、C 三个用户，那么你可以在通用计数系统中 增加一块儿内存区域
            2。并且以用户 ID 为 Key 来存储这三个用户的未读通知数据，当系统发送一个新的通知时
            3。我们会循环给每一个用户的未读数加 1，这个处理逻辑的伪代码就像下面这样:
            缺点：
                但随着系统中的用户越来越多，这个方案存在两个致命的问题。
            问题一：
                1。获取全量用户就是一个比较耗时的操作，相当于对用户库做一次全表的扫描
                2。这不仅会对数据库造成很大的压力，而且查询全量用户数据的响应时间是很长的，对于在线业务来说是难以接受的。
                3。如果你的用户库已经做了分库分表，那么就要扫描所有的库表，响应时间就更长了
                方案一：
                    1。那就是在发送系统通知之前，先从线下的数据仓库中获取全量的用户 ID
                    2。并且存储在一个本地的文件中，然后再轮询所有的用户ID，给这些用户增加未读计数。
                    分析：
                        1。这似乎是一个可行的技术方案，然而它给所有人增加未读计数，会消耗非常长的时间。
                        2。你计算一下，假如你的系统中有一个亿的用户，给一个用户增加未读数需要消耗 1ms
                        3。那么给所有人都增加未读计数就需要 100000000 * 1 /1000 = 100000 秒，也就是超过一天的时间;
                        4。即使你启动 100 个线程并发的设置，也需要十几分钟的时间才能完成
                        4。而用户很难接受这么长的延迟时间。
                        另外：
                            1。使用这种方式需要给系统中的每一个用户都记一个未读数的值
                            2。而在系统中，活跃用户只是很少的一部分，大部分的用户是不活跃的，甚至从来没有打开过系统通知
                            3。为这些用户记录未读数显然是一种浪费。
                方案二：
                    分析：
                        1。系统通知实际上是存储在一个大的列表中的，这个列表对所有用户共享
                        2。也就是所有人看到的都是同一份系统通知的数据
                        3。不过不同的人最近看到的消息不同，所以每个人会有不同的未读数
                        4。你可以记录一下在这个列表中每个人看过最后一条消息的 ID，然后统计这个 ID 之后有多少条消息，这就是未读数了
                    关键点：
                        1。用户访问系统通知页面需要设置未读数为 0，我们需要将用户最近看过的通知 ID 设置为最新的一条系统通知 ID;
                        2。如果最近看过的通知 ID 为空，则认为是一个新的用户，返回未读数为 0;
                        3。对于非活跃用户，比如最近一个月都没有登录和使用过系统的用户，可以把用户最近看过的通知 ID 清空，节省内存空间。
                    优点：
                        即节省内存，又能尽量减少获取未读数的延迟。
                    应用：
                        适用的另一个业务场景是全量用户打点的场景
                        分析：
                            1。这个红点和系统通知类似，也是一种通知全量用户的手段
                            2。果逐个通知用户，延迟也是无法接受的。
                        具体实现：
                            1。首先，我们为每一个用户存储一个时间戳，代表最近点过这个红点的时间，用户点了红点，就把这个时间戳设置为当前时间
                            2。然后，我们也记录一个全局的时间戳，这个时间戳标识最新的一次打点时间
                            3。如果你在后台操作给全体用户打点，就更新这个时间戳为当前时间
                            4。而我们在判断是否需要展示红点时，只需要判断用户的时间戳和全局时间戳的大小
                            5。如果用户时间戳小于全局时间戳，代表在用户最后一次点击红点之后又有新的红点推送
                            6。那么就要展示红点，反之，就不展示红点了。
                共性：
                    1。这两个场景的共性是全部用户共享一份有限的存储数据
                    2。每个人只记录自己在这份存储中的偏移量，就可以得到未读数了。
    需求三：
        如何为信息流的未读数设计方案
        复杂主要有这样几点原因；
            原因一：
                1。微博的信息流是基于关注关系的，未读数也是基于关注关系的
                2。你关注的人发布了新的微博，那么你作为粉丝未读数就要增加 1
                    情形一：
                        1。如果微博用户都是像我这样只有几百粉丝的“小透明”就简单了
                        2。你发微博的时候系统给你粉丝的未读数增加 1 不 是什么难事儿
                    情形二：
                        但是对于一些动辄几千万甚至上亿粉丝的微博大 V 就麻烦了，增加未读 数可能需要几个小时
                    例子：
                        1。假设你是杨幂的粉丝，想了解她实时发布的博文
                        2。那么如果当她发布博文几个小时之后，你才收到提醒，这显然是不能接受的
                3。所以未读数的延迟是你在设计方案时首先要考虑的内容。
            原因二
                其次，信息流未读数请求量极大、并发极高
                    原因：
                        1。接口是客户端轮询请求的，不是用户触发的
                        2。用户即使打开微博客户端什么都不做，这个接口也会被请求到
                            例子：
                                在几年前，请求未读数接口的量级就已经接近每秒 50 万次，这几年随着微博量级的增长，请求量也变得更高
                            分析：
                                而作为微博的非核心接口，我们不太可能使用大量的机器来抗未读数请求
                                问题：
                                    如何使用有限的资源来支撑如此高的流量是这个方案的难点。
                        3。它不像系统通知那样有共享的存储
                            原因：
                                每个人关注的人不同，信息流的列表也就不同，所以也就没办法采用系统通知未读数的方案。
        做法：
            第一步：
                在通用计数器中记录每一个用户发布的博文数;
            第二步：
                1。然后在 Redis 或者 Memcached 中记录一个人所有关注人的博文数快照
                2。当用户点击未读消息重置未读数为 0 时，将他关注所有人的博文数刷新到快照中;
            第三步：
                他关注所有人的博文总数减去快照中的博文总数就是他的信息流未读数
            例子：
                1。假如用户 A，像上图这样关注了用户 B、C、D，其中 B 发布的博文数是 10
                2。C 发布的博 文数是 8，D 发布的博文数是 14
                3。而在用户 A 最近一次查看未读消息时，记录在快照中的 这三个用户的博文数分别是 6、7、12
                4。因此用户 A 的未读数就是(10-6)+(8- 7)+(14-12)=7。
            优点：
                这个方案设计简单，并且是全内存操作，性能足够好，能够支撑比较高的并发
            现象：
                1。事实上微博 团队仅仅用 16 台普通的服务器就支撑了每秒接近 50 万次的请求
                2。这就足以证明这个方案的性能有多出色，因此，它完全能够满足信息流未读数的需求。
            缺点：
                1。比如说快照中需要存储关注关系，如果关注关系变更的时候更新不及时，那么就会造成未读数不准确
                2。快照采用的是全缓存存储，如果缓存满了就会剔除一些数据，那么被剔除用户的未读数就变为 0 了
                容忍度：
                    1。但是好在用户对于未读数的准确度要求不高(未读 10 条还是 11 条，其实用户有时候看不出来)
                    2。这些缺陷也是可以接受的。
    建议：
        1。缓存是提升系统性能和抵抗大并发量的神器
            例子：
                像是微博信息流未读数这么大的量级我们仅仅使用十几台服务器就可以支撑，这全都是缓存的功劳;
        2。要围绕系统设计的关键困难点想解决办法
            例子：
                就像我们解决系统通知未读数的延迟问题一样;
        3。合理分析业务场景，明确哪些是可以权衡的，哪些是不行的，会对你的系统设计增益良多
            例子：
                1。对于长久不登录用户，我们就会记录未读数为 0，通过这样的权衡
                2。可以极大地减少内存的占用，减少成本。

39 | 信息流设计(一):通用信息流系统的推模式要如何做?
    背景：
        1。最早的信息流系统起源于微博，我们知道，微博是基于关注关系来实现内容分发的，也就是说
        2。如果用户 A 关注了用户 B，那么用户 A 就需要在自己的信息流中，实时地看到用户 B 发布的最新内容
        3。这是微博系统的基本逻辑，也是它能够让信息快速流通、快速传播的关键
        4。由于微博的信息流一般是按照时间倒序排列的，所以我们通常把信息流系统称为 TimeLine(时间线）
        问题：
            那么当我们设计一套信息流系统时需要考虑哪些点呢?
    设计信息流系统的关注点有哪些
        关注点一：
            关注延迟数据：
            例子：
                你关注的人发了微博信息之后，信息需要在短时间之内出现在你的信息流中。
        关注点二：
            我们需要考虑如何支撑高并发的访问
            例子：
                1。信息流是微博的主体模块，是用户进入到微博之后最先看到的模块
                2。因此它的并发请求量是最高的，可以达到每秒几十万次请求。
        关注点三：
            信息流拉取性能直接影响用户的使用体验。
            例子：
                1。微博信息流系统中需要聚合的数据非常多，你打开客户端看一看，想一想其中需要聚合哪些数据?
                2。主要是微博的数据，用户的数据，除此之外，还需要查询微博是否被赞、评论点赞转发的计数、是否被关注拉黑等等
                3。聚合这么多的数据就需要查询多次缓存、数据库、计数器，而在每秒几十万次的请求下
            问题：
                如何保证在 100ms 之内完成这些查询操作，展示微博的信息流呢?
            难点：
                这是微博信息流系统最复杂之处，也是技术上最大的挑战。

    思路一：
        基于推模式实现信息流系统
            推模式：
                概念：
                    1。是指用户发送一条微博后，主动将这条微博推送给他的粉丝
                    2。从而实现微博的分发，也能以此实现微博信息流的聚合。
                思路：
                    1。假设微博系统是一个邮箱系统，那么用户发送的微博可以认为是进入到一个发件箱，用户的信息流可以认为是这个人的收件箱
                    2。推模式的做法是在用户发布一条微博时，除了往自己的发件箱里写入一条微博
                    3。同时也会给他的粉丝收件箱里写入一条微博。
                        具体：
                            1。假如用户 A 有三个粉丝 B、C、D，如果用 SQL 表示 A 发布一条微博时系统做的事情，
                            2。那么就像下面展示的这个样子:
                                insert into outbox(userId, feedId, create_time) values("A", $feedId, $current_t
                                insert into inbox(userId, feedId, create_time) values("B", $feedId, $current_ti
                                insert into inbox(userId, feedId, create_time) values("C", $feedId, $current_ti
                                insert into inbox(userId, feedId, create_time) values("D", $feedId, $current_ti
                            3。当我们要查询 B 的信息流时，只需要执行下面这条 SQL 就可以了:
                                select feedId from inbox where userId = "B";
                    4。如果你想要提升读取信息流的性能，可以把收件箱的数据存储在缓存里面，每次获取信息流的时候直接从缓存中读取就好了
                缺点：
                    问题一：
                        1。就是消息延迟
                            例子：
                                1。对明星来说，他们的粉丝数庞大，如果在发微博的同时还要将微博写入到上千万人的收件箱中
                                2。那么发微博的响应时间会非常慢，用户根本没办法接受
                                3。因此，我们一般会使用消息队列来消除写入的峰值，但即使这样，由于写入收件箱的消息实在太多
                                4。还是有可能在几个小时之后才能够看到明星发布的内容，这会非常影响用户的使用体验。
                        2。在推模式下，你需要关注的是微博的写入性能
                            原因：
                                用户每发一条微博，都会产生多次的数据库写入。
                            思路：
                                为了尽量减少微博写入的延迟，我们可以从两方面来保障。
                                一方面：
                                    在消息处理上，你可以启动多个线程并行地处理微博写入的消息。
                                另一方面：
                                    1。由于消息流在展示时可以使用缓存来提升读取性能
                                    2。所以我们应该尽量保证数据写入数据库的性能，必要时可以采用写入性能更好的数据库存储引擎。
                        例子：
                            1。我在网易微博的时候就是采用推模式来实现微博信息流的
                            2。当时为了提升数据库的插入性能，我们采用了 TokuDB 作为 MySQL 的存储引擎，这个引擎架构的核心是一个名为 分形树的索引结构(Fractal Tree Indexes)
                            3。我们知道数据库在写入的时候会产生对磁盘的随机写入，造成磁盘寻道，影响数据写入的性能
                            4。分形树结构和我们在11 讲中提到的 LSM 一样，可以将数据的随机写入转换成顺序写入，提升写入的性能
                            优点：
                                5。TokuDB 相比于 InnoDB 来说，数据压缩的性能更高，经过官方的测试，TokuDB 可以将存储在 InnoDB 中的 4TB 的数据压缩到 200G
                                6。这对于写入数据量很大的业务来说也是一大福音
                            缺点：
                                相比于 InnoDB 来说，TokuDB 的删除和查询性能都要差一些
                                方法：
                                    不过可以使用缓存加速查询性能，而微博的删除频率不高，
                    问题二：
                        存储成本很高
                        在这个方案中我们一般会这么来设计表结构:
                        第一步：
                            1。先设计一张 Feed 表，这个表主要存储微博的基本信息
                            2。包括微博 ID、创建人的 ID、创建时间、微博内容、微博状态(删除还是正常)等等，它使用微博 ID 做哈希分库分表
                        第二步：
                            1。另外一张表是用户的发件箱和收件箱表，也叫做 TimeLine 表(时间线表)
                            2。主要有三个字段，用户 ID、微博 ID 和创建时间。它使用用户的 ID 做哈希分库分表。
                        分析：
                            由于推模式需要给每一个用户都维护一份收件箱的数据，所以数据的存储量极大
                                例子：
                                    谢娜的粉丝目前已经超过 1.2 亿，那么如果采用推模式的话，谢娜每发送一条微博 就会产生超过 1.2 亿条的数据
                                解决思路：
                                    1。除了选择压缩率更高的存储引擎之外，还可以定期地清理数据
                                    2。因为微博的数据有比较明显的实效性，用户更加关最近几天发布的数据，通常不会翻阅很久之前的微博
                                    3。所以你可以定期地清理用户的收件箱，比如只保留最近 1 个月的数据就可以了。
                    问题三：
                        会遇到扩展性的问题
                        例子：
                            1。在微博中有一个分组的功能，它的作用是你可以将关注的人分门别类
                            2。比如你可以把关注的人分为“明星”“技术”“旅游”等类别，然后把杨幂放入“明星”分类里，将 InfoQ 放在“技术”类别里
                        问题：
                            那么引入了分组之后，会对推模式有什么样的影响呢?
                            分析：
                                1。首先是一个用户不止有一个收件箱，比如我有一个全局收件箱，还会针对每一个分组再分别创建一个收件箱
                                2。而一条微博在发布之后也需要被复制到更多的收件箱中了。
                            例如：
                                如果杨幂发了一条微博，那么不仅需要插入到我的收件箱中，还需要插入到我的“明星”收件箱中
                                    缺点：
                                        1。不仅增加了消息分发的压力
                                        2。同时由于每一个收件箱都需要单独存储，所以存储成本也就更高。
                    问题四：
                        在处理取消关注和删除微博的逻辑时会更加复杂
                        例子：
                            1。比如当杨幂删除了一条微博，那么如果要删除她所有粉丝收件箱中的这条微博，会带来额外的分发压力
                            2。我们还是尽量不要这么做。
                            3。而如果你将一个人取消关注，那么需要从你的收件箱中删除这个人的所有微博
                            4。假设他发了非常多的微博，那么即使你之后很久不登录，也需要从你的收件箱中做大量的删除操作，有些得不偿失
                        策略：
                            1。在读取自己信息流的时候，判断每一条微博是否被删除以及你是否还关注这条微博的作者
                            2。如果没有的话，就不展示这条微博的内容了
                            3。使用了这个策略之后，就可以尽量减少对于数据库多余的写操作了。
                适合场景：
                    比较适合于一个用户的粉丝数比较有限的场景
                    例子：
                        1。比如说微信朋友圈，你可以理解为我在微信中增加一个好友 是关注了他也被他关注
                        2。所以好友的上限也就是粉丝的上限(朋友圈应该是 5000)
                    优点：
                        1。有限的粉丝数可以保证消息能够尽量快地被推送给所有的粉丝，增加的存储成本也比较有限
                        2。如果你的业务中粉丝数是有限制的，那么在实现以关注关系为基础的信息流时，也可以采用推 模式来实现。
    思路二：
        基于拉模式实现信息流系统
        参考第40讲

40 | 信息流设计(二):通用信息流系统的拉模式要如何做?
    背景：
        1。由于微博大 V 用户粉丝量巨大，如果我们使用推模式实现信息流系统
        2。只能缓解这些用户的微博推送延迟问题，没有办法彻底解决
    拉模式：
        概念：
            指用户主动拉取他关注的所有人的微博，将这些微博按照发布时间的倒序进行排序和聚合之后，生成信息流数据的方法。
    分析：
        1。用户的收件箱不再有用，因为信息流数据不再出自收件箱，而是出自发件箱
        2。发件箱里是用户关注的所有人数据的聚合
        3。因此用户在发微博的时候就只需要写入自己的发件箱，而不再需要推送给粉丝的收件箱了，这样在获取信息流的时候，就要查询发件箱的数据了。
        sql表示：
            假设用户 A 关注了用户 B、 C、D，那么当用户 B 发送一条微博的时候，他会执行这样的操作:
                insert into outbox(userId, feedId, create_time) values("B", $feedId, $current_t
            当用户 A 想要获取他的信息流的时候，就要聚合 B、C、D 三个用户收件箱的内容了:
                select feedId from outbox where userId in (select userId from follower where fa
    优点：
        1。拉模式彻底解决了推送延迟的问题
            例子：
                大 V 发微博的时候不再需要推送到粉丝的收件箱，自然就不存在延迟的问题了。
        2。存储成本大大降低了
            例子：
                1。在推模式下，谢娜的粉丝有 1.2 亿，那么谢娜发送一条微博 就要被复制 1.2 亿条
                2。写入到存储系统中。在拉模式下只保留了发件箱，微博数据不再需要复制，成本也就随之降低了。
        3。功能扩展性更好了
            例子：
                比如，微博增加了分组的功能，而你想把关注的 A 和 B 分成一 个单独的组
                问题：
                    那么 A 和 B 发布的微博就形成了一个新的信息流，这个信息流要如何实现呢?
                方法：
                    1。你只需要查询这个分组下所有用户(也就是 A 和 B)
                    2。然后查询这些用户的发件箱，再把发件箱中的数据，按照时间倒序重新排序聚合就好了。
            参考代码：
                List<Long> uids = getFromGroup(groupId); // 获取分组下的所有用户
                Long<List<Long>> ids = new ArrayList<List<Long>>();
                for(Long id : uids) {
                    ids.add(getOutboxByUid(id)); // 获取发件箱的内容 id 列表
                }
                return merge(ids); // 合并排序所有的 id
    缺点：
        问题一：
            1。不同于推模式下获取信息流的时候，只是简单地查询收件箱中的数据
            2。在拉模式下，我们需要对多个发件箱的数据做聚合，这个查询和聚合的成本比较高
            例子：
                1。微博的关注上限是 2000，假如你关注了 2000 人，就要查询这 2000 人发布的微博信息
                2。然后再对查询出来的信息做聚合。
            问题：
                如何保证在毫秒级别完成这些信息的查询和聚合呢?
                答案：
                    还是缓存
                具体实现：
                    1。我们可以把用户发布的微博 ID 放在缓存中，不过如果把全部用户的所有微博都缓存起来，消耗的硬件成本 也是很高的
                    2。所以我们需要关注用户浏览信息流的特点，看看是否可能对缓存的存储成本做一些优化。
                    调查：
                        1。在实际执行中，我们对用户的浏览行为做了抽量分析，发现 97% 的用户都是在浏览最近 5 天之内的微博
                        2。也就是说，用户很少翻看五天之前的微博内容，所以我们只缓存了每个用户最近 5 天发布的微博 ID。
                    做法
                        1。假设我们部署 6 个缓存节点来存储这些微博 ID，在每次聚合时并行从这几个缓存节点中批量查询多个用户的微博 ID
                        2。获取到之后再在应用服务内存中排序后就好了，这就是对缓存的 6 次请求，可以保证在 5 毫秒之内返回结果
        问题二：
            缓存节点的带宽成本比较高。
            例子：
                1。假设微博信息流的访问量是每秒 10 万次请 求，也就是说，每个缓存节点每秒要被查询 10 万次
                2。假设一共部署 6 个缓存节点，用户人均关注是 90，平均来说每个缓存节点要存储 15 个用户的数据
                3。如果每个人平均每天发布 2 条微博，5 天就是发布 10 条微博，15 个用户就要存储 150 个微博 ID
                4。每个微博 ID 要 是 8 个字节，150 个微博 ID 大概就是 1kB 的数据
                5。单个缓存节点的带宽就是 1kB * 10 万 = 100MB，基本上跑满了机器网卡带宽了
            方法：
                1。在14 讲中我提到，部署多个缓存副本提升缓存可用性，其实，缓存副本也可以分摊带宽 的压力
                2。我们知道在部署缓存副本之后，请求会先查询副本中的数据，只有不命中的请求才会查询主缓存的数据
                例子：
                    1。假如原本缓存带宽是 100M，我们部署 4 组缓存副本，缓存副本的命中率是 60%
                    2。那么主缓存带宽就降到 100M * 40% = 40M
                    3。而每组缓存副本的带宽为 100M / 4 = 25M，这样每一组缓存的带宽都降为可接受的范围之内了。
    推拉结合的方案是怎样的：
        背景：
            1。我在系统搭建初期已经基于推模式实现了一套信息流系统
            2。如果把它推倒重新使用拉模式实现的话，系统的改造成本未免太高了
        问题：
            有没有一种基于推模式的折中的方案呢?
            案例：
                1。其实我在网易微博的时候，网易微博的信息流就是基于推模式来实现的
                2。当用户的粉丝量大量上涨之后，我们通过对原有系统的改造实现了一套推拉结合的方案
                3。也能够基本解决推模式存在的问题，具体怎么做呢?
        方案：
            核心在于大 V 用户在发布微博的时候，不再推送到全量用户，而是只推送给活跃的用户
        关键点一：
            1。我们要如何判断哪些是大 V 用户呢?
            2。或者说，哪些用户在发送微博时需要推送全量 用户，哪些用户需要推送活跃用户呢?
            方法：
                还是应该以粉丝数作为判断标准
            例子：
                粉丝数超过 50 万就算作大 V，需要只推送活跃用户。
        关键点二：
            我们要如何标记活跃用户呢?
            方法：
                活跃用户可以定义为最近几天内在微博中有过操作的用户
            例子：
                1。比如说刷新过信息流、发布过微博、转发评论点赞过微博，关注过其他用户等等
                2。一旦有用户有过这些操作，我们就把他标记为活跃的用户。
                对于大V用户：
                    1。我们可以存储一个活跃粉丝的列表，这个列表里面就是我们标记的活跃用户。
                    2。当某一个用户从不活跃用户变为活跃用户时，我们会查询这个用户的关注者中哪些是大V
                    3。然后把这个用户写入到这些大 V 的活跃粉丝列表里面，这个活跃粉丝列表是定长的
                    4。如果活跃粉丝数量超过了长度，就把最先加入的粉丝从列表里剔除，这样可以保证推送的效率。
        关键点三：
            1。一个用户被从活跃粉丝列表中剔除，或者是他从不活跃变成了活跃后
            2。由于他不在大 V 用户的活跃粉丝列表中，所以也就不会收到微博的实时推送
            3。因此，我们需要异步地把大 V 用户最近发布的微博插入到他的收件箱中，保证他的信息流数据的完整性。
        优点：
            采用推拉结合的方式可以一定程度上弥补推模式的缺陷
        缺点：
            带来了一些维护的成本
        例子：
            系统需要维护用户的在线状态，还需要多维护一套活跃的粉丝列表数据，在存储上的成本就更高了。
        应用：
            1。这种方式一般适合中等体量的项目，当粉丝量级在百万左右，活跃粉丝数量在 10 万级别时
            2。一般可以实现比较低的信息传播延迟以及信息流获取延迟，但是当你的粉丝数量继续上涨，
            3。流量不断提升之后，无论是活跃粉丝的存储还是推送的延迟都会成为瓶颈，所以改成拉模式会更好的支撑业务。