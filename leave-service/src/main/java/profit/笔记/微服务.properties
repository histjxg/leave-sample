01讲到底什么是微服务？
    概念：
        1。是由单一应用程序构成的小服务，拥有自己的进程与轻量化处理，服务依业务功能设计，以全自动的方式部署，与其他服务使用HTTP API通讯
        2。同时，服务会使用最小规模的集中管理 （例如Docker）技术，服务可以用不同的编程语言与数据库等。
    单体应用：
        背景：早期在业务规模不大、开发团队人员规模较小的时候，采用单体应用架构
        现象：然而随着业务规模的不断扩大，团队开发人员的不断扩张，单体应用架构就会开始出现问题
        缺点：
            1。部署效率底下
            2。团队协作开发成本高。
            3。系统高可用性差。
            4。线上发布变慢
    服务化：
        概念：
            服务化就是把传统的单机应用中通过JAR包依赖产生的本地方法调用，改造成通过RPC接口产生的远程方法调用
            例子：
                1。微博既包含了内容模块，也包含了消息模块和用户模块等，三个模块耦合在一起，一旦任何一个模块出现bug，依赖的资源出现问题，
                    整个单体都会受到影响；
        解决办法：
            1。首先可以把用户模块从单体应用中拆分出来，独立成一个服务部署，以RPC接口的形式对外提供服务
            2。微博和消息模块调用用户接口，就从进程内的调用变成远程RPC调用
            3。用户模块就可以独立开发、测试、上线和运维，可以交由专门的团队来做，与主模块不耦合。
            4。进一步的可以再把消息模块也拆分出来作为独立的模块，交由专门的团队来开发和维护。
        优点：
            解决单体应用膨胀、团队开发耦合度高、协作效率低下的问题。
    什么是微服务？
        背景：
            从2014年开始，得益于以Docker为代表的容器化技术的成熟以及DevOps文化的兴起，服务化的思想进一步演化，演变为今天我们所熟知的微服务。
        与服务化的区别：
            1。服务拆分粒度更细
                概念：微服务可以说是更细维度的服务化，小到一个子模块，只要该模块依赖的资源与其他模块都没有关系，那么就可以拆分为一个微服务。
            2。服务独立部署
                概念：
                    1。每个微服务都严格遵循独立打包部署的准则，互不影响
                    2。比如一台物理机上可以部署多个Docker实例，每个Docker实例可以部署一个微服务的代码。
            3。服务独立维护
                概念：每个微服务都可以交由一个小团队甚至个人来开发、测试、发布和运维，并对整个生命周期负责。
            4。服务治理能力要求高
                概念：因为拆分为微服务之后，服务的数量变多，因此需要有统一的服务治理平台，来对各个服务进行管理。
        例子：举的微博系统为例
            1。可以进一步对内容模块的功能进行拆分，比如内容模块又包含了feed模块、评论模块和个人页模块
            2。通过微服务化，将这三个模块变成三个独立的服务，每个服务依赖各自的资源，并独立部署在不同的服务池中，可以由不同的开发人员进行维护。
            3。评论服务需求变更时，只需要修改评论业务相关的代码，并独立上线发布
            4。而feed服务和个人页服务不需要变更，也不会受到发布可能带来的变更影响
        优点：
            微服务化给服务的发布和部署，以及服务的保障带来了诸多好处。
02讲从单体应用走向服务化
    什么时候进行服务化拆分？
        第一阶段：验证可行性
            目标：是快速开发和验证想法，证明产品思路是否可行
            设计：功能设计一般不会太复杂，开发采取快速迭代的方式，架构也不适合过度设计
            流程：
                1。将所有功能打包部署在一起，集中地进行开发、测试和运维，对于项目起步阶段，是最高效也是最节省成本的方式
                2。当可行性验证通过，功能进一步迭代，就可以加入越来越多的新特性。
        第二阶段：可行性通过
            现象：
            1。就需要大规模地扩张开发人员，以支撑多个功能的开发
            2。如果这个时候继续采用单体应用架构，多个功能模块混杂在一起开发、测试和部署的话，就会导致不同功能之间相互影响，一次打包部署需要所有的功能都测试OK才能上线。
            3。就会遇到上面的问题，这个时候就该考虑进行服务化拆分了。
    服务化拆分的两种姿势
        纵向拆分：是从业务维度进行拆分
            标准：标准是按照业务的关联程度来决定，
                1。关联比较密切的业务适合拆分为一个微服务
                2。而功能相对比较独立的业务适合单独拆分为一个微服务。
            例子：社交App为例
                你可以认为首页信息流是一个服务，评论是一个服务，消息通知是一个服务，个人主页也是一个服务。
        横向拆分：是从公共且独立功能维度拆分。
            标准：是按照是否有公共的被多个其他服务调用，且依赖的资源独立不与其他业务耦合。
            例子：社交App举例
                1。无论是首页信息流、评论、消息箱还是个人主页，都需要显示用户的昵称
                2。假如用户的昵称功能有产品需求的变更，你需要上线几乎所有的服务，这个成本就有点高了
                3。显而易见，如果我把用户的昵称功能单独部署成一个独立的服务，那么有什么变更我只需要上线这个服务即可，其他服务不受影响，开发和上线成本就大大降低了。
    服务化拆分的前置条件
        1。服务如何定义
            单体应用：不同功能模块之前相互交互时，通常是以类库的方式来提供各个模块的功能。
            微服务来说：每个服务都运行在各自的进程之中，应该以何种形式向外界传达自己的信息呢
                    接口：http或者RPC
                        调用：
                            1。通过接口描述约定
                            2。约定内容包括接口名，接口参数以及接口返回值

        2。服务如何发布和订阅：
            注册中心：
                1。服务提供者该如何对外暴露自己的地址
                2。服务调用者查询所需要调用的服务的地址
        3。服务如何监控
            指标：QPS（调用量）、AvgTime（平均耗时）以及P999（99.9%的请求性能在多少毫秒以内）
            监控方案：业务埋点、数据收集、数据处理，最后到数据展示的全链路功能。
        4。服务如何治理
            现象：可以想象，拆分为微服务架构后，服务的数量变多了，依赖关系也变复杂了
            问题：比如一个服务的性能有问题时，依赖的服务都势必会受到影响
            方法：熔断，设定一个调用性能阈值，如果一段时间内一直超过这个值，那么依赖服务的调用可以直接返回
        5。故障如何定位
            问题：在单体应用拆分为微服务之后，一次用户调用可能依赖多个服务，每个服务又部署在不同的节点上，如果用户调用出现问题
            思考：需要有一种解决方案能够将一次用户请求进行标记，并在多个依赖的服务系统中继续传递，以便串联所有路径，从而进行故障定位。

03讲初探微服务架构
    服务提供者：
            按照一定格式的服务描述，向注册中心注册服务，声明自己能够提供哪些服务以及服务的地址是什么，完成服务发布。
    服务消费者：
            请求注册中心，查询所需要调用服务的地址，然后以约定的通信协议向服务提供者发起请求，得到请求结果后再按照约定的协议解析结果，
                如果调用失败，可以通过重试等服务治理手段来保证成功率。
    监控：服务的请求耗时、调用量以及成功率等指标，调用经过的链路信息
    微服务架构下，服务调用主要依赖下面几个基本组件
    1。服务描述
        概念：服务调用首先要解决的问题就是服务如何对外描述
        三种方式RESTful API、XML配置以及IDL
            1。RESTful API：通常用于HTTP协议的服务描述，并且常用Wiki或者Swagger来进行管理
            2。XML:多用作RPC协议的服务描述，通过*.xml配置文件来定义接口名、参数以及返回值类型等
            3。IDL文件方式:通常用作Thrift和gRPC这类跨语言服务调用框架中，比如gRPC就是通过Protobuf文件来定义服务的接口名、参数以及返回值的数据结构
    2。注册中心
        概念：服务提供者将自己提供的服务以及地址登记到注册中心，服务消费者则从注册中心查询所需要调用的服务的地址，然后发起请求。
        注册中心的工作流程是：
            1。服务提供者在启动时，根据服务发布文件中配置的发布信息向注册中心注册自己的服务。
            2。服务消费者在启动时，根据消费者配置文件中配置的服务信息向注册中心订阅自己所需要的服务。
            3。注册中心返回服务提供者地址列表给服务消费者。
            4。当服务提供者发生变化，比如有节点新增或者销毁，注册中心将变更通知给服务消费者。
    3。服务框架
        背景：通过注册中心，服务消费者就可以获取到服务提供者的地址，有了地址后就可以发起调用。
        调用之前解决的问题：
            1。服务通信采用什么协议？
                选择：是采用四层TCP、UDP协议，还是采用七层HTTP协议，还是采用其他协议？
            2。数据传输采用什么方式？
                选择：同步还是异步，是在单连接上传输，还是多路复用。
            3。数据压缩采用什么格式？
                目的：通常数据传输都会对数据进行压缩，来减少网络传输的数据量，从而减少带宽消耗和网络传输时间
                例子：比如常见的JSON序列化、Java对象序列化以及Protobuf序列化等。
    4。服务监控（发现问题）
        流程：
            1。指标收集
                概念：就是要把每一次服务调用的请求耗时以及成功与否收集起来，并上传到集中的数据处理中心。
            2。数据处理
                概念：有了每次调用的请求耗时以及成功与否等信息，就可以计算每秒服务请求量、平均耗时以及成功率等指标。
            3。数据展示
                概念：数据收集起来，经过处理之后，还需要以友好的方式对外展示，才能发挥价值
                方式：通常都是将数据展示在Dashboard面板上，并且每隔10s等间隔自动刷新，用作业务监控和报警等。
    5。服务追踪（定位问题）
        目的：进行问题追踪和故障定位。
        原理：
            1。服务消费者发起调用前，会在本地按照一定的规则生成一个requestid，发起调用时，将requestid当作请求参数的一部分，传递给服务提供者。
            2。服务提供者接收到请求后，记录下这次请求的requestid，然后处理请求。如果服务提供者继续请求其他服务，会在本地再生成一个自己的requestid，然后把这两个requestid都当作请求参数继续往下传递。
        优点：
            1。一次请求，无论最后依赖多少次服务调用、经过多少服务节点
            2。都可以通过最开始生成的requestid串联所有节点，从而达到服务追踪的目的。
    6。服务治理（解决问题）
        1。单机故障
            传统：通常遇到单机故障，都是靠运维发现并重启服务或者从线上摘除故障节点
            服务治理：可以通过一定的策略，自动摘除故障节点，不需要人为干预，就能保证单机故障不会影响业务。
        2。单IDC故障
             方法：服务治理可以通过自动切换故障IDC的流量到其他正常IDC
                优点：可以避免因为单IDC故障引起的大批量业务受影响。
        3。依赖服务不可用
            例子：
                1。如你的服务依赖依赖了另一个服务，当另一个服务出现问题时，会拖慢甚至拖垮你的服务
                2。而服务治理可以通过熔断，在依赖服务异常的情况下，一段时期内停止发起调用而直接返回
            优点：
                1。保证了服务消费者能够不被拖垮
                2。也给服务提供者减少压力，使其能够尽快恢复。

04讲如何发布和引用服务？
    解决的问题：服务提供者如何发布一个服务，服务消费者如何引用这个服务。
        具体：
            1。就是这个服务的接口名是什么
            2。调用这个服务需要传递哪些参数？
            3。接口的返回值是什么类型？
            4。以及一些其他接口描述信息。
    最常见的服务发布和引用的方式有三种：
        1。RESTful API
            用作HTTP或者HTTPS协议的接口定义
            具体实现方式：参考加油卡项目
            场景：比较适合用作跨业务平台之间的服务协议
                例子：
                    1。比如你有一个服务，不仅需要在业务部门内部提供服务，还需要向其他业务部门提供服务，甚至开放给外网提供服务
                    2。这时候采用HTTP协议就比较合适，也省去了沟通服务协议的成本。
        2。XML配置
            服务发布和引用主要分三个步骤：
                1。服务提供者定义接口，并实现接口。
                2。服务提供者进程启动时，通过加载server.xml配置文件将接口暴露出去。
                3。服务消费者进程启动时，通过加载client.xml配置文件来引入要调用的接口。
            代码实现方式：参考dubbo.xml
            场景：一般是私有RPC框架会选择XML配置这种方式来描述接口，因为私有RPC协议的性能要比HTTP协议高，所以在对性能要求比较高的场景下，采用XML配置的方式比较合适
            缺点：对业务代码侵入性比较高，XML配置有变更的时候，服务消费者和服务提供者都要更新，
                如果要应用到跨部门之间的业务调用，一旦有XML配置变更，需要花费大量精力去协调不同部门做升级工作。
            建议：1适合公司内部联系比较紧密的业务之间采用
                2。所以对于XML配置方式的服务描述，一旦应用到多个部门之间的接口格式约定，如果有变更，最好是新增接口，不到万不得已不要对原有的接口格式做变更
        3。IDL文件
05讲如何注册和发现服务？
    注册中心原理：
        1。服务提供者（RPC Server）：提供服务，在启动时，根据服务发布文件server.xml中的配置的信息，向Registry注册自身服务，并向Registry定期发送心跳汇报存活状态。
        2。服务消费者（RPC Client）
            1。调用服务，在启动时，根据服务引用文件client.xml中配置的信息，向Registry订阅服务，把Registry返回的服务节点列表缓存在本地内存中，并与RPC Sever建立连接。
            2。RPC Client从本地缓存的服务节点列表中，基于负载均衡算法选择一台RPC Sever发起调用。
        3。服务注册中心（Registry）：当RPC Server节点发生变更时，Registry会同步变更，RPC Client感知后会刷新本地内存中缓存的服务节点列表。
    注册中心实现方式：
        1。注册中心API
            1。服务注册接口：服务提供者通过调用服务注册接口来完成服务注册。
            2。服务反注册接口：服务提供者通过调用服务反注册接口来完成服务注销。
            3。心跳汇报接口：服务提供者通过调用心跳汇报接口完成节点存活状态上报。
            4。服务订阅接口：服务消费者通过调用服务订阅接口完成服务订阅，获取可用的服务提供者节点列表。
            5。服务变更查询接口：服务消费者通过调用服务变更查询接口，获取最新的可用服务节点列表。
            后台管理接口：
                1。服务查询接口：查询注册中心当前注册了哪些服务信息。
                2。服务修改接口：修改注册中心中某一服务的信息。
        2。集群部署
            高可用：采用集群，并通过分布式一致性协议来确保集群中不同节点之间的数据保持一致。
            例子：ZooKeeper集群中包含多个节点，服务提供者和服务消费者可以同任意一个节点通信，因为它们的数据一定是相同的，
                工作原理：
                    1。每个Server在内存中存储了一份数据，Client的读请求可以请求任意一个Server
                    2。ZooKeeper启动时，将从实例中选举一个leader（Paxos协议）。
                    3。Leader负责处理数据更新等操作（ZAB协议）。
                    4。一个更新操作成功，当且仅当大多数Server在内存中成功修改 。
        3。目录存储：
            例子：以ZooKeeper为例，注册中心存储服务信息一般采用层次化的目录结构：
                1。每个目录在ZooKeeper中叫作znode，并且其有一个唯一的路径标识。
                2。znode可以包含数据和子znode。
                3。znode中的数据可以有多个版本，比如某一个znode下存有多个数据版本，那么查询这个路径下的数据需带上版本信息。
        4.服务健康状态检测
            目的：保证注册中心里保存的服务节点都是可用的，具备对服务提供者节点的健康状态检测功能，
            例子：ZooKeeper为例，它是基于ZooKeeper客户端和服务端的长连接和会话超时控制机制，来实现服务健康状态检测的。
                原理：
                    1。在ZooKeeper中，客户端和服务端建立连接后，会话也随之建立，并生成一个全局唯一的Session ID
                    2。服务端和客户端维持的是一个长连接，在SESSION_TIMEOUT周期内，服务端会检测与客户端的链路是否正常，具体方式是通过客户端定时向服务端发送心跳消息（ping消息），服务器重置下次SESSION_TIMEOUT时间
                    3。如果超过SESSION_TIMEOUT后服务端都没有收到客户端的心跳消息，则服务端认为这个Session就已经结束了，ZooKeeper就会认为这个服务节点已经不可用，将会从注册中心中删除其信息。
        5.服务状态变更通知
            原理：
                1。一旦注册中心探测到有服务提供者节点新加入或者被剔除
                2。必须立刻通知所有订阅该服务的服务消费者
                3。刷新本地缓存的服务节点信息
                4。确保服务调用不会请求不可用的服务提供者节点
            例子：继续以ZooKeeper为例，基于ZooKeeper的Watcher机制，来实现服务状态变更通知给服务消费者的
                1。服务消费者在调用ZooKeeper的getData方法订阅服务时
                2。还可以通过监听器Watcher的process方法获取服务的变更
                3。然后调用getData方法来获取变更后的数据，刷新本地缓存的服务节点信息。
        6.白名单机制
            问题：测试环境下的服务节点注册到了线上注册中心集群
            现象：这样的话线上流量就会调用到测试环境下的RPC Server节点，可能会造成意想不到的后果。
            方法：保护机制
                1。实际应用中，注册中心可以提供一个白名单机制，只有添加到注册中心白名单内的RPC Server
                2。才能够调用注册中心的注册接口，这样的话可以避免测试环境中的节点意外跑到线上环境中去。

06讲如何实现RPC远程服务调用？
    RPC调用过程：
        1。先建立网络连接
        2。双方还必须按照某种约定的协议进行网络通信
        3。服务端接收到请求时，需要以某种方式进行处理，处理成功后，把请求结果返回给客户端
        4。为了减少传输的数据大小，还要对数据进行压缩，也就是对数据进行序列化
    问题：
        1。客户端和服务端如何建立网络连接？
            方式一：HTTP通信
                1。基于应用层http协议
                2。三次握手建立连接
                3。完成请求后
                4。再经历一次四次挥手过程断开连接
            方式二：Socket通信
                概念：
                    1。Socket通信是基于TCP/IP协议的封装，建立一次Socket连接至少需要一对套接字
                    2。其中一个运行于客户端，称为ClientSocket
                    3。另一个运行于服务器端，称为ServerSocket
                Socket通信的过程分为四个步骤
                    1。服务器监听：ServerSocket通过调用bind()函数绑定某个具体端口，然后调用listen()函数实时监控网络状态，等待客户端的连接请求。
                    2。客户端请求：ClientSocket调用connect()函数向ServerSocket绑定的地址和端口发起连接请求。
                    3。服务端连接确认：当ServerSocket监听到或者接收到ClientSocket的连接请求时，调用accept()函数响应ClientSocket的请求，同客户端建立连接。
                    4。数据传输：当ClientSocket和ServerSocket建立连接后，ClientSocket调用send()函数，ServerSocket调用receive()函数，ServerSocket处理完请求后，调用send()函数，ClientSocket调用receive()函数，就可以得到得到返回结果。
            问题：网络闪断、连接超时、服务端宕机等各种异常
            方式：
                1。链路存活检测
                    方法：
                        1。客户端需要定时地发送心跳检测消息（一般是通过ping请求）给服务端
                        2。如果服务端连续n次心跳检测或者超过规定的时间都没有回复消息，则认为此时链路已经失效
                        3。这个时候客户端就需要重新与服务端建立连接。
                2。断连重试
                        原因：客户端主动关闭、服务端宕机或者网络故障等
                        方法：
                            1。这个时候客户端就需要与服务端重新建立连接
                            2。但一般不能立刻完成重连，而是要等待固定的间隔后再发起重连
                            3。避免服务端的连接回收不及时，而客户端瞬间重连的请求太多而把服务端的连接数占满。
        2。服务端如何处理请求？
            1。同步阻塞方式（BIO）
                概念：客户端每发一次请求，服务端就生成一个线程去处理
                例子：当客户端同时发起的请求很多时，服务端需要创建很多的线程去处理每一个请求
                缺点：如果达到了系统最大的线程数瓶颈，新来的请求就没法处理了。
                场景：适用于连接数比较小的业务场景，这样的话不至于系统中没有可用线程去处理请求。（程序也比较简单直观，易于理解。）

            2。同步非阻塞方式 (NIO)
                概念：客户端每发一次请求，服务端并不是每次都创建一个新线程来处理，而是通过I/O多路复用技术进行处理
                    就是把多个I/O的阻塞复用到同一个select的阻塞上，从而使系统在单线程的情况下可以同时处理多个客户端请求
                优点：开销小，不用为每个请求创建一个线程，可以节省系统开销。
                场景：连接数比较多并且请求消耗比较轻的业务场景，比如聊天服务器。这种方式相比BIO，相对来说编程比较复杂。
            3。异步非阻塞方式（AIO）
                概念：客户端只需要发起一个I/O操作然后立即返回，等I/O操作真正完成以后，客户端会得到I/O操作完成的通知
                    ，此时客户端只需要对数据进行处理就好了，不需要进行实际的I/O读写操作，因为真正的I/O读取或者写入操作已经由内核完成了
                优点：客户端无需等待，不存在阻塞等待问题。
                场景：连接数比较多而且请求消耗比较重的业务场景，比如涉及I/O操作的相册服务器。这种方式相比另外两种，编程难度最大，程序也不易于理解。
        3。数据传输采用什么协议？
            1。http协议：一种开放的协议
            2。dubbo协议：定制的私有协议
            契约：以便服务消费和服务提供者之间能够达成共识。
                1。服务消费者按照契约，对传输的数据进行编码，然后通过网络传输过去
                2。服务提供者从网络上接收到数据后，按照契约，对传输的数据进行解码，
                3。然后处理请求，再把处理后的结果进行编码，通过网络传输返回给服务消费者
                4。服务消费者再对返回的结果进行解码，最终得到服务提供者处理后的返回值。
            协议契约包括两个部分：
                1。消息头：存放的是协议的公共字段以及用户扩展字段
                2。消息体：存放的是传输数据的具体内容。

        4。数据该如何序列化和反序列化？
            序列化：
                概念：一般数据在网络中进行传输前，都要先在发送方一端对数据进行编码
                目的：减小数据传输量
                作用：加快网络传输（因素：带宽和数据传输量）
                例子：
                    1。一部高清电影原始大小为30GB，如果经过特殊编码格式处理，可以减小到3GB，
                    2。同样是100MB/s的网速，下载时间可以从300s减小到30s。
                方式：
                    1。文本类如XML/JSON等
                    2。二进制类如PB/Thrift等
                    采用那种方式取决于三个因素：
                        1。支持数据结构类型的丰富度
                            例子：数据结构种类支持的越多越好，这样的话对于使用者来说在编程时更加友好，有些序列化框架如Hessian 2.0还支持复杂的数据结构比如Map、List等
                        2。跨语言支持
                            序列化方式是否支持跨语言也是一个很重要的因素，否则使用的场景就比较局限，比如Java序列化只支持Java语言，就不能用于跨语言的服务调用了
                        3。性能
                            1。一个是序列化后的压缩比
                            2。一个是序列化的速度。
                            例子：常用的PB序列化和JSON序列化协议为例来对比分析
                                1。PB序列化的压缩比和速度都要比JSON序列化高很多，所以对性能和存储空间要求比较高的系统选用PB序列化更合适
                                2。而JSON序列化虽然性能要差一些，但可读性更好，更适合对外部提供服务。
            反序列化：
                概念：经过网络传输到达另一端后，再对数据进行解码
07讲如何监控微服务调用？（发现问题）
    问题：
        1。监控的对象是什么？
        2。具体监控哪些指标？
        3。从哪些维度进行监控？
    1。监控对象：分为四个层次，由上到下
        1。用户端监控
            概念：通常是指业务直接对用户提供的功能的监控。
            例子：微博首页Feed为例，它向用户提供了聚合关注的所有人的微博并按照时间顺序浏览的功能，对首页Feed功能的监控就属于用户端的监控
        2。接口监控
            概念：通常是指业务提供的功能所依赖的具体RPC接口的监控。
            例子：继续以微博首页Feed为例，这个功能依赖于用户关注了哪些人的关系服务，每个人发过哪些微博的微博列表服务，以及每条微博具体内容是什么的内容服务，对这几个服务的调用情况的监控就属于接口监控。
        3。资源监控
            概念：通常是指某个接口依赖的资源的监控
            例子：比如用户关注了哪些人的关系服务使用的是Redis来存储关注列表，对Redis的监控就属于资源监控。
        4。基础监控
            概念：通常是指对服务器本身的健康状况的监控
            例如：主要包括CPU利用率、内存使用量、I/O读写量、网卡带宽等
    2。监控指标
        1。请求量：两个维度
            1。一个是实时请求量
                比如：QPS（Queries Per Second）即每秒查询次数来衡量，它反映了服务调用的实时变化情况
            2。一个是统计请求量
                比如：PV（Page View）即一段时间内用户的访问量来衡量，比如一天的PV代表了服务一天的请求量，通常用来统计报表。
        2。响应时间
            大多数情况下，可以用一段时间内所有调用的平均耗时来反映请求的响应时间
        3。错误率
            概念：错误率的监控通常用一段时间内调用失败的次数占调用总次数的比率来衡量
            例子：对于接口的错误率一般用接口返回错误码为503的比率来表示。
    3。监控维度
        1。全局维度
            概念：从整体角度监控对象的的请求量、平均耗时以及错误率
            目的：对监控对象的调用情况有个整体了解。
        2。分机房维度
            背景：一般为了业务的高可用性，服务通常部署在不止一个机房
            原因：不同机房地域的不同，同一个监控对象的各种指标可能会相差很大，所以需要深入到机房内部去了解。
        3。单机维度
            原因：便是在同一个机房内部，可能由于采购年份和批次的不同，位于不同机器上的同一个监控对象的各种指标也会有很大差异。
            例子：一般来说，新采购的机器通常由于成本更低，配置也更高，在同等请求量的情况下，可能表现出较大的性能差异，因此也需要从单机维度去监控同一个对象。
        4。时间维度
            原因：同一个监控对象，在每天的同一时刻各种指标通常也不会一样，这种差异要么是由业务变更导致，要么是运营活动导致
            目的：为了了解监控对象各种指标的变化，通常需要与一天前、一周前、一个月前，甚至三个月前做比较。
        5。核心维度
            背景：业务上一般会依据重要性程度对监控对象进行分级
            例子：分成核心业务和非核心业务。核心业务和非核心业务在部署上必须隔离，分开监控，这样才能对核心业务做重点保障。
    监控系统原理
        1。数据采集
            概念：收集到每一次调用的详细信息，包括调用的响应时间、调用是否成功、调用的发起者和接收者分别是谁
            方式：
                1。服务主动上报
                    概念：通过在业务代码或者服务框架里加入数据收集代码逻辑，在每一次服务调用完成后，主动上报服务的调用信息。
                2。代理收集
                    概念：服务调用后把调用的详细信息记录到本地日志文件中，然后再通过代理去解析本地日志文件，然后再上报服务的调用信息。
            采样率：采集数据的频率。
                作用：决定了监控的实时性与精确度，
                缺点：对系统本身的性能也会有一定的影响，尤其是采集后的数据需要写到本地磁盘的时候，过高的采样率会导致系统写入磁盘的I/O过高，进而会影响到正常的服务调用
                注意：设置合理的采用率是数据采集的关键
                方法：
                    1。可以动态控制采样率，在系统比较空闲的时候加大采样率，追求监控的实时性与精确度
                    2。在系统负载比较高的时候减小采样率，追求监控的可用性与系统的稳定性。
        2。数据传输
            概念：要把数据通过一定的方式传输给数据处理中心进行处理
            方式：
                1。UDP传输
                    过程
                        1。数据处理单元提供服务器的请求地址
                        2。数据采集后通过UDP协议与服务器建立连接
                        3。然后把数据发送过去。
                2。Kafka传输
                    过程
                        1。数据采集后发送到指定的Topic
                        2。然后数据处理单元再订阅对应的Topic
                        3。就可以从Kafka消息队列中读取到对应的数据。
            格式：
                1。二进制协议：最常用的就是PB对象，它的优点是高压缩比和高性能，可以减少传输带宽并且序列化和反序列化效率特别高。
                2。文本协议：最常用的就是JSON字符串，它的优点是可读性好，但相比于PB对象，传输占用带宽高，并且解析性能也要差一些。

        3。数据处理
            概念：数据处理中心再按照服务的维度进行聚合，计算出不同服务的请求量、响应时间以及错误率等信息并存储起来
            维度：
                1。接口维度聚合：把实时收到的数据按照接口名维度实时聚合在一起，这样就可以得到每个接口的实时请求量、平均耗时等信息。
                2。机器维度聚合：这个维度是把实时收到的数据按照调用的节点维度聚合在一起，这样就可以从单机维度去查看每个接口的实时请求量、平均耗时等信息。
            存储数据库
                1。索引数据库：比如Elasticsearch，以倒排索引的数据结构存储，需要查询的时候，根据索引来查询。
                2。时序数据库：比如OpenTSDB，以时序序列数据的方式存储，查询的时候按照时序如1min、5min等维度来查询。
        4。数据展示
            概念：再通过接口或者Dashboard的形式对外展示服务的调用情况
            方式：
            1。曲线图：一般是用来监控变化趋势的
            2。饼状图：一般是用来监控占比分布的
            3。格子图：主要做一些细粒度的监控
08讲如何追踪微服务调用？（定位问题）
    背景：一次请求所涉及的服务，你可以想象如果这次请求失败了，要想查清楚到底是哪个应用导致，会是多么复杂的一件事情。
    服务追踪的作用
        1。优化系统瓶颈。
            概念：通过记录调用经过的每一条链路上的耗时，我们能快速定位整个系统的瓶颈点在哪里
            例子：比如你访问微博首页发现很慢，肯定是由于某种原因造成的，有可能是运营商网络延迟，有可能是网关系统异常，有可能是某个服务异常，还有可能是缓存或者数据库异常
            优点：通过服务追踪，可以从全局视角上去观察，找出整个系统的瓶颈点所在，然后做出针对性的优化。
        2。优化链路调用。
            概念：通过服务追踪可以分析调用所经过的路径，然后评估是否合理。
            例子一：
                比如一个服务调用下游依赖了多个服务，通过调用链分析，可以评估是否每个依赖都是必要的，是否可以通过业务优化来减少服务依赖。
            例子二：
                1。一般业务都会在多个数据中心都部署服务以实现异地容灾，这个时候经常会出现一种状况就是服务A调用了另外一个数据中心的服务B，而没有调用同处于一个数据中心的服务B。
                2。跨数据中心的调用视距离远近都会有一定的网络延迟，像北京和广州这种几千公里距离的网络延迟可能达到30ms以上，这对于有些业务几乎是不可接受的
            优点：通过对调用链路进行分析，可以找出跨数据中心的服务调用，从而进行优化，尽量规避这种情况出现。
        3。生成网络拓扑。
            概念：通过服务追踪系统中记录的链路信息，可以生成一张系统的网络调用拓扑图
            优点：
                1。反映系统都依赖了哪些服务，以及服务之间的调用关系是什么样的，可以一目了然
                2。网络拓扑图上还可以把服务调用的详细信息也标出来，也能起到服务监控的作用。
        4。透明传输数据。
            背景：业务上经常有一种需求，期望能把一些用户数据，从调用的开始一直往下传递，以便系统中的各个服务都能获取到这个信息
            例子：
                比如业务想做一些A/B测试，这时候就想通过服务追踪系统，把A/B测试的开关逻辑一直往下传递，经过的每一层服务都能获取到这个开关值，就能够统一进行A/B测试
        5。快速定位请求失败的原因

    服务追踪系统原理
    核心理念就是调用链：
        1。通过一个全局唯一的ID将分布在各个服务节点上的同一次请求串联起来
        2。从而还原原有的调用关系
        3。可以追踪系统问题
        4。分析调用数据并统计各种系统指标。
        例子：美团的MTrace的原理
            traceId：
                概念：用于标识某一次具体的请求ID。
                作用：串联某一次请求在系统中经过的所有路径
                流程：
                    1。当用户的请求进入系统后，会在RPC调用网络的第一层生成一个全局唯一的traceId
                    2。并且会随着每一层的RPC调用，不断往后传递
                    3。这样的话通过traceId就可以把一次用户请求在系统中调用的路径串联起来。
            spanId：
                概念：用于标识一次RPC调用在分布式请求中的位置。
                作用：是用于区分系统不同服务之间调用的先后关系
                流程
                    1。当用户的请求进入系统后，处在RPC调用网络的第一层A时spanId初始值是0
                    2。进入下一层RPC调用B的时候spanId是0.1
                    3。继续进入下一层RPC调用C时spanId是0.1.1
                    4。而与B处在同一层的RPC调用E的spanId是0.2，
                    5。这样的话通过spanId就可以定位某一次RPC请求在系统调用中所处的位置，以及它的上下游依赖分别是谁。
            annotation：
                概念：用于业务自定义埋点数据，可以是业务感兴趣的想上传到后端的数据，比如一次请求的用户UID。
                作用：用于业务自定义一些自己感兴趣的数据，在上传traceId和spanId这些基本信息之外，添加一些自己感兴趣的信息
    服务追踪系统实现
        服务追踪系统架构图，你可以看到一个服务追踪系统可以分为三层。
            1。数据采集层，负责数据埋点并上报。
                作用：就是在系统的各个不同模块中进行埋点，采集数据并上报给数据处理层进行处理。
                流程：
                    1。CS（Client Send）阶段 : 客户端发起请求，并生成调用的上下文。
                    2。SR（Server Recieve）阶段 : 服务端接收请求，并生成上下文
                    3。SS（Server Send）阶段 : 服务端返回请求，这个阶段会将服务端上下文数据上报
                    4。CR（Client Recieve）阶段 : 客户端接收返回结果，这个阶段会将客户端上下文数据上报，
            2。数据处理层，负责数据的存储与计算。
                作用：数据采集层上报的数据按需计算，然后落地存储供查询使用。
                数据处理的需求一般分为两类：
                    1。实时计算需求
                        要求：对收集的链路数据能够在秒级别完成聚合计算，以供实时查询
                        方式：一般采用Storm或者Spark Streaming来对链路数据进行实时聚合加工，存储一般使用OLTP数据仓库
                        例子：HBase，使用traceId作为RowKey，能天然地把一整条调用链聚合在一起，提高查询效率。
                    2。离线计算需求
                        要求：对计算效率要求就没那么高了，一般能在小时级别完成链路数据的聚合计算即可，一般用作数据汇总统计
                        方式：通过运行MapReduce或者Spark批处理程序来对链路数据进行离线计算，存储一般使用Hive。
            3。数据展示层，负责数据的图形化展示。
                作用：就是将处理后的链路信息以图形化的方式展示给用户。
                图形展示：一种是调用链路图，一种是调用拓扑图。

09讲微服务治理的手段有哪些？（解决问题）
    服务消费者A需要通过注册中心去查询服务提供者B的地址，可能会遇到的问题：
        1。注册中心宕机；
        2。服务提供者B有节点宕机；
        3。服务消费者A和注册中心之间的网络不通；
        4。服务提供者B和注册中心之间的网络不通；
        5。服务消费者A和服务提供者B之间的网络不通；
        6。服务提供者B有些节点性能变慢；
        7。服务提供者B短时间内出现问题。
    汇总：一次服务调用，服务提供者、注册中心、网络这三者都可能会有问题，
    方法：服务治理
        服务调用失败的两种原因：
            1。服务提供者自身出现问题：服务器宕机、进程意外退出等
            2。网络问题：服务提供者、注册中心、服务消费者这三者任意两者之间的网络出现问题。
        手段：
            1。注册中心主动摘除机制
                前提：要求服务提供者定时的主动向注册中心汇报心跳
                流程
                    1。注册中心根据服务提供者节点最近一次汇报心跳的时间与上一次汇报心跳时间做比较
                    2。如果超出一定时间，就认为服务提供者出现问题，继而把节点从服务列表中摘除
                    3。并把最近的可用服务节点列表推送给服务消费者。
            2。服务消费者摘除机制
                背景：
                    如果是因为注册中心与服务提供者之间的网络出现异常，最坏的情况是注册中心会把服务节点全部摘除，导致服务消费者没有可用的服务节点调用
                    但其实这时候服务提供者本身是正常的
                方法：
                    如果服务消费者调用服务提供者节点失败，就将这个节点从内存中保存的可用服务提供者节点列表中移除。
    负载均衡：
        背景：服务提供者节点不是唯一的，多是以集群的方式存在，尤其是对于大规模的服务调用来说，服务提供者节点数目可能有上百上千个
        方法
            1。随机算法
                概念：从可用的服务节点中随机选取一个节点
                现象：随机算法是均匀的，也就是说后端服务节点无论配置好坏，最终得到的调用量都差不多。
            2。轮询算法
                概念：就是按照固定的权重，对可用服务节点进行轮询
                方法：
                    1。如果所有服务节点的权重都是相同的，则每个节点的调用量也是差不多的。
                    2。但可以给某些硬件配置较好的节点的权重调大些，这样的话就会得到更大的调用量，
                优点：充分发挥其性能优势，提高整体调用的平均性能。

            3。最少活跃调用算法
                概念：这种算法是在服务消费者这一端的内存里动态维护着同每一个服务节点之间的连接数
                方法：
                    1。当调用某个服务节点时，就给与这个服务节点之间的连接数加1，调用返回后，就给连接数减1
                    2。然后每次在选择服务节点时，根据内存里维护的连接数倒序排列，选择连接数最小的节点发起调用
                优点：选择了调用量最小的服务节点，性能理论上也是最优的
            4。一致性Hash算法
                概念：指相同参数的请求总是发到同一服务节点。
                方法：当某一个服务节点出现故障时，原本发往该节点的请求，基于虚拟节点机制，平摊到其他节点上，不会引起剧烈变动。
    服务路由
        背景：对于服务消费者而言，在内存中的可用服务节点列表中选择哪个节点不仅由负载均衡算法决定，还由路由规则确定。
        概念：通过一定的规则如条件表达式或者正则表达式来限定服务节点的选择范围。
        原因：
            1。业务存在灰度发布的需求
                例子：
                    1。服务提供者做了功能变更，但希望先只让部分人群使用，然后根据这部分人群的使用反馈，再来决定是否做全量发布
                    2。就可以通过类似按尾号进行灰度的规则限定只有一定比例的人群才会访问新发布的服务节点。
            2。多机房就近访问的需求
                目的：一次服务调用尽量选择同一个IDC内部的节点，从而减少网络耗时开销，提高性能
                方法：可以通过IP段规则来控制访问，在选择服务节点时，优先选择同一IP段的节点。
        配置方式：
            1。静态配置
                例子：
                    1服务消费者本地存放服务调用的路由规则，在服务调用期间，路由规则不会发生改变，
                    2要想改变就需要修改服务消费者本地配置，上线后才能生效。
            2。动态配置
                例子：
                    1。路由规则是存在注册中心的，服务消费者定期去请求注册中心来保持同步
                    2。想改变服务消费者的路由配置，可以通过修改注册中心的配置
                    3。服务消费者在下一个同步周期之后，就会请求注册中心来更新配置，从而实现动态更新。
    服务容错
        对于服务调用失败的情况，需要有手段自动恢复，来保证调用成功。
        手段
            1。FailOver：失败自动切换
                概念：就是服务消费者发现调用失败或者超时后，自动从可用的服务节点列表总选择下一个节点重新发起调用，也可以设置重试的次数
                前提：这种策略要求服务调用的操作必须是幂等的，也就是说无论调用多少次，只要是同一个调用，返回的结果都是相同的，
                场景：读请求的场景
            2。FailBack：失败通知
                概念：就是服务消费者调用失败或者超时后，不再重试，而是根据失败的详细信息，来决定后续的执行策略
                例子：
                    1。非幂等的调用场景，如果调用失败后，不能简单地重试，而是应该查询服务端的状态
                    2。看调用到底是否实际生效，如果已经生效了就不能再重试了；如果没有生效可以再发起一次调用。
            3。FailCache：失败缓存
                概念：就是服务消费者调用失败或者超时后，不立即发起重试，而是隔一段时间后再次尝试发起调用
                例子
                    1。后端服务可能一段时间内都有问题，如果立即发起重试，可能会加剧问题，反而不利于后端服务的恢复
                    2。如果隔一段时间待后端节点恢复后，再次发起调用效果会更好。
            4。FailFast：快速失败
                概念：就是服务消费者调用一次失败后，不再重试
                场景：实际在业务执行时，一般非核心业务的调用，会采用快速失败策略，调用失败后一般就记录下失败日志就返回了。
            选择：
                1。一般情况下对于幂等的调用，可以选择FailOver或者FailCache
                2。非幂等的调用可以选择FailBack或者FailFast

10讲Dubbo框架里的微服务组件
    https://dubbo.incubator.apache.org/docs/zh-cn/dev/sources/images/dubbo-extension.jpg 
    1。服务发布与引用：
        流程：
            1。对应实现是图里的Proxy服务代理层，Proxy根据客户端和服务端的接口描述
            2。生成接口对应的客户端和服务端的Stub，使得客户端调用服务端就像本地调用一样。
    2。服务注册与发现
        流程
            1。对应实现是图里的Registry注册中心层，Registry根据客户端和服务端的接口描述
            2。解析成服务的URL格式，然后调用注册中心的API，完成服务的注册和发现。
    3。服务调用
        流程：
            1。对应实现是Protocol远程调用层，Protocol把客户端的本地请求转换成RPC请求。
            2。然后通过Transporter层来实现通信，Codec层来实现协议封装，Serialization层来实现数据序列化和反序列化。
    4。服务监控
        流程：
            1。对应实现层是Filter调用链层，通过在Filter调用链层中加入MonitorFilter
            2。实现对每一次调用的拦截，在调用前后进行埋点数据采集，上传给监控系统。
    5。服务治理
        对应实现层是Cluster层，负责服务节点管理、负载均衡、服务路由以及服务容错。
    客户端调用的过程：
        1。首先根据接口定义，通过Proxy层封装好的透明化接口代理，发起调用。
        2。然后在通过Registry层封装好的服务发现功能，获取所有可用的服务提供者节点列表。
        3。再根据Cluster层的负载均衡算法从可用的服务节点列表中选取一个节点发起服务调用，如果调用失败，根据Cluster层提供的服务容错手段进行处理。
        4。同时通过Filter层拦截调用，实现客户端的监控统计。
        5。最后在Protocol层，封装成Dubbo RPC请求，发给服务端节点。
    服务端从网络中接收到请求后的处理过程是这样的：
        1。首先在Protocol层，把网络上的请求解析成Dubbo RPC请求。
        2。然后通过Filter拦截调用，实现服务端的监控统计
        3。最后通过Proxy层的处理，把Dubbo RPC请求转化为接口的具体实现，执行调用。

11讲服务发布和引用的实践
    XML配置方式的服务发布和引用流程
        1。服务提供者定义接口
        2。服务提供者发布接口
        3。服务消费者引用接口
    服务发布和引用的那些坑
        背景：有的服务消费者会忽视这一点，并没有在服务引用配置文件中配置接口调用超时重试的次数
        方法：可以在服务发布的配置文件中预定义好类似超时重试次数，即使服务消费者没有在服务引用配置文件中定义，也能继承服务提供者的定义。
            1。服务发布预定义配置：服务提供这配置负载均衡信息，超时信息
                <motan:service ref="contentSliceRPCService"       interface="cn.sina.api.data.service.ContentSliceRPCService"
                    basicService="serviceBasicConfig" export="motan:8882" >
                <motan:method name="updateContent" requestTimeout="500"
                    retries="3" />
                </motan:service>
                问题：
                    1。当服务提供者发生节点变更，尤其是在网络频繁抖动的情况下，所有的服务消费者都会从注册中心拉取最新的服务节点信息
                    2。就包括了服务发布配置中预定的各项接口信息，这个信息不加限制的话可能达到1M以上
                    3。如果同时有上百个服务消费者从注册中心拉取服务节点信息
                    4。在注册中心机器部署为百兆带宽的情况下，很有可能会导致网络带宽打满的情况发生。
                方法：服务发布端的详细服务配置信息转移到服务引用端
            2。服务引用定义配置（消费者配置）
                <motan:service ref="userInfoService" requestTimeout="50" retries="2"                   interface="cn.sina.api.user.service.UserInfoService" basicService="serviceBasicConfig">
                </motan:service>
                注意：迁移步骤问题
            3。服务配置升级
                例子：由于引用服务的服务消费者众多，并且涉及多个部门，升级步骤就显得异常重要，通常可以按照下面步骤操作。
                    1。各个服务消费者在服务引用配置文件中添加服务详细信息。
                    2。服务提供者升级两台服务器，在服务发布配置文件中删除服务详细信息，并观察是否所有的服务消费者引用时都包含服务详细信息。
                    3。如果都包含，说明所有服务消费者均完成升级，那么服务提供者就可以删除服务发布配置中的服务详细信息。
                    4。如果有不包含服务详细信息的服务消费者，排查出相应的业务方进行升级，直至所有业务方完成升级。

12讲如何将注册中心落地？
    问题
        1。如何存储服务信息
        2。如何注册节点
        3。如何反注册
        4。如何查询节点信息
        5。如何订阅服务变更
    注册中心如何存储服务信息
        服务信息：
            分组方式：
                1。核心与非核心，从业务的核心程度来分。
                2。机房，从机房的维度来分。
                3。线上环境与测试环境，从业务场景维度来区分。
            内容：
                1。分组
                2。服务名
                3。节点：节点地址和节点其他信息
            格式：JSON字符串来存储，包含多个字段，每个字段代表不同的含义
    注册中心具体是如何工作的，包括四个流程。
        1。服务提供者注册流程。
        2。服务提供者反注册流程。
        3。服务消费者查询流程。
        4。服务消费者订阅变更流程。
    注册中心是如何工作的
        1。如何注册节点
            流程：
                1。首先查看要注册的节点是否在白名单内？如果不在就抛出异常，在的话继续下一步。
                2。其次要查看注册的Cluster（服务的接口名）是否存在？如果不存在就抛出异常，存在的话继续下一步。
                3。然后要检查Service（服务的分组）是否存在？如果不存在则抛出异常，存在的话继续下一步。
                4。最后将节点信息添加到对应的Service和Cluster下面的存储中。
        2。如何反注册
            流程：
                1。查看Service（服务的分组）是否存在，不存在就抛出异常，存在就继续下一步。
                2。查看Cluster（服务的接口名）是否存在，不存在就抛出异常，存在就继续下一步。
                3。删除存储中Service和Cluster下对应的节点信息。
                4。更新Cluster的sign值。
        3。如何查询节点信息
            1。首先从localcache（本机内存）中查找，如果没有就继续下一步
                为什么缓存在消费者本地：
                    原因：
                        主要是因为服务节点信息并不总是时刻变化的，并不需要每一次服务调用都要调用注册中心获取最新的节点信息
            2。接着从snapshot（本地快照）中查找，如果没有就继续下一步
                原因：
                    1。服务消费者同注册中心之间的网络不一定总是可靠的，服务消费者重启时
                    2。本机内存中还不存在服务提供者的节点信息，如果此时调用注册中心失败，那么服务消费者就拿不到服务节点信息了，也就没法调用了
                目的：
                    防止这种情况的发生，即使服务消费者重启后请求注册中心失败，依然可以读取本地快照，获取到服务节点信息。
        4。如何订阅服务变更
            1。服务消费者从注册中心获取了服务的信息后，就订阅了服务的变化，会在本地保留Cluster的sign值。
            2。服务消费者每隔一段时间，调用getSign()函数，从注册中心获取服务端该Cluster的sign值，并与本地保留的sign值做对比，如果不一致，就从服务端拉取新的节点信息，并更新localcache和snapshot。
    注册与发现的几个问题
        1。多注册中心
            1。对于服务消费者来说，要能够同时从多个注册中心订阅服务
            2。对于服务提供者来说，要能够同时向多个注册中心注册服务。
        2。并行订阅服务
            串行订阅：每订阅一个服务，服务消费者调用一次注册中心的订阅接口，获取这个服务的节点列表并初始化连接，总共需要执行几十次这样的过程
                 问题：在某些服务节点的初始化连接过程中，出现连接超时的情况，后续所有的服务节点的初始化连接都需要等待它完成，导致服务消费者启动变慢，最后耗费了将近五分钟时间来完成所有服务节点的初始化连接过程。
            并行订阅：每订阅一个服务就单独用一个线程来处理，
                    优点这样的话即使遇到个别服务节点连接超时，其他服务节点的初始化连接也不受影响，最慢也就是这个服务节点的初始化连接耗费的时间，最终所有服务节点的初始化连接耗时控制在了30秒以内。
        3。批量反注册服务
            偶发的注册调用失败：对服务调用基本没有影响，其结果顶多就是某一个服务少了一个可用的节点
            偶发的反注册调用失败：会导致不可用的节点残留在注册中心中，变成“僵尸节点”，但服务消费者端还会把它当成“活节点”，继续发起调用，最终导致调用失败
            僵尸节点：
                1。我们通过优化反注册逻辑，对于下线机器、节点销毁的场景
                2。通过调用注册中心提供的批量反注册接口，一次调用就可以把该节点上提供的所有服务同时反注册掉
                3。从而避免了“僵尸节点”的出现。

        4。服务变更信息增量更新
            流程：
                1。除了会查询订阅服务的可用节点列表做初始化连接，还会订阅服务的变更
                2。每隔一段时间从注册中心获取最新的服务节点信息标记sign，并与本地保存的sign值作比对
                3。如果不一样，就会调用注册中心获取最新的服务节点信息。
            问题：
                1。在网络频繁抖动时，服务提供者上报给注册中心的心跳可能会一会儿失败一会儿成功
                2。这时候注册中心就会频繁更新服务的可用节点信息，导致服务消费者频繁从注册中心拉取最新的服务可用节点信息
                3。严重时可能产生网络风暴，导致注册中心带宽被打满。
            解决办法：
                1。为了减少服务消费者从注册中心中拉取的服务可用节点信息的数据量，这个时候可以通过增量更新的方式
                2。注册中心只返回变化的那部分节点信息，尤其在只有少数节点信息变更时
            优点：
                可以大大减少服务消费者从注册中心拉取的数据量，从而最大程度避免产生网络风暴。

13讲开源服务注册中心如何选型？
    主流的服务注册与发现的解决方案，主要有两种：
        1。应用内注册与发现：
            概念：注册中心提供服务端和客户端的SDK，业务应用通过引入注册中心提供的SDK，通过SDK与注册中心交互，来实现服务的注册和发现。
            案例：属Netflix开源的Eureka
            Eureka的架构，它主要由三个重要的组件组成
                1。Eureka Server：注册中心的服务端，实现了服务信息注册、存储以及查询等功能。
                2。服务端的Eureka Client：集成在服务端的注册中心SDK，服务提供者通过调用SDK，实现服务注册、反注册等功能。
                3。客户端的Eureka Client：集成在客户端的注册中心SDK，服务消费者通过调用SDK，实现服务订阅、服务更新等功能。
            场景：一般适用于服务提供者和服务消费者同属于一个技术体系
        2。应用外注册与发现：
            概念：业务应用本身不需要通过SDK与注册中心打交道，而是通过其他方式与注册中心交互，间接完成服务注册与发现。
            案例：开源注册中心Consul
            Consul实现应用外服务注册和发现主要依靠三个重要的组件：
                1。Consul实现应用外服务注册和发现主要依靠三个重要的组件：
                2。Registrator：一个开源的第三方服务管理器项目，它通过监听服务部署的Docker实例是否存活，来负责服务提供者的注册和销毁。
                3。Consul Template：定时从注册中心服务端获取最新的服务提供者节点列表并刷新LB配置（比如Nginx的upstream），这样服务消费者就通过访问Nginx就可以获取最新的服务提供者信息。
            场景：一般适合服务提供者和服务消费者采用了不同技术体系的业务场景
            例子：
                1。服务提供者提供的是C++服务，而服务消费者是一个Java应用，这时候采用应用外的解决方案就不依赖于具体一个技术体系
                2。对于容器化后的云应用来说，一般不适合采用应用内SDK的解决方案，因为这样会侵入业务，而应用外的解决方案正好能够解决这个问题。
    注册中心选型要考虑的两个问题
        1。高可用性
            1。集群部署
                方法：通过部署多个实例组成集群来保证高可用性，这样的话即使有部分机器宕机，将访问迁移到正常的机器上就可以保证服务的正常访问。
            2。多IDC部署
                方法：就是部署在不止一个机房，这样能保证即使一个机房因为断电或者光缆被挖断等不可抗力因素不可用时，仍然可以通过把请求迁移到其他机房来保证服务的正常访问。
        2。数据一致性
            问题
                1。多个数据中心之间如何保证数据一致？
                2。如何确保访问数据中心中任何一台机器都能得到正确的数据？
                CAP理论：
                    C：（Consistency）代表一致性
                        概念：数据复制到多个节点就可能出现数据不一致的情况
                        问题：数据节点越多，分区容错性越高，但数据一致性越难保证。
                    A：（Availability）代表可用性
                        概念：所有节点上的数据都更新成功才可用
                        问题：数据节点越多，分区容错性越高，但数据一致性越难保证，为了保证数据一致性，又会带来可用性的问题。
                    P：(Partition Tolerance）代表分区容错性
                        分区：有可能出现网络故障，导致整个网络被分成了互不连通的区域
                            问题：一个区域内的节点就没法访问其他节点上的数据了，
                            方法：把数据复制到其他区域内的节点
                            分区容错性：这样即使出现分区，也能访问任意区域内节点上的数据
                    所以不同的注册中心解决方案选择的方向也就不同，大致可分为两种。
                        1。CP型注册中心
                            概念：牺牲可用性来保证数据强一致性
                            例子：ZooKeeper，etcd，Consul了
                                    1。ZooKeeper集群流程：
                                    1。集群内只有一个Leader
                                    2。在Leader无法使用的时候通过Paxos算法选举出一个新的Leader
                                    3。这个Leader的目的就是保证写信息的时候只向这个Leader写入
                                    4。Leader会同步信息到Followers，这个过程就可以保证数据的强一致性=
                                        问题：
                                            如果多个ZooKeeper之间网络出现问题，造成出现多个Leader，发生脑裂的话，注册中心就不可用了

                                2。etcd和Consul集群内都是通过raft协议来保证强一致性，如果出现脑裂的话， 注册中心也不可用。
                                    参考：04 | 分布式选举：国不可一日无君中的raft的算法
                        2。AP型注册中心
                            概念：牺牲一致性来保证可用性
                            例子：Eureka
                            流程：
                                对比下Zookeeper，Eureka不用选举一个Leader，每个Eureka服务器单独保存服务注册地址，因此有可能出现数据信息不一致的情况
                            优点：
                                网络出现问题的时候，每台服务器都可以完成独立的服务。
                        1选择依据：
                            1。对于注册中心来说，最主要的功能是服务的注册和发现，在网络出现问题的时候，可用性的需求要远远高于数据一致性
                            2。即使因为数据不一致，注册中心内引入了不可用的服务节点，也可以通过其他措施来避免
                                    比如：客户端的快速失败机制等，只要实现最终一致性，对于注册中心来说就足够了
                            建议：选择AP型注册中心，一般更加合适。
                        参考文章：
                            https://www.cnblogs.com/ZhuChangwu/p/11619270.html

14讲开源RPC框架如何选型？
    限定语言平台的开源RPC框架
        1。Dubbo：
            概念：国内最早开源的RPC框架，由阿里巴巴公司开发并于2011年末对外开源，仅支持Java语言。
            四个角色：
                1。Consumer是服务消费者
                    过程：通过注册中心获取到Provider节点后，通过Dubbo的客户端SDK与Provider建立连接，并发起调用
                2。Provider是服务提供者
                    过程：通过Dubbo的服务端SDK接收到Consumer的请求，处理后再把结果返回给Consumer。
                3。Registry是注册中心
                4。Monitor是监控系统
            调用框架是如何实现的。
                1。通信框架方面，Dubbo默认采用了Netty作为通信框架。
                2。通信协议方面，Dubbo除了支持私有的Dubbo协议外，还支持RMI协议、Hession协议、HTTP协议、Thrift协议等。
                3。序列化格式方面，Dubbo支持多种序列化格式，比如Dubbo、Hession、JSON、Kryo、FST等。

        2。Motan：
            概念：微博内部使用的RPC框架，于2016年对外开源，仅支持Java语言。
            前提：需要在Client端（服务消费者）和Server端（服务提供者）引入SDK
            功能模块：
                1。register：
                    概念：用来和注册中心交互，包括注册服务、订阅服务、服务变更通知、服务心跳发送等功能
                    流程：
                        1。Server端会在系统初始化时通过register模块注册服务
                        2。Client端会在系统初始化时通过register模块订阅到具体提供服务的Server列表
                        3。当Server列表发生变更时也由register模块通知Client。
                2。protocol：
                    概念：用来进行RPC服务的描述和RPC服务的配置管理，这一层还可以添加不同功能的filter用来完成统计、并发限制等功能。
                3。serialize：
                    概念：将RPC请求中的参数、结果等对象进行序列化与反序列化，即进行对象与字节流的互相转换，默认使用对Java更友好的Hessian 2进行序列化。
                4。transport：
                    概念：用来进行远程通信，默认使用Netty NIO的TCP长链接方式。
                5。cluster：
                    概念：Client端使用的模块，cluster是一组可用的Server在逻辑上的封装，包含若干可以提供RPC服务的Server，实际请求时会根据不同的高可用与负载均衡策略选择一个可用的Server发起远程调用。
        3。Tars：
            概念：腾讯内部使用的RPC框架，于2017年对外开源，仅支持C++语言。
            流程：
                1。服务发布流程：
                    1。在web系统上传server的发布包到patch，上传成功后
                    2。在web上提交发布server请求，由registry服务传达到node
                    3。然后node拉取server的发布包到本地，拉起server服务
                2。管理命令流程：
                    1。web系统上的可以提交管理server服务命令请求
                    2。由registry服务传达到node服务
                    3。然后由node向server发送管理命令。
                3。心跳上报流程：
                    1。server服务运行后，会定期上报心跳到node
                    2。node然后把服务心跳信息上报到registry服务，由registry进行统一管理。
                4。信息上报流程：
                    1。server服务运行后，会定期上报统计信息到stat，打印远程日志到log
                    2。定期上报属性信息到prop、上报异常信息到notify、从config拉取服务配置信息。
                5。client访问server流程：
                    1。client可以通过server的对象名Obj间接访问server
                    2。client会从registry上拉取server的路由信息（如IP、Port信息）
                    3。然后根据具体的业务特性（同步或者异步，TCP或者UDP方式）访问server（当然client也可以通过IP/Port直接访问server）。
        4。Spring Cloud：
            概念：国外Pivotal公司2014年对外开源的RPC框架，仅支持Java语言，最近几年生态发展得比较好，是比较火的RPC框架。
            Spring Cloud微服务架构是由多个组件一起组成的，各个组件的交互流程如
                1。请求统一通过API网关Zuul来访问内部服务，先经过Token进行安全认证。
                2。通过安全认证后，网关Zuul从注册中心Eureka获取可用服务节点列表。
                3。从可用服务节点中选取一个可用节点，然后把请求分发到这个节点。
                4。整个请求过程中，Hystrix组件负责处理服务超时熔断，Turbine组件负责监控服务间的调用和熔断相关指标，Sleuth组件负责调用链监控，ELK负责日志分析。
        对比选型：
            1。如果你的语言平台是C++，那么只能选择Tars；
            2。Spring Cloud不仅提供了基本的RPC框架功能，还提供了服务注册组件、配置中心组件、负载均衡组件、断路器组件、分布式消息追踪组件等一系列组件，也难怪被技术圈的人称之为“Spring Cloud全家桶”。
            3。如果你不想自己实现以上这些功能，那么Spring Cloud基本可以满足你的全部需求
            4。而Dubbo、Motan基本上只提供了最基础的RPC框架的功能，其他微服务组件都需要自己去实现。
            5。考虑性能：考虑Dubbo和Motan
    跨语言平台的开源RPC框架主要有以下几种
        gRPC：
            概念：Google于2015年对外开源的跨语言RPC框架，支持常用的C++、Java、Python、Go、Ruby、PHP、Android Java、Objective-C等多种语言。
            原理：
                通过IDL（Interface Definition Language）文件定义服务接口的参数和返回值类型，然后通过代码生成程序生成服务端和客户端的具体实现代码
            优点：
                这样在gRPC里，客户端应用可以像调用本地对象一样调用另一台服务器上对应的方法。
            特性：
                1。通信协议采用了HTTP/2，因为HTTP/2提供了连接复用、双向流、服务器推送、请求优先级、首部压缩等机制，所以在通信过程中可以节省带宽、降低TCP连接次数、节省CPU，尤其对于移动端应用来说，可以帮助延长电池寿命。
                2。IDL使用了ProtoBuf，ProtoBuf是由Google开发的一种数据序列化协议，它的压缩和传输效率极高，语法也简单，所以被广泛应用在数据存储和通信协议上。
                3。多语言支持，能够基于多种语言自动生成对应语言的客户端和服务端的代码。
        Thrift：
            概念：最初是由Facebook开发的内部系统跨语言的RPC框架，2007年贡献给了Apache基金，成为Apache开源项目之一，支持常用的C++、Java、PHP、Python、Ruby、Erlang等多种语言。
            优点：Thrift也有一套自己的接口定义语言IDL，可以通过代码生成器，生成各种编程语言的Client端和Server端的SDK代码，这样就保证了不同语言之间可以相互通信
            特性：
                1。支持多种序列化格式：如Binary、Compact、JSON、Multiplexed等。
                2。支持多种通信方式：如Socket、Framed、File、Memory、zlib等。
                3。服务端支持多种处理方式：如Simple 、Thread Pool、Non-Blocking等。
        对比选型
            从成熟度上来讲：
                1。Thrift因为诞生的时间要早于gRPC，所以使用的范围要高于gRPC，在HBase、Hadoop、Scribe、Cassandra等许多开源组件中都得到了广泛地应用。
                2。而且Thrift支持多达25种语言，这要比gRPC支持的语言更多，所以如果遇到gRPC不支持的语言场景下，选择Thrift更合适。
            gRPC作为后起之秀
                1。因为采用了HTTP/2作为通信协议、ProtoBuf作为数据序列化格式
                2。在移动端设备的应用以及对传输带宽比较敏感的场景下具有很大的优势，而且开发文档丰富
                3。据ProtoBuf文件生成的代码要比Thrift更简洁一些，从使用难易程度上更占优势
                4。所以如果使用的语言平台gRPC支持的话，建议还是采用gRPC比较好。
15讲如何搭建一个可靠的监控系统？
    开源监控系统实现方案主要有两种
        1。ELK为代表的集中式日志解决方案
            概念：是Elasticsearch、Logstash、Kibana三个开源软件产品首字母的缩写，它们三个通常配合使用，所以被称为ELK Stack
            软件的功能：
                1。Logstash
                    概念：负责数据收集和传输，它支持动态地从各种数据源收集数据，并对数据进行过滤、分析、格式化等，然后存储到指定的位置。
                    缺点：需要在各个服务器上部署Logstash来从不同的数据源收集数据，所以比较消耗CPU和内存资源，容易造成服务器性能下降，
                    方案：引入了Beats作为数据收集器
                        优点：所占系统的CPU和内存几乎可以忽略不计，
                        具体实现：可以安装在每台服务器上做轻量型代理，从成百上千或成千上万台机器向Logstash或者直接向Elasticsearch发送数据。
                        Beats支持多种数据源，主要包括：
                            1。Packetbeat，用来收集网络流量数据。
                            2。Topbeat，用来收集系统、进程的CPU和内存使用情况等数据。
                            3。Filebeat，用来收集文件数据。
                            4。Winlogbeat，用来收集Windows事件日志收据。
                            流程：Beats将收集到的数据发送到Logstash，经过Logstash解析、过滤后，再将数据发送到Elasticsearch，最后由Kibana展示
                2。Elasticsearch：
                    1。负责数据处理，它是一个开源分布式搜索和分析引擎，具有可伸缩、高可靠和易管理等特点
                    2。基于Apache Lucene构建，能对大容量的数据进行接近实时的存储、搜索和分析操作，通常被用作基础搜索引擎。
                3。Kibana：
                    负责数据展示，也是一个开源和免费的工具，通常和Elasticsearch搭配使用，对其中的数据进行搜索、分析并且以图表的方式展示
        2。Graphite、TICK和Prometheus等为代表的时序数据库解决方案
            Graphite
                1。Carbon：
                    概念：主要作用是接收被监控节点的连接，收集各个指标的数据，将这些数据写入carbon-cache并最终持久化到Whisper存储文件中去。
                2。Whisper：
                    概念：一个简单的时序数据库
                    作用：是存储时间序列数据，可以按照不同的时间粒度来存储数据
                    例子：比如1分钟1个点、5分钟1个点、15分钟1个点三个精度来存储监控数据。
                3。Graphite-Web：
                    概念：一个Web App，其主要功能绘制报表与展示，即数据展示
                    流程：
                        1。为了保证Graphite-Web能及时绘制出图形，Carbon在将数据写入Whisper存储的同时
                        2。，会在carbon-cache中同时写入一份数据，Graphite-Web会先查询carbon-cache，如果没有再查询Whisper存储。
            TICK
                概念：ICK是Telegraf、InfluxDB、Chronograf、Kapacitor四个软件首字母的缩写，是由InfluxData开发的一套开源监控工具栈，因此也叫作TICK Stack
            Prometheus
                概念：还有一种比较有名的时间序数据库解决方案Prometheus，它是一套开源的系统监控报警框架
    选型对比
        从监控系统的四个环节来分别对比
            1。数据收集
                1。ELK是通过在每台服务器上部署Beats代理来采集数据
                2。Graphite本身没有收据采集组件，需要配合使用开源收据采集组件，比如StatsD
                3。TICK使用了Telegraf作为数据采集组件
                4。Prometheus通过jobs/exporters组件来获取StatsD等采集过来的metrics信息。
            2。数据传输
                1。ELK是Beats采集的数据传输给Logstash，经过Logstash清洗后再传输给Elasticsearch
                2。Graphite是通过第三方采集组件采集的数据，传输给Carbon
                3。TICK是Telegraf采集的数据，传输给InfluxDB
                4。Prometheus是Prometheus Server隔一段时间定期去从jobs/exporters拉取数据
                汇总：前三种都是采用“推数据”的方式，而Prometheus是采取拉数据的方式，因此Prometheus的解决方案对服务端的侵入最小，不需要在服务端部署数据采集代理。
            3。数据处理
            4。数据展示
                1。Graphite、TICK和Prometheus自带的展示功能都比较弱，界面也不好看，不过好在它们都支持Grafana来做数据展示。Grafana是一个开源的仪表盘工具，它支持多种数据源比如Graphite、InfluxDB、Prometheus以及Elasticsearch等
                2。ELK采用了Kibana做数据展示，Kibana包含的数据展示功能比较强大，但只支持Elasticsearch，而且界面展示UI效果不如Grafana美观。

16讲如何搭建一套适合你的服务追踪系统？
    OpenZipkin
        背景：OpenZipkin是Twitter开源的服务追踪系统
        组成部分：
            1。负责收集探针Reporter埋点采集的数据，经过验证处理并建立索引。
            2。存储服务调用的链路数据，默认使用的是Cassandra，是因为Twitter内部大量使用了Cassandra，你也可以替换成Elasticsearch或者MySQL
            3。将格式化和建立索引的链路数据以API的方式对外提供服务，比如被UI调用。
            4。以图形化的方式展示服务调用的链路数据。
        流程：
            1。通过在业务的HTTP Client前后引入服务追踪代码，这样在HTTP方法“/foo”调用前
            2。生成trace信息：TraceId：aa、SpanId：6b、annotation：GET /foo，以及当前时刻的timestamp：1483945573944000
            3。然后调用结果返回后，记录下耗时duration，之后再把这些trace信息和duration异步上传给Zipkin Collector。
    Pinpoint
        背景：Pinpoint是Naver开源的一款深度支持Java语言的服务追踪系统
        组成部分：
            1。Pinpoint Agent：通过Java字节码注入的方式，来收集JVM中的调用数据，通过UDP协议传递给Collector，数据采用Thrift协议进行编码。
            2。Pinpoint Collector：收集Agent传过来的数据，然后写到HBase Storgage。
            3。HBase Storage：采用HBase集群存储服务调用的链路信息。
            4。Pinpoint Web UI：通过Web UI展示服务调用的详细链路信息。
    选型对比
        1。埋点探针支持平台的广泛性
            OpenZipkin：官方提供了C#、Go、Java、JavaScript、Ruby、Scala、PHP等主流语言版本的Library，而且开源社区还提供了更丰富的不同语言版本的Library
            Pinpoint：仅支持java
            建议：从探针支持的语言平台广泛性上来看，OpenZipkin比Pinpoint的使用范围要广，而且开源社区很活跃，生命力更强。
        2。系统集成难易程度
            具体怎么集成百度：
            从系统集成难易程度上看，Pinpoint要比OpenZipkin简单。
        3。调用链路数据的精确度
            1。OpenZipkin收集到的数据只到接口级别，进一步的信息就没有了。只能绘制服务与服务之间的调用链路拓扑图
            2。采用了字节码注入的方式实现trace信息收集，所以它能拿到的信息比OpenZipkin多得多，不仅能够绘制服务与服务之间，还能绘制与DB之间的调用链路拓扑图
            3。从调用链路数据的精确度上看，Pinpoint要比OpenZipkin精确得多。

17讲如何识别服务节点是否存活？（针对服务节点问题）
    心跳开关保护机制
        概念：
            即使在网络频繁抖动的时候，注册中心中可用的节点会不断变化，服务消费者也不至于同时去请求注册中心获取最新的服务节点信息。
        背景：
            1。在网络频繁抖动的情况下，注册中心中可用的节点会不断变化
            2。这时候服务消费者会频繁收到服务提供者节点变更的信息，于是就不断地请求注册中心来拉取最新的可用服务节点信息
            3。当有成百上千个服务消费者，同时请求注册中心获取最新的服务提供者的节点信息时
            4。可能会把注册中心的带宽给占满，尤其是注册中心是百兆网卡的情况下。
        问题：
            1导致服务消费者感知最新的服务节点信息延迟，原先可能在10s内就能感知到服务提供者节点信息的变更
            2。现在可能会延迟到几分钟，所以在网络正常的情况下，开关并不适合打开；
        建议：
            可以作为一个紧急措施，在网络频繁抖动的时候，才打开这个开关
        作用：
            防止服务提供者节点频繁变更导致的服务消费者同时去注册中心获取最新服务节点信息
    服务节点摘除保护机制
        概念：
            需要根据实际业务的情况，设定一个阈值比例，即使遇到刚才说的这种情况，注册中心也不能摘除超过这个阈值比例的节点。
        背景：
            1。如果遇到网络问题，大批服务提供者节点汇报给注册中心的心跳信息都可能会传达失败
            2。注册中心就会把它们都从可用节点列表中移除出去，造成剩下的可用节点难以承受所有的调用，引起“雪崩”
            3。但是这种情况下，可能大部分服务提供者节点是可用的，仅仅因为网络原因无法汇报心跳给注册中心就被“无情”的摘除了
        场景
            1。业务明确要下线大批量节点的情况是可以预知的，这种情况下可以关闭阈值保护；
            2。正常情况下，应该打开阈值保护，以防止网络抖动时，大批量可用的服务节点被摘除
        作用：
            为了防止服务提供者节点被大量摘除引起服务消费者可以调用的节点不足
    静态注册中心
        概念：
            服务消费者并不严格以注册中心中的服务节点信息为准，而是更多的以服务消费者实际调用信息来判断服务提供者节点是否可用
        现象：
            1。服务提供者节点就不需要向注册中心汇报心跳信息
            2。注册中心中的服务节点信息也不会动态变化，也可以称之为静态注册中心。
        流程：
            1。如果服务消费者调用某一个服务提供者节点连续失败超过一定次数，可以在本地内存中将这个节点标记为不可用。
            2。并且每隔一段固定时间，服务消费者都要向标记为不可用的节点发起保活探测，如果探测成功了
            3。就将标记为不可用的节点再恢复为可用状态，重新发起调用。
        选型
        网络的复杂性：
            1。动态注册中心，心跳机制不一定是可靠的
            2。服务消费者端的保活机制，事实证明这种机制足以应对网络频繁抖动等复杂的场景
        特殊场景：
            业务上线或者运维人工增加或者删除服务节点这种预先感知的情况下，还是有必要去修改注册中心中的服务节点信息。

18讲如何使用负载均衡算法？(调用)
    引入负载均衡算法原因：
        1。一个是要考虑调用的均匀性，也就是要让每个节点都接收到调用，发挥所有节点的作用
        2。一个考虑调用的性能，也就是哪个节点响应最快，优先调用哪个节点
    常见的负载均衡算法
    1。随机算法
        概念：从可用的服务节点中，随机挑选一个节点来访问
        实现逻辑：随机算法通常是通过生成一个随机数来实现，比如服务有10个节点，那么就每一次生成一个1～10之间的随机数，假设生成的是2，那么就访问编号为2的节点。
        特点：实现比较简单，在请求量远超可用服务节点数量的情况下，各个服务节点被访问的概率基本相同
        场景：主要应用在各个服务节点的性能差异不大的情况下。
        代码示例：https://github.com/weibocom/motan/blob/master/motan-core/src/main/java/com/weibo/api/motan/cluster/loadbalance/RandomLoadBalance.java
    2。轮询算法
        概念：按照固定的顺序，把可用的服务节点，挨个访问一次
        实现逻辑：
            1。服务有10个节点，放到数组里就是一个大小为10的数组
            2。这样的话就可以从序号为0的节点开始访问，访问后序号自动加1，下一次就会访问序号为1的节点，以此类推。
        特点：轮询算法能够保证所有节点被访问到的概率是相同的
        场景：各个服务节点性能差异不大的情况下。
        代码示例：https://github.com/weibocom/motan/blob/master/motan-core/src/main/java/com/weibo/api/motan/cluster/loadbalance/RoundRobinLoadBalance.java
    3。加权轮询算法
        概念：每个节点赋予一个权重，从而使每个节点被访问到的概率不同，权重大的节点被访问的概率就高，权重小的节点被访问的概率就小。
        实现逻辑：
            1。加权轮询算法是生成一个节点序列，该序列里有n个节点，n是所有节点的权重之和。
            2。在这个序列中，每个节点出现的次数，就是它的权重值
            3。比如有三个节点：a、b、c，权重分别是3、2、1，那么生成的序列就是{a、a、b、c、b、a}，这样的话按照这个序列访问
            4。前6次请求就会分别访问节点a三次，节点b两次，节点c一次。从第7个请求开始，又重新按照这个序列的顺序来访问节点
        注意：
            1。尽可能保证生产的序列的均匀，如果生成的不均匀会造成节点访问失衡
            2。比如刚才的例子，如果生成的序列是{a、a、a、b、b、c}，就会导致前3次访问的节点都是a
        特点：给每个节点设置不同的权重来控制访问的概率
        场景：用在服务节点性能差异比较大的情况
        代码实现：https://github.com/weibocom/motan/blob/master/motan-core/src/main/java/com/weibo/api/motan/cluster/loadbalance/ConfigurableWeightLoadBalance.java
    4。最少活跃连接算法
        概念：每一次访问都选择连接数最少的节点
        原因：
            1。不同节点处理请求的速度不同，使得同一个服务消费者同每一个节点的连接数都不相同
            2。连接数大的节点，可以认为是处理请求慢，而连接数小的节点，可以认为是处理请求快
            3。所以在挑选节点时，可以以连接数为依据，选择连接数最少的节点访问。
        实现逻辑：需要记录跟每一个节点的连接数，这样在选择节点时，才能比较出连接数最小的节点。
        场景：服务端节点性能差异较大，而又不好做到预先定义权重时
        代码实现：https://github.com/weibocom/motan/blob/master/motan-core/src/main/java/com/weibo/api/motan/cluster/loadbalance/ActiveWeightLoadBalance.java
    5。一致性hash算法
        概念：通过某个hash函数，把同一个来源的请求都映射到同一个节点上
        特点：
            1。同一个来源的请求，只会映射到同一个节点上，可以说是具有记忆功能
            2。只有当这个节点不可用时，请求才会被分配到相邻的可用节点上。
        场景：服务端节点处理不同客户端请求差异较大的场景
        代码实现：https://github.com/weibocom/motan/blob/master/motan-core/src/main/java/com/weibo/api/motan/cluster/loadbalance/ConsistentHashLoadBalance.java

    自适应最优选择算法
        场景：
            1。服务节点数量众多，且性能差异比较大；
            2。服务节点列表经常发生变化，增加节点或者减少节点时有发生；
            3。客户端和服务节点之间的网络情况比较复杂，有些在一个数据中心，有些不在一个数据中心需要跨网访问，而且网络经常延迟或者抖动。
        以上算法满足不了要求
        实现逻辑
            1。在客户端本地维护一份同每一个服务节点的性能统计快照
            2。并且每隔一段时间去更新这个快照。在发起请求时，根据“二八原则”，把服务节点分成两部分，找出20%的那部分响应最慢的节点
            3。然后降低权重。
            4。这样的话，客户端就能够实时的根据自身访问每个节点性能的快慢，动态调整访问最慢的那些节点的权重，来减少访问量，从而可以优化长尾请求。
        实现关键点
            1。每隔一段时间获取客户端同每个服务节点之间调用的平均性能统计
                具体流程
                    1。需要在内存中开辟一块空间记录客户端同每一个服务节点之间调用的平均性能，并每隔一段固定时间去更新
                    2。这个更新的时间间隔不能太短，太短的话很容易受瞬时的性能抖动影响，导致统计变化太快，没有参考性
                    3。同时也不能太长，太长的话时效性就会大打折扣，效果不佳。根据我的经验，1分钟的更新时间间隔是个比较合适的值。
            2。按照这个性能统计对服务节点进行排序，对排在性能倒数20%的那部分节点赋予一个较低的权重，其余的节点赋予正常的权重。
                    1。权重值的设定，即使服务节点之间的性能差异较大，也不适合把权重设置得差异太大
                    2。这样会导致性能较好的节点与性能较差的节点之间调用量相差太大，这样也不是一种合理的状态。
                    3。在实际设定时，可以设置20%性能较差的节点权重为3，其余节点权重为5。

19讲如何使用服务路由？
    服务路由：服务消费者在发起服务调用时，必须根据特定的规则来选择服务节点，从而满足某些特定的需求。
    服务路由的应用场景
        1。分组调用
            背景：
                1。为了保证服务的高可用性，实现异地多活的需求，一个服务往往不止部署在一个数据中心，而且出于节省成本等考虑，
                2。有些业务可能不仅在私有机房部署，还会采用公有云部署，甚至采用多家公有云部署
                3。服务节点也会按照不同的数据中心分成不同的分组，这时对于服务消费者来说，选择哪一个分组调用，就必须有相应的路由规则
        2。灰度发布
            背景：
                1。服务上线发布的过程中，一般需要先在一小部分规模的服务节点上先发布服务，然后验证功能是否正常。如果正常的话就继续扩大发布范围；
                2。如果不正常的话，就需要排查问题，解决问题后继续发布。这个过程就叫作灰度发布，也叫金丝雀部署。
        3。流量切换
            背景：
                1。在业务线上运行过程中，经常会遇到一些不可抗力因素导致业务故障，比
                2。比如某个机房的光缆被挖断，或者发生着火等事故导致整个机房的服务都不可用
                3。这个时候就需要按照某个指令，能够把原来调用这个机房服务的流量切换到其他正常的机房。
        4。读写分离
            背景：
                1。对于大多数互联网业务来说都是读多写少，所以在进行服务部署的时候，可以把读写分开部署
                2。所有写接口可以部署在一起，而读接口部署在另外的节点上
    服务路由的规则
        1。条件路由
            例子：host = 10.20.153.10 => host = 10.20.153.11
                1。分隔符“=>”前面是服务消费者的匹配条件，后面是服务提供者的过滤条件
                2。当服务消费者节点满足匹配条件时，就对该服务消费者执行后面的过滤规则
                3。这段表达式表达的意义就是IP为“10.20.153.10”的服务消费者都调用IP为“10.20.153.11”的服务提供者节点。
            2。脚本路由
    服务路由的获取方式
        1。本地配置
            概念：
                存储在服务消费者本地上
            实现：
                1。服务消费者发起调用时
                2。从本地固定位置读取路由规则
                3。然后按照路由规则选取一个服务节点发起调用。
        2。配置中心管理
            概念：所有的服务消费者都从配置中心获取路由规则，由配置中心来统一管理。
        3。动态下发
            过程：
                1。一般是运维人员或者开发人员，通过服务治理平台修改路由规则
                2。服务治理平台调用配置中心接口，把修改后的路由规则持久化到配置中心。
                3。因为服务消费者订阅了路由规则的变更，于是就会从配置中心获取最新的路由规则，按照最新的路由规则来执行。
        选型
            1。一般来讲，服务路由最好是存储在配置中心中，由配置中心来统一管理
                原因：
                    1。所有的服务消费者就不需要在本地管理服务路由
                    2。大部分的服务消费者并不关心服务路由的问题，或者说也不需要去了解其中的细节
                    3。通过配置中心，统一给各个服务消费者下发统一的服务路由，节省了沟通和管理成本。
            2。某些服务消费者有特定的需求，需要定制自己的路由规则，这个时候就适合通过本地配置来定制
            3。动态下发可以理解为一种高级功能，它能够动态地修改路由规则，在某些业务场景下十分有用
                例如：
                    1。比如某个数据中心存在问题，需要把调用这个数据中心的服务消费者都切换到其他数据中心
                    2。这时就可以通过动态下发的方式，向配置中心下发一条路由规则，将所有调用这个数据中心的请求都迁移到别的地方

20讲服务端出现故障时该如何应对？
    背景：
        1。单体应用改造成微服务的一个好处是可以减少故障影响范围，故障被局限在一个微服务系统本身，而不是整个单体应用都崩溃
        2。那么具体到一个微服务系统，如果出现了故障，应该如何处理呢？
    微服务系统故障
    1。集群故障：
        背景：微服务系统一般都是集群部署的，根据业务量大小而定，集群规模从几台到甚至上万台都有可能
        场景：一旦某些代码出现bug，可能整个集群都会发生故障，不能提供对外提供服务
        原因：
            1。是代码bug所导致
                例子：如说某一段Java代码不断地分配大对象，但没有及时回收导致JVM OOM退出
            2。流量冲击，超出了系统的最大承载能力，
                例子：比如“双11”这种购物活动，电商系统会在零点一瞬间涌入大量流量，超出系统的最大承载能力，一下子就把整个系统给压垮了。
        方法：
        1。限流
            概念：限流就是限制流量
            问题一：
                1。系统能够承载的流量根据集群规模的大小是固定的，可以称之为系统的最大容量
                2。当真实流量超过了系统的最大容量后，就会导致系统响应变慢，服务调用出现大量超时，反映给用户的感觉就是卡顿、无响
                方法：
                    应该根据系统的最大容量，给系统设置一个阈值，超过这个阈值的请求会被自动抛弃，这样的话可以最大限度地保证系统提供的服务正常。
            问题二：
                1。一个微服务系统会同时提供多个服务，每个服务在同一时刻的请求量也是不同的，很可能出现的一种情况就是
                2。系统中某个服务的请求量突增，占用了系统中大部分资源，导致其他服务没有资源可用
                方法：
                    针对系统中每个服务的请求量也设置一个阈值，超过这个阈值的请求也要被自动抛弃，这样的话不至于因为一个服务影响了其他所有服务。
            指标
                1。QPS即每秒请求量（一般不选用）
                    问题：QPS因为不同服务的响应快慢不同，所以系统能够承载的QPS相差很大
                2。工作线程数（选用）
                    1。设置一个总的最大工作线程数，总请求量过大会限流
                    2。单个服务的最大工作线程数，
        2。降级
            概念：降级就是通过停止系统中的某些功能，来保证系统整体的可用性
            开关实现
                1。在系统运行的内存中开辟一块区域，专门用于存储开关的状态，也就是开启还是关闭
                2。并且需要监听某个端口，通过这个端口可以向系统下发命令，来改变内存中开关的状态
                3。当开关开启时，业务的某一段逻辑就不再执行，而正常情况下，开关是关闭的状态。
                场景：
                    1。新增的业务逻辑
                        原因：新增的业务逻辑相对来说不成熟，往往具备一定的风险，所以需要加开关来控制新业务逻辑是否执行；
                    2。另一种是依赖的服务或资源
                        原因：因为依赖的服务或者资源不总是可靠的，所以最好是有开关能够控制是否对依赖服务或资源发起调用，来保证即使依赖出现问题，也能通过降级来避免影响。
            影响程度进行分级
                1。一级降级是对业务影响最小的降级，在故障的情况下，首先执行一级降级，所以一级降级也可以设置成自动降级，不需要人为干预；
                2。二级降级是对业务有一定影响的降级，在故障的情况下，如果一级降级起不到多大作用的时候，可以人为采取措施，执行二级降级
                3。三级降级是对业务有较大影响的降级，这种降级要么是对商业收入有重大影响，要么是对用户体验有重大影响，所以操作起来要非常谨慎，不在最后时刻一般不予采用
    2。单IDC故障：
        背景：现在大多数互联网公司为了保证业务的高可用性，往往业务部署在不止一个IDC
        场景：然而现实中时常会发生某个IDC的光缆因为道路施工被挖断，导致整个IDC脱网。
        原因：不可抗力比如机房着火、光缆被挖断
        高可用：
            1。同城双活，也就是在一个城市的两个IDC内部署
            2。异地多活，一般是在两个城市的两个IDC内部署
            3。三地五中心，支付宝金融级别的应用
            好处：当有一个IDC发生故障时，可以把原来访问故障IDC的流量切换到正常的IDC，来保证业务的正常访问。
            流量切换：
                1。基于DNS解析的流量切换：
                    概念：一般是通过把请求访问域名解析的VIP从一个IDC切换到另外一个IDC
                    例子
                        1。比如访问“www.weibo.com”，正常情况下北方用户会解析到联通机房的VIP
                        2。南方用户会解析到电信机房的VIP，如果联通机房发生故障的话，会把北方用户访问也解析到电信机房的VIP
                    缺点：网络延迟可能会变长。
                2。基于RPC分组的流量切换
                    流程
                        1。假如一个IDC出现故障，那么原先路由到这个分组的流量，就可以通过向配置中心下发命令
                        2。把原先路由到这个分组的流量全部切换到别的分组，这样的话就可以切换故障IDC的流量了。
    3。单机故障：
        背景：然而现实中时常会发生某个IDC的光缆因为道路施工被挖断，导致整个IDC脱网。
        问题：但会导致调用到故障机器上的请求都失败，影响整个系统的成功率。
        方法：自动重启
        实现过程：
            1。具体来讲，你可以设置一个阈值，比如以某个接口的平均耗时为准，当监控单机上某个接口的平均耗时超过一定阈值时，就认为这台机器有问题
            2。这个时候就需要把有问题的机器从线上集群中摘除掉，然后在重启服务后，重新加入到集群中。
            3。最好是设置一个可重启的单机数量占整个集群的最大比例，一般这个比例不要超过10%
            注意：需要防止网络抖动造成的接口超时从而触发自动重启
                方法：
                    1。一种方法是在收集单机接口耗时数据时，多采集几个点，比如每10s采集一个点，采集5个点
                    2。当5个点中有超过3个点的数据都超过设定的阈值范围，才认为是真正的单机问题，这时会触发自动重启策略。

21讲服务调用失败时有哪些处理手段？
    背景：
        1。微服务相比于单体应用最大的不同之处在于
        2。服务的调用从同一台机器内部的本地调用变成了不同机器之间的远程方法调用
    因素：
        1。服务端（执行）
            1。服务提供者也可能由于诸如CPU、网络I/O、磁盘、内存、网卡等硬件原因导致调用失败
            2。本身程序执行问题比如GC暂停导致调用失败。
        2。网络传输
            原因：网络的复杂性是不可控的，网络丢包、延迟以及随时可能发生的瞬间抖动都有可能造成调用失败。
    方法：
    1。超时
        问题：
            一个系统的问题会影响所有调用这个系统所提供服务的服务消费者，如果不加以控制，严重的话会引起整个系统雪崩。
        方法：设置一个超时时间
            注意超时时间的设置
                1。不是越短越好，因为太短可能会导致有些服务调用还没有来得及执行完就被丢弃了
                2。当然时间也不能太长，太长有可能导致服务消费者被拖垮
                3。建议：比较合适的超时时间需要根据正常情况下，服务提供者的服务水平来决定
                    例子：就是按照服务提供者线上真实的服务水平，取P999或者P9999的值，也就是以99.9%或者99.99%的调用都在多少毫秒内返回为准。
        作用：以避免依赖的服务迟迟没有返回调用结果，把服务消费者拖死。
    2。重试
        背景：
            1。虽然设置超时时间可以起到及时止损的效果，但是服务调用的结果毕竟是失败了
            2。而大部分情况下，调用失败都是因为偶发的网络问题或者个别服务提供者节点有问题导致的
        例子：
            1。如果能换个节点再次访问说不定就能成功。而且从概率论的角度来讲，假如一次服务调用失败的概率为1%，
            2。那么连续两次服务调用失败的概率就是0.01%，失败率降低到原来的1%。
        方法：设置一个服务调用超时后的重试次数
            例子：
                1。假如某个服务调用的超时时间设置为100ms，重试次数设置为1，那么当服务调用超过100ms后
                2。服务消费者就会立即发起第二次服务调用，而不会再等待第一次调用返回的结果了。
    3。双发
        概念：
            同时发起两次服务调用，一方面可以提高调用的成功率，另一方面两次服务调用哪个先返回就采用哪次的返回结果，平均响应时间也要比一次调用更快
        缺点：一次调用会给后端服务两倍的压力，所要消耗的资源也是加倍的
        方法：备份请求；
        思路：
            1。服务消费者发起一次服务调用后，在给定的时间内如果没有返回请求结果，那么服务消费者就立刻发起另一次服务调用
            2。这里需要注意的是，这个设定的时间通常要比超时时间短得多，比如超时时间取的是P999，那么备份请求时间取的可能是P99或者P90
            3。这是因为如果在P99或者P90的时间内调用还没有返回结果，那么大概率可以认为这次请求属于慢请求了，再次发起调用理论上返回要更快一些。
    4。熔断
        背景：
            1。服务提供者出现故障，短时间内无法恢复时，无论是超时重试还是双发不但不能提高服务调用的成功率
            2。反而会因为重试给服务提供者带来更大的压力，从而加剧故障。
        方法：
            1。需要服务消费者能够探测到服务提供者发生故障，并短时间内停止请求，给服务提供者故障恢复的时间，待服务提供者恢复后，再继续请求
            2。这就好比一条电路，电流负载过高的话，保险丝就会熔断，以防止火灾的发生
        工作原理
            1。客户端的每一次服务调用用断路器封装起来，通过断路器来监控每一次服务调用。
            2。如果某一段时间内，服务调用失败的次数达到一定阈值，那么断路器就会被触发，后续的服务调用就直接返回，也就不会再向服务提供者发起请求了。
            一旦服务提供者恢复之后，服务调用如何恢复呢？
                1。Closed状态：正常情况下，断路器是处于关闭状态的，偶发的调用失败也不影响。
                2。Open状态：当服务调用失败次数达到一定阈值时，断路器就会处于开启状态，后续的服务调用就直接返回，不会向服务提供者发起请求。
                3。Half Open状态：
                    1。当断路器开启后，每隔一段时间，会进入半打开状态，这时候会向服务提供者发起探测调用，以确定服务提供者是否恢复正常。
                    2。如果调用成功了，断路器就关闭；如果没有成功，断路器就继续保持开启状态，并等待下一个周期重新进入半打开状态。
        Hystrix的断路器也包含三种状态：关闭、打开、半打开
            实现原理：
                1。Hystrix会把每一次服务调用都用HystrixCommand封装起来，它会实时记录每一次服务调用的状态，包括成功、失败、超时还是被线程拒绝
                2。当一段时间内服务调用的失败率高于设定的阈值后，Hystrix的断路器就会进入进入打开状态，新的服务调用就会直接返回，不会向服务提供者发起调用
                3。再等待设定的时间间隔后，Hystrix的断路器又会进入半打开状态，新的服务调用又可以重新发给服务提供者了；
                4。如果一段时间内服务调用的失败率依然高于设定的阈值的话，断路器会重新进入打开状态，否则的话，断路器会被重置为关闭状态。
            如何计算一段时间内服务调用的失败率，那么Hystrix是如何做的呢？
                1。Hystrix通过滑动窗口来对数据进行统计，默认情况下，滑动窗口包含10个桶，每个桶时间宽度为1秒
                2。每个桶内记录了这1秒内所有服务调用中成功的、失败的、超时的以及被线程拒绝的次数
                3。当新的1秒到来时，滑动窗口就会往前滑动，丢弃掉最旧的1个桶，把最新1个桶包含进来。
                4。任意时刻，Hystrix都会取滑动窗口内所有服务调用的失败率作为断路器开关状态的判断依据，
                5。这10个桶内记录的所有失败的、超时的、被线程拒绝的调用次数之和除以总的调用次数就是滑动窗口内所有服务的调用的失败率。

22讲如何管理服务配置？
    背景：
        1。单体应用只需要管理一套配置
        2。而拆分为微服务后，每一个系统都有自己的配置，并且都各不相同，而且因为服务治理的需要，有些配置还需要能够动态改变，以达到动态降级、切流量、扩缩容等目的
    本地配置
        1。把配置当作代码同等看待，随着应用程序代码一起发布
        2。把配置都抽离到单独的配置文件当中，使配置与代码分离
        缺点：修改配置，就需要重新走一遍代码或者配置的发布流程
    配置中心
        思路：
            1。就是把服务的各种配置，如代码里配置的各种参数、服务降级的开关甚至依赖的资源等都在一个地方统一进行管理
            2。服务启动时，可以自动从配置中心中拉取所需的配置，并且如果有配置变更的情况
            3。同样可以自动从配置中心拉取最新的配置信息，服务无须重新发布
        功能：
            1。配置注册功能
            2。配置反注册功能
            3。配置查看功能
            4。配置变更订阅功能
        实现
            1。配置存储结构
                存储配置是按照Group来存储的，同一类配置放在一个Group下，以K, V键值对存储。
            2。配置注册
                1。配置中心对外提供接口/config/service?action=register来完成配置注册功能
                2。需要传递的参数包括配置对应的分组Group，以及对应的Key、Value值
            3。配置反注册
                1。配置中心对外提供接口config/service?action=unregister来完成配置反注册功能
                2。需要传递的参数包括配置对象的分组Group，以及对应的Key
            4。配置查看
                1。配置中心对外提供接口config/service?action=lookup来完成配置查看功能
                2。需要传递的参数包括配置对象的分组Group，以及对应的Key。
            5。配置变更订阅
                1。配置中心对外提供接口config/service?action=getSign来完成配置变更订阅接口
                2。客户端本地会保存一个配置对象的分组Group的sign值
                3。同时每隔一段时间去配置中心拉取该Group的sign值，与本地保存的sign值做对比。
                4。一旦配置中心中的sign值与本地的sign值不同，客户端就会从配置中心拉取最新的配置信息
    应用场景
        1。资源服务化
            例子：
                1。以微博的业务为例，核心缓存Memcached就有上千台机器，经常会遇到个别机器因为硬件故障而不可用，
                2。这个时候如果采用的是本地配置的话，就需要去更改本地配置，把不可用的IP改成可用的IP，然后发布新的配置，这样的过程十分不便
                3。但如果采用资源服务化的话，把对应的缓存统统归结为一类配置
                4。然后如果有个别机器不可用的话，只需要在配置中心把对应的IP换成可用的IP即可，应用程序会自动同步到本机，也无须发布。
        2。业务动态降级
            1。比如要具备动态降级能力，在依赖的服务出现故障的情况下，可以快速降级对这个服务的调用，从而保证不受影响
            2。服务消费者可以通过订阅依赖服务是否降级的配置，当依赖服务出现故障的时候，通过向配置中心下达指令
            3。修改服务的配置为降级状态，这样服务消费者就可以订阅到配置的变更，从而降级对该服务的调用。

        3。分组流量切换
            1。服务消费者可以通过订阅依赖服务的分组配置，当依赖服务的分组配置发生变更时
            2。服务消费者就对应的把调用切换到新的分组，从而实现分组流量切换。
        开源配置中心与选型
            1。Spring Cloud Config：
              1。Spring Cloud中使用的配置中心组件，只支持Java语言，配置存储在git中，
              2。变更配置也需要通过git操作，如果配置中心有配置变更，需要手动刷新。
            2。Disconf
                1。百度开源的分布式配置管理平台，只支持Java语言
                2。基于Zookeeper来实现配置变更实时推送给订阅的客户端，并且可以通过统一的管理界面来修改配置中心的配置
            3。Apollo
                1。携程开源的分布式配置中心，支持Java和.Net语言
                2。客户端和配置中心通过HTTP长连接实现实时推送，并且有统一的管理界面来实现配置管理。
            选择：
                1。Spring Cloud Config作为配置中心的功能比较弱，只能通过git命令操作，而且变更配置的话还需要手动刷新，如果不是采用Spring Cloud框架的话不建议选择
                2。而Disconf和Apollo的功能都比较强大，在国内许多互联网公司内部都有大量应用
                3。其中Apollo对Spring Boot的支持比较好，如果应用本身采用的是Spring Boot开发的话，集成Apollo会更容易一些

23讲如何搭建微服务治理平台？
    微服务治理平台：
        概念：与服务打交道的统一入口，无论是开发人员还是运维人员，都能通过这个平台对服务进行各种操作
            1。开发人员可以通过这个平台对服务进行降级操作
            2。运维人员可以通过这个平台对服务进行上下线操作
    功能：
    1。服务管理
        概念：可以调用注册中心提供的各种管理接口来实现服务的管理
        1。服务上下线：
            当上线一个新服务的时候，可以通过调用注册中心的服务添加接口，新添加一个服务
            同样要下线一个已有服务的时候，也可以通过调用注册中心的服务注销接口，删除一个服务。
        2。节点添加/删除
            当需要给服务新添加节点时候，可以通过调用注册中心的节点注册接口，来给服务新增加一个节点
            而当有故障节点出现或者想临时下线一些节点时，可以通过调用注册中心的节点反注册接口，来删除节点。
        3。服务查询
            这个操作会调用注册中心的服务查询接口，可以查询当前注册中心里共注册了多少个服务，每个服务的详细信息。
        4。服务节点查询
            这个操作会调用注册中心的节点查询接口，来查询某个服务下一共有多少个节点。
    2。服务治理
        概念：可以调用配置中心提供的接口，动态地修改各种配置来实现服务的治理。
        1。限流
            例子：
                1。一般是在系统出现故障的时候，比如像微博因为热点突发事件的发生，可能会在短时间内流量翻几倍，超出系统的最大容量。
                2。这个时候就需要调用配置中心的接口，去修改非核心服务的限流阈值，从而减少非核心服务的调用，给核心服务留出充足的冗余度。
        2。降级
            原因：
                1。因为突发流量的到来，导致系统的容量不足
                2。因为某些依赖服务的问题，导致系统被拖慢
            方法：
                1。这时可以通过降级一些非核心业务，来增加系统的冗余度
                2。这时可以降级对依赖服务的调用，避免被拖死。
        3。切流量
            背景：通常为了服务的异地容灾考虑，服务部署在不止一个IDC内
            例子：
                1。当某个IDC因为电缆被挖断、机房断电等不可抗力时，需要把故障IDC的流量切换到其他正常IDC，这时候可以调用配置中心的接口，
                2。向所有订阅了故障IDC服务的消费者下发指令，将流量统统切换到其他正常IDC，从而避免服务消费者受影响。

        3。服务监控
            1。整体监控：
                例子：服务依赖拓扑图，将整个系统内服务间的调用关系和依赖关系进行可视化的展示；
                展示：使用服务追踪系统提供的服务依赖拓扑图
            2。服务监控
                例子：服务的QPS、AvgTime、P999等监控指标
                展示：可以通过Grafana等监控系统UI来展示。
        4。问题定位
            1。宏观层面
                做法：通过服务监控来发觉异常
                例子：某个服务的平均耗时异常导致调用失败；
            2。微观层面
                概念：通过服务追踪来具体定位一次用户请求失败具体是因为服务调用全链路的哪一层导致的。
        5。日志查询
            微服务治理平台可以通过接入类似ELK的日志系统，能够实时地查询某个用户的请求的详细信息或者某一类用户请求的数据统计。
        6。服务运维
            1。发布部署：
                概念：当服务有功能变更，需要重新发布部署的时候，可以调用容器管理平台分批按比例进行重新部署，然后发布到线上。
            2。扩缩容
                概念：在流量增加或者减少的时候，需要相应地增加或者缩减服务在线上部署的实例，这时候可以调用容器管理平台来扩容或者缩容。
    如何搭建微服务治理平台
        关键点
            1。能够封装对微服务架构内的各个基础设施组件的调用
            2。从而对外提供统一的服务操作API
            3。还提供了可视化的界面
        第一层：Web Portal
            概念：微服务治理平台的前端展示层
                1。服务管理界面，可以进行节点的操作，比如查询节点、删除节点。
                2。服务治理界面，可以进行服务治理操作，比如切流量、降级等，还可以查看操作记录
                3。服务监控界面，可以查看服务的详细信息，比如QPS、AvgTime、耗时分布区间以及P999等
                4。服务运维界面，可以执行服务的扩缩容操作，还可以查看扩缩容的操作历史。

        第二层：API
            概念：后端服务层，这一层对应的需要提供Web Portal接口以调用
                1。添加服务接口。这个接口会调用注册中心提供的服务添加接口来新发布一个服务。
                2。删除服务接口。这个接口会调用注册中心提供的服务注销接口来下线一个服务
                3。服务降级/限流/切流量接口。这几个接口会调用配置中心提供的配置修改接口，来修改对应服务的配置，然后订阅这个服务的消费者就会从配置中心拉取最新的配置，从而实现降级、限流以及流量切换。
                4。服务扩缩容接口。这个接口会调用容器平台提供的扩缩容接口，来实现服务的实例添加和删除。
                5。服务部署接口。这个接口会调用容器平台提供的上线部署接口，来实现服务的线上部署。
        第三层：DB
            概念：存储一些基本信息
            1。用户权限
                原因：因为微服务治理平台的功能十分强大，所以要对用户的权限进行管理
                权限：可浏览、可更改以及管理员三个权限
                    可更改的权限进行细分：按照不同服务的负责人进行权限划分，一个人只能对它负责的服务的进行更改操作而不能修改其他人负责的服务
            2。操作记录：用来记录下用户在平台上所进行的变更操作，比如降级记录、扩缩容记录、切流量记录等。
            3。元数据
                概念：主要是用来把服务在各个系统中对应的记录映射到微服务治理平台中，统一进行管理
                例子：
                    1。某个服务在监控系统里可能有个特殊标识
                    2。在注册中心里又使用了另外一个标识，为了统一就需要在微服务治理平台统一进行转换，然后进行数据串联。

24讲微服务架构该如何落地？
    从一个案例入手：
    首先从众多业务中找到一个小的业务进行试点
        思路：
            1。前期的技术方案以满足这个小的业务需求为准，力求先把这个小业务的微服务架构落地实施，从中发现各种问题并予以解决，
            2。然后才可以继续考虑更大规模的推广。
        优点：
            1。这样的话，即使微服务架构的改造因为技术方案不成熟
            2。对业务造成了影响，也只是局限在一个小的业务之中，不会对整体业务造成太大影响
        例子：
            1。微博业务的微服务改造，从2013年开始进行微服务架构的研发
            2。到2014年用户关系服务开始进行微服务改造
            3。再到2015年Feed业务开始进行微服务改造
            4。从几个服务上线后经过春晚流量的考验后
            5。逐步推广到上百个服务的上线，整个过程持续了两年多时间。
        注意：稳定性永远是在第一位的，业务架构改造追求的是稳步推进，中间可以有小的波折，但对整体架构的演进方向不会产生影响。
    做好技术取舍
        建议
            1。一切以业务的实际情况为准，只要满足当前的需求就好，切忌好高骛远
            2。尤其是对于技术能力很强的开发者来说，很容易陷入对技术的完美追求，投入过多精力在架构的雕花工作上，而忽视了眼下业务最实际的需求。
            3。尤其是在团队技术人力紧张，开发周期短的时候，更需要集中力量去满足业务最迫切的需求
            4。而对于架构的完善以及一些附加功能的追求，可以在后面业务落地后逐步进行完善。
            5。在做技术选型的时候，还要考虑到团队的实际掌控能力，尤其是对一些新技术方案的引入要尤其慎重
                如果没有合适的人能够掌控这些技术，那么贸然引入新技术，一旦业务受影响时，如果没有人能有效干预，这对业务来说是灾难性的后果。
        例子：
            1。以微博的服务化框架Motan为例，因为微博平台的开发语言主要是Java，所以最早Motan只支持Java语言
            2。从2017年开始，有了跨语言服务化调用的需求，才在此基础上，对架构进行了升级，加入了对Go、PHP等语言的支持
    采用DevOps
        概念：对微服务架构进行一站式开发、测试、上线和运维。
    统一微服务治理平台
        概念：需要开发和运维深入合作，发挥各自专业的特长，将微服务治理的功能以及之前运维系统的基础功能结合在一起，打造成“一站式”微服务治理平台。

25讲微服务为什么要容器化？
    微服务带来的问题
    问题一：一个业务需求就需要同时测试多个微服务接口的功能，上线发布多个系统，给测试和运维的工作量增加了很多。
        方法：DevOps
        概念：
            理解为开发和运维的结合，服务的开发者不再只负责服务的代码开发，还要负责服务的测试、上线发布甚至故障处理等全生命周期过程
        优点：
            把测试和运维从微服务拆分后所带来的复杂工作中解放出来
        过程：
            DevOps要求开发、测试和发布的流程必须自动化，这就需要保证开发人员将自己本地部署测试通过的代码和运行环境，
            能够复制到测试环境中去，测试通过后再复制到线上环境进行发布
    问题二：阿里云的环境跟本地不一样，为此服务部署的初始化工作十分繁琐。
        Docker解决
    什么是Docker
        概念：
            1。Docker是容器技术的一种，事实上已经成为业界公认的容器标准
            2。基于Linux内核的Cgroups、Namespace机制来实现进程的封装和隔离的
        容器：
            1。本质就是Linux操作系统里的进程，但与操作系统中运行的一般进程不同的是
            2。容器通过Namespace和Cgroups这两种机制，可以拥有自己的root文件系统、自己的网络配置、自己的进程空间
            3。甚至是自己的用户ID空间，这样的话容器里的进程就像是运行在宿主机上的另外一个单独的操作系统内，从而实现与宿主机操作系统里运行的其他进程隔离
        作用：解决了应用程序运行时隔离的问题
        问题：
            1。要想实现应用能够从一台机器迁移到另外一台机器上还能正常运行，
            2。就必须保证另外一台机器上的操作系统是一致的，而且应用程序依赖的各种环境也必须是一致的。
            方案：Docker镜像
                概念：镜像不光可以打包应用程序本身，而且还可以打包应用程序的所有依赖，甚至可以包含整个操作系统
                作用：解决了DevOps中微服务运行的环境难以在本地环境、测试环境以及线上环境保持一致的难题。
            过程：
                1。开发就可以把在本地环境中运行测试通过的代码，以及依赖的软件和操作系统本身打包成一个镜像
                2。然后自动部署在测试环境中进行测试，测试通过后再自动发布到线上环境上去
                3。整个开发、测试和发布的流程就打通了。

    微服务容器化实践
        背景：
            1。Docker能帮助解决服务运行环境可迁移问题的关键，利用Docker镜像的分层机制
            2。实际在使用Docker镜像的时候往往并不是把业务代码、依赖的软件环境以及操作系统本身直接都打包成一个镜像
        关键：
            利用Docker镜像的分层机制，在每一层通过编写Dockerfile文件来逐层打包镜像
        原因：
            1。虽然不同的微服务依赖的软件环境不同，但是还是存在大大小小的相同之处
            2。因此在打包Docker镜像的时候，可以分层设计、逐层复用，这样的话可以减少每一层镜像文件的大小。
        例子：微博的Docker镜像大致分为四层。
            1。基础环境层。这一层定义操作系统运行的版本、时区、语言、yum源、TERM等。
            2。运行时环境层。这一层定义了业务代码的运行时环境，比如Java代码的运行时环境JDK的版本
            3。Web容器层。这一层定义了业务代码运行的容器的配置，比如Tomcat容器的JVM参数
            4。业务代码层。这一层定义了实际的业务代码的版本，比如是V4业务还是blossom业务。
            FROM registry.intra.weibo.com/weibo_rd_content/tomcat_feed:jdk8.0.40_tomcat7.0.81_g1_dns
            ADD confs /data1/confs/
            RUN chmod +x /data1/weibo/bin/200.sh /data1/weibo/bin/503.sh /data1/weibo/bin/catalina.sh
            WORKDIR /data1/weibo/bin
            解释：
                1。FROM代表了上一层镜像文件是“tomcat_feed:jdk8.0.40_tomcat7.0.81_g1_dns”，从名字可以看出上一层镜像里包含了Java运行时环境JDK和Web容器Tomcat，以及Tomcat的版本和JVM参数等
                2。ADD就是要在这层镜像里添加的文件， 这里主要包含了业务的代码和配置等；
                3。RUN代表这一层镜像启动时需要执行的命令；
                4。WORKDIR代表了这一层镜像启动后的工作目录

26讲微服务容器化运维：镜像仓库和资源调度
    背景：业务容器化后，运维面对的不再是一台台实实在在的物理机或者虚拟机了，而是一个个Docker容器，它们可能都没有固定的IP
    一个容器运维平台通常包含以下几个组成部分
    1。镜像仓库
        作用：解决的是Docker镜像存储和访问的问题
        概念：
            1。其实跟Git代码仓库类似，就是有一个集中存储的地方，把镜像存储在这里
            2。在服务发布的时候，各个服务器都访问这个集中存储来拉取镜像，然后启动容器。
        如何搭建一套私有的镜像仓库
        1。权限控制
            概念：哪些用户可以拉取镜像，哪些用户可以修改镜像。
            都设有两层权限控制
                1。一是必须登录才可以访问，这是最外层的控制，它规定了哪些人可以访问镜像仓库
                2。二是对镜像按照项目的方式进行划分，每个项目拥有自己的镜像仓库目录，并且给每个项目设置项目管理员、开发者以及客人这三个角色
                    1。项目管理员和开发者拥有自己镜像仓库目录下镜像的修改权限
                    2。客人只拥有访问权限
                    3。项目管理员可以给这个项目设置哪些人是开发者
        2。镜像同步
            现象：
                1。在实际的生产环境中，往往需要把镜像同时发布到几十台或者上百台集群节点上
                2。单个镜像仓库实例往往受带宽原因限制无法同时满足大量节点的下载需求
                3。这个时候就需要配置多个镜像仓库实例来做负载均衡，同时也就产生镜像在多个镜像仓库实例之间同步的问题了
            问题：通过手工维护十分繁琐，那有什么好的办法吗？
            方案：
                1。一种是一主多从，主从复制的方案
                    例子：开源镜像仓库Harbor采用了这种方案；
                    Harbor所采取的主从复制的方案是：把镜像传到一个主镜像仓库实例上去，然后其他从镜像仓库实例都从主镜像仓库实例同步
                        1。Harbor还支持层次型的发布方式，如果集群部署在多个IDC，可以先从一个主IDC的镜像仓库同步到其他从IDC的镜像仓库
                        2。再从各个从IDC同步给下面的分IDC
                2。另一种是P2P的方案
                    例子：阿里的容器镜像分发系统蜻蜓采用了P2P方案。微博的镜像仓库是基于Harbor搭建的，
        3。高可用性
            例子：高可用性设计无非就是把服务部署在多个IDC，这样的话即使有IDC出问题，也可以把服务迁移到别的正常IDC中去
            方法：同样对于镜像仓库的搭建，也可以采用多IDC部署，那么需要做到的就是不同IDC之间的镜像同步。
    2。资源调度
        作用：决定了Docker镜像可以分发到哪些机器上的问题
        1。物理机集群
            概念：大部分中小团队应该都拥有自己的物理机集群，并且大多按照集群 - 服务池 - 服务器这种模式进行运维。
            问题：主要是服务器的配置不统一
                1。一种情况就是几年前采购的机器的配置可能还是12核16G内存的配置
                2。一些年采购的机器都至少是32核32G内存的配置
            方法：
                1。旧的机器用于跑一些非核心占用资源量不大的业务
                2。新采购的机器用于跑一些核心且服务调用量高的业务。
        2。虚拟机集群
            背景：不少业务团队在使用物理机集群之后，发现物理机集群存在使用率不高、业务迁移不灵活的问题，因此纷纷转向了虚拟化方向，构建自己的私有云
            例子：以OpenStack技术为主的私有云集群在国内外不少业务团队都有大规模的应用
            优点：
                1。就是可以整合企业内部的服务器资源
                2。通过虚拟化技术进行按需分配，提高集群的资源使用率，节省成本。
        3。公有云集群
            背景：现在越来越多的业务团队，尤其是初创公司，因为公有云快速灵活的特性，纷纷在公有云上搭建自己的业务。
            优点：
                1。公有云最大的好处除了快速灵活、分钟级即可实现上百台机器的创建
                2。还有个好处就是配置统一、便于管理，不存在机器配置碎片化问题。
            方法：
                1。通过Docker Machine可以在企业内部的物理机集群，
                2。或者虚拟机集群比如OpenStack集群，
                3。又或者公有云集群比如AWS集群等上创建机器并且直接部署容器
                问题：
                    1。资源调度最大的难点不在于机器的创建和容器的部署
                    2。而在于如何对接各个不同的集群，统一管理来自不同集群的机器权限管理
                    3。成本核算以及环境初始化等操作，这个时候就需要有一个统一的层来完成这个操作
                方案：需要针对新的模式重新开发这套运维平台
                    例子：以微博的业务为例，
                        思路：
                            1。为了满足内部三种不同集群资源的统一管理，专门研发了容器运维平台DCP，来实现对接多个不同的集群。
                            2。它的难点在于不仅对外要对接不同的云厂商，针对不同云厂商提供的ECS创建的API，统一封装一层API来实现机器管理
                            3。对内也要针对私有云上不同集群的机器进行管理，进行上下线和配置初始化等操作。
                        以DCP配置初始化操作为例，流程
                            1。以DCP配置初始化操作为例，在创建完主机后，还需要在主机上进行安装NTP服务、修改sysctl配置、安装Docker软件等操作这时候就需要借助配置管理软件来向主机上进行分发
                            2。因为微博内网的主机，之前都是通过Puppet进行分发的，考虑到稳定性并没有对这一部分进行修改；
                            3。而针对阿里云上创建的主机，则使用的是编程功能更为强大的Ansible进行分发。

    3。容器调度
    4。服务编排

27讲微服务容器化运维：容器调度和服务编排
    容器调度：
        思路：现在集群里有一批可用的物理机或者虚拟机，当服务需要发布的时候，该选择哪些机器部署容器的问题。
        背景：
            1。集群机器的规模扩大到几十台或者上百台时，要发布的服务也有几十个或者上百个的时候
            2。由于每个服务对容器的要求，以及每台机器上正在运行的容器情况变得很复杂，就不太可能靠人肉运维了
        方法：容器调度系统
            解决方案：
                1。Docker原生的调度系统Swarm
                2。Mesosphere出品的Mesos
                3。Google开源的大名鼎鼎的Kubernetes
        问题：
            1。主机过滤
                目的：为了解决容器创建时什么样的机器可以使用的问题
                方式：针对主机层次的过滤方式
                    1。存活过滤：
                        概念：也就是说必须选择存活的节点，因为主机也有可能下线或者是故障状态
                    2。硬件过滤
                        例子：
                            1。面对的集群有Web集群、RPC集群、缓存集群以及大数据集群等
                            2。不同的集群硬件配置差异很大，比如Web集群往往用作计算节点，它的CPU一般配置比较高
                            3。而大数据集群往往用作数据存储，它的磁盘一般配置比较高
                            选择：
                                如果要创建计算任务的容器，显然就需要选择Web集群，而不是大数据集群。
                注意：除此之外，Swarm还提供了容器层次的过滤，可以实现只有运行了某个容器的主机才会被加入候选集等功能。
            2。调度策略
                目的：解决容器创建时选择哪些主机最合适的问题，一般都是通过给主机打分来实现的
                例子：Swarm就包含了两种类似的策略：spread和binpack
                    共同点：它们都会根据每台主机的可用CPU、内存以及正在运行的容器的数量来给每台主机打分。
                    spread策略：
                        概念：选择一个资源使用最少的节点，以使容器尽可能的分布在不同的主机上运行。
                        优点：可以使每台主机的负载都比较平均，而且如果有一台主机有故障，受影响的容器也最少
                    binpack策略：
                        概念：它会选择一个资源使用最多的节点，好让容器尽可能的运行在少数机器上
                        优点：节省资源的同时也避免了主机使用资源的碎片化。
                场景一
                    1。各主机的配置基本相同，并且使用也比较简单，一台主机上只创建一个容器。
                    这样的话，每次创建容器的时候，直接从还没有创建过容器的主机当中随机选择一台就可以了。
                场景二：
                    1。在某些在线、离线业务混布的场景下，为了达到主机资源使用率最高的目标
                    2。需要综合考量容器中跑的任务的特点，比如在线业务主要使用CPU资源
                    3。而离线业务主要使用磁盘和I/O资源，这两种业务的容器大部分情况下适合混跑在一起。
                场景三：
                    1。主机上的资源都是充足的，每个容器只要划定了所用的资源限制
                    2。理论上跑在一起是没有问题的，但是某些时候会出现对每个资源的抢占
                    例子：都是CPU密集型或者I/O密集型的业务就不适合容器混布在一台主机上。
                实际的业务场景，对调度策略的要求比较灵活，如果Swarm提供的spread和binpack满足不了的话，可能就需要考虑自行研发容器调度器了。

    服务编排
        1。服务依赖
            背景：
                1。大部分情况下，微服务之间是相互独立的，在进行容器调度的时候不需要考虑彼此
                2。但有时候也会存在一些场景，比如服务A调度的前提必须是先有服务B，这样的话就要求在进行容器调度的时候，还需要考虑服务之间的依赖关系。
                方案：Docker官方提供了Docker Compose的解决方案。
                    原理：
                        它允许用户通过一个单独的docker-compose.yaml文件来定义一组相互关联的容器组成一个项目，从而以项目的形式来管理应用
                    例子：
                        1。要实现一个Web项目，不仅要创建Web容器比如Tomcat容器，还需要创建数据库容器比如MySQL容器，负载均衡容器比如Nginx容器等
                        2。这个时候就可以通过docker-compose.yaml来配置这个Web项目里包含的三个容器的创建。

        2。服务发现
            背景：
                1。容器调度完成以后，容器就可以启动了，但此时容器还不能对外提供服务
                2。服务消费者并不知道这个新的节点，所以必须具备服务发现机制，使得新的容器节点能够加入到线上服务中去
            服务发现机制：
                1。一种是基于Nginx的服务发现
                    概念：
                        1。这种主要是针对提供HTTP服务的，当有新的容器节点时，修改Nginx的节点列表配置
                        2。然后利用Nginx的reload机制，会重新读取配置从而把新的节点加载进来。
                    例子：
                        1。比如基于Consul-Template和Consul，把Consul作为DB存储容器的节点列表，
                        2。Consul-Template部署在Nginx上，Consul-Template定期去请求Consul，如果Consul中存储的节点列表发生变化
                        3。就会更新Nginx的本地配置文件，然后Nginx就会重新加载配置。
                2。一种是基于注册中心的服务发现。
                    概念：这种主要是针对提供RPC服务的，当有新的容器节点时，需要调用注册中心提供的服务注册接口。
        3。自动扩缩容
            背景：
                1。容器完成调度后，仅仅做到有容器不可用时故障自愈还不够
                2。还需要根据实际服务的运行状况，做到自动扩缩容。
                例子：微博例子
                    1。一个很常见的场景就是，大部分互联网业务的访问呈现出访问时间的规律性
                    2。以微博业务为例，白天和晚上的使用人数要远远大于凌晨的使用人数；
                    3。而白天和晚上的使用人数也不是平均分布的，午高峰12点半和晚高峰10点半是使用人数最多的时刻。
                    4。这个时候就需要根据实际使用需求，在午高峰和晚高峰的时刻，增加容器的数量，确保服务的稳定性
                    5。在凌晨以后减少容器的数量，减少服务使用的资源成本。
            具体做法：
                1。根据容器的CPU负载情况来设置一个扩缩容的容器数量或者比例
                2。比如可以设定容器的CPU使用率不超过50%，一旦超过这个使用率就扩容一倍的机器。

28讲微服务容器化运维：微博容器运维平台DCP
    DCP整体架构
    1。基础设施层
        作用：解决镜像仓库的问题
    2。主机层
        作用：解决如何进行资源调度的问题
    3。调度层
        作用：解决主要解决容器如何在资源上创建的问题
    4。编排层
        作用：主要解决容器如何运作以对外提供服务的问题

29讲微服务如何实现DevOps？
        背景：
            1。把一个大的单体应用拆分成多个微服务之后，每个服务都可以独立进行开发、测试和运维
            2。但当拆分的微服务足够多时，却又仿佛陷入一个新的泥沼，无论是业务代码的开发还是测试和运维，工作量都比之前提升了很多。
        问题：
            1。一个业务需求可能要同时修改多个微服务的代码，这样的话多个微服务都需要进行测试
            2。测试通过了都需要把代码发布到线上，显然工作量成倍增加
    什么是DevOps？
        传统的流程：
            1。开发人员开发完业务代码后，把自测通过的代码打包交给测试人员
            2。然后测试人员把代码部署在测试环境中进行测试，如果测试不通过，就反馈bug给开发人员进行修复
            3。如果通过，开发就把测试通过的代码交给运维人员打包，然后运维人员再发布到线上环境中去
        问题：
            开发人员、测试人员和运维人员的职责划分十分明确，他们往往分属于不同的职能部门，一次业务上线流程需要三者之间进行多次沟通，
            周期基本是以天为单位；
            方案：DevOps的方案
            思想：
                1。DevOps是一种新型的业务研发流程，业务的开发人员不仅需要负责业务代码的开发
                2。还需要负责业务的测试以及上线发布等全生命周期
                3。真正做到掌控服务全流程。DevOps就是下图中心的部分，集开发、测试和运维三者角色于一体。
        过程：
        1。CI（Continuous Integration），持续集成
            概念：开发完成代码开发后，能自动地进行代码检查、单元测试、打包部署到测试环境，进行集成测试，跑自动化测试用例。
        2。CD（Continuous Deploy），持续部署
            1。代码测试通过后，能自动部署到类生产环境中进行集成测试，测试通过后再进行小流量的灰度验证
            2。验证通过后代码就达到线上发布的要求了，就可以把代码自动部署到线上。
    微博的DevOps实践
        比较通用的实现DevOps的方案主要有两种
            1。一种是使用Jenkins
            2。一种是使用GitLab
    实现DevOps的关键点
        1。持续集成阶段
            目的：保证每一次开发的代码都没有问题，即使合并到主干也能正常工作，依靠三部分的作用
                1。代码检查
                    概念：通过代码检查可以发现代码潜在的一些bug
                    比如：
                        1。比如Java对象有可能是null空指针等
                        2。实际执行时可以在持续集成阶段集成类似Sonarqube之类的工具来实现代码检查。
                2。单元测试
                    概念：针对每个具体代码模块的，单元测试的覆盖度越高，各个代码模块出错的概率就越小
                    建议：在单元测试阶段多花费一些功夫，其实从整个代码开发周期角度来看，收益还是要远大于付出的。
                3。集成测试
                    概念：集成测试就是将各个代码的修改集成到一起，统一部署在测试环境中进行测试
                    过程：
                        1。在新的业务需求确定时，就开始编写测试用例，这样在跑自动化测试用例时，就不需要测试的介入了，省去了沟通成本
                        2。当然，业务开发人员也可以自己编写测试用例，这样的话就不需要专职的业务测试人员了。
        2。持续交付阶段
            目的：保证最新的业务代码，能够在类生产环境中可能够正常运行
            一般做法：
                1。一般做法都是从线上生成环境中摘掉两个节点，然后在这两个节点上部署最新的业务代码
                2。再进行集成测试，集成测试通过后再引入线上流量，来观察服务是否正常。
                问题一：如何从线上生产环境中摘除两个节点
                    方法：这就需要接入线上的容器管理平台
                    例子：微博的容器管理平台DCP就提供了类似下面的API，能够从线上生产环境中摘除某个节点，然后部署最新的业务代码。
                问题二：如何观察服务是否正常
                    1。由于这两个节点上运行的代码是最新的代码，在引入线上流量后可能会出现内存泄露等在集成测试阶段无法发现的问题
                    2。所以这个阶段这两个节点上运行最新代码后的状态必须与线上其他节点一致
                        观察：
                            1。一个是观察节点本身的状态，如CPU、内存、I/O、网卡等
                        2。观察业务运行产生的warn、error的日志量的大小，尤其是error日志量有异常时，往往就说明最新的代码可能存在异常，需要处理后才能发布到线上。
        3。持续部署阶段
            目的：把在类生产环境下运行通过的代码自动的发布到线上所有节点中去，这里的关键点就在于实际的线上发布阶段并不是想象中的那么直接
            一般：许多公司在这个阶段都采用了手动发布的方式以控制风险，或者只做到持续交付阶段，对于持续部署并不要求自动化。

30讲如何做好微服务容量规划？
    问题：
        1。服务数量众多，纯靠人肉运维难以管理
            比如：微博Feed业务仅仅RPC服务就有将近40个。
        2。服务的接口表现差异巨大
            比如：
                1。有的接口属于访问量比较大，但接口响应时间比较短的轻接口；有的接口属于访问量比较小，但接口响应时间比较长的重接口。
                2。微博Feed业务中计数接口的平均耗时只有2～3ms，而微博Feed业务中Feed接口的平均耗时要超过200ms。
        3。服务部署的集群规模大小不同，需要扩容的机器数量差异很大。
            比如：微博的AB测试服务集群只有大约20台机器，扩容只需要几台机器就满足了；而Feed服务则有上千台机器，往往扩容需要上百台机器。
        4。服务之间还存在依赖关系，在服务扩容的时候，还需要考虑依赖服务的容量是否足够
            比如：微博Feed业务扩容还依赖用户关系服务和Card服务，扩容时还需要考虑依赖的用户关系服务和Card服务容量是否有问题。
    方法：容量规划系统：
        作用：根据各个微服务部署集群的最大容量和线上实际运行的负荷，来决定各个微服务是否需要弹性扩缩容，以及需要扩缩容多少台机器。
    容量规划系统关键点
    1。如何做好容量评估
        概念：如何评估集群的最大容量和线上实际运行的负荷
        注意：一般集群的容量评估都是通过线上实际压测来确定的
        压测的关键点：
            1。选择合适的压测指标
                1。一类是系统类指标
                    比如：机器的CPU使用率、内存占用量、磁盘I/O使用率以及网卡带宽等
                    问题：
                        1。系统类指标比如CPU使用率并不能直接反映出服务压测时的健康状况，有时候CPU使用率不高的时候，接口耗时也可能有问题
                        2。有时候CPU使用率较高时，接口耗时表现依然很正常
                2。一类是服务类指标
                    比如：接口响应的平均耗时、P999耗时、错误率
                    问题：
                        1。服务类的指标比如接口响应的平均耗时也不能精确的反映服务的实际健康状态
                        例子：
                            已经出现一定比例的慢请求，而在平均耗时上并不能看出有多大变化，这时候实际服务已经处于不健康的状态了，应该停止压测了。
                3。接口的慢速比：接口响应时间高于某个阈值的比例
                    例子：
                        1。比如微博在进行Feed接口压测时，选择的压测指标就是Feed接口响应时间大于1s的比例
                        2。压测的终止条件是Feed接口响应时间大于1s的比例超过1%
            2。压测获取单机的最大容量
                背景：集群的最大容量就是单机的最大容量 × 集群内的机器数量
                1。单机压测：一般有两种方式
                    1。一种是通过日志回放等手段，模拟线上流量来对单机进行压测
                    2。一种是通过TCP-Copy的方式，把线上机器的流量拷贝过来对单机进行压测。
                缺点：通常为了避免产生“脏数据”，往往需要去掉一些上行的修改请求，所以不能完全模拟线上真实情况
                2。集群压测：（建议采用）
                    概念：对整个集群进行压测，以获取单机的最大容量
                    做法：通过不断把线上集群的节点摘除，以减少机器数的方式，来增加线上节点单机的流量，从而达到压测的目的。
                    缺点：压测的时候会对线上用户的实际请求产生影响，如果压测出问题了，会直接影响线上服务
                    方法：
                        1。一般会选择在业务低峰期进行压测，最大限度减少对线上服务造成的影响。
                        2。通常会在工作日进行压测，以便出现问题时，也能人为快速介入。
            3。实时获取集群的运行负荷
                流程：
                    1。通过压测能够获取到单机的最大容量
                    2。再乘以集群内的机器数量就是集群的最大容量了
                    3。下一步获取集群实际运行的负荷，就可以判断集群是否需要扩容了
                实际做法：
                    1。统计每台单机在不同耗时区间内的请求数，推送到集中处理的地方进行聚合
                    2。将同一个集群内的单机位于不同耗时区间内的请求进行汇总，就得到整个集群的请求在不同耗时区间内的分布了
                    3。再利用区间加权的方式就可以计算整个集群的运行负荷。

    2。如何做好调度决策
        概念：如何确定弹性扩缩容的时机以及机器数
        判断依据：就可以根据水位线来做决定。
            例子：
                1。一条是安全线，一条是致命线。当集群的水位线位于致命线以下时，就需要立即扩容，在扩容一定数量的机器后
                2。水位线回到安全线以上并保持一段时间后，就可以进行缩容了。
        扩容：
            方法：在决定扩多少机器时，一般有两种方式，一种是按数量，一种是按比例
            建议：因为不同的集群内机器数量差别可能很大，所以一般采取按比例的方式
            例子：比如每一次扩容都增加30%的机器数量，再看扩容后的水位线是否处于致命线以上了。
        2.缩容
            背景：在扩容完成后，集群的水位线保持在安全线以上一段时间后，就需要缩容，以节省机器成本
            思路：可以根据实际业务特点来决定多久后可以缩容
            例子
                1。微博的业务一般突发流量维持在1个小时以内，因此集群的水位线在安全线以上超过1个小时之后，就可以缩容
                2。而在缩容时也不是一次把所有扩容的机器都缩掉，而是采用逐步缩容的方式，每隔5分钟判断一次集群的水位线是否还在致命线以上，然后按照10%、30%、50%、100%的比例进行缩容
                3。这样可以避免缩容太快导致集群水位线又降到致命线以下又得再扩容机器。
                    注意：根据水位线决定是否扩缩容时还需要防止网络抖动等原因造成的水位线瞬间抖动
                    网络抖动现象：根据水位线决定是否扩缩容时还需要防止网络抖动等原因造成的水位线瞬间抖动
                    方法：可以每分钟采集一次系统的水位线，一共采集5个点，只有5个点里有3个点满足扩容条件，才真正触发扩容。

31讲微服务多机房部署实践
    问题：
        1。一切正常时用户请求该访问哪个机房？
        2。多个机房之间的数据如何同步？
        3。多个机房之间的数据如何确保持一致性？
    多机房负载均衡
        概念：当服务部署在多个机房时，最简单的就是遵循用户就近访问的原则，比如北方用户访问联通机房，南方用户访问电信机房。
        特殊情况：
            1。某个机房的流量比较大，但是该机房的服务器规模有限并不足以支撑线上流量。
            2。某个机房服务有问题，需要切一部分流量到另外一个机房。
        结果：
            有时候并不能完全遵循就近访问的原则，而是要根据需要调配流量，达到各个机房流量均衡的目的
    多机房数据同步
        背景：想要实现服务部署到多机房供用户访问是有前提：
            前提：
                每个机房的数据都是一样的，用户访问哪个机房都可以获取到一样的数据，这就要求多个机房之间的数据必须保持同步
            例子：对于微博这种高并发访问的服务来说，数据通常都会有两层存储即缓存层和数据库层
                问题：保证多个机房的数据一致，不仅要保证数据库层的数据一致，还需要保证缓存层的数据一致
        1。主从机房架构
            原理：
                1。以一个机房为主机房，所有的写请求都只发给主机房的处理机，
                2。由主机房的处理机来更新本机房的缓存和数据库，其他机房的缓存也通过主机房的处理机来更新
                3。而数据库则通过MySQL的binlog同步机制的方式实现数据同步
            问题：
                如果主机房出现问题，就没法更新缓存和数据库了
        2。独立机房架构
            原理：
                1。所有都有写请求，并通过一个叫WMB的消息同步组件把各自机房的写请求同步一份给对方机房，这样的话相当于每个机房都有全量的写请求
                2。每个机房的处理机接收到写请求后更新各自机房的缓存，只有一个机房会更新数据库
                3。其他机房的数据库通过MySQL的binlog同步机制实现数据同步。
            优点：
                任意一个机房出现问题，都不影响别的机房的数据更新
            原因：
                每个机房的写消息都是全量的，所以每个机房可以更新自己的缓存，并从数据库主库同步数据
                关键点：在于WMB消息同步组件，它可以把各个机房之间的写请求进行同步。
                如何实现：
                    1。reship：负责把本机房的写请求分发一份给别的机房。
                    2。collector：负责从别的机房读取写请求，然后再把请求转发给本机房的处理机。
                    方法一：通过MCQ消息队列
                        流程：
                            1。联通机房的写请求写入到联通机房的MCQ里
                            2。然后联通机房的reship就从联通机房的MCQ里读取
                            3。再写入到电信机房的MCQ里，电信机房的collector就可以从电信机房的MCQ里读取到写请求
                            4。再写入到电信机房的另外一个MCQ里，电信机房的队列机就会从这个MCQ里读取写请求，然后更新缓存
                        缺点：
                            1。需要多次与MCQ消息队列打交道，当有大量写请求到来时，不仅要扩容reship和collector确保有足够的处理能力
                            2。还需要扩容MCQ消息队列以确保能够承受大量读取和写入

                    方法二：RPC调用实现
                        流程
                            1。还需要扩容MCQ消息队列以确保能够承受大量读取和写入
                            2。然后联通机房的reship RPC就会调用电信机房的collector RPC
                            3。这样电信机房的collector RPC就会调用电信机房的处理机RPC
                            4。从而实现把联通机房的写请求同步给电信机房的处理机进行处理。

    多机房数据一致性
        背景：
            1。类似金融类的业务要求多机房之间的数据必须是强一致的，也就是一个机房的数据必须时刻同另外一个机房的数据完全一致
            2。而社交媒体类的业务则要求没那么高，只需要能达到最终一致即可
        例子：
            1。系统会给每一次写请求生成一个全局唯一的requestId，联通机房的写请求一方面会调用联通机房的处理机RPC来修改缓存和数据库
            2。另一方面还会调用联通机房的reship RPC，reship RPC再调用电信机房的collector RPC来同步写请求
            3。电信机房的collector RPC最后会调用电信机房的处理RPC来更新缓存
            4。在这整个过程的每一个环节，requestId始终保持向下传递，无论是处理成功或者失败都记录一条包含requestId和机房标记的处理日志，并写到Elasticsearch集群上去
            5。然后通过一个定时线程，每隔1分钟去扫描Elasticsearch集群上的日志，找出包含同一个requestId的不同机房的处理日志，
            6。然后验证是否在各个机房请求都处理成功了，如果有的机房某一阶段处理失败，则可以根据日志信息重试该阶段直到成功，从而保证数据的最终一致性。

32讲微服务混合云部署实践
    问题：
        1。跨云服务如何实现负载均衡？
        2。跨云服务如何实现数据同步？
        3。跨云服务如何实现容器运维？
    跨云服务的负载均衡
        背景：
            1。多机房的负载均衡，它主要考虑用户的就近访问，把用户的请求分别路由到不同的机房
            2。同样的道理，当服务上云后还需要考虑把一定比例的用户请求路由到云上部署的服务，
        例子：微博的服务不仅在私有云的两个机房永丰和土城有部署，在阿里云上也部署了服务
            1。为了做到负载均衡，把用户的访问按照DNS解析到不同的机房
            2。私有云机房部署了VIP和Nginx分别用作四层和七层的负载均衡
            3。阿里云机房部署了SLB和Nginx分别用作四层和七层的负载均衡。
    跨云服务的数据同步
        在公有云部署服务和内部私有云部署服务还是有一些不同的，主要体现在下面两个方面。
        1。私有云与公有云之间的网络隔离
            实现原理：需要架设专门的VPN网络或者专线
            例子：微博
                1。在内部私有云和阿里云之间搭建了两条跨云专线，分别打通了内部的联通、电信机房与阿里云的联通、电信可用区
                2。这样的话不仅实现了私有云和公有云之间的网络互动，双专线也保证了高可用性，即使一条专线断了，也可以通过另外一条专线实现数据同步
                    注意：
                        1。这样做需要保证专线的冗余度充足，任何一根专线的带宽能够承担所有跨云的流量
                    原因：
                        因为一旦一根专线断了，所有流量都通过另外一根专线的话，就会把专线打满，出现网络延迟影响服务
        2。数据库能否上云
            关键点：取决于数据的隐私性
            原因：
                1。企业内部私有云部署的数据库与外网隔离，再加上有种种防护措施，一般情况下不会出现数据库数据外泄情况
                2。公有云厂商普遍采用了虚拟化技术，不同公司的虚拟机有可能部署在同一台物理机上，所以能否实现有效的数据隔离非常关键，
                3。尤其对于企业的核心业务数据，往往会出于安全隐私的考虑，并不敢直接放到云上部署
            例子：
                微博的服务在阿里云部署时，并没有部署数据库，只部署了缓存，当缓存穿透时需要访问内网数据库

    跨云服务的容器运维
        背景：
            1。微服务容器化后，便具备了可移植性，不仅可以在内部私有云上部署
            2。还可以在外部公有云上部署，这就要求有一套统一的容器运维平台不仅能对接内部私有云的基础设施
            3。也能对接外部的公有云，这部分内容你可以在第28期容器运维平台DCP中找到
        DCP在实施跨云的容器运维时关键点
        1。跨云的主机管理
            关键点：
                如何对内部私有云的机器和公有云的ECS进行管理，在DCP里是按照“主机-服务池-集群”的模式进行管理的
                    主机：某一台具体的服务器，可能是私有云内创建的虚拟机，也有可能是公有云创建的ECS。
                    服务机：针对具体某个服务而言，由这个服务部署的主机组成，可能包含私有云的主机，也可能包含公有云的主机，规模可能是几台也可能是上百台。
                    集群：针对具体某个业务线而言，可能包含多个服务池，比如微博的内容业务线包含了Feed服务池，也包含了评论服务池等。
            在实际扩容时，如下图所示，可能有三种情况。
                1。私有云内弹性扩容：
                    流程：
                        1。当某个服务池的容量不足需要进行扩容时，如果该服务池所在的集群内的主机数量充足
                        2。则只需要在私有云内弹性扩容加入服务池即可
                2。公有云弹性扩容：
                    流程：
                        1。当某个服务池的容量不足需要进行扩容时，如果该服务池所在的集群内没有多余的主机可用时
                        2。就需要在公有云上弹性扩容，然后加入服务池。
                3。私有云和公有云同时弹性扩容：
                    流程：
                        1。当某个服务池的容量不足需要进行扩容时，如果该服务池所在的集群内的主机数量不足时
                        2。就需要在同时在私有云和公有云上进行弹性扩容，最后都加入到服务池中去。
        2。跨云服务发现。
            1。一种是针对HTTP服务采用的nginx-upsync-module
            2。一种是针对RPC服务的Config Service
        3。跨云弹性扩容。
            概念：
                有流量上涨，超出了内部私有云机房部署所能承受的范围时，可以扩容阿里云机房的机器，然后把流量切换到阿里云机房
                方案一：
                    1。是在DNS层切换，把原先解析到私有云机房VIP的流量
                    2。解析到阿里云机房的SLB，这时候阿里云机房部署的SLB、Nginx和Java Web都需要扩容
                    场景：，DNS层的切换主要是针对大规模流量增长的情况，这个时候一般四层VIP、七层Nginx和Java Web的容量都不足以应对，就需要在DNS层就把流量切到阿里云机房，在阿里云扩容SLB、Nginx和Java Web
                方案二：
                    1。是在Nginx层切换，把原先转发到私有云机房Nginx的流量
                    2。转发到阿里云机房的Java Web，这个时候只需要扩容阿里云的Java Web。
                    场景：针对私有云内某个机房的Java Web容量不足或者服务有问题的时候，需要把这个机房的一部分流量切换到其他机房，这个时候就可以只扩容阿里云机房的Java Web，然后从Nginx层把流量切换到阿里云机房。
        4。跨云服务编排。
            背景：在进行服务编排时，如果服务跨云部署，就要考虑跨机房访问的问题了
            例子：
                1。微博的Feed服务不仅依赖User RPC，还依赖Card RPC，这样的话如果Feed服务需要扩容的话
                2。就需要先扩容User RPC和Card RPC。由于Feed服务在永丰、土城、阿里云三个机房内都有部署
                3。任意一个机房内部署的Feed服务需要扩容时，就需要扩容同一个机房内的User RPC和Card RPC。

33讲下一代微服务架构ServiceMesh
    概念：
        1。是一种新型的用于处理服务与服务之间通信的技术
        2。尤其适用以云原生应用形式部署的服务，能够保证服务与服务之间调用的可靠性
    原理：
        在实际部署时，Service Mesh通常以轻量级的网络代理的方式跟应用的代码部署在一起，从而以应用无感知的方式实现服务治理。
    与传统的微服务架构区别的两个原因
        1。跨语言服务调用的需要。
            传统问题：
                1。微博的业务为例，移动服务端的业务主要采用的是PHP语言开发，API平台的业务主要采用的是Java语言开发，移动服务端调用API平台使用的是HTTP请求
                2。如果要进行服务化，改成RPC调用，就需要一种既支持PHP语言又支持支持Java语言的的服务化框架
        2。云原生应用服务治理的需要
            1。微服务越来越多开始容器化，并使用Kubernetes类似的容器平台对服务进行管理，逐步朝云原生应用的方向进化。
            2。而传统的服务治理要求在业务代码里集成服务框架的SDK
    服务A调用服务B的过程
        1。服务A要调用服务B，经过Linkerd来代理转发
        2。服务A和服务B的业务代码不需要关心服务框架功能的实现。
        推论：
            1。Linkerd需要具备负载均衡、熔断、超时重试、监控统计以及服务路由等功能
            2。对于跨语言服务调用来说，即使服务消费者和服务提供者采用的语言不同，也不需要集成各自语言的SDK。
    服务网格的来源
        1。对于云原生应用来说，可以在每个服务部署的实例上，都同等的部署一个Linkerd实例
        2。服务A要想调用服务B，首先调用本地的Linkerd实例，
        3。经过本地的Linked实例转发给服务B所在节点上的Linkerd实例
        4。最后再由服务B本地的Linkerd实例把请求转发给服务B
        结论：
            所有的服务调用都得经过Linkerd进行代理转发，所有的Linkerd组合起来就像一个网格一样
    Service Mesh的实现原理
        关键在于两点
            1。轻量级的网络代理也叫SideCar
                作用：转发服务之间的调用
                传统的流程：
                    服务消费者：
                        1。除了自身的业务逻辑实现外
                        2。需要集成部分服务框架的逻辑，比如服务发现、负载均衡、熔断降级、封装调用等
                    服务提供者：
                        1。除了实现服务的业务逻辑外
                        2。集成部分服务框架的逻辑，比如线程池、限流降级、服务注册等。
                流程：
                    1。服务框架的功能都集中实现在SideCar里，并在每一个服务消费者和服务提供者的本地都部署一个SideCar
                    2。服务消费者和服务提供者只管自己的业务实现，服务消费者向本地的SideCar发起请求
                    3。本地的SideCar根据请求的路径向注册中心查询，得到服务提供者的可用节点列表后
                    4。再根据负载均衡策略选择一个服务提供者节点，并向这个节点上的SideCar转发请求
                    5。服务提供者节点上的SideCar完成流量统计、限流等功能后
                    6。再把请求转发给本地部署的服务提供者进程，从而完成一次服务请求
                    正向代理：服务消费者节点上的SideCar
                    反向代理：服务提供者节点上的SideCar
                    关键点：
                        1。服务消费者发出的请求如何通过正向代理转发
                        2。服务提供者收到的请求如何通过反向代理转发
                        方案一：基于iptables的网络拦截
                            例子 消费者：节点A  节点B：服务提供者
                            流程：
                                1。节点A上服务消费者发出的TCP请求都会被拦截
                                2。然后发送给正向代理监听的端口15001，正向代理处理完成后再把请求转发到节点B的端口9080
                                3。节点B端口9080上的所有请求都会被拦截发送给反向代理监听的端口15001
                                4。反向代理处理完后再转发给本机上服务提供者监听的端口9080。
                            缺点：有一定的性能损耗
                            优点：是从网络层实现调用拦截，能做到完全的业务无感知，所以适合云原生应用

                        方案二：采用协议转换的方式。
                            流程：
                                1。节点A上的服务消费者请求直接发给正向代理监听的端口15001，
                                2。正向代理处理完成后，再把请求转发到节点B上反向代理监听的端口15001
                                3。反向代理处理完成后再发送给本机上的服务提供者监听的端口9080
                            缺点：
                                要求代理层加入业务逻辑，才能把请求转发给对应的服务提供者监听的端口


            2。基于SideCar的服务治理也被叫作Control Plane
                背景：
                    1。既然SideCar能实现服务之间的调用拦截功能，那么服务之间的所有流量都可以通过SideCar来转发
                    2。这样的话所有的SideCar就组成了一个服务网格，再通过一个统一的地方与各个SideCar交互
                    3。就能控制网格中流量的运转了，这个统一的地方就在Sevice Mesh中就被称为Control Plane
                作用：是向SideCar发送各种指令，以完成各种服务治理功能
                    1。服务发现
                        流程：
                            1。服务提供者会通过SideCar注册到Control Plane的注册中心
                            2。这样的话服务消费者把请求发送给SideCar后，SideCar就会查询Control Plane的注册中心来获取服务提供者节点列表。
                    2。负载均衡
                        流程
                            1。SideCar从Control Plane获取到服务提供者节点列表信息后
                            2。就需要按照一定的负载均衡算法从可用的节点列表中选取一个节点发起调用
                            3。可以通过Control Plane动态修改SideCar中的负载均衡配置
                    3。请求路由
                        流程：
                            1。SideCar从Control Plane获取的服务提供者节点列表
                            2。也可以通过Control Plane来动态改变
                        例子：
                            进行A/B测试、灰度发布或者流量切换时，就可以动态地改变请求路由。

                    4。故障处理
                        背景：服务之间的调用如果出现故障，就需要加以控制
                        手段：超时重试、熔断
                        流程：SideCar转发请求时，通过Control Plane动态配置。
                    5。安全认证
                        流程：
                            可以通过Control Plane控制一个服务可以被谁访问，以及访问哪些信息
                    6。监控上报
                        流程：
                            1。所有SideCar转发的请求信息，都会发送到Control Plane，
                            2。再由Control Plane发送给监控系统，比如Prometheus等。
                    7。日志记录
                        流程：
                            1。所有SideCar转发的日志信息，也会发送到Control Plane
                            2。再由Control Plane发送给日志系统，比如Stackdriver等。
                    8。配额控制
                        流程：
                            1。可以在Control Plane里给服务的每个调用方配置最大调用次数
                            2。在SideCar转发请求给某个服务时，会审计调用是否超出服务对应的次数限制。

34讲Istio：ServiceMesh的代表产品
    Linkerd与Istio区别
        区别一
            内容：Istio引入了Control Plane的理念，称得上Linkerd的进化，算是第二代的Service Mesh产品。；
            优势：通过Control Plane能带来强大的服务治理能力，
        区别二：
            内容：Istio默认的SideCar采用了Envoy，它是用C++语言实现的，Linkerd采用的是Scala实现的
            优势：性能和资源消耗上小，对于延迟敏感型和资源敏感型的服务来说，尤其重要
        区别三：
            优势：Google可以将Kubernetes与Istio很自然的整合，打造成云原生应用默认的服务治理方案。
            背景：
                1。有Google和IBM的背书，尤其是在微服务容器化的大趋势下，云原生应用越来越受欢迎
                2。而Google开源的Kubernetes可以说已经成为云原生应用默认采用的容器平台
    Istio整体架构
    Istio的架构可以说由两部分组成，分别是Proxy和Control Plane。
        Proxy：
            概念：
                1。就是前面提到的SideCar，与应用程序部署在同一个主机上，
                2。应用程序之间的调用都通过Proxy来转发，目前支持HTTP/1.1、HTTP/2、gRPC以及TCP请求。
                3。Istio的Proxy采用的是Envoy，Envoy是跟上一期提到的Linkerd是同一代的产品
                4。既要作为服务消费者端的正向代理，又要作为服务提供者端的反向代理
                5。一般需要具备服务发现、服务注册、负载均衡、限流降级、超时熔断、动态路由、监控上报和日志推送等功
                特点：
                1。性能损耗低
                    原因：
                        1。因为采用了C++语言实现，Envoy能提供极高的吞吐量和极少的长尾延迟
                        2。而且对系统的CPU和内存资源占用也不大，所以跟业务进程部署在一起不会对业务进程造成影响。
                2。可扩展性高
                    概念：Envoy提供了可插拔过滤器的能力，用户可以开发定制过滤器以满足自己特定的需求
                3。动态可配置
                    概念：
                        1。Envoy对外提供了统一的API，包括CDS（集群发现服务）、RDS（路由发现服务）
                        2。LDS（监听器发现服务）、EDS（EndPoint发现服务）、HDS（健康检查服务）、ADS（聚合发现服务）等。
                        3。通过调用这些API，可以实现相应配置的动态变更，而不需要重启Envoy。
                        4。Envoy是Istio中最基础的组件，所有其他组件的功能都是通过调用Envoy提供的API
                        5。在请求经过Envoy转发时，由Envoy执行相关的控制逻辑来实现的。

        Control Plane 
            背景：与Proxy通信，来实现各种服务治理功能，包括三个基本组件：Pilot、Mixer以及Citadel
            Pilot
                作用：实现流量控制，它通过向Envoy下发各种指令来实现流量控制
                Pilot主要包含以下几个部分：
                    1。Rules API：对外封装统一的API，供服务的开发者或者运维人员调用，可以用于流量控制
                    2。Envoy API：对内封装统一的API，供Envoy调用以获取注册信息、流量控制信息等。
                    3。抽象模型层：对服务的注册信息、流量控制规则等进行抽象，使其描述与平台无关。
                4。平台适配层：用于适配各个平台如Kubernetes、Mesos、Cloud Foundry等，把平台特定的注册信息、资源信息等转换成抽象模型层定义的平台无关的描述。
                Pilot是如何实现流量管理功能的呢？
                    1。服务发现和负载均衡
                        流程：
                            1。服务B也就是服务提供者注册到对应平台的注册中心中去
                                例子：比如Kubernetes集群中的Pod，启动时会注册到注册中心etcd中。
                            2。然后服务A也就是服务消费者在调用服务B时，请求会被Proxy拦截
                            3。然后Proxy会调用Pilot查询可用的服务提供者节点
                            4。再以某种负载均衡算法选择一个节点发起调用。

                    2。请求路由
                        背景：Pilot可以对服务进行版本和环境的细分
                        例子：
                            1。服务B包含两个版本v1.5和v2.0-alpha，其中v1.5是生产环境运行的版本，而v2.0-alpha是灰度环境运行的版本
                            2。当需要做A/B测试时，希望灰度服务B的1%流量运行v2.0-alpha版本，就可以通过调用Pilot提供的Rules API
                            3。Pilot就会向Proxy下发路由规则，Proxy在转发请求时就按照给定的路由规则
                            4。把1%的流量转发给服务B的v2.0-alpha版本，99%的流量转发给服务B的v1.5版本
                    3。超时重试
                        流程：
                            1。缺省状态下，Proxy转发HTTP请求时的超时是15s
                            2。可以通过调用Pilot提供的Rules API来修改路由规则，覆盖这个限制
                            3。还可以通过修改路由规则，来指定某些HTTP请求的超时重试次数
                    4。故障注入
                        概念：Istio还提供了故障注入的功能，能在不杀死服务节点的情况下
                        做法：通过修改路由规则，将特定的故障注入到网络中
                        原理：在TCP层制造数据包的延迟或者损坏，从而模拟服务超时和调用失败的场景，以此来观察应用是否健壮
            Mixer
                作用：实现策略控制和监控日志收集等功能
                方式：一次Proxy转发的请求都要调用Mixer
                优点：
                    1。实现是可扩展的，通过适配层来适配不同的后端平台
                    2。这样的话Istio的其他部分就不需要关心各个基础设施比如日志系统、监控系统的实现细节。
                假设：
                    1。理论上每一次的服务调用Proxy都需要调用Mixer，一方面检查调用的合法性，
                    2。一方面要上报服务的监控信息和日志信息，所以这就要求Mixer必须是高可用和低延迟的，那么Mixer是如何做到的呢？
                Mixer实现了两级的缓存结构实现原理：
                    1。Proxy端的本地缓存：
                        原理：
                            1。为了减少Proxy对Mixer的调用以尽量降低服务调用的延迟
                            2。在Proxy这一端会有一层本地缓存，但由于Proxy作为SideCar与每个服务实例部署在同一个节点上，
                            3。所以不能对服务节点有太多的内存消耗，所以就限制了Proxy本地缓存的大小和命中率。
                    2。Mixer的本地缓存
                        原理：
                            1。Mixer是独立运行的，所以可以在Mixer这一层使用大容量的本地缓存，从而减少对后端基础设施的调用
                            2。一方面可以减少延迟，另一方面也可以最大限度减少后端基础设施故障给服务调用带来的影响。
                那么Mixer是如何实现策略控制和监控日志收集功能呢？
                1。策略控制
                    1。对服务的调用进行速率限制
                        方式：在Mixer中配置规则来实现
                            1。需要配置速率控制的yaml文件，每一次Proxy转发请求前都会先调用Mixer
                            2。Mixer就会根据这个yaml文件中的配置，来对调用进行速率限制
                    2。对服务的调用进行访问控制
                        方式：在Mixer中配置规则来实现
                            1。需要配置访问控制的yaml文件，每一次Proxy转发请求前都会先调用Mixer
                            2。Mixer就会根据这个yaml文件中的配置，来对调用进行访问控制。
                2。监控和日志收集
                    原理：
                        1。Mixer的监控、日志收集功能也是通过配置监控yaml文件来实现的，Proxy发起的每一次服务调用都会先调用Mixer
                        2。把监控信息发给Mixer，Mixer再根据配置的yaml文件来决定监控信息该发到哪。
            Citadel
                作用：作用是保证服务之间访问的安全
            工作原理：实际的安全保障并不是Citadel独立完成的，而是需要Proxy、Pilot以及Mixer的配合
            流程：
                1。Citadel里存储了密钥和证书。
                2。通过Pilot把授权策略和安全命名信息分发给Proxy。
                3。Proxy与Proxy之间的调用使用双向TLS认证来保证服务调用的安全。
                4。最后由Mixer来管理授权和审计。

35讲微博ServiceMesh实践之路（上）
