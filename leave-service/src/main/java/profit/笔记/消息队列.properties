01 | 为什么需要消息队列？
    哪些问题适合使用消息队列来解决？
    1. 异步处理
    案例一：秒杀系统
        1。风险控制
        2。库存锁定；
        3。生成订单；
        4。短信通知；
        5。更新统计数据。
        正常处理：App 将请求发送给网关，依次调用上述 5 个流程，然后将结果返回给 APP。
        分析：
            1。能否决定秒杀成功，实际上只有风险控制和库存锁定这 2 个步骤，
            2。只要用户的秒杀请求通过风险控制，并在服务端完成库存锁定，就可以给用户返回秒杀结果了，对于后续的生成订单、短信通知和更新统计数据等步骤，并不一定要在秒杀请求中处理完成。
        优化：
          1。5个步骤减少2个步骤（风险控制，库存锁定）
          2。订单，短信，统计通过消息队列发送
        优势：
            1。响应速度更快
            2。大量的服务器资源用来处理秒杀请求
            3。秒杀结束后再把资源用于处理后面的步骤，充分利用有限的服务器资源处理更多的秒杀请求
    2：流量控制
        1。如何避免过多的请求压垮我们的秒杀系统
            设计方案：
                使用消息队列隔离网关和后端服务，以达到流量控制和保护后端服务的目的。
        方法一。加入消息队列后控制
            1。网关在收到请求后，将请求放入请求消息队列；
            2。后端服务从请求消息队列中获取 APP 请求，完成后续秒杀处理过程，然后返回结果
            优势：
                1。根据下游的处理能力自动调节流量，达到“削峰填谷”的作用
            缺点：
            1。增加了系统调用链环节，导致总体的响应时延变长。
            2。上下游系统都要将同步调用改为异步消息，增加了系统的复杂度。
        方法二：令牌桶控制流量。
                原理：单位时间内只发放固定数量的令牌到令牌桶中，规定服务在处理请求之前必须先从令牌桶中拿出一个令牌，如果令牌桶中没有令牌，则拒绝请求
                实现：不需要破坏原有的调用链，只要网关在处理 APP 请求时增加一个获取令牌的逻辑。
                令牌桶：可以简单地用一个有固定容量的消息队列加一个“令牌发生器”来实现
                    令牌发生器按照预估的处理能力，匀速生产令牌并放入令牌队列（如果队列满了则丢弃令牌），网关在收到请求时去令牌队列消费一个令牌，获取到令牌则继续调用后端秒杀服务，如果获取不到令牌则直接返回秒杀失败。
    3。服务解耦
        案例：电商系统，新订单创建
            1。支付系统需要发起支付流程；
            2。风控系统需要审核订单的合法性；
            3。服系统需要给用户发短信告知用户；
            4。经营分析系统需要更新统计数据；
        分析：
            1。下游系统的增加，订单系统的开发团队不得不花费精力，应对下游系统
            2。任何一个下游系统接口变更，都需要订单模块重新进行一次上线，对于一个电商的核心服务来说，这几乎是不可接受的
        增加消息队列：
            优势：无论增加、减少下游系统或是下游系统需求如何变化，订单服务都无需做任何更改，实现了订单服务与下游服务的解耦。
    4。作为发布 / 订阅系统实现一个微服务级系统间的观察者模式；
    5。连接流计算任务和数据；
    6。用于将消息广播给大量接收者。

        问题：
            1。引入消息队列带来的延迟问题；
            2。增加了系统的复杂度；
            3。可能产生数据不一致的问题。

02 | 该如何选择消息队列？
    选择消息队列产品的基本标准
        1。首先，必须是开源的产品，这个非常重要
        2。这个产品必须是近年来比较流行并且有一定社区活跃度的产品
        3。必须具备几个特性
            1。消息的可靠传递：确保不丢消息；
            2。Cluster：支持集群，确保不会因为某个节点宕机导致服务不可用，当然也不能丢消息；
            3。性能：具备足够好的性能，能满足绝大多数场景的性能要求。
    可供选择的消息队列产品
        1。RabbitMQ：
            语言：Erlang 语言编写的，支持AMQP协议
            特点：
                1开箱即用的消息队列，相当轻量级的消息队列，非常容易部署和使用
                2.比较流行
                3。支持非常灵活的路由配置，和其他消息队列不同的是，它在生产者（Producer）和队列（Queue）之间增加了一个 Exchange 模块（交换机）
                    Exchange 模块：
                    作用：和交换机也非常相似，根据配置的路由规则将生产者发出的消息分发到不同的队列中
                        路由规则：也非常灵活，甚至你可以自己来实现路由规则
                4。支持的编程语言大概是所有消息队列中最多的。
            缺点：
            1。RabbitMQ 对消息堆积的支持并不好
            2。RabbitMQ 的性能是我们介绍的这几个消息队列中最差的
            3。RabbitMQ 使用的编程语言 Erlang，非常小众的语言
            选择：如果说，消息队列并不是你将要构建系统的主角之一，你对消息队列功能和性能都没有很高的要求，只需要一个开箱即用易于维护的产品
        2。RocketMQ：
            来源：阿里巴巴，捐赠给Apache，成为 Apache 的顶级项目
            特点：不错的性能，稳定性和可靠性
            语言：java语言开发
            优势
                1。贡献者大多数都是中国人，源代码相对也比较容易读懂，你很容易对 RocketMQ 进行扩展或者二次开发
                2。在线业务的响应时延做了很多的优化，大多数情况下可以做到毫秒级的响应
                    如：如果你的应用场景很在意响应时延，那应该选择使用 RocketMQ。
                3。RocketMQ 的性能比 RabbitMQ 要高一个数量级，每秒钟大概能处理几十万条消息
            缺点：国产的消息队列，相比国外的比较流行的同类产品，在国际上还没有那么流行，与周边生态系统的集成和兼容程度要略逊一筹
            选择：如果你的系统使用消息队列主要场景是处理在线业务，比如在交易系统中用消息队列传递订单，低延迟和金融级的稳定性是你需要的
        3。Kafka：
            目的：是用于处理海量的日志
            语言： Scala 和 Java 语言开发
            设计：大量使用了批量和异步的思想，这种设计使得 Kafka 能做到超高的性能
            性能：
                尤其是异步收发的性能，是三者中最好的，但与 RocketMQ 并没有量级上的差异，大约每秒钟可以处理几十万条消息。
            缺点：
                Kafka 不太适合在线业务场景。
                    说明：它的同步收发消息的响应时延比较高，因为当客户端发送一条消息的时候，Kafka 并不会立即发送出去，而是要等一会儿攒一批再发送，
                            在它的 Broker 中，很多地方都会使用这种“先攒一波再一起处理”的设计。当你的业务场景中，
                        每秒钟消息数量没有那么多的时候，Kafka 的时延反而会比较高
            选择：如果你需要处理海量的消息，像收集日志、监控信息或是前端的埋点这类数据，或是你的应用场景大量使用了大数据、流计算相关的开源产品
    第二梯队的消息队列
    ActiveMQ和ZeroMQ

03 | 消息模型：主题和队列有什么区别？
    主题和队列有什么区别？
        生产者就是发布者，消费者就是订阅者，队列就是主题，并没有本质的区别。它们最大的区别其实就是，
        一份消息数据能不能被消费多次的问题。
    队列：
        含义：先进先出（FIFO, First-In-First-Out）的线性表（Linear List）。在具体应用中通常用链表或者数组来实现。队列只允许在后端（称为 rear）进行插入操作，在前端（称为 front）进行删除操作。
            关键点：
                1。先进先出，在消息入队出队过程中，需要保证这些消息严格有序，按照什么顺序写进队列，必须按照同样的顺序从队列中读出来
                2。队列是没有“读”这个操作的，“读”就是出队，也就是从队列中“删除”这条消息。
        早期队列：消费者《==队列《===生产者
            消息顺序：生产者消费的自然顺序，
            消息接受：任何一条消息只能被其中一个消费者接受（多个消费者）
            消息集合：多个生产者往同一个队列里面发送消息
            缺点：
                1。一份消息数据能被消费多次的
            解决方案：建立多个队列，每个消费创建一个队列
                例子：对于一份订单数据，风控系统、分析系统、支付系统等都需要接收消息。这个时候，单个队列就满足不了需求，一个可行的解决方式是，为每个消费者创建一个单独的队列，让生产者发送多份。

    发布 - 订阅模型（Publish-Subscribe Pattern）
       概念：
        发布者：消息的发送方
        订阅者：消息的接收方称
        主题：服务端存放消息的容器
        订阅：这里既是一个动作，同时还可以认为是主题在消费时的一个逻辑副本，每份订阅中，订阅者都可以接收到主题的所有消息
        过程：发布者将消息发送到主题中，订阅者在接收消息之前需要先“订阅主题”
        优点：一份消息数据能被消费多次的
    现代的消息队列产品使用的消息模型大多是这种发布 - 订阅模型

    RabbitMQ 的消息模型
        组成：
            生产者：发送消息给Exchange
            Exchange：位于生产者和队列之间
            队列：由 Exchange 上配置的策略来决定将消息投递到哪些队列中
            消费者：接受来自队列的消息
        一份消息数据能不能被消费多次：
            解决方案：
                需要配置 Exchange 将消息发送到多个队列，每个队列中都存放一份完整的消息数据，可以为一个消费者提供消费服
    RocketMQ 的消息模型
        注意点：RocketMQ 只在队列上保证消息的有序性，主题层面是无法保证消息的严格顺序的。
        发布者：生产者先将消息发送给服务端，也就是 Broker，服务端在收到消息并将消息写入主题或者队列中后
        主题：每个主题包含多个队列，通过多个队列来实现多实例并行生产和消费
        订阅者：通过消费组（Consumer Group）来体现的
                概念：每个消费组都消费主题中一份完整的消息，不同消费组之间消费进度彼此不受影响，
                例子：一条消息被 Consumer Group1 消费过，也会再给 Consumer Group2 消费。
                消费者：消费组中包含多个消费者，同一个组内的消费者是竞争消费的关系，每个消费者负责消费组内的一部分消息。
                        例子：如果一条消息被消费者 Consumer1 消费了，那同组的其他消费者就不会再收到这条消息。
        不引入队列的问题：
            请求 - 确认：确保消息不会在传递过程中由于网络或服务器故障丢失。具体的做法也非常简单 
                实现原理：在生产端，生产者先将消息发送给服务端，也就是 Broker，服务端在收到消息并将消息写入主题或者队列中后，会给生产者发送确认的响应。
                        如果生产者没有收到服务端的确认或者收到失败的响应，则会重新发送消息；在消费端，消费者在收到消息并完成自己的消费业务逻辑（比如，将数据保存到数据库中）后，
                        也会给服务端发送消费成功的确认，服务端只有收到消费确认后，才认为一条消息被成功消费，否则它会给消费者重新发送这条消息，直到收到对应的消费成功确认。
                问题：确保消息的有序性，在某一条消息被成功消费之前，下一条消息是不能被消费的，否则就会出现消息空洞，违背了有序性这个原则。
                结果：每个主题在任意时刻，至多只能有一个消费者实例在进行消费，那就没法通过水平扩展消费者的数量来提升消费端总体的消费性能

        队列：解决每个主题在任意时刻，至多只能有一个消费者实例在进行消费（增加了队列）
        消费过程：
            现象：在 Topic 的消费过程中，由于消息需要被不同的组进行多次消费，所以消费完的消息并不会立即被删除；
                 解决办法：RocketMQ 为每个消费组在每个队列上维护一个消费位置
                        作用：这个位置之前的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一
    Kafka 的消息模型
        参考RocketMQ
        区别：在 Kafka 中，队列这个概念的名称不一样，Kafka 中对应的名称是“分区（Partition）”，含义和功能是没有任何区别的。

04 | 如何利用事务消息实现分布式事务？
    消息队列中的“事务”
        概念：主要解决的是消息生产者和消息消费者的数据一致性问题。
    数据库事务：
        事务：要么都成功，要么都失败
            原子性：是指一个事务操作不可分割，要么成功，要么失败，不能有一半成功一半失败的情况。
            一致性：是指这些数据在事务执行完成这个时间点之前，读到的一定是更新前的数据，之后读到的一定是更新后的数据，不应该存在一个时刻，让用户读到更新过程中的数据。
            隔离性：是指一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对正在进行的其他事务是隔离的，并发执行的各个事务之间不能互相干扰
            例子：有点儿像我们打网游中的副本，我们在副本中打的怪和掉的装备，与其他副本没有任何关联也不会互相影响
            持久性：是指一个事务一旦完成提交，后续的其他操作和故障都不会对事务的结果产生任何影响。
    分布式事务：
        元素：
            1。可用性
            2。不严重牺牲性能
            3。数据的一致性
        综合：
            1。顺序一致性
            2。最终一致性
    实现方案：
        1。2PC（Two-phase Commit，也叫二阶段提交）
        2。TCC(Try-Confirm-Cancel)
        3。事务消息
    消息队列是如何实现分布式事务的？
        分布式事务：Kafka 和 RocketMQ 都提供了事务相关功能。

    案例：电商系统
        订单系统来说，它创建订单的过程中实际上执行了 2 个步骤的操作
            1。在订单库中插入一条订单数据，创建订单；
            2。发消息给消息队列，消息的内容就是刚刚创建的订单。
        理想流程：
            1购物车系统订阅相应的主题
            2接收订单创建的消息
            3然后清理购物车
            4在购物车中删除订单中的商品
        任何一步失败的带来的后果：
            1。创建了订单，没有清理购物车；
            2。订单没创建成功，购物车里面的商品却被清掉了。
                解决思路：
                        1。对于消费者，接受消息失败；
                            解决方法：失败的处理比较简单，只要成功执行购物车清理后再提交消费确认即可，如果失败，由于没有提交消费确认，消息队列会自动重试。
                        2问题关键点是订单系统，（生产者）
                            创建订单和发送消息这两个步骤要么都操作成功，要么都操作失败，
                            不允许一个成功而另一个失败的情况出现。订单系统，
                实现：
                    1。订单系统在消息队列上开启一个事务
                    2。订单系统给消息服务器发送一个“半消息”
                        半消息：
                            含义：不是说消息内容不完整，它包含的内容就是完整的消息内容
                            与普通消息的区别：在事务提交之前，对于消费者来说，这个消息是不可见的。
                    3。半消息发送成功后，订单系统就可以执行本地事务了，在订单库中创建一条订单记录，并提交订单库的数据库事务
                    4。根据本地事务的执行结果决定提交或者回滚事务消息
                        1。提交：订单创建成功，那就提交事务消息，购物车系统就可以消费到这条消息继续后续的流程
                        2。回滚：订单创建失败，那就回滚事务消息，购物车系统就不会收到这条消息。
                    问题：第四步提交事务消息时失败了怎么办
                        Kafka：直接抛出异常，让用户自行处理
                            优化：我们可以在业务代码中反复重试提交，直到提交成功，或者删除之前创建的订单进行补偿
                        RocketMQ：
                            解决方案：增加了事务反查的机制来解决事务消息提交失败的问题
                                解释：如果 Producer 也就是订单系统，在提交或者回滚事务消息时发生网络异常，RocketMQ 的 Broker 没有收到提交或者回滚的请求，Broker 会定期去 Producer \
                                    上反查这个事务对应的本地事务的状态，然后根据反查结果决定提交或者回滚这个事务。
                                支撑：需要实现一个反查本地事务状态的接口，告知 RocketMQ 本地事务是成功还是失败。
                                    反查本地事务的实现：
                                            不依赖发送方，并不依赖消息的发送方，也就是订单服务的某个实例节点上的任何数据。这种情况下，
                                            即使是发送事务消息的那个订单服务节点宕机了，
                                            RocketMQ 依然可以通过其他订单服务的节点来执行反查，确保事务的完整性。
                                思路：
                                    要根据消息中的订单 ID，在订单库中查询这个订单是否存在即可，如果订单存在则返回成功，否则返回失败。
                                    RocketMQ 会自动根据事务反查的结果提交或者回滚事务消息。

05 | 如何确保消息不会丢失?
    检测消息丢失的方法
        1。分布式链路追踪系统，类似的追踪系统可以很方便地追踪每一条消息
        2。利用消息队列的有序性来验证是否有消息丢失
            原理：
                在 Producer 端，我们给每个发出的消息附加一个连续递增的序号，然后在 Consumer 端来检查这个序号的连续性。
                    没有消息丢失：Consumer 收到消息的序号必然是连续递增的，或者说收到的消息，其中的序号必然是上一条消息的序号 +1
                    消息丢失：检测到序号不连续，那就是丢消息了，还可以通过缺失的序号来确定丢失的是哪条消息，方便进一步排查原因。
                具体实现：
                    1。客户端利用拦截机制
                    2。利用这个拦截器机制，在 Producer 发送消息之前的拦截器中将序号注入到消息中
                    3。在 Consumer 收到消息的拦截器中检测序号的连续性
                    优点：消息检测的代码不会侵入到你的业务代码中，待你的系统稳定后，也方便将这部分检测的逻辑关闭或者删除。
                注意：
                    1。Kafka 和 RocketMQ：不保证在 Topic 上的严格顺序，只能保证分区上的消息是有序的，所以我们在发消息的时候必须要指定分区，并且，在每个分区单独检测消息序号的连续性。
                    2。Producer 是多实例：协调多个producer之间的发送顺序，所以也需要每个 Producer 分别生成各自的消息序号，并且需要附加上 Producer 的标识，在 Consumer 端按照每个 Producer 分别来检测序号的连续性。
                    3。Consumer 实例的数量最好和分区数量一致，做到 Consumer 和分区一一对应，这样会比较方便地在 Consumer 内检测消息序号的连续性

    确保消息可靠传递
        生产阶段：在这个阶段，从消息在 Producer 创建出来，经过网络传输发送到 Broker 端。
            请求确认机制：
                实现：
                    1。当你的代码调用发消息方法时，消息队列的客户端会把消息发送到 Broker
                    2。Broker 收到消息后，会给客户端返回一个确认响应，表明消息已经收到了
                    3。客户端收到响应后，完成了一次正常消息的发送
                异步发送：需要在回调方法里进行检查
                        注意：多丢消息的原因就是，我们使用了异步发送，却没有在回调中检查发送结果。
                        producer.send(record, (metadata, exception) -> {
                            if (metadata != null) {
                                System.out.println(" 消息发送成功。");
                            } else {
                                System.out.println(" 消息发送失败！");
                                System.out.println(exception);
                            }
                        });
                自动重试：有些消息队列在长时间没收到发送确认响应后，会自动重试，如果重试再失败，就会以返回值或者异常的方式告知用户。
                异常情况：编写发送消息代码时，需要注意，正确处理返回值或者捕获异常，保证消息不会丢失
                同步发送：
                    try {
                        RecordMetadata metadata = producer.send(record).get();
                        System.out.println(" 消息发送成功。");
                    } catch (Throwable e) {
                        System.out.println(" 消息发送失败！");
                        System.out.println(e);
                    }

        存储阶段：在这个阶段，消息在 Broker 端存储，如果是集群，消息会在这个阶段被复制到其他的副本上。
            Broker 正常：不会出现丢失消息的问题
            Broker故障：进程死掉了或者服务器宕机了，还是可能会丢失消息
                解决方案：
                    单个Broker节点：
                        1。需要配置 Broker 参数，在收到消息后，将消息写入磁盘后再给 Producer 返回确认响应，这样即使发生宕机，
                            由于消息已经被写入磁盘，就不会丢失消息，恢复后还可以继续消费
                        例子：在 RocketMQ 中，需要将刷盘方式 flushDiskType 配置为 SYNC_FLUSH 同步刷盘。
                    多个Broker节点组成的集群：
                        1。需要将 Broker 集群配置成：至少将消息发送到 2 个以上的节点，再给客户端回复发送确认响应
                           优势：这样当某个 Broker 宕机时，其他的 Broker 可以替代宕机的 Broker，也不会发生消息丢失
        消费阶段：在这个阶段，Consumer 从 Broker 上拉取消息，经过网络传输发送到 Consumer 上。
            请求确认机制
                1。客户端从 Broker 拉取消息后，执行用户的消费业务逻辑
                2。才会给 Broker 发送消费确认响应
                3。如果 Broker 没有收到消费确认响应，下次拉消息的时候还会返回同一条消息
                    目的：确保消息不会在网络传输过程中丢失，也不会因为客户端在执行消费逻辑中出错导致丢失。
                注意点：
                    不要在收到消息后就立即发送消费确认，而是应该在执行完所有消费业务逻辑之后，再发送消费确认。
                实现案例代码：
                    Python 语言消费 RabbitMQ
                        def callback(ch, method, properties, body):
                            print(" [x] 收到消息 %r" % body)
                            # 在这儿处理收到的消息
                            database.save(body)
                            print(" [x] 消费完成 ")
                            # 完成消费业务逻辑后发送消费确认响应
                            ch.basic_ack(delivery_tag = method.delivery_tag)

                        channel.basic_consume(queue='hello', on_message_callback=callback)

                问题：
                    Broker和Consumer 都是有可能收到重复消息的
                        原因：
                            消息在网络传输过程中发送错误，由于发送方收不到确认，会通过重发来保证消息不丢失。
                            但是，如果确认响应在网络传输时丢失，也会导致重发消息。

06 | 如何处理消费过程中的重复消息？
    消息重复的情况必然存在
        MQTT 协议服务质量标准
            1。At most once：至多一次。消息在传递时，最多会被送达一次。换一个说法就是，没什么消息可靠性保证，允许丢消息。
                            应用场景：比如每分钟上报一次机房温度数据，可以接受数据少量丢失
            2。At least once：至少一次。消息在传递时，至少会被送达一次。
                             解释：不允许丢消息，但是允许有少量重复消息出现。
            3。Exactly once：恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是最高的等级。
                业务逻辑具备幂等性：消费多次等于消费一次。
                At least once + 幂等消费 = Exactly once。
    用幂等性解决重复消息问题
        幂等：
            概念：如果一个函数 f(x) 满足：f(f(x)) = f(x)，则函数 f(x) 满足幂等性
            特点：其任意多次执行所产生的影响均与一次执行的影响相同
            例子：
                1。不考虑并发情况：将账户 X 的余额设置为 100 元”，执行一次后对系统的影响是，账户 X 的余额变成了 100 元。只要提供的参数 100 元不变，那即使再执行多少次，账户 X 的余额始终都是 100 元，不会变化，这个操作就是一个幂等的操作
                2。将账户 X 的余额加 100 元”，这个操作它就不是幂等的，每执行一次，账户余额就会增加 100 元，执行多次和执行一次对系统的影响（也就是账户的余额）是不一样的
            思路：
                1从业务逻辑设计上入手，将消费的业务逻辑设计成具备幂等性的操作
                2。不是所有的业务都能设计成天然幂等的，这里就需要一些方法和技巧来实现幂等。
            方法：
        1. 利用数据库的唯一约束实现幂等
            案例：将账户 X 的余额加 100 元，可以通过改造业务逻辑，让它具备幂等性
                解决步骤
                    1。限定每个转账单每个账户只可以执行一次变更操作
                    2。在数据库中建一张转账流水表，这个表有三个字段：转账单 ID、账户 ID 和变更金额
                    3。给转账单 ID 和账户 ID 这两个字段联合起来创建一个唯一约束
                流程：
                    1。在转账流水表中增加一条转账记录
                    2。再根据转账记录，异步操作更新用户余额即可
                分析：
                    1。由于：“账户 ID 转账单 ID”的唯一约束，对于同一个转账单同一个账户只能插入一条记录，后续重复的插入操作都会失败
                    2。我们只要写一个 SQL，正确地实现它就可以了。
                做法：
                    1。INSERT IF NOT EXIST
                    2。Redis 的 SETNX 命令来替代数据库中的唯一约束，来实现幂等消费。
        2. 为更新的数据设置前置条件
            前置条件：
                满足：更新数据，同时变更前置条件中需要判断的数据
                不满足：拒绝更新数据
                分析：由于第一次更新数据的时候已经变更了前置条件中需要判断的数据，不满足前置条件，则不会重复执行更新数据操作。
                案例：
                    “将账户 X 的余额增加 100 元”这个操作并不满足幂等性 
                    解决：我们可以把这个操作加上一个前置条件，变为：“如果账户 X 当前的余额为 500 元，将余额加 100 元”
                执行流程：
                    1。发消息时在消息体中带上当前的余额
                    2。消费的时候进行判断数据库中，当前余额是否与消息中的余额相等
                    3。只有相等才执行变更操作。

                另外解决办法：给你的数据增加一个版本号属
                    流程：
                    1。每次更数据前，比较当前数据的版本号是否和消息中的版本号一致
                    2。如果不一致就拒绝更新数据
                    3。更新数据的同时将版本号 +1，一样可以实现幂等更新

        3. 记录并检查操作
            Token 机制或者 GUID（全局唯一 ID）机制：
                思路：在执行数据更新操作之前，先检查一下是否执行过这个更新操作。
                实现：
                    1。发送消息时，给每条消息指定一个全局唯一的 ID
                    2。消费时，先根据这个 ID 检查这条消息是否有被消费过
                    3。如果没有消费过，才更新数据
                    4。将消费状态置为已消费
                困难点：
                    原子性：检查消费状态，然后更新数据并且设置消费状态，
                    案例：
                        全局 ID 为 8，操作为：给 ID 为 666 账户增加 100 元
                        情况：
                            1。t0 时刻：Consumer A 收到条消息，检查消息执行状态，发现消息未处理过，开始执行“账户增加 100 元”；
                            2。t1 时刻：Consumer B 收到条消息，检查消息执行状态，发现消息未处理过，因为这个时刻，Consumer A 还未来得及更新消息执行状态。
                        结果：账户被错误地增加了两次 100 元，分布式系统中非常容易犯的错误
                        引申：我们可以用事务来实现，也可以用锁来实现，但是在分布式系统中，无论是分布式事务还是分布式锁都是比较难解决问题。

07 | 消息积压了该如何处理？
    消息积压：
        原因：一定是系统中的某个部分出现了性能问题，来不及处理上游发送的消息，才导致的
        分析
            1。避免出现消息积压：如何来优化代码的性能
        优化代码的性能：
            1。发送端性能优化
                1。如果说，你的代码发送消息的性能上不去，你需要优先检查一下，是不是发消息之前的业务逻辑耗时太多导致的。
                2。设置合适的并发和批量大小
                        过程：Producer 发消息给 Broker，Broker 收到消息后返回确认响应，这是一次完整的交互
                            一次交互耗时1ms：
                                1。发送端准备数据、序列化消息、构造请求等逻辑的时间，也就是发送端在发送网络请求之前的耗时；
                                2。发送消息和返回响应在网络传输中的耗时；
                                3。Broker 处理消息的时延。
                            分析
                                单线程：每次只发送 1 条消息，那么每秒只能发送 1000ms / 1ms * 1 条 /ms = 1000 条 消息，这种情况下并不能发挥出消息队列的全部实力。
                            性能：
                                1。无论是增加每次发送消息的批量大小，还是增加并发，都能成倍地提升发送性能
                        选择：
                            1。选择批量发送还是增加并发，主要取决于发送端程序的业务性质
                            2。只要能够满足你的性能要求，怎么实现方便就怎么实现。
                        案例
                            案例一：选择并行发
                                发送端是一个微服务，主要接受 RPC 请求处理在线业务，很自然的，微服务在处理每次请求的时候，
                                就在当前线程直接发送消息就可以了，因为所有 RPC 框架都是多线程支持多并发的，自然也就实现了并行发送消息。
                                在线业务比较在意的是请求响应时延，选择批量发送必然会影响 RPC 服务的时延，
                                ，比较明智的方式就是通过并发来提升发送性能。
                            案例二：选择批量发
                                离线分析系统，它不关心时延，更注重整个系统的吞吐量。发送端的数据都是来自于数据库，这种情况就更适合批量发送，
                                你可以批量从数据库读取数据，然后批量来发送消息，同样用少量的并发就可以获得非常高的吞吐量。

            2。消费端性能优化
                1。消费速度<生产速度:时间长了，整个系统就会出现问题
                        1。消息队列的存储被填满无法提供服务
                        2。要么消息丢失，这对于整个系统来说都是严重故障
                2。消费速度<生产速度：暂时的，只要消费端的性能恢复之后，超过发送端的性能，那积压的消息是可以逐渐被消化掉的。
                3。消费速度>生产速度:系统才能健康的持续运行
                优化方案
                1。优化消费业务逻辑
                   消费代码难优化的情况：
                        方法：（不可取）
                            消费端：
                            1。收到消息的 OnMessage 方法中，不处理任何业务逻辑，把这个消息放到一个内存队列里面就返回了。
                            2。启动很多的业务线程，这些业务线程里面是真正处理消息的业务逻辑，这些线程从内存队列里取消息处理，这样它就解决了单个 Consumer 不能并行消费的问。
                        优点：就解决了单个 Consumer 不能并行消费的问题。
                        问题：因为会丢消息。如果收消息的节点发生宕机，在内存队列中还没来及处理的这些消息就会丢失。

                2。通过水平扩容，增加消费端的并发数，提升性能
                    注意：
                        1。在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区（也叫队列）数量，确保 Consumer 的实例数和分区数量是相等的。
                        2。如果 Consumer 的实例数量超过分区数量，这样的扩容实际上是没有效果的
                            原因：对于消费者来说，在每个分区上实际上只能支持单线程消费。
                3。不用关注消息队列方面：
                    1。消息队列本身的处理能力要远大于业务系统的处理能力
                    2。主流消息队列的单个节点，消息收发的性能可以达到每秒钟处理几万至几十万条消息的水平
                    3。可以通过水平扩展 Broker 的实例数成倍地提升处理能力
                        2。出现了消息积压：该如何进行紧急处理，最大程度地避免消息积压对业务的影响。
    消息积压了该如何处理？
        导致突然积压的原因
            1。发送变快了
                比如：说是赶上大促或者抢购
                难度：短时间内不太可能优化消费端的代码来提升消费性能，
                方法：通过扩容消费端的实例数来提升总体的消费能力。
                    没有服务器资源：
                        方法：没办法的办法是，将系统降级，通过关闭一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。
            2。消费变慢了
                思路：
                    1。检查你的消费实例，分析一下是什么原因导致消费变慢
                落实：
                    1。检查一下日志是否有大量的消费错误
                    2。如果没有错误的话，可以通过打印堆栈信息
                    3。看一下你的消费线程是不是卡在什么地方不动了
                            比如：触发了死锁或者卡在等待某些资源上了。
            3。特殊情况：发送消息的速度还是消费消息的速度和原来都没什么变化
                思路：检查一下你的消费端，是不是消费失败导致的一条消息反复消费这种情况比较多，这种情况也会拖慢整个系统的消费速度。
        发现：通过消息队列内置了监控的功能，监控数据，很容易确定是哪种原因

08 | 答疑解惑（一） : 网关如何接收服务端的秒杀结果？
    1。网关如何接收服务端的秒杀结果？
        问题：
            网关在发送消息之后，是如何来接收后端服务的秒杀结果，又如何来给APP 返回响应的呢？
        方案：
            profit.jikeshijian.xiaoxiduilie.RequestHandler08
        问题点一：
            如何收到后端服务的请求
            答案
                1。网关在收到 APP 的秒杀请求后，直接给消息队列发消息
                    1。至于消息的内容，并不一定是 APP 请求的 Request，只要包含足够的字段就行了
                    2。比如用户 ID、设备 ID、请求时间等等
                    3。还需要包含这个请求的 ID 和网关的 ID
                2。如果发送消息失败，可以直接给 APP 返回秒杀失败结果
                3。成功发送消息之后，线程就阻塞等待秒杀结果。
                    注意：
                        这里面不可能无限等待下去，需要设定一个等待的超时时间。
                4。等待结束之后，去存放秒杀结果的 Map 中查询是否有返回的秒杀结果
                    1。如果有就构建 Response，给 APP 返回秒杀结果，
                    2。如果没有，按秒杀失败处理。
        问题点二：
            网关如何来接收从后端秒杀服务返回的秒杀结果。
            答案：
                1。我们可以选择用 RPC 的方式来返回秒杀结果，这里网关节点是 RPC 服务端，后端服务为客户端
                2。之前网关发出去的消息中包含了网关的 ID，后端服务可以通过这个网关 ID 来找到对应的网关实例
                3。秒杀结果中需要包含请求 ID，这个请求 ID 也是从消息中获取的。
                4。网关收到后端服务的秒杀结果之后，用请求 ID 为 Key，把这个结果保存到秒杀结果的 Map 中，
                5。然后通知对应的处理 APP 请求的线程，结束等待
            原因：
                1。处理 APP 请求的线程，在结束等待之后，会去秒杀的结果 Map 中查询这个结果
                2。然后再给 APP 返回响应。
    2。详解 RocketMQ 和 Kafka 的消息模型
        案例：
            1。假设有一个主题 MyTopic，我们为主题创建 5 个队列，分布到 2 个 Broker 中。
            2。生产这一端，假设我们有 3 个生产者实例：Produer0，Produer1 和 Producer2。
        问题点一：生产端
            这 3 个生产者是如何对应到 2 个 Broker 的，又是如何对应到 5 个队列的呢？
            答案：
                不用对应，随便发
                解释：
                    每个生产者可以在 5 个队列中轮询发送，也可以随机选一个队列发送，或者只往某个队列发送，这些都可以
                例子：
                    比如 Producer0 要发 5 条消息，可以都发到队列 Q0 里面，也可以 5 个队列每个队列发一条。
        问题点二：消费端
            消费组、消费者和队列这几个概念的对应关系。
            每个消费组和队列：
                1。每个消费组就是一份订阅，它要消费主题 MyTopic 下，所有队列的全部消息
                2。队列里的消息并不是消费掉就没有了
                注意：
                    这里的“消费”，只是去队列里面读了消息，并没有删除，消费完这条消息还是在队列里面。
            多个消费组之间：
                在消费同一个主题时，消费组之间是互不影响的。
                例子：
                    1。比如我们有 2 个消费组：G0 和 G1。
                    2。G0 消费了哪些消息，G1 是不知道的，也不用知道
                    3。G0 消费过的消息，G1 还可以消费。
                    4。即使 G0 积压了很多消息，对 G1 来说也没有任何影响。
        问题点三：消费组的内部
            一个消费组中可以包含多个消费者的实例
            例子：
                1。比如说消费组 G1，包含了 2 个消费者 C0 和 C1
            问题：
                那这 2 个消费者又是怎么和主题 MyTopic 的 5 个队列对应的呢？
                答案：
                    1。由于消费确认机制的限制，这里面有一个原则是，在同一个消费组里面，每个队列只能被一个消费者实例占用。
                        注意：
                            至于如何分配，这里面有很多策略，我就不展开说了
                    2。总之保证每个队列分配一个消费者就行了
                例子：
                    1。我们可以让消费者 C0 消费 Q0，Q1 和 Q2，C1 消费 Q3 和 Q4
                    2。如果 C0 宕机了，会触发重新分配，这时候 C1 同时消费全部 5 个队列。
        问题点四：消费位置
            1。每个消费组内部维护自己的一组消费位置，每个队列对应一个消费位置
            2。消费位置在服务端保存，并且，消费位置和消费者是没有关系的
            3。每个消费位置一般就是一个整数，记录这个消费组中，这个队列消费到哪个位置了
            4。这个位置之前的消息都成功消费了，之后的消息都没有消费或者正在消费。

        注意：
            队列占用只是针对消费组内部来说的，对于其他的消费组来说是没有影响的
            例子：
                1。比如队列 Q2 被消费组 G1 的消费者 C1 占用了
                2。对于消费组 G2 来说，是完全没有影响的，G2 也可以分配它的消费者来占用和消费队列 Q2。

    3。如何实现单个队列的并行消费？
        问题：
            如果不要求严格顺序，如何实现单个队列的并行消费？
        答案：
            有很多的实现方式，在 JMQ（京东自研的消息队列产品）中，它实现的思路是这样的。
        例子：
        理想情况
            1。比如说，队列中当前有 10 条消息，对应的编号是 0-9，当前的消费位置是 5
            2。同时来了三个消费者来拉消息，把编号为 5、6、7 的消息分别给三个消费者，每人一条
            3。过了一段时间，三个消费成功的响应都回来了，这时候就可以把消费位置更新为 8 了，这样就实现并行消费。
        不理想情况：
            还有可能编号为 6、7 的消息响应回来了，编号 5 的消息响应一直回不来
            问题：
                怎么办？
                分析：
                    1。这个位置 5 就是一个消息空洞。
                方法
                    1。为了避免位置 5 把这个队列卡住，可以先把消费位置 5 这条消息，复制到一个特殊重试队列中
                    2。然后依然把消费位置更新为 8，继续消费
                    3。再有消费者来拉消息的时候，优先把重试队列中的那条消息给消费者就可以了。
                缺点：
                    并行消费开销还是很大的，不应该作为一个常规的，提升消费并发的手段
                    优化方法：
                        如果消费慢需要增加消费者的并发数，还是需要扩容队列数。
    4。如何保证消息的严格顺序？
        背景：
            主题层面是无法保证严格顺序的，只有在队列上才能保证消息的严格顺序。
        情形一：
            如果说，你的业务必须要求全局严格顺序
            方法：
                就只能把消息队列数配置成 1，生产者和消费者也只能是一个实例，这样才能保证全局严格顺序。
        情形二：
            大部分情况下，我们并不需要全局严格顺序，只要保证局部有序就可以满足要求了
            例子：
                1。在传递账户流水记录的时候，只要保证每个账户的流水有序就可以了
                2。不同账户之间的流水记录是不需要保证顺序的。
        局部保证有序的方法：
            1。在发送端，我们使用账户 ID 作为 Key，采用一致性哈希算法计算出队列编号，指定队列来发送消息
            2。一致性哈希算法可以保证，相同 Key 的消息总是发送到同一个队列上，这样可以保证相同 Key 的消息是严格有序的
            3。如果不考虑队列扩容，也可以用队列数量取模的简单方法来计算队列编号。


09 | 学习开源代码该如何入手？
    背景：
        1。对于很多开源软件来说，如果我们把它作为我们业务系统的重要组成部分之一，真正地用于生产，仅仅知道如何使用是远远不够的
        2。必须掌握它的实现原理和很多细节，这样才能找到最佳的使用姿势
        3。当你的系统出现问题时，你才有可能基于它的实现原理，再根据一些现象来排查问题原因。
    1。通过文档来了解开源项目
        问题点一：
            学习源代码应该从哪儿入手呢？
        答案：
            最佳的方式就是先看它的文档。
            优点：
                1。通过看文档，你可以快速地掌握这个软件整体的结构，它有哪些功能特性
                2。它涉及到的关键技术、实现原理和它的生态系统等等
            作用：
                1。在掌握了这些之后，你对它有个整体的了解，然后再去看它的源代码
                2。就不会再有那种盲人摸象找不到头绪的感觉了。
            注意：
                必须去看这些开源软件官方网站上的文档，尽量不要去网上搜一些翻译的中文文档。为什么呢？
                原因：
                    1。这些开源软件，特别是一些社区活跃的软件，它的迭代是很快的，即使是自带官方中文翻译的项目
                    2。它的中文文档很多都会落后于英文版，你能看到的中文版本很多时候都已经过时了
                    3。那非官方的翻译，问题可能就不止是过时的问题了，可能还会出现一些错漏的地方。
        问题点二：
            如果说你的英文阅读水平确实有限，直接阅读英文文档有困难或者看得非常慢，怎么办？
            方法：
                1。去看它的英文官网，即使阅读大段的技术文章有困难，网站的标题你总能看懂吧？
                2。找到你需要阅读的文章后，你可以在网上搜一下对应的中文版本，先看一遍中文版
                3。然后再对着英文原版过一遍，弥补中文版可能过时或翻译不准确的问题。
        案例：以Kafka 的官网为例子
            1。如果说你对这个项目完全不了解，没用过这个软件
                做法：
                    1。首先需要看的文档是Quick Start，按照 Quick Start 中的指导快速把它的环境搭起来
                    2。把它运行起来，这样你会对这个项目有个感性认识，也便于你在后续深入学习的时候“跑”一些例子。
            2。然后你需要找一下它的Introduction，一般里面会有项目的基本介绍
                注意：
                    1。需要找到这个项目用到的一些基本概念或者名词的介绍文档
                        例子：
                            1。在 Kafka 的文档中，这些内容就在 Introduction 里面
                            2。比如 Topic、Producer、 Consumer、Partition 这些概念在 Kafka 中代表的含义。
                    2。有些开源项目会单独有一个 Basic Concepts 文档来讲这些基础概念，这个文档非常重要
                        原因：
                            1。这些开源社区的开发者都有个很不好的爱好：发明概念
                            2。很多开源项目都会自己创造一些名词或者概念，了解这些基本概念才有可能看懂它项目的其他文档。
            3。对项目有个基本的了解之后呢，接下来你可以看一下它的使用场景、功能特性以及相关的生态系统的介绍
                例子：
                    1。在 Kafka 中功能相关的内容在Use cases和EcoSystem两篇文章中
                    2。有些项目中会有类似名为 Features 的文档介绍功能和特性。
                扩展：
                    1。其中项目的生态系统，也就是 EcoSystem，一般会介绍它这个项目适用的一些典型的使用场景
                    2。在某个场景下适合与哪些其他的系统一起来配合使用等
                    3。如果说你的系统不是特别特殊或者说冷门的话，你大概率可以在 EcoSystem 里面找到和你类似的场景
                优点：
                    可以少走很多的弯路。
            4。读完上面这些文档之后，对这个项目的整体会有一个比较全面的了解了：
                1。这个项目是干什么的？
                2。能解决哪些问题？
                3。适合在哪些场景使用？
                4。有哪些功能？
                5。如何使用？

            5。对这些问题有一个初步的答案之后，接下来你就可以去深入学习它的实现原理了
                注意；
                   1。这是不是意味着，你可以立即去看它的源码呢？这样做或许可行，但并不是最好的方法。
                        问题：
                            大部分开源项目都是怎么诞生的吗？
                        答案：
                            1。某个大学或者大厂的科学家，某天脑海里突然出现了一个改变世界的想法
                            2。科学家们会基于这个想法做一些深入的研究，然后写了一篇论文在某个学术期刊或者会议上发表。
                            3。论文发表后在业内获得很多的赞，这时候就轮到像 Google、Facebook 这样的大厂出手了
                            4。这个论文很有价值，不如我们把它实现出来吧？一个开源项目就这样诞生了。
                    2。对于这样的开源项目，它背后的这篇论文就是整个项目的灵魂
                    3。你如果能把这篇论文看完并且理解透了，这个项目的实现原理也就清楚了。
                        例子：
                            1。对于 Kafka 来说，它的灵魂是这篇博文：The Log: What every software engineer should know about real-time data’s unifying abstraction，
                            2。对应的中文译稿在这里：《日志：每个软件工程师都应该知道的有关实时数据的统一抽象》。
    2。用以点带面的方式来阅读源码
        注意：
            在读源码的时候，千万不要上来就找 main 方法这样泛泛地去看，为什么？
            原因：
                1。一篇文章，它是一个线性结构，你从前往后读就行了
                2。一本书呢？
                    1。如果我们看目录的话，可以认为是个树状结构，但大多数的书的内容还是按照线性结构来组织的
                    2。你可以从前往后读，也可以通过目录跳着读。
        问题：
            那程序的源代码是什么结构？
            答案：
                那是一个网状结构，关系错综复杂
            缺点：
                1。这种结构是非常不适合人类去阅读的
                2。你如果是泛泛去读源代码，很容易迷失在这个代码织成的网里面
            问题：
                那怎么办？
                方法：
                    1。带着问题去读源码，最好是带着问题的答案去读源码
                    2。你每次读源码之前，确定一个具体的问题
                例子：
                    1。RocketMQ 的消息是怎么写到文件里的？
                    2。Kafka 的 Coordinator 是怎么维护消费位置的？
                分析：
                    类似这种非常细粒度的问题，粒度细到每个问题的答案就是一两个流程就可以回答，这样就可以了。
                    问题：
                        如果说你就想学习一下源代码，或者说提不出这些问题怎么办呢？
                    答案：
                        看文档
                        思路：
                            1。确定问题后，先不要着急看源代码，而是应该先找一下是否有对应的实现文档，
                            2。核心功能都会有专门的文档来说明它的实现原理
                                例子：
                                    比如在 Kafka 的文档中，DESIGN和IMPLEMENTATION两个章节中，介绍了 Kafka 很多功能的实现原理和细节
                            3。一些更细节的非核心的功能不一定有专门的文档来说明，但是我们可以去找一找是否有对应的 Improvement Proposal。
                                问题：
                                    这个 Improvement Proposal 是什么呢？
                                    答案：
                                        1。可以认为它是描述一个新功能的文档，一般开源项目需要增加一个新的功能或者特性的时候
                                        2。都会创建一个 Improvement Proposal，一般标题都是"xIP- 新功能名称"
                                        3。其中 IP 就是 Improvement Proposal 的缩写，x 一般就是这个开源项目的名称的首字
                                    例子：
                                        比如 Kafka 中 Improvement Proposal 的标题就都是以 KIP 来开头。
                                    注意：
                                        1。每个 Improvement Proposal 都是有固定格式的，一般要说明为什么需要增加这个功能
                                        2。会对系统产生那些影响和改变，还有我们最关心的设计和实现原理的简述。
        总结：
            1。读完讲解实现的文档再去看源代码，也就是我刚刚说的，不只是带着问题去读，而是带着答案去读源码
                优点：
                    1。这样你在读源码的时候，不仅仅是更容易理解源代码，
                    2。还可以把更多的精力放在一些实现细节上，这样阅读源码的效果会更好。
            2。使用这种以问题为阅读单元的方式来读源代码
                优点：
                    你每次只要花很短的时间，阅读很少的一部分源码，就能解决一个问题，得到一些收获
                概念：
                    1。这种方式其实是通过一个一个的问题，在网状的源代码中，每次去读几个点组成的那一两条线
                    2。随着你通过阅读源码了解的问题越来越多，你对项目源码的理解也会越来越全面和深入。

10 | 如何使用异步设计提升系统性能？
    异步模式设计的程序：
        优点：
            显著减少线程等待，从而在高吞吐量的场景中，极大提升系统的整体性能，显著降低时延。
        例子：
            1。消息队列这种需要超高吞吐量和超低时延的中间件系统
            2。在其核心流程中，一定会大量采用异步的设计思想。
    案例：
        1。假设我们要实现一个转账的微服务 Transfer( accountFrom, accountTo, amount)
        2。这个服务有三个参数：分别是转出账户、转入账户和转账金额。
    问题：
        我们要从账户 A 中转账 100 元到账户 B 中：
        方法一：
            1。先从 A 的账户中减去 100 元；
            2。再给 B 的账户加上 100 元，转账完成。
        分析：
            1。我们调用了另外一个微服务 Add(account, amount)，它的功能是给账户 account 增加金额 amount
            2。当 amount 为负值的时候，就是扣减响应的金额。
    1。同步实现的性能瓶颈
        伪代码：
            Transfer(accountFrom, accountTo, amount) {
                // 先从 accountFrom 的账户中减去相应的钱数
                Add(accountFrom, -1 * amount)
                // 再把减去的钱数加到 accountTo 的账户中
                Add(accountTo, amount)
                return OK
            }
        过程：
            1。首先从 accountFrom 的账户中减去相应的钱数
            2。再把减去的钱数加到 accountTo 的账户中
            3。这种同步实现是一种很自然方式，简单直接。
        性能分析：
            1。假设微服务 Add 的平均响应时延是 50ms
            2。那么很容易计算出我们实现的微服务 Transfer 的平均响应时延大约等于执行 2 次 Add 的时延，也就是 100ms
        问题：
            那随着调用 Transfer 服务的请求越来越多，会出现什么情况呢？
            答案：
                1。每处理一个请求需要耗时 100ms，并在这 100ms 过程中是需要独占一个线程的
                2。每个线程每秒钟最多可以处理 10 个请求，
                3。每台计算机上的线程资源并不是无限的，假设我们使用的服务器同时打开的线程数量上限是 10,000
                4。可以计算出这台服务器每秒钟可以处理的请求上限是： 10,000 （个线程）* 10（次请求每秒） = 100,000 次每秒。
            现象：
                1。如果请求速度超过这个值，那么请求就不能被马上处理，只能阻塞或者排队，
                2。这时候 Transfer 服务的响应时延由 100ms 延长到了：排队的等待时延 + 处理时延 (100ms)。
                3。在大量请求的情况下，我们的微服务的平均响应时延变长了。
                问题：
                    这是不是已经到了这台服务器所能承受的极限了呢？
                分析：
                    1。其实远远没有，如果我们监测一下服务器的各项指标，会发现无论是 CPU、内存，还是网卡流量或者是磁盘的 IO 都空闲的很
                    2。那我们 Transfer 服务中的那 10,000 个线程在干什么呢？
                    3。对，绝大部分线程都在等待 Add 服务返回结果。
        缺点：
            采用同步实现的方式，整个服务器的所有线程大部分时间都没有在工作，而是都在等待。
        思路；
            减少或者避免这种无意义的等待，就可以大幅提升服务的吞吐能力，从而提升服务的总体性能。

    2。采用异步实现解决等待问题
        伪代码：
            TransferAsync(accountFrom, accountTo, amount, OnComplete()) {
                // 异步从 accountFrom 的账户中减去相应的钱数，然后调用 OnDebit 方法。
                AddAsync(accountFrom, -1 * amount, OnDebit(accountTo, amount, OnAllDone(OnComplete())))
                }
            // 扣减账户 accountFrom 完成后调用
            OnDebit(accountTo, amount, OnAllDone(OnComplete())) {
                //  再异步把减去的钱数加到 accountTo 的账户中，然后执行 OnAllDone 方法
                AddAsync(accountTo, amount, OnAllDone(OnComplete()))
            }
            // 转入账户 accountTo 完成后调用
            OnAllDone(OnComplete()) {
                OnComplete()
            }
        代码分析：
            1。TransferAsync 服务比 Transfer 多了一个参数，并且这个参数传入的是一个回调方法 OnComplete()
            2。这个 TransferAsync() 方法的语义是：请帮我执行转账操作，当转账完成后，请调用 OnComplete() 方法
            3。调用 TransferAsync 的线程不必等待转账完成就可以立即返回了
            4。待转账结束后，TransferService 自然会调用 OnComplete() 方法来执行转账后续的工作。
        相对于同步来说，我们先定义 2 个回调方法：
            1。OnDebit()：扣减账户 accountFrom 完成后调用的回调方法；
            2。OnAllDone()：转入账户 accountTo 完成后调用的回调方法。
        一步实现的语义：
            1。异步从 accountFrom 的账户中减去相应的钱数，然后调用 OnDebit 方法；
            2。在 OnDebit 方法中，异步把减去的钱数加到 accountTo 的账户中，然后执行 OnAllDone 方法；
            3。在 OnAllDone 方法中，调用 OnComplete 方法。
        与同步的区别：
            线程模型上由同步顺序调用改为了异步调用和回调的机制。
        性能分析：
            1。低请求数量的场景下，平均响应时延一样是 100ms。
            2。在超高请求数量场景下，异步的实现不再需要线程等待执行结果
            3。只需要个位数量的线程，即可实现同步场景大量线程一样的吞吐量。
        优点：
            1。由于没有了线程的数量的限制，总体吞吐量上限会大大超过同步实现
            2。并且在服务器 CPU、网络带宽资源达到极限之前，响应时延不会随着请求数量增加而显著升高
            3。几乎可以一直保持约 100ms 的平均响应时延。
    3。简单实用的异步框架: CompletableFuture
        概念：
            异步框架有 Java8 内置的CompletableFuture
        作用：
            1。调用异步方法获得返回值 CompletableFuture 对象后
            2。既可以调用 CompletableFuture 的 get 方法
            3。像调用同步方法那样等待调用的方法执行结束并获得返回值，也可以像异步回调的方式一样
            4。调用 CompletableFuture 那些以 then 开头的一系列方法，为 CompletableFuture 定义异步方法结束之后的后续操作。
    总结：
        异步思想：
            原理：
                1。当我们要执行一项比较耗时的操作时，不去等待操作结束，
                2。而是给这个操作一个命令：“当操作完成后，接下来去执行什么。”
        异步编程模型优点：
            虽然并不能加快程序本身的速度，但可以减少或者避免线程等待，只用很少的线程就可以达到超高的吞吐能力。
        异步编程模型缺点：
            1。相比于同步实现，异步实现的复杂度要大很多，代码的可读性和可维护性都会显著的下降
            2。相比于同步实现，异步实现的复杂度要大很多，代码的可读性和可维护性都会显著的下降

11 | 如何实现高性能的异步网络传输？
    背景：
        1。同步模型会阻塞线程等待资源
        2。异步模型不会阻塞线程，它是等资源准备好后，再通知业务代码来完成后续的资源处理逻辑
        IO 密集型系统：
            概念：
                1。大部分时间都在执行 IO 操作
                2。这个 IO 操作主要包括网络 IO 和磁盘 IO，以及与计算机连接的一些外围设备的访问
            注意：
                1。我们开发的业务系统，很少有非常耗时的计算，更多的是网络收发数据，读写磁盘和数据库这些 IO 操作
                2。这样的系统基本上都是 IO 密集型系统，特别适合使用异步的设计来提升系统性能。
        CPU密集型系统：
            概念：
                大部分时间都是在使用 CPU 执行计算操作
    理想的异步网络框架应该是什么样的？
        背景：
            1。如果要实现通过网络来传输数据，需要用到开发语言提供的网络通信类库
            2。大部分语言提供的网络通信基础类库都是同步的。一个 TCP 连接建立后，用户代码会获得一个用于收发数据的通道
            3。每个通道会在内存中开辟两片区域用于收发数据的缓存。
        同步网络 IO 的模型：
            发送数据的过程：
                1。直接往这个通道里面来写入数据就可以了
                2。用户代码在发送时写入的数据会暂存在缓存中，然后操作系统会通过网卡
                3。把发送缓存中的数据传输到对端的服务器上。
                注意：
                    1。只要这个缓存不满，或者说，我们发送数据的速度没有超过网卡传输速度的上限
                    2。那这个发送数据的操作耗时，只不过是一次内存写入的时间，这个时间是非常快的
                    3。发送数据的时候同步发送就可以了，没有必要异步。
            接收数据：
                分析：
                    1。对于数据的接收方来说，它并不知道什么时候会收到数据
                过程：
                    1。用一个线程阻塞在那儿等着数据，当有数据到来的时候，操作系统会先把数据写入接收缓存
                    2。然后给接收数据的线程发一个通知，线程收到通知后结束等待，开始读取数据
                    3。处理完这一批数据后，继续阻塞等待下一批数据到来，这样周而复始地处理收到的数据。
        现象：
            1。同步网络 IO 模型在处理少量连接的时候，是没有问题的
            2。但是如果要同时处理非常多的连接，同步的网络 IO 模型就有点儿力不从心了。
            原因：
                1。每个连接都需要阻塞一个线程来等待数据，大量的连接数就会需要相同数量的数据接收线程。
            问题：
                当这些 TCP 连接都在进行数据收发的时候，会导致什么情况呢？
            答案：
                1。会有大量的线程来抢占 CPU 时间，造成频繁的 CPU 上下文切换
                2。导致 CPU 的负载升高，整个系统的性能就会比较慢。
            方法：
                使用异步的模型来解决网络 IO 问题
                提出问题：
                    1。抛开你知道的各种语言的异步类库和各种异步的网络 IO 框架，
                    2。对于业务开发者来说，一个好的异步网络框架，它的 API 应该是什么样的呢？
                答案：
                    1。只用少量的线程就能处理大量的连接，有数据到来的时候能第一时间处理就可以了。
                最简单的实现方式：
                    1。事先定义好收到数据后的处理逻辑，把这个处理逻辑作为一个回调方法，在连接建立前就通过框架提供的 API 设置好
                    2。当收到数据的时候，由框架自动来执行这个回调方法就好了。

    使用 Netty 来实现异步网络通信
        参考代码：
            // 创建一组线性
            EventLoopGroup group = new NioEventLoopGroup();

            try{
                // 初始化 Server
                ServerBootstrap serverBootstrap = new ServerBootstrap();
                serverBootstrap.group(group);
                serverBootstrap.channel(NioServerSocketChannel.class);
                serverBootstrap.localAddress(new InetSocketAddress("localhost", 9999));

                // 设置收到数据后的处理的 Handler
                serverBootstrap.childHandler(new ChannelInitializer<SocketChannel>() {
                    protected void initChannel(SocketChannel socketChannel) throws Exception {
                        socketChannel.pipeline().addLast(new MyHandler());
                    }
                });
                // 绑定端口，开始提供服务
                ChannelFuture channelFuture = serverBootstrap.bind().sync();
                channelFuture.channel().closeFuture().sync();
            } catch(Exception e){
                e.printStackTrace();
            } finally {
                group.shutdownGracefully().sync();
            }
        功能：
            1。首先我们创建了一个 EventLoopGroup 对象，命名为 group，这个 group 对象你可以简单把它理解为一组线程
                作用：
                    就是来执行收发数据的业务逻辑
            2。然后，使用 Netty 提供的 ServerBootstrap 来初始化一个 Socket Server，绑定到本地 9999 端口上。
            3。在真正启动服务之前，我们给 serverBootstrap 传入了一个 MyHandler 对象
                MyHandler：
                    1。是我们自己来实现的一个类，它需要继承 Netty 提供的一个抽象类：ChannelInboundHandlerAdapter
                    2。在这个 MyHandler 里面，我们可以定义收到数据后的处理逻辑。
                    3。这个设置 Handler 的过程，就是我刚刚讲的，预先来定义回调方法的过程。
            4。最后就可以真正绑定本地端口，启动 Socket 服务了。
        运行过程：
            1。服务启动后，如果有客户端来请求连接，Netty 会自动接受并创建一个 Socket 连接
            2。当收到来自客户端的数据后，Netty 就会在我们第一行提供的 EventLoopGroup 对象中
            3。获取一个 IO 线程，在这个 IO 线程中调用接收数据的回调方法，来执行接收数据的业务逻辑
            4。在这个例子中，就是我们传入的 MyHandler 中的方法。
        注意：
            1。真正需要业务代码来实现的就两个部分：
                1。一个是把服务初始化并启动起来
                2。实现收发消息的业务逻辑 MyHandler。
                例子：
                    像线程控制、缓存管理、连接管理这些异步网络 IO 中通用的、比较复杂的问题，Netty 已经自动帮你处理好了
            2。如果说，你的业务需要更灵活的实现，自己来维护收发数据的线程
                方法：
                    可以选择更加底层的 Java NIO。其实，Netty 也是基于 NIO 来实现的。

    使用 NIO 来实现异步网络通信
        背景：
            在 Java 的 NIO 中，它提供了一个 Selector 对象，来解决一个线程在多个网络连接上的多路复用问题。
        解释：
            1。在 NIO 中，每个已经建立好的连接用一个 Channel 对象来表示。
            2。在一个线程里，接收来自多个 Channel 的数据。
            3。也就是说，这些 Channel 中，任何一个 Channel 收到数据后，第一时间能在同一个线程里面来处理。
        一个线程对应多个 Channel，有可能会出现这两种情况：
            1。线程在忙着处理收到的数据，这时候 Channel 中又收到了新数据；
            2。线程闲着没事儿干，所有的 Channel 中都没收到数据，也不能确定哪个 Channel 会在什么时候收到数据
        扩展：
            1。Selecor 通过一种类似于事件的机制来解决这个问题
            2。首先你需要把你的连接，也就是 Channel 绑定到 Selector 上
            3。然后你可以在接收数据的线程来调用 Selector.select() 方法来等待数据到来
            4。这个 select 方法是一个阻塞方法，这个线程会一直卡在这儿，直到这些 Channel 中的任意一个有数据到来，就会结束等待返回数据
            5。它的返回值是一个迭代器，你可以从这个迭代器里面获取所有 Channel 收到的数据，然后来执行你的数据接收的业务逻辑。

12 | 序列化与反序列化：如何通过网络传输结构化的数据？
    背景：
        1。在 TCP 的连接上，它传输数据的基本形式就是二进制流，也就是一段一段的 1 和 0
        2。在一般编程语言或者网络框架提供的 API 中，传输数据的基本形式是字节，也就是 Byte。
        3。一个字节就是 8 个二进制位，8 个 Bit，所以在这里，二进制流和字节流本质上是一样的。
    问题：
        对于我们编写的程序来说，它需要通过网络传输的数据是什么形式的呢？
        答案：
            是结构化的数据，
        例子：
            1。一条命令、一段文本或者是一条消息。
            2。对应到我们写的代码中，这些结构化的数据是什么？
            3。这些都可以用一个类（Class）或者一个结构体（Struct）来表示。
    前提：
        要想使用网络框架的 API 来传输结构化的数据，必须得先实现结构化的数据与字节流之间的双向转换。
    序列化：
        概念：
            将结构化数据转换成字节流的过程
        作用：
            1。用于在网络上传输数据
            2。将结构化数据保存在文件中
                原因：
                    1。在文件内保存数据的形式也是二进制序列
                    2。网络传输过程中的数据是一样的
        扩展：
            1。很多处理海量数据的场景中，都需要将对象序列化后，把它们暂时从内存转移到磁盘中
            2。等需要用的时候，再把数据从磁盘中读取出来，反序列化成对象来使用
        优点：
            1。不仅可以长期保存不丢失数据
            2。可以节省有限的内存空间。
    反序列化：
        概念：
            将字节流转换成结构化数据的过程
    你该选择哪种序列化实现？
        序列化方式：
            1。把一个对象转换成字符串并打印出来，这个字符串只要转成字节序列，就可以在网络上传输或者保存在文件中了。
            2。Google 的 Protobuf、Kryo、Hessian 等；
            3。像 JSON、XML 这些标准的数据格式，也可以作为一种序列化实现来使用。
        权衡的因素：
            1。序列化后的数据最好是易于人类阅读的；
            2。实现的复杂度是否足够低；
            3。序列化和反序列化的速度越快越好；
            4。序列化后的信息密度越大越好，也就是说，同样的一个结构化数据，序列化之后占用的存储空间越小越好
            注意：
                1。大多数情况下，易于阅读和信息密度是矛盾的，实现的复杂度和性能也是互相矛盾的。
                2。我们需要根据所实现的业务，来选择合适的序列化实现。
            分析：
                1。像 JSON、XML 这些序列化方法，可读性最好，但信息密度也最低。
                2。像 Kryo、Hessian 这些通用的二进制序列化实现，适用范围广，使用简单，性能比 JSON、XML 要好一些，但是肯定不如专用的序列化实现。
        案例一：
            1。比如说电商类、社交类的应用系统，这些系统的特点是，业务复杂，需求变化快，
            2。但是对性能的要求没有那么苛刻
            方法
                使用 JSON 这种实现简单
            优点：
                1。数据可读性好的序列化实现，这种实现使用起来非常简单
                2。序列化后的 JSON 数据我们都可以看得懂，无论是接口调试还是排查问题都非常方便
            缺点：
                多一点点 CPU 时间和存储空间而已。
        案例二：
            1。如果 JSON 序列化的性能达不到你系统的要求，可以采用性能更好的二进制序列化实现
                优点：
                    实现的复杂度和 JSON 序列化是差不多的，都很简单，但是序列化性能更好，信息密度也更高
                缺点：
                    失去了可读性。
                比如：
                    比如我们用 Kryo 来序列化 User 对象

    实现高性能的序列化和反序列化
        背景：
            1。绝大部分系统，使用上面这两类通用的序列化实现都可以满足需求
            2。而像消息队列这种用于解决通信问题的中间件，它对性能要求非常高，通用的序列化实现达不到性能要求
        扩展
            很多的消息队列都选择自己实现高性能的专用序列化和反序列化。
            优点：
                可以提高序列化性能，并有效减小序列化后的字节长度。
        方法：
            1。在专用的序列化方法中，不必考虑通用性。
            2。我们可以固定字段的顺序，这样在序列化后的字节里面就不必包含字段名
            3。只要字段值就可以了，不同类型的数据也可以做针对性的优化：
        案例：
            03   | 08 7a 68 61 6e 67 73 61 6e | 17 | 01
            User |    z  h  a  n  g  s  a  n  | 23 | true
        解释：
            对象类型：
                1。我们需要标识一下这个对象的类型
                2。。我们用一个字节来表示类型，比如用 03 表示这是一个 User 类型的对象。
            name：
                1。按照 name、age、married 这个固定顺序来序列化这三个属性。
                2。按照顺序，第一个字段是 name，我们不存字段名，直接存字段值“zhangsan”就可以了
                3。由于名字的长度不固定，我们用第一个字节 08 表示这个名字的长度是 8 个字节
                4。后面的 8 个字节就是 zhangsan。
            age：
                我们直接用一个字节表示就可以了，23 的 16 进制是 17 。
            married：
                用一个字节来表示，01 表示已婚，00 表示未婚，这里面保存一个 01。
        优点：
            1。同样的一个 User 对象，JSON 序列化后需要 47 个字节，这里只要 12 个字节就够了。
            2。更高效，序列化出来的字节更少，在网络传输过程中的速度也更快
        缺点：
            1。需要为每种对象类型定义专门的序列化和反序列化方法
            2。实现起来太复杂了，大部分情况下是不划算的。

13 | 传输协议：应用程序之间对话的语言
    背景：
        1。我们已经可以实现高性能的结构化数据传输了
        2。应用程序之间要想互相通信，一起配合来实现业务功能，还需要有一套传输协议来支持。
        传输协议：
            1。应用程序之间对话的语言。
        设计传输协议：
            并没有太多规范和要求，只要是通信双方的应用程序都能正确处理这个协议，并且没有歧义就好了。
    如何“断句”？
        思路来源：
            1。既然传输协议也是一种语言，那么在应用程序之间“通话”的过程中
            2。与我们人类用自然语言沟通有很多相似之处，但是需要处理的问题却又不同。
        断句：
            概念：
                无论是汉语还是英语，都是通过标点符号来分隔句子的
            例子：
                古代汉语是没有标点符号的，断句全靠上下文
                缺点：
                    但这种断句方式有的时候会出现歧义
                例子：
                    “下雨天留客天天留我不留”，不同的断句方式，意思完全不一样。
            自然语言中断句：
                方法一：
                    1。在数据传输的过程中，无论你定义什么字符作为分隔符，理论上，它都有可能会在传输的数据中出现
                    2。为了区分“数据内的分隔符”和真正的分隔符，你必须得在发送数据阶段，加上分隔符之前
                    3。把数据内的分隔符做转义，收到数据之后再转义回来
                    缺点：
                        损失一些性能。
                方法二：
                    1。给每句话前面加一个表示这句话长度的数字
                    2。收到数据的时候，我们按照长度来读取就可以了
                    例子：
                        03 下雨天 03 留客天 02 天留 03 我不留
                    优点：
                        它实现起来要比分隔符的方法简单很多，性能也更好
    用双工收发协议提升吞吐量
        单工通信：
            概念：
                任何一个时刻，数据只能单向传输，一个人说的时候，另外一个人只能听。
            例子：
                1。HTTP1 协议，就是这样一种单工协议，客户端与服务端建立一个连接后，客户端发送一个请求
                2。直到服务端返回响应或者请求超时，这段时间内，这个连接通道上是不能再发送其他请求的
                缺点：
                    效率是比较低的，
                办法：
                    很多浏览器和 App 为了解决这个问题，只能同时在服务端和客户端之间创建多个连接，这也是没有办法的办法。
        双工通信：
            概念：
                同时进行数据的双向收发，互相是不会受到任何影响的
            优点：
                要提高吞吐量，应用层的协议也必须支持双工通信。
            扩展：
                1。在实际上设计协议的时候，我们一般不关心顺序
                2。只要需要确保请求和响应能够正确对应上就可以了。
                方法：
                    1。发送请求的时候，给每个请求加一个序号，这个序号在本次会话内保证唯一
                    2。然后在响应中带上请求的序号，这样就可以把请求和响应对应上了。

14 | 内存管理：如何避免内存溢出和频繁的垃圾回收？
    背景：
        1。像 Java、Go 语言等，采用的都是自动内存管理机制
        2。在编写代码的时候，不需要显式去申请和释放内存。
        3。当我们创建一个新对象的时候，系统会自动分配一块内存用于存放新创建的对象，对象使用完毕后
        4。系统会自动择机收回这块内存，完全不需要开发者干预。
        优点：
            1。非常方便的，不仅极大降低了开发难度，提升了开发效率
            2。解决了内存泄漏的问题
    现象一：：
        1。一个业务逻辑非常简单的微服务，日常情况下都能稳定运行
        2。为什么一到大促就卡死甚至进程挂掉
    现象二：
        1。一个做数据汇总的应用，按照小时、天这样的粒度进行数据汇总都没问题
        2。到年底需要汇总全年数据的时候，没等数据汇总出来，程序就死掉了。
    原因：
        程序在设计的时候，没有针对高并发高吞吐量的情况做好内存管理
    自动内存管理机制的实现原理
        申请内存管理逻辑：
            1。计算要创建对象所需要占用的内存大小；
            2。在内存中找一块儿连续并且是空闲的内存空间，标记为已占用；
            3。把申请的内存地址绑定到对象的引用上，这时候对象就可以使用了。
            内存回收：
                需要做两件事：
                    一件事：
                        先是要找出所有可以回收的对象，将对应的内存标记为空闲
                        问题：
                            如何找出可以回收的对象呢？
                        方法：
                            大多采用的是“标记 - 清除”算法
                            标记阶段：
                                1。从 GC Root 开始，你可以简单地把 GC Root 理解为程序入口的那个对象
                                2。标记所有可达的对象
                                原因：
                                    程序中所有在用的对象一定都会被这个 GC Root 对象直接或者间接引用。

                            清除阶段：
                                1。遍历所有对象，找出所有没有标记的对象
                                2。这些没有标记的对象都是可以被回收的，清除这些对象，释放对应的内存即可。
                        关键点：
                            在执行标记和清除过程中，必须把进程暂停，否则计算的结果就是不准确的。
                            现象：
                                垃圾回收的时候，我们的程序会卡死
                            变种现象：
                                可以减少一些进程暂停的时间，但都不能完全避免暂停进程。
                    另一件事：
                        需要整理内存碎片
                            问题：
                                什么是内存碎片？
                            例子：
                                1。我们的内存只有 10 个字节，一开始这 10 个字节都是空闲的
                                2。我们初始化了 5 个 Short 类型的对象，每个 Short 占 2 个字节，正好占满 10 个字节的内存空间
                                3。程序运行一段时间后，其中的 2 个 Short 对象用完并被回收了。
                                问题：
                                    如果我需要创建一个占 4 个字节的 Int 对象，是否可以创建成功呢？
                                    答案：
                                        不一定
                                    分析：
                                        1。我们刚刚回收了 2 个 Short，正好是 4 个字节
                                        2。创建一个 Int 对象需要连续 4 个字节的内存空间，2 段 2 个字节的内存
                                        3。并不一定就等于一段连续的 4 字节内存
                                        4。如果这两段 2 字节的空闲内存不连续，我们就无法创建 Int 对象，这就是内存碎片问题。
                        概念：
                            1。垃圾回收完成后，还需要进行内存碎片整理，将不连续的空闲内存移动到一起
                            2。以便空出足够的连续内存空间供后续使用
                        现象：
                            整理过程中需要移动内存中的数据，也都不可避免地需要暂停进程

    为什么在高并发下程序会卡死？
        分析：
            1。一般来说，我们的微服务在收到一个请求后，执行一段业务逻辑，然后返回响应
            2。这个过程中，会创建一些对象，比如说请求对象、响应对象和处理中间业务逻辑中需要使用的一些对象等等
            3。随着这个请求响应的处理流程结束，我们创建的这些对象也就都没有用了，它们将会在下一次垃圾回收过程中被释放。
        现象：
            直到下一次垃圾回收之前，这些已经没有用的对象会一直占用内存。
            问题：
                虚拟机是如何决定什么时候来执行垃圾回收呢？
            答案：
                如果内存不够用了，那肯定要执行一次垃圾回收的，否则程序就没法继续运行了。
        情形一：
            1。在低并发情况下，单位时间内需要处理的请求不多，创建的对象数量不会很多
            2。自动垃圾回收机制可以很好地发挥作用，它可以选择在系统不太忙的时候来执行垃圾回收
            3。每次垃圾回收的对象数量也不多，相应的，程序暂停的时间非常短，短到我们都无法感知到这个暂停
            4。这是一个良性的循环。
        情形二：
            1。在高并发的情况下，我们的程序会非常繁忙，短时间内就会创建大量的对象，这些对象将会迅速占满内存
            2。这时候，由于没有内存可以使用了，垃圾回收被迫开始启动
            3。这次被迫执行的垃圾回收面临的是占满整个内存的海量对象，它执行的时间也会比较长
            问题：
                1。相应的，这个回收过程会导致进程长时间暂停。
                2。进程长时间暂停，又会导致大量的请求积压等待处理，垃圾回收刚刚结束
                3。更多的请求立刻涌进来，迅速占满内存，再次被迫执行垃圾回收，进入了一个恶性循环
                4。如果垃圾回收的速度跟不上创建对象的速度，还可能会产生内存溢出的现象。
            现象：
                一到大促，大量请求过来，我们的服务就卡死了。

    高并发下的内存管理技巧
        背景：
            使用过被丢弃的对象才是垃圾回收的目标
        思路：
            我们需要想办法在处理大量请求的同时，尽量少的产生这种一次性对象。
        方法一：
            优化你的代码中处理请求的业务逻辑，尽量少的创建一次性对象，特别是占用内存较大的对象。
                例子：
                    1。我们可以把收到请求的 Request 对象在业务流程中一直传递下去，而不是每执行一个步骤，
                    2。就创建一个内容和 Request 对象差不多的新对象
        方法二
            对于需要频繁使用，占用内存较大的一次性对象，我们可以考虑自行回收并重用这些对象
            具体实现：
                1。我们可以为这些对象建立一个对象池
                2。收到请求后，在对象池内申请一个对象，使用完后再放回到对象池中
                3。这样就可以反复地重用这些对象，非常有效地避免频繁触发垃圾回收。
        方法三：
            如果可能的话，使用更大内存的服务器，也可以非常有效地缓解这个问题。
        方法四：(不可取)
            要从根本上来解决这个问题，办法只有一个，那就是绕开自动垃圾回收机制，自己来实现内存管理
            缺点：
                1。自行管理内存将会带来非常多的问题
                2。比如说极大增加了程序的复杂度，可能会引起内存泄漏等等。
            例子：
                1。流计算平台 Flink，就是自行实现了一套内存管理机制，一定程度上缓解了处理大量数据时垃圾回收的问题
                2。但是也带来了一些问题和 Bug，总体看来，效果并不是特别好

15 | Kafka如何实现高性能IO？
    1。使用批量消息提升服务端处理能力
        批量处理：
            概念：
                一种非常有效的提升系统吞吐量的方法
            例子：
                在 Kafka 内部，消息都是以“批”为单位处理的。
            问题：
                一批消息从发送端到接收端，是如何在 Kafka 中流转的呢？
            答案：
                发送端：( Producer 这一端)
                    在 Kafka 的客户端 SDK中，Kafka 的 Producer 只提供了单条发送的 send() 方法， 并没有提供任何批量发送的接口
                    原因：
                        1。Kafka 根本就没有提供单条发送的功能，虽然它提供的 API 每次只能发送一条消息
                        2。但实际上，Kafka 的客户端 SDK 在实现消息发送逻辑的时候，采用了异步批量发送的机制。
                    具体流程：
                        1。当你调用 send() 方法发送一条消息之后，无论你是同步发送还是异步发送，Kafka 都不会立即就把这条消息发送出去。
                        2。它会先把这条消息，存放在内存中缓存起来，然后选择合适的时机把缓存中的所有消息组成一批
                        3。一次性发给 Broker。简单地说，就是攒一波一起发。

                服务端：( Broker 这一端)
                    问题：
                        如何处理这一批一批的消息呢？
                        答案：
                            1。在服务端，Kafka 不会把一批消息再还原成多条消息，再一条一条地处理，这样太慢了。
                            2。Kafka 这块儿处理的非常聪明，每批消息都会被当做一个“批消息”来处理
                            3。在 Broker 整个处理流程中，无论是写入磁盘、从磁盘读出来、还是复制到其他副本这些流程中
                            4。批消息都不会被解开，一直是作为一条“批消息”来进行处理的。
                消费时：
                    1。消息同样是以批为单位进行传递的，Consumer 从 Broker 拉到一批消息后
                    2。在客户端把批消息解开，再一条一条交给用户代码处理。
                    例子：
                        1。你在客户端发送 30 条消息，在业务程序看来，是发送了 30 条消息
                        2。而对于 Kafka 的 Broker 来说，它其实就是处理了 1 条包含 30 条消息的“批消息”而已
                    优点
                        显然处理 1 次请求要比处理 30 次请求要快得多。
                总结：
                    1。构建批消息和解开批消息分别在发送端和消费端的客户端完成
                    优点：
                        1。不仅减轻了 Broker 的压力，
                        2。最重要的是减少了 Broker 处理请求的次数，提升了总体的处理能力。

    2。使用顺序读写提升磁盘 IO 性能
        背景：
            1。相比于网络传输和内存，磁盘 IO 的速度是比较慢的
            2。对于消息队列的服务端来说，性能的瓶颈主要在磁盘 IO 这一块。

        磁盘的一个特性：
            1。顺序读写的性能要远远好于随机读写
                例子：
                    1。在 SSD（固态硬盘）上，顺序读写的性能要比随机读写快几倍
                    2。如果是机械硬盘，这个差距会达到几十倍
                    原因：
                        1。操作系统每次从磁盘读写数据的时候，需要先寻址
                        2。也就是先要找到数据在磁盘上的物理位置，然后再进行数据读写
                        3。如果是机械硬盘，这个寻址需要比较长的时间
                        原因：
                            1。它要移动磁头，这是个机械运动
                            2。机械硬盘工作的时候会发出咔咔的声音，就是移动磁头发出的声音。
            2。顺序读写相比随机读写省去了大部分的寻址时间
                原因：
                    它只要寻址一次，就可以连续地读写下去，所以说，性能要比随机读写要好很多。
        应用：
            Kafka 就是充分利用了磁盘的这个特性
        原理：
            1。它的存储设计非常简单，对于每个分区，它把从 Producer 收到的消息
            2。顺序地写入对应的 log 文件中，一个文件写满了，就开启一个新的文件这样顺序写下去
            3。消费的时候，也是从某个全局的位置开始，也就是某一个 log 文件中的某个位置开始，顺序地把消息读出来。

    3。利用 PageCache 加速消息读写
        PageCache：
            概念：
                1。是现代操作系统都具有的一项基本特性。
                2。操作系统在内存中给磁盘上的文件建立的缓存
            扩展：
                1。无论我们使用什么语言编写的程序，在调用系统的 API 读写文件的时候
                2。并不会直接去读写磁盘上的文件，应用程序实际操作的都是 PageCache，也就是文件在内存中缓存的副本
            例子：
                1。应用程序在写入文件的时候，操作系统会先把数据写入到内存中的 PageCache，然后再一批一批地写到磁盘上
                2。读取文件的时候，也是从 PageCache 中来读取数据，这时候会出现两种可能情况。
                    情况一：
                        PageCache 中有数据，那就直接读取，这样就节省了从磁盘上读取数据的时间
                    情况二：
                        1。PageCache 中没有数据，这时候操作系统会引发一个缺页中断
                        2。应用程序的读取线程会被阻塞，操作系统把数据从文件中复制到 PageCache 中
                        3。然后应用程序再从 PageCache 中继续把数据读出来
                        4。这时会真正读一次磁盘上的文件，这个读的过程就会比较慢。
            注意：
                1。用户的应用程序在使用完某块 PageCache 后，操作系统并不会立刻就清除这个 PageCache
                2。而是尽可能地利用空闲的物理内存保存这些 PageCache，除非系统内存不够用，操作系统才会清理掉一部分 PageCache。
                    清理策略：
                        LRU 或它的变种算法
                3。它保留 PageCache 的逻辑是：优先保留最近一段时间最常使用的那些 PageCache。
            应用：
                1。Kafka 在读写消息文件的时候，充分利用了 PageCache 的特性
                2。消息刚刚写入到服务端就会被消费，按照 LRU 的“优先清除最近最少使用的页”这种策略
                3。读取的时候，对于这种刚刚写入的 PageCache，命中的几率会非常高。
                 扩展：
                    大部分情况下，消费读消息都会命中 PageCache
                优点：
                    1。一个是读取的速度会非常快
                    2。给写入消息让出磁盘的 IO 资源，间接也提升了写入的性能。
    4。ZeroCopy：零拷贝技术
        在服务端，处理消费的大致逻辑是这样的：
            1。首先，从文件中找到消息数据，读到内存中；
            2。然后，把消息通过网络发给客户端。
        这个过程中，数据实际上做了 2 次或者 3 次复制：
            1。从文件复制数据到 PageCache 中，如果命中 PageCache，这一步可以省掉；
            2。从 PageCache 复制到应用程序的内存空间中，也就是我们可以操作的对象所在的内存；
            3。从应用程序的内存空间复制到 Socket 的缓冲区，这个过程就是我们调用网络应用框架的 API 发送数据的过程。
        优化；
            1。Kafka 使用零拷贝技术可以把这个复制次数减少一次，上面的 2、3 步骤两次复制合并成一次复制
            2。直接从 PageCache 中把数据复制到 Socket 缓冲区中，这样不仅减少一次数据复制，
            3。更重要的是，由于不用把数据复制到用户内存空间，DMA 控制器可以直接完成数据复制，不需要 CPU 参与，速度更快。
        注意：
            1。如果你遇到这种从文件读出数据后再通过网络发送出去的场景
            2。并且这个过程中你不需要对这些数据进行处理，
            3。那一定要使用这个零拷贝的方法，可以有效地提升性能。

16 | 缓存策略：如何使用缓存来减少磁盘IO？
    背景：
        1。现代的消息队列，都使用磁盘文件来存储消息。
            原因：
                1。磁盘是一个持久化的存储，即使服务器掉电也不会丢失数据
                2。磁盘很便宜，这样我们就可以用比较低的成本，来存储海量的消息
        2。绝大多数用于生产系统的服务器，都会使用多块儿磁盘组成磁盘阵列
            优点：
                1。不仅服务器掉电不会丢失数据，即使其中的一块儿磁盘发生故障
                2。也可以把数据从其他磁盘中恢复出来。
            缺点：
                读写速度很慢。
                例子：
                    1。一般来说 SSD（固态硬盘）每秒钟可以读写几千次
                    2。如果说我们的程序在处理业务请求的时候直接来读写磁盘，假设处理每次请求需要读写 3～5 次
                    3。即使每次请求的数据量不大，你的程序最多每秒也就能处理 1000 次左右的请求。
                方法：
                    使用内存作为缓存来加速应用程序的访问速度，是几乎所有高性能系统都会采用的方法。
                    原因：
                        而内存的随机读写速度是磁盘的 10 万倍
                    缓存：
                        概念：
                            把低速存储的数据，复制一份副本放到高速的存储中，用来加速数据的访问。
                        使用：
                            在一些执行比较慢的方法上加上一个 @Cacheable 的注解，

    1。选择只读缓存还是读写缓存？
        背景：
            使用缓存，首先你就会面临选择读缓存还是读写缓存的问题。
            区别：
                在更新数据的时候，是否经过缓存。
        应用：
            1。Kafka 使用的 PageCache，它就是一个非常典型的读写缓存
            2。操作系统会利用系统空闲的物理内存来给文件读写做缓存，这个缓存叫做 PageCache。
        写入过程：
            1。应用程序在写文件的时候，操作系统会先把数据写入到 PageCache 中
            2。数据在成功写到 PageCache 之后，对于用户代码来说，写入就结束了。
            3。然后，操作系统再异步地把数据更新到磁盘的文件中
            注意：
                在数据写到 PageCache 中后，它并不是同时就写到磁盘上了，这中间是有一个延迟的
            现象：
                1。操作系统可以保证，即使是应用程序意外退出了，操作系统也会把这部分数据同步到磁盘上
                2。但是，如果服务器突然掉电了，这部分数据就丢失了。
        读入过程：
            1。应用程序在读文件的时候，操作系统也是先尝试从 PageCache 中寻找数据
            2。如果找到就直接返回数据，找不到会触发一个缺页中断
            3。然后操作系统把数据从文件读取到 PageCache 中，再返回给应用程序。
        设计思想：
            1。一种牺牲数据一致性换取性能的设计
                方法：
                    1。应用程序可以调用 sync 等系统调用，强制操作系统立即把缓存数据同步到磁盘文件中去
                    2。但是这个同步的过程是很慢的，也就失去了缓存的意义。
            扩展：
                1。写缓存的实现是非常复杂的。应用程序不停地更新 PageCache 中的数据，操作系统需要记录哪些数据有变化，同时还要在另外一个线程中
                2。把缓存中变化的数据更新到磁盘文件中
                3。在提供并发读写的同时来异步更新数据，这个过程中要保证数据的一致性，并且有非常好的性能，实现这些真不是一件容易的事儿。
            问题：
                为什么 Kafka 可以使用 PageCache 来提升它的性能呢？
            答案：
                1。首先，消息队列它的读写比例大致是 1：1
                    原因：
                        1。大部分我们用消息队列都是一收一发这样使用。
                        2。这种读写比例，只读缓存既无法给写加速，读的加速效果也有限，并不能提升多少性能。
                2。Kafka 它并不是只靠磁盘来保证数据的可靠性，它更依赖的是，在不同节点上的多副本来解决数据可靠性问题
                    优点：
                        这样即使某个服务器掉电丢失一部分文件内容，它也可以从其他节点上找到正确的数据，不会丢消息。
                3。PageCache 这个读写缓存是操作系统实现的，Kafka 只要按照正确的姿势来使用就好了，不涉及到实现复杂度的问题
        读次数和写次数的关系：
            1。一般读的数据的频次会都会远高于写数据的频次
            2。从经验值来看，读次数一般都是写次数的几倍到几十倍。这种情况下，使用只读缓存来加速系统才是非常明智的选择。

    2。保持缓存数据新鲜
        只读缓存：
            1。缓存中的数据来源只有一个途径，就是从磁盘上来。
            2。当数据需要更新的时候，磁盘中的数据和缓存中的副本都需要进行更新
            缺点：
                由于节点宕机、网络传输故障等情况的存在，我们是无法保证缓存中的数据和磁盘中的数据是完全一致的。
            方法：
                分布式系统中，使用事务或者一些分布式一致性算法来保证数据一致性

        注意：
            如果出现数据不一致的情况，数据一定是以磁盘上的那份拷贝为准
        问题：
            让缓存中的数据与磁盘上的数据保持同步
            问题一：
                同步更新
                关键点：
                    更新磁盘成功了，但是更新缓存失败了
                现象：
                    如果多次重试都失败，那这次更新是算成功还是失败呢？
            问题二：
                异步更新缓存
                关键点：
                    怎么保证更新的时序？
                    例子：
                        1。比如，我先把一个文件中的某个数据设置成 0，然后又设为 1
                        2。这个时候文件中的数据肯定是 1，但是缓存中的数据可不一定就是 1 了
                    原因；
                        把缓存中的数据更新为 0，和更新为 1 是两个并发的异步操作，不一定谁会先执行。
        现象：
            1。这些问题都会导致缓存的数据和磁盘中的数据不一致
            2。在下次更新这条数据之前，这个不一致的问题它是一直存在的。
        方法一：
            可以使用分布式事务来解决，只是付出的性能、实现复杂度等代价比较大。
        方法二：
            定时将磁盘上的数据同步到缓存中
            情形一：
                全量更新，每次同步时直接全量更新就可以了
                原因：
                    在异步的线程中更新数据，同步的速度即使慢一些也不是什么大问题
                缺点：
                    如果缓存的数据太大，更新速度慢到无法接受
            情形二：
                增量更新，每次只更新从上次缓存同步至今这段时间内变化的数据
                缺点：
                    代价是实现起来会稍微有些复杂。
            缺点：
                缓存更新不那么及时
            优点：
                实现起来非常简单，鲁棒性非常好
        方法三：
            1。从来不去更新缓存中的数据，而是给缓存中的每条数据设置一个比较短的过期时间
            2。数据过期以后即使它还存在缓存中，我们也认为它不再有效，需要从磁盘上再次加载这条数据
        应用：
            条件一：
                1。很多情况下，缓存的数据更新不那么及时，我们的系统也是能够接受的
                2。对数据一致性没有那么敏感的场景下
                选择：
                    选择方法二和方法三。
                例子：
                    1。你刚刚发了一封邮件，收件人过了一会儿才收到。
                    2。你改了自己的微信头像，在一段时间内，你的好友看到的你还是旧的头像，这些都是可以接受的
            条件二：
                而像交易类的系统，它对数据的一致性非常敏感
                选择：
                    提到的第一种方法，在更新数据的时候同时来更新缓存
                例子：
                    1。你给别人转了一笔钱，别人查询自己余额却没有变化，
                    2。一般来说，都不使用缓存或者使用我们提到的第一种方法，在更新数据的时候同时来更新缓存。

    3。缓存置换策略
        背景：
            1。在使用缓存的过程中，除了要考虑数据一致性的问题
            2。还需要关注的另一个重要的问题是，在内存有限的情况下，要优先缓存哪些数据，让缓存的命中率最高。
        一次缓存命中：
            概念：
                1。当应用程序要访问某些数据的时候，如果这些数据在缓存中
                2。那直接访问缓存中的数据就可以了，这次访问的速度是很快的
        缓存穿透：
            如果这些数据不在缓存中，那只能去磁盘中访问数据，就会比较慢
        注意：
            缓存的命中率越高，应用程序的总体性能就越好。
        问题：
            用什么样的策略来选择缓存的数据，能使得缓存的命中率尽量高一些呢？
            情形一：
                如果你的系统是那种可以预测未来访问哪些数据的系统
                例子：
                    有的系统它会定期做数据同步，每次同步的数据范围都是一样的
                方法：
                    缓存策略很简单，就是你要访问什么数据，就缓存什么数据，甚至可以做到百分之百的命中。
            情形二：
                并没有办法准确地预测未来会有哪些数据会被访问到
                方法：
                    使用一些策略来尽可能地提高缓存命中率。
                    例子：
                        1。我们都会在数据首次被访问的时候，顺便把这条数据放到缓存中
                        2。随着访问的数据越来越多，总有把缓存占满的时刻，这个时候就需要把缓存中的一些数据删除掉
                        3。以便存放新的数据，这个过程称为缓存置换。
                    思路：
                        命中率最高的置换策略，一定是根据你的业务逻辑，定制化的策略
                        例子一：
                            你如果知道某些数据已经删除了，永远不会再被访问到，那优先置换这些数据肯定是没问题的。
                        例子二：
                            1。你的系统是一个有会话的系统，你知道现在哪些用户是在线的
                            2。哪些用户已经离线，那优先置换那些已经离线用户的数据，尽量保留在线用户的数据也是一个非常好的策略
        LRU 算法：最近最少使用算法
            思想：
                1。最近刚刚被访问的数据，它在将来被访问的可能性也很大
                2。而很久都没被访问过的数据，未来再被访问的几率也不大。
            应用：
                Kafka 使用的 PageCache，是由 Linux 内核实现的它的置换算法，它的就是一种 LRU 的变种算法
                在淘汰时增加了一个考量维度：
                    页面位置与尾部的距离。因为越是靠近尾部的数据，被访问的概率越大。
                优点：
                    不仅命中率更高，还能有效地避免“挖坟”问题：
                例子：
                    1。例如某个客户端正在从很旧的位置开始向后读取一批历史数据
                    2。内存中的缓存很快都会被替换成这些历史数据，相当于大部分缓存资源都被消耗掉了，这样会导致其他客户端的访问命中率下降
                    3。加入位置权重后，比较旧的页面会很快被淘汰掉，减少“挖坟”对系统的影响。

17 | 如何正确使用锁保护共享数据，协调异步线程？
    锁：
        原理：
            任何时间都只能有一个线程持有锁，只有持有锁的线程才能访问被锁保护的资源。
    避免滥用锁：
        原则：
            如果能不用锁，就不用锁；如果你不确定是不是应该用锁，那也不要用锁。
            原因：
                虽然说使用锁可以保护共享资源，但是代价还是不小的。
                情形一：
                    1。加锁和解锁过程都是需要 CPU 时间的，这是一个性能的损失
                    2。使用锁就有可能导致线程等待锁，等待锁过程中线程是阻塞的状态，过多的锁等待会显著降低程序的性能。
                情形二：
                    1。如果对锁使用不当，很容易造成死锁，导致整个程序“卡死”，这是非常严重的问题
                    缺点：
                        本来多线程的程序就非常难于调试，如果再加上锁，出现并发问题或者死锁问题，你的程序将更加难调试。
        注意：
            只有在并发环境中，共享资源不支持并发访问，或者说并发访问共享资源会导致系统错误的情况下，才需要使用锁。

    锁的用法
        1。在访问共享资源之前，先获取锁。
        2。如果获取锁成功，就可以访问共享资源了。
        3。最后，需要释放锁，以便其他线程继续访问共享资源。
        代码一：
            private Lock lock = new ReentrantLock();

            public void visitShareResWithLock() {
                lock.lock();
                try {
                    // 在这里安全的访问共享资源
                } finally {
                    lock.unlock();
                }
            }
        代码二：
            private Object lock = new Object();

            public void visitShareResWithLock() {
                synchronized (lock) {
                    // 在这里安全的访问共享资源
                }
            }
        注意：
            1。使用完锁，一定要释放它
                忽视：
                    1。比较容易出现状况的地方是，很多语言都有异常机制，当抛出异常的时候，不再执行后面的代码。
                    2。如果在访问共享资源时抛出异常，那后面释放锁的代码就不会被执行，这样，锁就一直无法释放，形成死锁
                做法：
                    要考虑到代码可能走到的所有正常和异常的分支，确保所有情况下，锁都能被释放。
            2。有些语言提供了 try-with 的机制，不需要显式地获取和释放锁，可以简化编程，有效避免这种问题

    如何避免死锁？
        死锁：
            概念：
                由于某种原因，锁一直没有释放，后续需要获取锁的线程都将处于等待锁的状态，这样程序就卡死了。
            原因一：
                获取了锁之后没有释放，
            原因二：
                会不会死锁取决于，你获取的这把锁它是不是可重入锁，如果是可重入锁，那就没有问题，否则就会死锁。
            原因三：
                如果你的程序中存在多把锁，就有可能出现这些锁互相锁住的情况
                例子：
                    第一个线程，先获取 lockA，再获取 lockB，而第二个线程正好相反，先获取 lockB，再获取 lockA。   
            建议：
                1。避免滥用锁，程序里用的锁少，写出死锁 Bug 的几率自然就低。
                2。对于同一把锁，加锁和解锁必须要放在同一个方法中，这样一次加锁对应一次解锁，代码清晰简单，便于分析问题。
                3。尽量避免在持有一把锁的情况下，去获取另外一把锁，就是要尽量避免同时持有多把锁。
                4。如果需要持有多把锁，一定要注意加解锁的顺序，解锁的顺序要和加锁顺序相反。
                    例子：
                        获取三把锁的顺序是 A、B、C，释放锁的顺序必须是 C、B、A。
                5。给你程序中所有的锁排一个顺序，在所有需要加锁的地方，按照同样的顺序加解锁
                    例子：
                        如果两个线程都按照先获取 lockA 再获取 lockB 的顺序加锁，就不会产生死锁。

    使用读写锁要兼顾性能和安全性
        问题：
            如果说某个方法在访问它的时候，只是去读取，并不更新数据，那是不是就不需要加锁呢？
            答案：
                还是需要的
            原因：
                1。如果一个线程读数据的同时，另外一个线程同时在更新数据
                2。那么你读到的数据有可能是更新到一半的数据，这肯定是不符合预期的。
        使用的一般锁：
            优点：
                解决了安全性的问题
            缺点：
                牺牲了性能
        思路；
            1。读访问可以并发执行。
            2。写的同时不能并发读，也不能并发写。
        方法：
            Java 中提供的读写锁：
            代码；
                ReadWriteLock rwlock = new ReentrantReadWriteLock();

                public void read() {
                    rwlock.readLock().lock();
                    try {
                        // 在这儿读取共享数据
                    } finally {
                        rwlock.readLock().unlock();
                    }
                }
                public void write() {
                    rwlock.writeLock().lock();
                    try {
                        // 在这儿更新共享数据
                    } finally {
                        rwlock.writeLock().unlock();
                    }
                }
            解释：
                读数据：
                    1。需要读数据的时候，我们获取读锁，获取到的读锁不是一个互斥锁，
                    2。read() 方法是可以多个线程并行执行的，这样使得读数据的性能依然很好。
                写数据：
                    1。我们获取写锁，当一个线程持有写锁的时候
                    2。其他线程既无法获取读锁，也不能获取写锁，达到保护共享数据的目的。

18 | 如何用硬件同步原语（CAS）替代锁？
    硬件同步原语：
    概念：
        由计算机硬件提供的一组原子操作，我们比较常用的原语主要是 CAS 和 FAA 这两种。
    CAS原语：
        概念：
            字面意思先比较，再交换
        参考代码；
            function cas(p : pointer to int, old : int, new : int) returns bool {
                if *p ≠ old {
                    return false
                }
                *p ← new
                return true
            }
        输入参数一共有三个：
            1。p: 要修改的变量的指针。
            2。old: 旧值。
            3。new: 新值。
        CAS原语的逻辑解释：
            1。先比较一下变量 p 当前的值是不是等于 old
            2。如果等于，那就把变量 p 赋值为 new，并返回 true
            3。否则就不改变变量 p，并返回 false。
    FAA 原语：
        代码参考：
            function faa(p : pointer to int, inc : int) returns int {
                int value <- *location
                *p <- value + inc
                return value
            }
            解释代码：
                1。先获取变量 p 当前的值 value
                2。然后给变量 p 增加 inc，最后返回变量 p 之前的值 value。
    原语的特殊之处：
        1。如果我们用编程语言来实现，肯定是无法保证原子性的
        2。它们都是由计算机硬件，具体说就是 CPU 提供的实现，可以保证操作的原子性。
        3。原子操作具有不可分割性，也就不存在并发的问题
        4。在某些情况下，原语可以用来替代锁，实现一些即安全又高效的并发操作。

    CAS 版本的账户服务
        参考第18讲
        账户锁的版本执行流程：
            1。需要先获取锁，然后变更账户的值
            2。最后释放锁，完成一次转账。
        账户CAS 原语的实现：
            1。首先，它用 for 来做了一个没有退出条件的循环。
            2。在这个循环的内部，反复地调用 CAS 原语，来尝试给账户的余额 +1
            3。先取得账户当前的余额，暂时存放在变量 old 中，再计算转账之后的余额，保存在变量 new 中
            4。然后调用 CAS 原语来尝试给变量 balance 赋值。我们刚刚讲过，CAS 原语它的赋值操作是有前置条件的
            5。只有变量 balance 的值等于 old 时，才会将 balance 赋值为 new。
        两种情况：
            情形一：安全
                1。执行到第 3 条 CAS 原语时，没有其他线程同时改变了账户余额
                2。那我们是可以安全变更账户余额的，这个时候执行 CAS 的返回值一定是 true，转账成功
                3。就可以退出循环了。并且，CAS 这一条语句，它是一个原子操作，赋值的安全性是可以保证的。
            情形二：不安全
                1。有其他线程改变了账户余额，这个时候是无法保证数据安全的，不能再进行赋值。
                2。执行 CAS 原语时，由于无法通过比较的步骤，所以不会执行赋值操作。
                3。本次尝试转账失败，当前线程并没有对账户余额做任何变更
                4。由于返回值为 false，不会退出循环，所以会继续重试，直到转账成功退出循环。
        应用：
            类似于这样的逻辑：先读取数据，做计算，然后更新数据，无论这个计算是什么样的，都可以使用 CAS 原语来保护数据安全，
            FAA原语的区别：
                这个计算的逻辑只能局限于简单的加减法
        缺点：
            使用 CAS 原语反复重试赋值的方法，它是比较耗费 CPU 资源的
            原因：
                1。在 for 循环中，如果赋值不成功，是会立即进入下一次循环没有等待的。
                2。如果线程之间的碰撞非常频繁，经常性的反复重试，这个重试的线程会占用大量的 CPU 时间
                3。随之系统的整体性能就会下降。
        缓解方法：
            使用 Yield()， 大部分编程语言都支持 Yield() 这个系统调用
                作用：
                    Yield() 的作用是，告诉操作系统，让出当前线程占用的 CPU 给其他线程使用
                做法：
                    1。每次循环结束前调用一下 Yield() 方法，可以在一定程度上减少 CPU 的使用率，缓解这个问题
                    2。你也可以在每次循环结束之后，Sleep() 一小段时间，但是这样做的代价是，性能会严重下降。

19 | 数据压缩：时间换空间的游戏
    数据压缩：
        优点：
            数据压缩不仅能节省存储空间，还可以用于提升网络传输性能。
        应用：
            1。消息队列中使用
            2。日常开发的应用程序也可以使用
            例子：
                1。我们的程序要传输大量的数据，或者要在磁盘、数据库中存储比较大的数据2。
                2。都可以考虑使用数据压缩来提升性能，还能节省网络带宽和存储空间。
    什么情况适合使用数据压缩？
    情形一：
        首先你需要考虑，当前这个场景是不是真的适合使用数据压缩。
            例子：
                进程之间通过网络传输数据，这个数据是不是需要压缩呢
                分析：
                    1。不压缩直接传输需要的时间是： 传输未压缩数据的耗时。
                2。使用数据压缩需要的时间是： 压缩耗时 + 传输压缩数据耗时 + 解压耗时
    影响压缩的因素：
        1。比如数据的压缩率、网络带宽、收发两端服务器的繁忙程度等等。
        2。非常耗费 CPU 资源。
            现象一：
                    如果你的应用处理业务逻辑就需要耗费大量的 CPU 资源，就不太适合再进行压缩和解压。
            现象二：
                如果你的系统的瓶颈是磁盘的 IO 性能，CPU 资源又很闲，这种情况就非常适合在把数据写入磁盘前先进行压缩。
            现象三：
                如果你的系统读写比严重不均衡，你还要考虑，每读一次数据就要解压一次是不是划算。
    压缩本质：
        是资源的置换，是一个时间换空间，或者说是 CPU 资源换存储资源的游戏
        分析：
            1。每一个系统它都有一个性能瓶颈资源，可能是磁盘 IO，网络带宽，也可能是 CPU
            2。如果使用压缩，能用长板来换一些短板，那总体上就能提升性能，这样就是划算的。
            3。如果用了压缩之后，短板更短了，那就不划算了，不如不用。
    应该选择什么压缩算法？
        有损压缩：
            概念；
                主要是用来压缩音视频，它压缩之后是会丢失信息的
        无损压缩：
            概念：
                数据经过压缩和解压过程之后，与压缩之前相比，是 100% 相同的。
            例子：
                压缩前：
                    00000000000000000000
                压缩后：
                    20 个 0
        压缩算法：
            ZIP，GZIP，SNAPPY，LZ4 等等。
        考核指标：
            1。考虑数据的压缩率和压缩耗时
            2。压缩率越高的算法，压缩耗时也越高
        选择：
            1。如果是对性能要求高的系统，可以选择压缩速度快的算法，比如 LZ4
            2。如果需要更高的压缩比，可以考虑 GZIP 或者压缩率更高的 XZ 等算法。
        影响因素：
            1。压缩样本对压缩速度和压缩比的影响也是比较大的，同样大小的一段数字和一段新闻的文本
            2。即使是使用相同的压缩算法，压缩率和压缩时间的差异也是比较大的
        如何检测：
            在选择压缩算法的之前，用系统的样例业务数据做一个测试，可以帮助你找到最合适的压缩算法。
    如何选择合适的压缩分段？
        背景：
            1。大部分的压缩算法，他们的区别主要是，对数据进行编码的算法，压缩的流程和压缩包的结构大致一样的
            2。而在压缩过程中，你最需要了解的就是如何选择合适的压缩分段大小
        压缩过程：
            1。根据你的业务，选择合适的压缩分段，在压缩率、压缩速度和解压浪费之间找到一个合适的平衡。
            2。确定了如何对数据进行划分和压缩算法之后，就可以进行压缩了，压缩的过程就是用编码来替换原始数据的过程
            注意：
                压缩之后的压缩包就是由这个编码字典和用编码替换之后的数据组成的。
        压缩分段：
            如果要对流数据进行压缩，那必须把流数据划分成多个帧，一帧一帧的分段压缩。
            原因：
                1。缩算法在开始压缩之前，一般都需要对被压缩数据从头到尾进行一次扫描
                2。扫描的目的是确定如何对数据进行划分和编码，一般的原则是重复次数多
                3。占用空间大的内容，使用尽量短的编码，这样压缩率会更高。

        被压缩数据长度越大的影响：
            重码率会更高，压缩比也就越高。
            解释：
                1。比如我们这篇文章，可能出现了几十次“压缩”这个词，如果将整篇文章压缩，这个词的重复率是几十次，
                2。但如果我们按照每个自然段来压缩，那每段中这个词的重复率只有二三次。显然全文压缩的压缩率肯定高于分段压缩。
        分段越大的影响：
            1。实际上分段大小超过一定长度之后，再增加长度对压缩率的贡献就不太大了
            2。过大的分段长度，在解压缩的时候，会有更多的解压浪费。
            例子：
                1。一个 1MB 大小的压缩文件，即使你只是需要读其中很短的几个字节
                2。也不得不把整个文件全部解压缩，造成很大的解压浪费。
    Kafka 是如何处理消息压缩的？
        1。Kafka 是否开启压缩，这是可以配置，它也支持配置使用哪一种压缩算法。
            原因：
                不同的业务场景是否需要开启压缩，选择哪种压缩算法是不能一概而论的
        2。开启压缩时，Kafka 选择一批消息一起压缩，每一个批消息就是一个压缩分段。使用者通过参数配置每批消息的大小。
        3。在 Kafka 中，生产者生成一个批消息发给服务端，在服务端中是不会拆分批消息的。
        4。那按照批来压缩，意味着，在服务端也不用对这批消息进行解压，可以整批直接存储，
        5。然后整批发送给消费者。最后，批消息由消费者进行解压。
        优点：
            1。在服务端不用解压，就不会耗费服务端宝贵的 CPU 资源，
            2。同时还能获得压缩后，占用传输带宽小，占用存储空间小的这些好处
        扩展：
            1。在使用 Kafka 时，如果生产者和消费者的 CPU 资源不是特别吃紧，开启压缩后
            2。可以节省网络带宽和服务端的存储空间，提升总体的吞吐量，一般都是个不错的选择。

20 | RocketMQ Producer源码分析：消息生产的实现过程
    背景：
        1。在分析源代码的过程中，我们的首要目的就是搞清楚功能的实现原理
        2。最好能有敏锐的嗅觉，善于发现代码中优秀的设计和巧妙构思，学习、总结并记住这些方法
        3。在日常开发中，再遇到类似场景，你就可以直接拿来使用。
    注意：
        本节课的问题是非常清晰的，就是要搞清楚 Producer 是如何发消息的。
    问题：
        带着这个问题，接下来我们该如何分析源码呢？
    建议：
        先看一下单元测试用例
        原因：
            1。一般单元测试中，每一个用例就是测试代码中的一个局部或者说是一个小流程
    做法：
        首先我们先分析一下 RocketMQ 客户端的单元测试，看看 Producer 提供哪些 API，更重要的是了解这些 API 应该如何使用。
    前期花费大量时间编写测试用例
        作用：
            1。看似浪费时间，实际上会节省非常多后期联调测试、集成测试、以及上线后出现问题解决问题的时间，
            2。并且能够有效降低线上故障的概率，总体来说是非常划算的
        建议：
            你在日常进行开发的过程中，也多写一些测试用例，尽量把单元测试的覆盖率做到 50% 以上。
    具体流程参考：
        第20讲
21 | Kafka Consumer源码分析：消息消费的实现过程
22 | Kafka和RocketMQ的消息复制实现的差异点在哪？
    背景：
        1。把消息复制到多个节点上，不仅可以解决丢消息的问题，还可以保证消息服务的高可用。
        2。即使某一个节点宕机了，还可以继续使用其他节点来收发消息
    消息复制面临什么问题？
        消息队列的三大保证：
            1。高性能
                特点：
                    1。任何的复制实现方式，数据的写入性能一定是不如单节点的。
                        原因：
                            1。无论采用哪种复制实现方式，都需要数据被写入到多个节点之后再返回
                            2。性能一定是不如只写入一个节点的。
                    2。需要写入的节点数量越多，可用性和数据可靠性就越好，但是写入性能就越低，这是一个天然的矛盾
                    3。不管采用哪种复制方式，消费消息的时候，都只是选择多副本中一个节点去读数据而已，这和单节点消费并没有差别。
            2。高可用：
                方法：
                    当某个主节点宕机的时候，尽快再选出一个主节点来接替宕机的主节点。
                实现方式一：
                    自选举的方式：
                        由还存活的这些节点通过投票，来选出一个新的主节点，这种投票的实现方式
                    优点：
                        没有外部依赖，可以实现自我管理
                    缺点：
                        1。投票的实现都比较复杂，并且选举的过程是比较慢的，
                        2。几秒至几十秒都有可能，在选出新的主节点前，服务一直是不可用的。
                实现方式二：
                    第三方的管理服务来管理这些节点
                        发现某个主节点宕机的时候，由管理服务来指定一个新的主节点
                    缺点：
                        但引入管理服务会带来一系列问题，比如管理服务本身的高可用、数据一致性如何保证？
            3。数据一致性的保证
                要求：
                    1。不丢消息
                    2。严格顺序
                方法：
                    采用“主 - 从”的复制方式
                        原理：
                            1。数据先写入到主节点上，从节点只从主节点上复制数据，如果出现主从数据不一致的情况
                            2。必须以主节点上的数据为准
                        注意：
                            1。主节点它并不是不可变的，在很多的复制实现中，当主节点出现问题的时候
                            2。其他节点可以通过选举的方式，变成主节点
                            3。只要保证，在任何一个时刻，集群的主节点数不能超过 1 个，就可以确保数据一致性。
        注意：
            大部分复制的实现，都不会选择把消息写入全部副本再返回确认
            原因：
                1。这样虽然可以保证数据一致性，但是，一旦这些副本中有任何一个副本宕机，写入就会卡死了
            方法：
                如果只把消息写入到一部分副本就认为写入成功并返回确认，就可以解决卡死的问题，
                优点：
                    并且性能也会比写全部副本好很多。
        问题：
            到底写入多少个副本算写入成功呢？
            模式：
                假设我们的集群采用“一主二从三副本”的模式
            情形一：
                1。如果只要消息写入到两个副本就算是写入成功了
                2。那这三个节点最多允许宕机一个节点，否则就没法提供服务了
            情形二：
                1。如果说我们把要求写入的副本数量降到 1，只要消息写入到主节点就算成功了
                2。那三个节点中，可以允许宕机两个节点，系统依然可以提供服务，这个可用性就更好一些
                缺点：
                    1。主节点有一部分消息还没来得复制到任何一个从节点上
                    2。主节点就宕机了，这时候就会丢消息，数据一致性又没有办法保证了。
    RocketMQ 如何实现复制？
        传统的复制模式：
            1。复制的基本单位是 Broker，也就是服务端的进程
            2。复制采用的也是主从方式，通常情况下配置成一主一从，也可以支持一主多从。
        复制方式：
            1。异步复制
                概念：
                    消息先发送到主节点上，就返回“写入成功”，然后消息再异步复制到从节点上
                特点：
                    需要的副本数是 1
                问题：
                    如果采用异步复制的方式会不会丢消息呢？
                    答案：
                        并不会丢消息
                        原因：
                            1。在 RocketMQ 中，Broker 的主从关系是通过配置固定的，不支持动态切换
                            2。如果主节点宕机，生产者就不能再生产消息了，消费者可以自动切换到从节点继续进行消费。
                            3。这时候，即使有一些消息没有来得及复制到从节点上，这些消息依然躺在主节点的磁盘上
                            4。除非是主节点的磁盘坏了，否则等主节点重新恢复服务的时候
                            5。这些消息依然可以继续复制到从节点上，也可以继续消费，不会丢消息，消息的顺序也是没有问题的。
                优点：
                   比较好的性能和数据一致性。
                缺点
                    牺牲了可用性
                    问题：
                        那 RocketMQ 又是如何解决可用性的问题的呢？
                        分析：
                            一对儿主从节点可用性不行，多来几对儿主从节点不就解决了？
                        方法：
                            1。RocketMQ 支持把一个主题分布到多对主从节点上去，每对主从节点中承担主题中的一部分队列
                            2。如果某个主节点宕机了，会自动切换到其他主节点上继续发消息
                        优点：
                            既解决了可用性的问题，还可以通过水平扩容来提升 Topic 总体的性能。
                        缺点：
                            无法保证严格顺序
                            原因：
                                1。在需要保证消息严格顺序的场景下，由于在主题层面无法保证严格顺序，所以必须指定队列来发送消息
                                2。对于任何一个队列，它一定是落在一组特定的主从节点上，如果这个主节点宕机
                                3。其他的主节点是无法替代这个主节点的，否则就无法保证严格顺序
                            优化方法：
                                RocketMQ 引入 Dledger，使用新的复制方式，可以很好地解决这个问题
                                具体实现：
                                    1。Dledger 在写入消息的时候，要求至少消息复制到半数以上的节点之后，
                                    2。才给客户端返回写入成功，并且它是支持通过选举来动态切换主节点的。
                                例子：
                                    1。当主节点宕机的时候，2 个从节点会通过投票选出一个新的主节点来继续提供服务，相比主从的复制模式
                                        优点：
                                            解决了可用性的问题
                                    2。由于消息要至少复制到 2 个节点上才会返回写入成功，即使主节点宕机了，也至少有一个节点上的消息是和主节点一样的。
                                    3。Dledger 在选举时，总会把数据和主节点一样的从节点选为新的主节点
                                        优点：
                                            保证了数据的一致性，既不会丢消息，还可以保证严格顺序。
                                缺点：
                                    1。选举过程中不能提供服务
                                    2。最少需要 3 个节点才能保证数据一致性，3 节点时，只能保证 1 个节点宕机时可用
                                    3。如果 2 个节点同时宕机，即使还有 1 个节点存活也无法提供服务，资源的利用率比较低
                                    4。由于至少要复制到半数以上的节点才返回写入成功，性能上也不如主从异步复制的方式快。
            2。同步双写
                概念：
                    消息同步双写到主从节点上，主从都写成功，才返回“写入成功”。
                特点：
                    需要的副本数是 2
    Kafka 是如何实现复制的？
        背景：
            1。Kafka 中，复制的基本单位是分区
            2。每个分区的几个副本之间，构成一个小的复制集群
            3。Broker 只是这些分区副本的容器，所以 Kafka 的 Broker 是不分主从的。
        方法：
            分区的多个副本中也是采用一主多从的方式。
                1。Kafka 在写入消息的时候，采用的也是异步复制的方式
                2。消息在写入到主节点之后，并不会马上返回写入成功，而是等待足够多的节点都复制成功后再返回
                3。Kafka 使用 ZooKeeper 来监控每个分区的多个节点
                    1。如果发现某个分区的主节点宕机了，Kafka 会利用 ZooKeeper 来选出一个新的主节点
                        优点：
                            解决了可用性的问题
                    2。选举的时候，会从所有 ISR 节点中来选新的主节点，这样可以保证数据一致性。
                4。默认情况下，如果所有的 ISR 节点都宕机了，分区就无法提供服务了
                方法；
                    1。也可以选择配置成让分区继续提供服务
                    2。这样只要有一个节点还活着，就可以提供服务，代价是无法保证数据一致性，会丢消息。

23 | RocketMQ客户端如何在集群中找到正确的节点？
    NameServer 是如何提供服务的？
        NameServer：
            概念：
                1。是一个独立的进程，为 Broker、生产者和消费者提供服务。
                2。NameServer 支持只部署一个节点，也支持部署多个节点组成一个集群，这样可以避免单点故障。
                注意：
                    1。在集群模式下，NameServer 各节点之间是不需要任何通信的
                    2。也不会通过任何方式互相感知，每个节点都可以独立提供全部服务。
            功能：
                1。为客户端提供寻址服务，协助客户端找到主题对应的 Broker 地址
                2。负责监控每个 Broker 的存活状态。
        通信流程：
            1。每个 Broker 都需要和所有的 NameServer 节点进行通信
            2。当 Broker 保存的 Topic 信息发生变化的时候，它会主动通知所有的 NameServer 更新路由信息
            3。为了保证数据一致性，Broker 还会定时给所有的 NameServer 节点上报路由信息
            4。这个上报路由信息的 RPC 请求，也同时起到 Broker 与 NameServer 之间的心跳作用
            5。NameServer 依靠这个心跳来确定 Broker 的健康状态。
        客户端和NameServer通信：
            1。因为每个 NameServer 节点都可以独立提供完整的服务，所以，对于客户端来说，包括生产者和消费者
            2。只需要选择任意一个 NameServer 节点来查询路由信息就可以了
            3。客户端在生产或消费某个主题的消息之前，会先从 NameServer 上查询这个主题的路由信息
            4。然后根据路由信息获取到当前主题和队列对应的 Broker 物理地址
            5。再连接到 Broker 节点上进行生产或消费。
        实现了自动切换失效 Broker 的功能：
            1。如果 NameServer 检测到与 Broker 的连接中断了，NameServer 会认为这个 Broker 不再能提供服务
            2。NameServer 会立即把这个 Broker 从路由信息中移除掉，避免客户端连接到一个不可用的 Broker 上去
            3。而客户端在与 Broker 通信失败之后，会重新去 NameServer 上拉取路由信息
            4。然后连接到其他 Broker 上继续生产或消费消息，这样就实现了自动切换失效 Broker 的功能。
        源代码参考第22讲：

    NameServer 如何处理 Broker 注册的路由信息？
        1。根据 Broker 请求过来的路由信息，依次对比并更新 clusterAddrTable、brokerAddrTable、topicQueueTable
        2。brokerLiveTable 和 filterServerTable 这 5 个保存集群信息和路由信息的 Map 对象中的数据。
        3。在 RouteInfoManager 中，这 5 个 Map 作为一个整体资源，使用了一个读写锁来做并发控制
        优点：
            避免并发更新和更新过程中读到不一致的数据问题。
    客户端如何寻找 Broker？
        流程：
            1。初始化返回的 topicRouteData 后，获取读锁。
            2。在 topicQueueTable 中获取主题对应的队列信息，并写入返回结果中。
            3。遍历队列，找出相关的所有 BrokerName。
            4。遍历这些 BrokerName，从 brokerAddrTable 中找到对应的 BrokerData，并写入返回结果中。
            5。释放读锁并返回结果。

24 | Kafka的协调服务ZooKeeper：实现分布式系统的“瑞士军刀”
    ZooKeeper
        概念：
            1。是一个非常特殊的中间件
            2。提供了很多基本的操作，能实现什么样的功能更多取决于使用者如何来使用它。
            3。分布式的协调服务框架
        作用：
            1。解决分布式集群中，应用系统需要面对的各种通用的一致性问题
            2。ZooKeeper 本身可以部署为一个集群，集群的各个节点之间可以通过选举来产生一个 Leader
            3。选举遵循半数以上的原则，所以一般集群需要部署奇数个节点。
        核心功能：
            提供了一个分布式的存储系统，数据的组织方式类似于 UNIX 文件系统的树形结构
        应用：
            1。分布式系统中一些需要整个集群所有节点都访问的元数据
            2。比如集群节点信息、公共配置信息等，特别适合保存在 ZooKeeper 中。
        存储结构：
            1。每个节点被称为一个“ZNode”
            2。提供了一种特殊的 ZNode 类型：临时节点
                临时节点：
                    特点：
                        如果创建临时节点的客户端与 ZooKeeper 集群失去连接，这个临时节点就会自动消失
                    作用：
                        维护了 ZooKeeper 集群与所有客户端的心跳，通过判断心跳的状态，来确定是否需要删除客户端创建的临时节点。
        通知机制：
            订阅 ZNode 状态变化的通知机制Watcher，一旦 ZNode 或者它的子节点状态发生了变化，订阅的客户端会立即收到通知。
            作用：
                1。随时来获取业务集群中每个节点的存活状态，并且可以监控业务集群的节点变化情况
                2。当有节点上下线时，都可以收到来自 ZooKeeper 的通知。
        扩展：
            还可以用 ZooKeeper 来实现业务集群的快速选举、节点间的简单通信、分布式锁等很多功能。

    Kafka 在 ZooKeeper 中保存了哪些信息？
        参考第24讲

    Kafka 客户端如何找到对应的 Broker？
        参考第24讲

25 | RocketMQ与Kafka中如何实现事务？
    参考第25讲
26 | MQTT协议：如何支持海量的在线IoT设备?

27 | Pulsar的存储计算分离设计：全新的消息队列设计思路

28 | 答疑解惑（二）：我的100元哪儿去了？











