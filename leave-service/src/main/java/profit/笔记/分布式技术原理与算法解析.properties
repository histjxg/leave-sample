00 开篇词 | 四纵四横，带你透彻理解分布式技术
    问题：
        为什么知识碎片化、不成体系、见树不见林
    原因：
        1。在计算机学科课程设置中，分布式技术尴尬如同中小学中的性教育，重要但不受重视
        2。信息碎片化与信息孤立
    学习思路：
        思路一：
            1。首先为你梳理出一个脉络清晰、四纵四横的分布式核心技术知识体系
            2。然后从这个纵横的技术体系中抽取最核心、最普适的技术思想以及概念
            3。结合各种适用场景一一解析
            优点：
                1。帮助你找到核心知识点，并将这些知识点联系起来
                2。快速形成分布式核心技术的知识网络，从而形成自己的技术判断力，进而规划出自己的技术路线。
        思路二：
            1。从一个熟知的事物出发，进行浅出的讲解
            2。帮助你从已有知识体系扩展到新的知识体系
            优点：
                迅速、牢固地掌握分布式技术的核心知识点。
        思路三：
            透过表象深入讲解技术本质，而不是 case by case 地讲解
            优点：
                帮助你知其然并知其所以然，真正做到理解与运用时的举一反三。
        思路四：
            针对同一分布式问题的不同方法，从多维度、多角度进行对比、分析
            优点：
                1。方便你在工作中灵活选型，避免重复“造轮子”
                2。甚至可以综合权衡各种方法的优缺点，提炼发明出新的方法，最终做到活学活用。
    技术栈：
        四纵向：（自底向上）---基类
            资源：
                分布式资源池化
                    概念：
                        CPU，内存，网络等物理资源虚拟化，形成逻辑资源池以便统一管理
                    作用：
                        解决资源的分布式和异构性问题
            通信：
                分布式通信
                    概念：
                        通过消息队列，远程调用，订阅发布等方式，实现简单高效的通信
                    作用：
                        解决进程之间的分布式通信问题
            数据：
                分布式数据存储与管理
                    概念：
                        分布式数据库，分布式文件系统，分布式缓存，支持不同类型数据的存储和管理
                    作用：
                        解决数据的分布式和多元化问题
            计算：
                分布式计算
                    概念：
                        基于分布式的计算模式，包括批处理计算，离线计算，在线计算，融合计算，根据应用类型构建高效智能分布式计算框架
                    作用：
                        解决应用的分布式计算问题
            规律：
                在一定资源上，进行一定通信，通过一定计算，完成一定数据的加工和处理，从而对外提供特定的服务
        四横向：（从左向右）--派生类
            协同：
                分布式协同
                    概念：
                        分布式互斥，分布式选举，分布式共识，分布式事务等
                    作用：
                        解决分布式状态及数据的一致性问题
            调度：
                分布式调度
                    概念：
                        单体调度，双层调度，共享调度
                    作用：
                        解决资源与请求者的匹配问题
            追踪高可用：
                分布式追踪高可用
                    概念：
                        分布式日志搜集，分布式问题建模，负载均衡，流量控制，故障隔离，故障恢复
                    作用：
                        解决分布式定位，可靠性问题
            部署：
                分布式部署
                    概念：
                        自动化，智能化部署
                    作用：
                        解决服务分布式部署问题
        四纵四横的关系：
            如果我们把横向的 4 个层次比作派生类的话，那么纵向的 4 条技术线应该是它们的基类

01 | 分布式缘何而起：从单兵，到游击队，到集团军
    分布式起源
        单机模式：
            概念：
                所有应用程序和数据均部署在一台电脑或服务器上，由一台计算机完成所有的处理。
            例子：
                1。以铁路售票系统为例，铁路售票系统包括用户管理、火车票管理和订单管理等模块
                2。数据包括用户数据、火车票数据和订单数据等
                3。如果使用单机模式，那么所有的模块和数据均会部署在同一台计算机上
                4。也就是说数据存储、请求处理均由该计算机完成
            优点：
                功能、代码和数据集中，便于维护、管理和执行。
            缺点：
                1。单个计算机的处理能力取决于CPU 和内存等，但硬件的发展速度和性能是有限的
                2。性能受限、存在单点失效问题。
        游击队模式：
            概念：
                数据并行或数据分布式
            并行计算：
                概念：
                    采用消息共享模式使用多台计算机并行运行或执行多项任务
                原理：
                    每台计算机上执行相同的程序，将数据进行拆分放到不同的计算机上进行计算。
                目的：
                    数据进行拆分，任务程序在每台机器上运行
            思路：
                1。首先把单机模式中的应用和数据分离，才可能实现对数据的拆分
                    应用：
                        执行任务的程序
                            任务：
                                提交的请求
                                例子：
                                    用户提交的查询火车票、购买火车票的请求
                        例子：
                            铁路售票系统为例，运行在服务器上的用户管理、火车票管理和订单管理等程序就是应用
                2。在单机模式中，应用和数据均在一台计算机或服务器上，要实现数据的并行
                3。首先必须将应用和数据分离以便将应用部署到不同的计算机或服务器上
                4。然后，对同类型的数据进行拆分
                    例子：
                        不同计算机或服务器上的应用可以到不同的数据库上获取数据执行任务
            案例：
                以铁路售票系统的数据并行为例，主要包括两个步骤
                步骤一：
                    将应用与数据分离，分别部署到不同的服务器上：
                步骤二：
                    对数据进行拆分，比如把同一类型的数据拆分到两个甚至更多的数据库中
                    优点：
                        这样应用服务器上的任务就可以针对不同数据并行执行了。
            优点：
                1。可以利用多台计算机并行处理多个请求，使得我们可以在相同的时间内完成更多的请求处理
                2。解决了单机模式的计算效率瓶颈问题。
            缺点：
                问题一：
                    1。相同的应用部署到不同的服务器上，当大量用户请求过来时
                    2。如何能比较均衡地转发到不同的应用服务器上呢？
                    方法：
                        设计一个负载均衡器
                问题二：
                    当请求量较大时，对数据库的频繁读写操作，使得数据库的 IO 访问成为瓶颈
                    方法：
                        1。读写分离
                        2。读数据库只接收读请求，写数据库只接收写请求
                        3。当然读写数据库之间要进行数据同步，以保证数据一致性。
                问题三：
                    当有些数据成为热点数据时，会导致数据库访问频繁，压力增大。
                    方法：
                        缓存机制，将热点数据加载到缓存中，一方面可以减轻数据库的压力，另一方面也可以提升查询效率。
                问题四：
                    对提升单个任务的执行性能及降低时延无效。
        集团军模式：
            概念：
                任务并行或任务分布式
                    解释：
                        将单个复杂的任务拆分为多个子任务，从而使得多个子任务可以在不同的计算机上并行执行。
            优点：
                提供了更好的性能、扩展性、可维护性
            案例：
                仍以铁路售票系统为例，任务并行首先是对应用进行拆分
                分析：
                    1。比如按照领域模型将用户管理、火车票管理、订单管理拆分成多个子系统分别运行在不同的计算机或服务器上
                    2。原本包括用户管理、火车票管理和订单管理的一个复杂任务，被拆分成了多个子任务在不同计算机或服务器上执行
                核心步骤：
                    1。首先将单任务拆分成多个子任务
                    2。然后让多个子任务并行执行
            缺点：
                设计上的复杂性问题
    分布式：
        概念：
            将相同或相关的程序运行在多台计算机上，从而实现特定目标的一种计算方式。
        扩展：
            从这个定义来看，数据并行、任务并行其实都可以算作是分布式的一种形态
        驱动力量：
            我们对于性能、可用性及可扩展性的不懈追求。

02 | 分布式系统的指标：啥是分布式的三围
    分布式系统的指标
        性能（Performance）
            概念：
                主要用于衡量一个系统处理各种任务的能力
            指标：
                吞吐量：
                    概念：
                        系统在一定时间内可以处理的任务数
                    作用：
                        可以非常直接地体现一个系统的性能
                    例子：
                        1。好比在客户非常多的情况下，要评判一个银行柜台职员的办事效率，
                        2。你可以统计一下他在 1 个小时内接待了多少客户
                    指标：
                        QPS（Queries Per Second）
                            概念：
                                查询数每秒，用于衡量一个系统每秒处理的查询数
                            应用：
                                用于读操作
                            特点：
                                越高说明对读操作的支持越好
                        TPS（Transactions Per Second）
                            概念：
                                事务数每秒，用于衡量一个系统每秒处理的事务数。
                            应用：
                                通常对应于写操作
                            特点：
                                越高说明对写操作的支持越好
                        BPS（Bits Per Second）
                            概念：
                                即比特数每秒，用于衡量一个系统每秒处理的数据量
                            应用：
                                对于一些网络系统、数据管理系统，我们不能简单地按照请求数或事务数来衡量其性能
                                    原因：
                                        请求与请求、事务与事务之间也存在着很大的差异
                                    例子：
                                        有的事务大需要写入更多的数据
                                    方法：
                                        BPS 更能客观地反应系统的吞吐量。
                响应时间：
                    概念：
                        一个请求或输入需要花费的时间
                    作用：
                        直接影响到用户体验，对于时延敏感的业务非常重要
                    例子：
                        用户搜索导航，特别是用户边开车边搜索的时候，如果响应时间很长，就会直接导致用户走错路。
                完成时间：
                    概念：
                        系统真正完成一个请求或处理需要花费的时间
                    缩短时间方法：
                        任务并行，缩短整个任务的完成时间。
                        应用：
                            需要计算海量数据或处理大规模任务时，用户对完成时间的感受非常明显。

        资源占用（Resource Usage）
            概念：
                一个系统提供正常能力需要占用的硬件资源，比如 CPU、内存、硬盘等。
            空载资源占用：
                概念：
                    一个系统在没有任何负载时的资源占用
                作用：
                    体现了这个系统自身的资源占用情况
                例子：
                    1。你在手机上安装一个 App，安装的时候通常会提示你有多少 KB，这就是该 App 的空载硬盘资源占用
                    2。对于同样的功能，空载资源占用越少，说明系统设计越优秀，越容易被用户接受。
            满载资源占用：
                概念：
                    一个系统满额负载时的资源占用
                作用：
                    体现了这个系统全力运行时占用资源的情况，也体现了系统的处理能力
                例子：
                    同样的硬件配置上，运行的业务越多，资源占用越少，说明这个系统设计得越好。

        可用性（Availability）
            概念：
                指的是系统在面对各种异常时可以正确提供服务的能力
            作用：
                是分布式系统的一项重要指标，衡量了系统的鲁棒性，是系统容错能力的体现。
            衡量方式一：
                系统停止服务的时间与总的时间之比
                例子：
                    1。假设一个网站总的运行时间是 24 小时，在 24 小时内，如果网站故障导致不可用的时间是 4 个小时
                    2。那么系统的可用性就是 4/24=0.167，也就是 0.167 的比例不可用，或者说 0.833 的比例可用。

            衡量方式二：
                某功能的失败次数与总的请求次数之比
                例子一：
                    比如对网站请求 1000 次，其中有 10 次请求失败，那么可用性就是 99%。
                例子二：
                    1。可能经常在一个系统的宣传语中见到或听到 3 个 9（或 3N，3 Nines）、5 个 9（或 9N，9 Nines）
                    2。这些宣传语中所说的 3 个 9、5 个 9，实际上就是系统厂商对可用性的一种标榜
                    3。表明该系统可以在 99.9% 或 99.999% 的时间里能对外无故障地提供服务。
            可靠性：
                概念：
                    用来表示一个系统完全不出故障的概率
                应用：
                    更多地用在硬件领域
                区别：
                    而可用性则更多的是指在允许部分组件失效的情况下，一个系统对外仍能正常提供服务的概率。

        可扩展性（Scalability）
            概念：
                分布式系统通过扩展集群机器规模提高系统性能 (吞吐、响应时间、 完成时间)、存储容量、计算能力的特性，是分布式系统的特有性质。
            初衷：
                利用集群多机的能力处理单机无法解决的问题。
                局限性：
                    完成某一具体任务所需要的机器数目，即集群规模，取决于单个机器的性能和任务的要求。
            案例：
                当任务的需求随着具体业务不断提高时
                方法：
                    1。除了升级系统的性能做垂直 / 纵向扩展外
                        具体实现：
                            增加单机的硬件能力，比如 CPU 增强、内存增大等
                    2。另一个做法就是通过增加机器的方式去水平 / 横向扩展系统规模。
                        具体实现：
                            增加计算机数量。
            指标：
                加速比
                    概念：
                        一个系统进行扩展后相对扩展前的性能提升。
                    例子一：
                        如果你的扩展目标是为了提高系统吞吐量，则可以用扩展后和扩展前的系统吞吐量之比进行衡量。
                    例子二：
                        如果你的目标是为了缩短完成时间，则可以用扩展前和扩展后的完成时间之比进行衡量。

    不同场景下分布式系统的指标
        背景：
            1。我们都希望自己的分布式系统是高性能、高可用、高扩展和低资源占用的
            2。但出于硬件成本、开发效率等因素的约束，我们无法在性能、可用性、可靠性和资源占用做到面面俱到
            3。因此，在不同的业务场景中，设计者们需要有所取舍。
        参考：
            第02讲不同场景下分布式系统的指标.png

03 | 分布式互斥：有你没我，有我没你
    分布式互斥：
        概念：
            同一时刻只能有一个程序能够访问这种资源，在分布式系统里，这种排他性的资源访问方式
        例子：
            1。你正在一家餐厅使用自助咖啡机泡制咖啡，突然有个人过来挪走了你的杯子，开始泡制他自己的咖啡
            2。你耐着性子等他操作完，继续泡制自己的咖啡。结果你开始没多久，他又回来中断了你泡制咖啡的过程。
            3。相信要不了几个回合，你和他就会上演一场“有你没我，有我没你”的格斗了。
        临界资源：
            概念：
                互斥访问的共享资源
    集中式算法：(霸道总裁)
        原理：
            1。引入一个协调者程序，得到一个分布式互斥算法
            2。这个互斥算法，就是我们所说的集中式算法，也可以叫做中央服务器算法
            原因：
                协调者代表着集中程序或中央服务器。
            流程：
                每个程序在需要访问临界资源时，先给协调者发送一个请求
                情形一：
                    如果当前没有程序使用这个资源，协调者直接授权请求程序访问；
                情形二：
                    否则，按照先来后到的顺序为请求程序“排一个号”。
                        1。如果有程序使用完资源，则通知协调者，协调者从“排号”的队列里取出排在最前面的请求，并给它发送授权消息
                        2。拿到授权消息的程序，可以直接去访问临界资源。
        例子：
            1。程序 1、2、3、4 为普通运行程序，另一个程序为协调者
            2。当程序 2 和程序 4 需要使用临界资源时，它们会向协调者发起申请，请求协调者授权。
            3。不巧的是，程序 3 正在使用临界资源
            分析：
                1。协调者根据程序 2 和 4 的申请时间顺序，依次将它们放入等待队列。
                2。在这个案例里，程序 4 的申请时间早于程序 2，因此排在程序 2 的前面。
                3。程序 3 使用完临界资源后，通知协调者释放授权
                4。此时，协调者从等待队列中取出程序 4，并给它发放授权。这时，程序 4 就可以使用临界资源了。
        现象：
            一个程序完成一次临界资源访问，需要如下几个流程和消息交互：
                1。协调者发送请求授权信息，1 次消息交互；
                2。协调者向程序发放授权信息，1 次消息交互；
                3。程序使用完临界资源后，向协调者发送释放授权，1 次消息交互。
            结论：
                每个程序完成一次临界资源访问，需要进行 3 次消息交互。
        优点：
            直观、简单、信息交互量少、易于实现，并且所有程序只需和协调者通信，程序之间无需通信
        缺点：
            一方面：
                协调者会成为系统的性能瓶颈
                例子：
                    1。如果有 100 个程序要访问临界资源，那么协调者要处理 100*3=300 条消息
                    2。也就是说，协调者处理的消息数量会随着需要访问临界资源的程序数量线性增加。
            另一方面：
                容易引发单点故障问题：
                现象：
                    协调者故障，会导致所有的程序均无法访问临界资源，导致整个系统不可用。
        应用：
            在可靠性和性能有一定保障的情况下，集中式算法可以适用于比较广泛的应用场景。
            例子：
                1。比如中央服务器计算能力强、性能高、故障率低
                2。或者中央服务器进行了主备备份，主故障后备可以立马升为主，且数据可恢复的情况下

    分布式算法:(民主协商)
        原理：
            1。当一个程序要访问临界资源时，先向系统中的其他程序发送一条请求消息
                请求消息：
                    需要包含所请求的资源、请求者的 ID，以及发起请求的时间。
            2。在接收到所有程序返回的同意消息后，才可以访问临界资源
        概念：
            民主协商法。在分布式领域中，我们称之为分布式算法，或者使用组播和逻辑时钟的算法。
        例子：
            1。程序 1、2、3 需要访问共享资源 A
            2。在时间戳为 8 的时刻，程序 1 想要使用资源 A，于是向程序 2 和 3 发起使用资源 A 的申请，希望得到它们的同意
            3。在时间戳为 12 的时刻，程序 3 想要使用资源 A，于是向程序 1 和 2 发起访问资源 A 的请求。
            分析：
                程序2：
                    此时程序 2 暂时不访问资源 A，因此同意了程序 1 和 3 的资源访问请求
                程序 3：
                    1。对于程序 3 来说，由于程序 1 提出请求的时间更早
                    2。因此同意程序 1 先使用资源，并等待程序 1 返回同意消息。
                程序1：
                    1。程序 1 接收到其他所有程序的同意消息之后，开始使用资源 A。
                    2。当程序 1 使用完资源 A 后，释放使用权限
                    3。向请求队列中需要使用资源 A 的程序 3 发送同意使用资源的消息，并将程序 3 从请求队列中删除。
                程序3：
                    程序 3 收到了其他所有程序的同意消息，获得了使用资源 A 的权限，开始使用临界资源 A 的旅程
            现象：
                一个程序完成一次临界资源的访问，需要进行如下的信息交互：
                1。向其他 n-1 个程序发送访问临界资源的请求，总共需要 n-1 次消息交互
                2。需要接收到其他 n-1 个程序回复的同意消息，方可访问资源，总共需要 n-1 次消息交互。
            结论：
                1。一个程序要成功访问临界资源，至少需要 2*(n-1) 次消息交互
                2。现在系统中的 n 个程序都要访问临界资源，则会同时产生 2n(n-1) 条消息
                注意：
                    1。在大型系统中使用分布式算法，消息数量会随着需要访问临界资源的程序数量呈指数级增加
                    2。容易导致高昂的“沟通成本”。
        特点：
            是一个“先到先得”和“投票全票通过”的公平访问机制，让每个程序按时间顺序公平地访问资源，
        优点：
            简单粗暴、易于实现
        缺点：
            通信成本较高，可用性也比集中式算法低
            一方面：
                1。当系统内需要访问临界资源的程序增多时，容易产生“信令风暴”
                2。也就是程序收到的请求完全超过了自己的处理能力，而导致自己正常的业务无法开展。
            另一方面：
                1。一旦某一程序发生故障，无法发送同意消息，那么其他程序均处在等待回复的状态中
                2。使得整个系统处于停滞状态，导致整个系统不可用
            优化方法：
                如果检测到一个程序故障，则直接忽略这个程序，无需再等待它的同意消息
                例子：
                    一个人离开餐厅了，那你在使用咖啡机前，也无需征得他的同意。
                缺点：
                    每个程序都需要对其他程序进行故障检测，这无疑带来了更大的复杂性。
        应用：
            临界资源使用频度较低，且系统规模较小的场景
            场景一：
                1。分布式算法适合节点数目少且变动不频繁的系统，且由于每个程序均需通信交互，
                2。运行在局域网中的分布式文件系统，具有 P2P 结构的系统等。
            场景二：
                1。Hadoop 是我们非常熟悉的分布式系统，其中的分布式文件系统 HDFS 的文件修改就是一个典型的应用分布式算法的场景。
                2。处于同一个局域网内的计算机 1、2、3 中都有同一份文件的备份信息，且它们可以相互通信。这个共享文件，就是临界资源。
                3。当计算机 1 想要修改共享的文件时，需要进行如下操作：
                    1。计算机 1 向计算机 2、3 发送文件修改请求；
                    2。计算机 2、3 发现自己不需要使用资源，因此同意计算机 1 的请求；
                    3。计算机 1 收到其他所有计算机的同意消息后，开始修改该文件；
                    4。计算机 1 修改完成后，向计算机 2、3 发送文件修改完成的消息，并发送修改后的文件数据；
                    5。计算机 2 和 3 收到计算机 1 的新文件数据后，更新本地的备份文件。

    令牌环算法(轮值 CEO)
        原理：
            1。所有程序构成一个环结构，令牌按照顺时针（或逆时针）方向在程序之间传递
            2。收到令牌的程序有权访问临界资源，访问完成后将令牌传送到下一个程序；
            3。若该程序不需要访问临界资源，则直接把令牌传送给下一个程序。
        概念：
            1。在分布式领域，这个算法叫作令牌环算法，也可以叫作基于环的算法
            2。为了便于理解与记忆，你完全可以把这个方法形象地理解为轮值 CEO 法。
        缺点：
            不管环中的程序是否想要访问资源，都需要接收并传递令牌，所以也会带来一些无效通信，降低了系统的实时性。
            例子：
                1。假设系统中有 100 个程序，那么程序 1 访问完资源后，即使其它 99 个程序不需要访问
                2。也必须要等令牌在其他 99 个程序传递完后，才能重新访问资源

        优点：
            公平性高，在改进单点故障后，稳定性也很高
            例子：
                1。对于集中式和分布式算法都存在的单点故障问题
                2。在令牌环中，若某一个程序（例如上图的无人机 2）出现故障，则直接将令牌传递给故障程序的下一个程序
                3。（例如，上图中无人机 1 直接将令牌传送给无人机 3）
                4。从而很好地解决单点故障问题，提高系统的健壮性，带来更好的可用性
            不足：
                要求每个程序都要记住环中的参与者信息，这样才能知道在跳过一个参与者后令牌应该传递给谁。
        应用：
            适用于系统规模较小，并且系统中每个程序使用临界资源的频率高且使用时间比较短的场景。
        案例：
            1。令牌环算法非常适合通信模式为令牌环方式的分布式系统，
            2。例如移动自组织网络系统。一个典型的应用场景就是无人机通信。
            分析：
                1。无人机在通信时，工作原理类似于对讲机，同一时刻只能发送信息或接收信息
                2。因此，通信中的上行链路（即向外发送信息的通信渠道）是临界资源。
            内容：
                1。所有的无人机组成一个环，按照顺时针方向通信
                2。每个无人机只知道其前一个发送信息的无人机，和后一个将要接收信息的无人机
                3。拥有令牌的无人机可以向外发送信息，其他无人机只能接收数据。
                4。拥有令牌的无人机通信完成后，会将令牌传送给后一个无人机。
            现象：
                1。所有的无人机轮流通信并传输数据，从而消除了多个无人机对通信资源的争夺
                2。使得每个无人机都能接收到其他无人机的信息，降低了通信碰撞导致的丢包率
                3。保证了网络通信的稳定性，提高了多个无人机之间的协作效率。

    有适合大规模系统中的分布式互斥算法吗？
        注意：
            上面提到的集中式、分布式和令牌环 3 个互斥算法，都不适用于规模过大、节点数量过多的系统
        问题：
            什么样的互斥算法适用于大规模系统呢？
        分析：
            由于大规模系统的复杂性，我们很自然地想到要用一个相对复杂的互斥算法
        答案：
            1。时下有一个很流行的互斥算法，两层结构的分布式令牌环算法
            2。把整个广域网系统中的节点组织成两层结构，可以用于节点数量较多的系统，或者是广域网系统。
                广域网由多个局域网组成:
                    1.因此在该算法中，局域网是较低的层次
                    2.广域网是较高的层次。
            具体做法：
                每个局域网中包含若干个局部进程和一个协调进程
                局部进程
                    局部进程在逻辑上组成一个环形结构，在每个环形结构上有一个局部令牌 T 在局部进程间传递
                协调进程：
                    1。局域网与局域网之间通过各自的协调进程进行通信，这些协调进程同样组成一个环结构，这个环就是广域网中的全局环
                    2。在这个全局环上，有一个全局令牌在多个协调进程间传递。

04 | 分布式选举：国不可一日无君
    集群：
        概念：
            一般是由两个或两个以上的服务器组建而成，每个服务器都是一个节点
            例子：
                1。数据库集群：数据库集群提供了读写功能
                2。管理集群：提供了管理、故障恢复等功能。
        问题：
            对于一个集群来说，多个节点到底是怎么协同，怎么管理的呢
            例子：
                数据库集群，如何保证写入的数据在每个节点上都一致呢？
        思路：
            1。选一个“领导”来负责调度和管理其他节点就可以了啊。
            2。这个“领导”，在分布式中叫做主节点
            3。而选“领导”的过程在分布式领域中叫作分布式选举。
    分布式选举：
        主节点：
            概念：
                1。在一个分布式集群中负责对其他节点的协调和管理
                2。其他节点都必须听从主节点的安排。
            作用：
                1。主节点的存在，就可以保证其他节点的有序运行
                2。以及数据库集群中的写入数据在每个节点上的一致性。
                一致性：
                    概念：
                        数据在每个集群节点中都是一样的，不存在不同的情况。
            问题：
                如果主故障了，集群就会天下大乱
                例子一：
                    就好比一个国家的皇帝驾崩了，国家大乱一样
                例子二：
                    比如，数据库集群中主节点故障后，可能导致每个节点上的数据会不一致。
                选举：(方法)
                    作用：
                        就是选出一个主节点，由它来协调和管理其他节点，以保证集群有序运行和节点间数据的一致性。

    分布式选举的算法
        1。Bully 算法(长者为大)
            概念：
                Bully 算法是一种霸道的集群选主算法
                    原因：
                        选举原则是“长者”为大，即在所有活着的节点中，选取 ID 最大的节点作为主节点。
            节点的角色：
                1。普通节点
                    场景：
                        1。初始化时，所有节点都是平等的，都是普通节点，并且都有成为主的权利
                2。主节点
                    场景：
                        1。当选主成功后，有且仅有一个节点成为主节点，其他所有节点都是普通节点
                        2。当且仅当主节点故障或与其他节点失去联系后，才会重新选主。
            选举过程中用到的消息：
                1。Election 消息，用于发起选举；
                2。Alive 消息，对 Election 消息的应答；
                3。Victory 消息，竞选成功的主节点向其他节点发送的宣誓主权的消息。
            原则：
                “长者为大”
                假设条件是：
                    集群中每个节点均知道其他节点的 ID
            具体的选举过程：
                步骤一：
                    1。集群中每个节点判断自己的 ID 是否为当前活着的节点中 ID 最大的
                    2。如果是，则直接向其他节点发送 Victory 消息，宣誓自己的主权；
                步骤二：
                    1。如果自己不是当前活着的节点中 ID 最大的
                    2。则向比自己 ID 大的所有节点发送 Election 消息，并等待其他节点的回复；
                步骤三：
                    1。若在给定的时间范围内，本节点没有收到其他节点回复的 Alive 消息，则认为自己成为主节点
                    2。并向其他节点发送 Victory 消息，宣誓自己成为主节点
                    3。若接收到来自比自己 ID 大的节点的 Alive 消息，则等待其他节点发送 Victory 消息；
                步骤四：
                    1。若本节点收到比自己 ID 小的节点发送的 Election 消息
                    2。则回复一个 Alive 消息，告知其他节点，我比你大，重新选举。
            应用：
                目前已经有很多开源软件采用了 Bully 算法进行选主
                例子：
                    比如 MongoDB 的副本集故障转移功能
                    说明：
                        1。MongoDB 的分布式选举中，采用节点的最后操作时间戳来表示 ID
                        2。时间戳最新的节点其 ID 最大，也就是说时间戳最新的、活着的节点是主节点。
            特点：
                1。选择特别霸道和简单，谁活着且谁的 ID 最大谁就是主节点
                2。其他节点必须无条件服从
            优点：
                选举速度快、算法复杂度低、简单易实现。
            缺点：
                1。需要每个节点有全局的节点信息，因此额外信息存储较多
                2。其次，任意一个比当前主节点 ID 大的新节点或节点故障后恢复加入集群的时候，都可能会触发重新选举，成为新的主节点
                3。如果该节点频繁退出、加入集群，就会导致频繁切主。

        2。Raft 算法(民主投票)
            概念：
                1。Raft 算法是典型的多数派投票选举算法，其选举机制与我们日常生活中的民主投票机制类似，核心思想是“少数服从多数”
                2。也就是说，Raft 算法中，获得投票最多的节点成为主。
            集群的节点的角色：
                1。Leader
                    概念：
                        即主节点，同一时刻只有一个 Leader，负责协调和管理其他节点；
                2。Candidate
                    概念：
                        即候选者，每一个节点都可以成为 Candidate，节点在该角色下才可以被选为新的 Leader；
                3。Follower
                    概念：
                        Leader 的跟随者，不可以发起选举
            选举过程：
                第一步：
                    初始化时，所有节点均为 Follower 状态
                第二步：
                    开始选主时，所有节点的状态由 Follower 转化为 Candidate，并向其他节点发送选举请求。
                第三步：
                    1。其他节点根据接收到的选举请求的先后顺序，回复是否同意成为主
                    2。这里需要注意的是，在每一轮选举中，一个节点只能投出一张票。
                第四步：
                    1。若发起选举请求的节点获得超过一半的投票，则成为主节点
                    2。其状态转化为 Leader，其他节点的状态则由 Candidate 降为 Follower
                    3。Leader 节点与 Follower 节点之间会定期发送心跳包，以检测主节点是否活着。
                第五步：
                    1。当 Leader 节点的任期到了，即发现其他服务器开始下一轮选主周期时
                    2。Leader 节点的状态由 Leader 降级为 Follower，进入新一轮选主。
            注意：
                每一轮选举，每个节点只能投一次票
                例子一：
                    1。这种选举就类似人大代表选举，正常情况下每个人大代表都有一定的任期
                    2。任期到后会触发重新选举，且投票者只能将自己手里唯一的票投给其中一个候选者
                    对应到 Raft 算法中
                        1。选主是周期进行的，包括选主和任值两个时间段，
                            选主阶段：
                                对应投票阶段
                            任值阶段：
                                对应节点成为主之后的任期
                        2。例外的时候，如果主节点故障，会立马发起选举，重新选出一个主节点。
                例子二：
                    1。Google 开源的 Kubernetes，擅长容器管理与调度，为了保证可靠性，通常会部署 3 个节点用于数据备份
                    2。这 3 个节点中，有一个会被选为主，其他节点作为备。Kubernetes 的选主采用的是开源的 etcd 组件
                    3。而，etcd 的集群管理器 etcds，是一个高可用、强一致性的服务发现存储仓库
                    4。就是采用了 Raft 算法来实现选主和一致性的。
            优点：
                1。选举速度快、算法复杂度低、易于实现
                2。该算法选举稳定性比 Bully 算法好
                原因：
                    1。当有新节点加入或节点故障恢复后，会触发选主
                    2。但不一定会真正切主，除非新节点或故障后恢复的节点获得投票数过半，才会导致切主。
            缺点：
                要求系统内每个节点都可以相互通信，且需要获得过半的投票数才能选主成功，因此通信量大

        3。ZAB 算法(具有优先级的民主投票)
            概念：
                1。ZAB（ZooKeeper Atomic Broadcast）选举算法是为 ZooKeeper 实现分布式协调功能而设计的
                2。相较于 Raft 算法的投票机制：
                    1。ZAB 算法增加了通过节点 ID 和数据 ID 作为参考进行选主
                    2。节点 ID 和数据 ID 越大，表示数据越新，优先成为主
                3。相比较于 Raft 算法
                    1。ZAB 算法尽可能保证数据的最新性
                    2。所以，ZAB 算法可以说是对 Raft 算法的改进

            集群中每个节点拥有 3 种角色：
                1。Leader
                    概念：
                        主节点；
                2。Follower
                    概念：
                        跟随者节点；
                3。Observer
                    概念：
                        观察者，无投票权。
            选举过程中，集群中的节点拥有 4 个状态：
                1。Looking 状态：
                    概念：
                        即选举状态
                    说明：
                        当节点处于该状态时，它会认为当前集群中没有 Leader，因此自己进入选举状态。
                2。Leading 状态：
                    概念：
                        即领导者状态
                    说明：
                        表示已经选出主，且当前节点为 Leader。
                3。Following 状态：
                    概念：
                        即跟随者状态
                    说明：
                        集群中已经选出主后，其他非主节点状态更新为 Following，表示对 Leader 的追随。
                4。Observing 状态：
                    概念：
                        即观察者状态
                    说明：
                        表示当前节点为 Observer，持观望态度，没有投票权和选举权。
            投票过程中节点的特点：
                每个节点都有一个唯一的三元组 (server_id, server_zxID, epoch)
                    1。server_id
                        概念：
                            表示本节点的唯一 ID
                    2。server_zxID
                        概念：
                            表示本节点存放的数据 ID，数据 ID 越大表示数据越新，选举权重越大
                    3。epoch
                        概念：
                            表示当前选取轮数，一般用逻辑时钟表示。
            核心：
                1。少数服从多数，ID 大的节点优先成为主
                2。选举过程中通过 (vote_id, vote_zxID) 来表明投票给哪个节点
                    1。vote_id
                        概念：
                            表示被投票节点的 ID
                    2。vote_zxID
                        概念：
                            表示被投票节点的服务器 zxID
            选主的原则：
                1。server_zxID 最大者成为 Leader
                2。若 server_zxID 相同，则 server_id 最大者成为 Leader。
            案例：
                1。我以 3 个 Server 的集群为例，此处每个 Server 代表一个节点
                2。与你介绍 ZAB 选主的过程。
                    第一步：
                        1。当系统刚启动时，3 个服务器当前投票均为第一轮投票，即 epoch=1，且 zxID 均为 0
                        2。此时每个服务器都推选自己，并将选票信息 <epoch, vote_id, vote_zxID> 广播出去
                    第二步：
                        1。根据判断规则，由于 3 个 Server 的 epoch、zxID 都相同
                        2。因此比较 server_id，较大者即为推选对象
                        3。因此 Server 1 和 Server 2 将 vote_id 改为 3，更新自己的投票箱并重新广播自己的投票。
                    第三步：
                        1。此时系统内所有服务器都推选了 Server 3
                        2。因此 Server 3 当选 Leader，处于 Leading 状态，向其他服务器发送心跳包并维护连接
                        3。Server1 和 Server2 处于 Following 状态。
            优点：
                1。ZAB 算法性能高，对系统无特殊要求
                2。选举稳定性比较好
                    说明：
                        1。当有新节点加入或节点故障恢复后，会触发选主，但不一定会真正切主
                        2。除非新节点或故障后恢复的节点数据 ID 和节点 ID 最大，且获得投票数过半，才会导致切主。

            缺点：
                1。容易出现广播风暴
                说明：
                    1。采用广播方式发送信息，若节点中有 n 个节点
                    2。每个节点同时广播，则集群中信息量为 n*(n-1) 个消息
                2。选举时间相对较长
                    原因
                        1。且除了投票，还增加了对比节点 ID 和数据 ID
                        2。这就意味着还需要知道所有节点的 ID 和数据 ID
        三种选举算法的对比分析
            参考：
                第04讲三种选举算法的对比分析.png
        扩展：
            问题：
                为什么“多数派”选主算法通常采用奇数节点，而不是偶数节点呢？
            答案：
                1。如果现在采用偶数节点集群，当两个节点均获得一半投票时
                2。在这种情况下，无法选出主，必须重新投票选举
                3。但即使重新投票选举，两个节点拥有相同投票数的概率也会很大。
                4。多数派选主算法通常采用奇数节点。
            例子：
                大家通常看到 ZooKeeper、 etcd、Kubernetes 等开源软件选主均采用奇数节点的一个关键原因。

05 | 分布式共识：存异求同
    背景：
        1。分布式选举问题：
            是从多个节点中选出一个主节点是从多个节点中选出一个主节点
            1。相关的选举方法几乎都有一个共同特点：
                每个节点都有选举权和被选举权
            2。大部分选举方法采用多数策略
                说明：
                    也就是说一个节点只有得到了大部分节点的同意或认可才能成为主节点，然后主节点向其他节点宣告主权。
        2。这个选主过程就是一个分布式共识问题
            原因：
                集群节点“存异”：
                    每个节点在选出主节点之前都可以认为自己会成为主节点
                求同：
                    通过选举的过程选出主节点，让所有的节点都认可该主节点
        3。分布式共识的本质就是“存异求同”。
        分析：
            从本质上看，分布式选举问题，其实就是传统的分布式共识方法，主要是基于多数投票策略实现的
            案例：
                用于分布式在线记账一致性问题中
            缺点：
                1。那么记账权通常会完全掌握到主节点的手里，这使得主节点非常容易造假，且存在性能瓶颈。
                2。因此，分布式选举不适用于分布式在线记账的一致性问题
            方法：
                分布式共识技术
    分布式在线记账：
        概念：
            1。指在没有集中的发行方，也就是没有银行参与的情况下
            2。任意一台接入互联网的电脑都能参与买卖，所有看到该交易的服务器都可以记录这笔交易
            3。并且记录信息最终都是一致的，以保证交易的准确性
        问题：
            如何保证交易的一致性，就是该场景下的分布式共识问题。
    分布式共识：
        例子：
            1。现在有 5 台服务器，分散在美国华盛顿、英国伦敦、法国巴黎、中国北京、中国上海，分别对应着用户{A,B,C,D,E}。
            2。现在，用户 A 给用户 B 转了 100 元。
        传统方法：
            我们通过银行进行转账并记录该笔交易
        分布式在线记账方法中：
            没有银行这样的一个集中方，而是由上述 5 台服务器来记录该笔交易。
            问题：
                5 台服务器均是有各自想法的个体，都可以自主操作或记录，那么如何保证记录的交易是一致的呢？
            答案：
                分布式共识技术
                    概念：
                        在多个节点均可独自操作或记录的情况下，使得所有节点针对某个状态达成一致的过程
                    作用：
                        通过共识机制，我们可以使得分布式系统中的多个节点的数据达成一致。
            扩展：
                1。分布式在线记账，就是近几年比较火的区块链技术解决的问题。
                2。分布式共识技术，就是区块链技术共识机制的核心。

    分布式共识方法：
    挖矿：
        传统交易方式：
            1。用户 A 给用户 B 转账，需要银行来实行具体的转账操作并记录交易
            2。银行会从中收取相应的手续费
        采用分布式在线记账的话：
            1。参与记录这笔交易的服务器，也可以从中获得一些奖励（这些奖励，在区块链技术中可以换成钱）
            2。所有服务器帮助记录交易并达成一致的过程，就是区块链中的“挖矿”
            区块链：
                概念：
                    由包含交易信息的区块从后向前有序链接起来的数据结构
                区块：
                    概念：
                        是指很多交易数据的集合
                    组成：
                        每个区块包括区块头和区块体
                            1。区块头：包括前一区块的哈希值、本区块的哈希值和时间戳；
                            2。区块体：用来存储交易数据
    3 种主流的解决分布式在线记账一致性问题的共识技术
        1。PoW（Proof-of-Work，工作量证明）
            背景：
                1。分布式选举问题中：
                    同一轮选举中有且仅有一个节点成为主节点。
                2。在分布式在线记账问题：
                    1。针对同一笔交易，有且仅有一个节点或服务器可以获得记账权
                    2。然后其他节点或服务器同意该节点或服务器的记账结果，达成一致。
                3。分布式共识包括两个关键点
                    1。获得记账权
                    2。所有节点或服务器达成一致。
            概念：
                以每个节点或服务器的计算能力（即“算力”）来竞争记账权的机制，因此是一种使用工作量证明机制的共识算法
                说明：
                    谁的计算力强、工作能力强，谁获得记账权的可能性就越大。
                    问题：
                        如何体现节点的“算力”呢？
                    答案：
                        每个节点都去解一道题，谁能先解决谁的能力就强。
            PoW 算法获取记账权的原理是：
                1。假设每个节点会划分多个区块用于记录用户交易
                2。利用区块的 index、前一个区块的哈希值、交易的时间戳、区块数据和 nonce 值
                3。通过 SHA256 哈希算法计算出一个哈希值，并判断前 k 个值是否都为 0
                    情形一：
                        如果不是，则递增 nonce 值，重新按照上述方法计算；
                    情形二：
                        如果是，则本次计算的哈希值为要解决的题目的正确答案
                4。谁最先计算出正确答案，谁就获得这个区块的记账权。
                注意：
                    1。nonce 值：是用来找到一个满足哈希值的数字；
                    2。k：为哈希值前导零的个数，标记了计算的难度，0 越多计算难度越大。
            共识的过程：
                1。获得记账权的节点将该区块信息广播给其他节点
                2。其他节点判断该节点找到的区块中的所有交易都是有效且之前未存在过的
                3。则认为该区块有效，并接受该区块，达成一致。
            案例：
                以上文提到的分散在世界各地的 5 台服务器为例，和你说明基于 PoW 的共识记账过程。
                步骤一：
                    1。假设客户端 A 产生一个新的交易，基于 PoW 的共识记账过程为：
                        1。客户端 A 产生新的交易，向全网进行广播，要求对交易进行记账。
                        2。每个记账节点接收到这个请求后，将收到的交易信息放入一个区块中。
                        3。每个节点通过 PoW 算法，计算本节点的区块的哈希值，尝试找到一个具有足够工作量难度的工作量证明。
                步骤二：
                    1。若节点 D 找到了一个工作量证明向全网广播
                    2。当然，当且仅当包含在该区块中的交易都是有效且之前未存在过的，其他节点才会认同该区块的有效性
                步骤三：
                    1。其他节点接收到广播信息后，若该区块有效，接受该区块
                    2。并跟随在该区块的末尾，制造新区块延长该链条
                    3。将被接受的区块的随机哈希值视为新区块的随机哈希值。
                现象：
                    1。PoW 算法中，谁的计算能力强，获得记账权的可能性就越大
                    2。但必须保证其记账的区块是有效的，并在之前未存在过，才能获得其他节点的认可。
            应用：
                比特币平台采用了 PoW 算法，属于区块链 1.0 阶段
                    说明：
                        1。其重心在于货币，比特币大约 10min 才会产生一个区块，区块的大小也只有 1MB，仅能够包含 3000～4000 笔交易
                        2。平均每秒只能够处理 5~7（个位数）笔交易。
            优点：
                1。相对的公平
                    原因：
                        PoW 通过“挖矿”的方式发行新币，把比特币分散给个人
                2。PoW 的容错机制，允许全网 50% 的节点出错
                    说明：
                        如果要破坏系统，则需要投入极大成本（若你有全球 51% 的算力，则可尝试攻击比特币）。
            缺点：
                共识达成的周期长、效率低，资源消耗大。
                说明：
                    1。PoW 机制每次达成共识需要全网共同参与运算，增加了每个节点的计算量
                    2。并且如果题目过难，会导致计算时间长、资源消耗多
                    3。而如果题目过于简单，会导致大量节点同时获得记账权，冲突多
        2。PoS（Proof-of-Stake，权益证明）
            背景：
                为了解决 PoW 算法的问题，引入了 PoS 算法。
            核心原理：
                1。由系统权益代替算力来决定区块记账权，拥有的权益越大获得记账权的概率就越大。
                    权益：
                        概念：
                            每个节点占有货币的数量和时间
                            货币：
                                概念：
                                    节点所获得的奖励
                2。PoW 算法充分利用了分布式在线记账中的奖励，鼓励“利滚利”。
            案例：
                1。在股权证明 PoS 模式下，根据你持有货币的数量和时间，给你发利息
                2。每个币每天产生 1 币龄，比如你持有 100 个币，总共持有了 50 天，那么，你的币龄就为 5000
                3。这个时候，如果你发现了一个 PoS 区块，你的币龄就会被减少 365。
                4。每被减少 365 币龄，你就可以从区块中获得 0.05 个币的利息 (可理解为年利率 5%)。
                分析：
                    在这个案例中，利息 = （5000*5% ）/365 = 0.68 个币

            获得区块记账权：
                是根据节点拥有的股权或权益进行计算的。
                注意：
                    1。通过 PoS 算法决定区块记账权的流程和 PoW 算法类似
                    2。唯一不同的就是，每个节点在计算自己记账权的时候，
                    3。通过计算自己的股权或权益来评估，如果发现自己权益最大
                    4。则将自己的区块广播给其他节点，当然必须保证该区块的有效性。
                例子：
                    假设一个公链网络中，共有 3 个节点，A 、B 和 C。
                        1。其中 A 节点拥有 10000 个币，总共持有 30 天
                        2。而 B 和 C 节点分别有 1000 和 2000 个币，分别持有 15 和 20 天。
            应用：
                以太坊平台属于区块链 2.0 阶段，在区块链 1.0 的基础上进一步强调了合约，采用了 PoS 算法。
                说明：
                    1。12 年发布的点点币（PPC），综合了 PoW 工作量证明及 PoS 权益证明方式
                    2。从而在安全和节能方面实现了创新。
            特点：
                PoS 将算力竞争转变成权益竞争
            优点：
                1。与 PoW 相比，PoS 不需要消耗大量的电力就能够保证区块链网络的安全性
                2。同时也不需要在每个区块中创建新的货币来激励记账者参与当前网络的运行，这也就在一定程度上缩短了达成共识所需要的时间
                现象：
                    基于 PoS 算法的以太坊每秒大概能处理 30 笔左右的交易。
            缺点：
                1。PoS 算法中持币越多或持币越久，币龄就会越高，持币人就越容易挖到区块并得到激励，而持币少的人基本没有机会
                2。这样整个系统的安全性实际上会被持币数量较大的一部分人掌握，容易出现垄断现象。

        3。DPoS（Delegated Proof of Stake，委托权益证明）
            背景：
                1。为了解决 PoS 算法的垄断问题
                2。2014 年比特股（BitShares）的首席开发者丹尼尔 · 拉里默（Dan Larimer）提出了委托权益证明法，也就是 DPoS 算法
            原理：
                1。是由被社区选举的可信帐户（受托人，比如得票数排行前 101 位）来拥有记账权。
                    类似：
                        1。类似股份制公司的董事会制度，普通股民虽然拥有股权
                        2。但进不了董事会，他们可以投票选举代表（受托人）代他们做决策
                2。为了成为正式受托人，用户要去社区拉票，获得足够多的信任
                3。用户根据自己持有的货币数量占总量的百分比来投票
                    类似：
                        1。好比公司股票机制，假设总的发行股票为 1000
                        2。现在股东 A 持股 10，那么股东 A 投票权为 10/1000=1/100。
                        3。根据自己拥有的权益，投票选出可代表自己的受托节点，受托节点之间竞争记账权。
                4。在 DPos 算法中，通常会选出 k(比如 101) 个受托节点，它们的权利是完全相等的
                    受托节点：
                        1。受托节点之间争取记账权也是根据算力进行竞争的。
                        2。只要受托节点提供的算力不稳定，计算机宕机或者利用手中的权力作恶
                        3。随时可以被握着货币的普通节点投票踢出整个系统，而后备的受托节点可以随时顶上去。
            应用：
                1。DPoS 在比特股和 Steem 上已运行多年，整个网络中选举出的多个节点能够在 1s 之内对 99.9% 的交易进行确认。
                2。此外，DPoS 在 EOS（Enterprise Operation System，为商用分布式应用设计的一款区块链操作系统）中也有广泛应用
                3。被称为区块链 3.0 阶段。
            特点：
                1。DPoS 是在 PoW 和 PoS 的基础上进行改进的
                2。相比于 PoS 算法，DPoS 引入了受托人
            优点：
                1。DPoS 能耗更低，具有更快的交易速度。
                    原因：
                        1。由投票选举出的若干信誉度更高的受托人记账
                        2。解决了所有节点均参与竞争导致消息量大、达成一致的周期长的问题
                2。每隔一定周期会调整受托人，避免受托人造假和独权。
            缺点：
                1。在 DPoS 中，由于大多数持币人通过受托人参与投票，投票的积极性并不高
                2。且一旦出现故障节点，DPoS 无法及时做出应对，导致安全隐患。
        三种分布式共识算法对比分析：
            第05讲三种分布式共识算法对比分析.png
    扩展：
        问题：
            一致性与共识的区别是什么？
        答案：
            一致性：
                概念：
                    1。分布式系统中的多个节点之间，给定一系列的操作
                    2。在约定协议的保障下，对外界呈现的数据或状态是一致的。
                特点：
                    强调的是结果
                注意：
                    共识算法是保障系统满足不同程度一致性的核心技术。
            共识：
                概念：
                    分布式系统中多个节点之间，彼此对某个状态达成一致结果的过程。
                特点：
                    强调的是达成一致的过程

06 | 分布式事务：All or nothing
    案例：
        内容：
            对于网上购物的每一笔订单来说，电商平台一般都会有两个核心步骤
                1。一是订单业务采取下订单操作
                2。二是库存业务采取减库存操作
        分析：
            1。这两个业务会运行在不同的机器上，甚至是运行在不同区域的机器上
            2。针对同一笔订单，当且仅当订单操作和减库存操作一致时，才能保证交易的正确性。
        说明：
            1。也就是说一笔订单，只有这两个操作都完成，才能算做处理成功，否则处理失败
            2。充分体现了“All or nothing”的思想。
    事务：
        概念：
            1。包含一系列操作的、一个有边界的工作序列，有明确的开始和结束标志
            2。且要么被完全执行，要么完全失败，即 all or nothing
            3。通常情况下，我们所说的事务指的都是本地事务，也就是在单机上的事务。
        特征：
            1。原子性（Atomicity）
                概念：
                    事务最终的状态只有两种，全部执行成功和全部不执行
                例子：
                    1。若处理事务的任何一项操作不成功，就会导致整个事务失败
                    2。一旦操作失败，所有操作都会被取消（即回滚），使得事务仿佛没有被执行过一样。
            2。一致性（Consistency）
                概念：
                    是指事务操作前和操作后，数据的完整性保持一致或满足完整性约束
                例子：
                    1。用户 A 和用户 B 在银行分别有 800 元和 600 元，总共 1400 元
                    2。用户 A 给用户 B 转账 200 元，分为两个步骤
                        步骤一：从 A 的账户扣除 200 元
                        步骤二：对 B 的账户增加 200 元 ;
                    3。一致性就是要求上述步骤操作后，最后的结果是用户 A 还有 600 元，用户 B 有 800 元，总共 1400 元
                    4。而不会出现用户 A 扣除了 200 元，但用户 B 未增加的情况 (该情况，用户 A 和 B 均为 600 元，总共 1200 元)。
            3。隔离性（Isolation）
                概念：
                    1。是指当系统内有多个事务并发执行时，多个事务不会相互干扰
                    2。即一个事务内部的操作及使用的数据，对其他并发事务是隔离的。
            4。持久性（Durability）
                概念：
                    1。也被称为永久性，是指一个事务完成了，那么它对数据库所做的更新就被永久保存下来了
                    2。即使发生系统崩溃或宕机等故障，只要数据库能够重新被访问，那么一定能够将其恢复到事务完成时的状态。
    分布式事务：
        概念：
            在分布式系统中运行的事务，由多个本地事务组合而成
            说明：
                在分布式场景下，对事务的处理操作可能来自不同的机器，甚至是来自不同的操作系统
            例子：
                文章开头提到的电商处理订单问题，就是典型的分布式事务。
        BASE理论：
            背景：
                1。但随着分布式系统规模不断扩大，复杂度急剧上升，达成强一致性所需时间周期较长，限定了复杂业务的处理
                2。为了适应复杂业务，出现了 BASE 理论，该理论的一个关键点就是采用最终一致性代替强一致性。
                强一致性：
                    概念：
                        1。分布式事务基本能够满足 ACID，其中的 C 是强一致性
                        2。也就是所有操作均执行成功，才提交最终结果，以保证数据一致性或完整性
            概念：
                包括基本可用（Basically Available）、柔性状态（Soft State）和最终一致性（Eventual Consistency）。
                1。基本可用：
                    概念：
                        分布式系统出现故障的时候，允许损失一部分功能的可用性
                    例子：
                        某些电商 618 大促的时候，会对一些非核心链路的功能进行降级处理。
                2。柔性状态：
                    概念：
                        在柔性事务中，允许系统存在中间状态，且这个中间状态不会影响系统整体可用性。
                    例子：
                        数据库读写分离，写库同步到读库（主库同步到从库）会有一个延时，其实就是一种柔性状态。
                3。最终一致性
                    概念：
                        事务在操作过程中可能会由于同步延迟等问题导致不一致，但最终状态下，数据都是一致的。
            特点：
                BASE 理论为了支持大型分布式系统，通过牺牲强一致性，保证最终一致性，来获得高可用性，是对 ACID 原则的弱化
        目的：
            主要是解决在分布式环境下，组合事务的一致性问题
    方法：
        方法一：(采用了强一致性,遵从 ACID)
            基于 XA 协议的二阶段提交协议方法；
                XA协议:
                    概念：
                        是一个分布式事务协议，规定了事务管理器和资源管理器接口
                    组成：
                        1。事务管理器
                            概念：
                                作为协调者，负责各个本地资源的提交和回滚
                        2。本地资源管理器。
                            概念：
                                分布式事务的参与者，通常由数据库实现
                            例子;
                                比如 Oracle、DB2 等商业数据库都实现了 XA 接口。
                基于 XA 协议的二阶段提交方法中，二阶段提交协议：（The two-phase commit protocol，2PC）
                    作用：
                        用于保证分布式系统中事务提交时的数据一致性，是 XA 在全局事务中用于协调多个资源的机制。
                    问题：
                        两阶段提交协议如何保证分布在不同节点上的分布式事务的一致性呢？
                        思路：
                            1。为了保证它们的一致性，我们需要引入一个协调者来管理所有的节点
                            2。并确保这些节点正确提交操作结果，若提交失败则放弃事务
                        具体过程：
                            两阶段提交协议的执行过程，分为投票（voting）和提交（commit）两个阶段
                                第一阶段：(投票)
                                    1。协调者（Coordinator，即事务管理器）会向事务的参与者（Cohort，即本地资源管理器）发起执行操作的 CanCommit 请求，并等待参与者的响应
                                    2。参与者接收到请求后，会执行请求中的事务操作，记录日志信息但不提交
                                    3。待参与者执行成功，则向协调者发送“Yes”消息，表示同意操作
                                    4。若不成功，则发送“No”消息，表示终止操作
                                第二阶段：(提交)
                                    1。当所有的参与者都返回了操作结果（Yes 或 No 消息）后，系统进入了提交阶段
                                    2。在提交阶段，协调者会根据所有参与者返回的信息向参与者发送 DoCommit 或 DoAbort 指令：
                                        情形一：
                                            1。若协调者收到的都是“Yes”消息，则向参与者发送“DoCommit”消息
                                            2。参与者会完成剩余的操作并释放资源，然后向协调者返回“HaveCommitted”消息；
                                        情形二：
                                            1。如果协调者收到的消息中包含“No”消息，则向所有参与者发送“DoAbort”消息
                                            2。此时发送“Yes”的参与者则会根据之前执行操作时的回滚日志对操作进行回滚
                                            3。然后所有参与者会向协调者发送“HaveCommitted”消息；
                                    3。协调者接收到“HaveCommitted”消息，就意味着整个事务结束了。
                        例子：
                            1。我以用户 A 要在网上下单购买 100 件 T 恤为例
                            2。重点与你介绍下单操作和减库存操作这两个操作，帮助你加深对二阶段提交协议的理解。
                                第一阶段：(投票)
                                    1.订单系统中将与用户 A 有关的订单数据库锁住
                                    2.准备好增加一条关于用户 A 购买 100 件 T 恤的信息,并将同意消息“Yes”回复给协调者
                                    3.而库存系统由于 T 恤库存不足，出货失败，因此向协调者回复了一个终止消息“No”。
                                第二阶段:(提交)
                                    1.由于库存系统操作不成功，因此，协调者就会向订单系统和库存系统发送“DoAbort”消息
                                    2.订单系统接收到“DoAbort”消息后，将系统内的数据退回到没有用户 A 购买 100 件 T 恤的版本,并释放锁住的数据库资源
                                    3.订单系统和库存系统完成操作后，向协调者发送“HaveCommitted”消息，表示完成了事务的撤销操作。
                            3。用户 A 购买 100 件 T 恤这一事务已经结束，用户 A 购买失败。
                        算法思路：
                            1。协调者下发请求事务操作，参与者将操作结果通知协调者
                            2。协调者根据所有参与者的反馈结果决定各参与者是要提交操作还是撤销操作。
                        缺点：
                            1。同步阻塞问题：
                                概念：
                                    二阶段提交算法在执行过程中，所有参与节点都是事务阻塞型的
                                说明：
                                    1。也就是说，当本地资源管理器占有临界资源时
                                    2。其他资源管理器如果要访问同一临界资源，会处于阻塞状态。
                            2。单点故障问题：
                                概念：
                                    基于 XA 的二阶段提交算法类似于集中式算法，一旦事务管理器发生故障，整个系统都处于停滞状态
                                说明：
                                    1。尤其是在提交阶段，一旦事务管理器发生故障，资源管理器会由于等待管理器的消息
                                    2。而一直锁定事务资源，导致整个系统被阻塞。
                            3。数据不一致问题：
                                例子：
                                    1。在提交阶段，当协调者向参与者发送 DoCommit 请求之后
                                    2。如果发生了局部网络异常，或者在发送提交请求的过程中协调者发生了故障
                                    3。就会导致只有一部分参与者接收到了提交请求并执行提交操作
                                    4。但其他未接到提交请求的那部分参与者则无法执行事务提交。
                                    5。于是整个分布式系统便出现了数据不一致的问题。

        方法二：(采用了强一致性,遵从 ACID)
            三阶段提交协议方法；
                背景：
                    1。是对二阶段提交（2PC）的改进
                    2。为了解决两阶段提交的同步阻塞和数据不一致问题，三阶段提交引入了超时机制和准备阶段。
                        超时机制：
                            概念：
                                在协调者和参与者中引入超时机制
                            说明：
                                1。如果协调者或参与者在规定的时间内没有接收到来自其他节点的响应
                                2。就会根据当前的状态选择提交或者终止整个事务。
                        准备阶段：
                            概念：
                                在第一阶段和第二阶段中间引入了一个准备阶段，也就是在提交阶段之前，加入了一个预提交阶段
                            说明：
                                在预提交阶段排除一些不一致的情况，保证在最后提交之前各参与节点的状态是一致的。
                概念：
                    1。3PC 把 2PC 的提交阶段一分为二
                    2。这样三阶段提交协议就有 CanCommit、PreCommit、DoCommit 三个阶段。
                        第一阶段：(CanCommit 阶段)
                            CanCommit 阶段与 2PC 的投票阶段类似：
                                1。协调者向参与者发送请求操作（CanCommit 请求），询问参与者是否可以执行事务提交操作，然后等待参与者的响应；
                                2。参与者收到 CanCommit 请求之后，回复 Yes，表示可以顺利执行事务；否则回复 No。

                        第二阶段：(PreCommit 操作)
                            协调者根据参与者的回复情况，来决定是否可以进行 PreCommit 操作。
                                情形一：
                                    如果所有参与者回复的都是“Yes”，那么协调者就会执行事务的预执行：
                                        1。发送预提交请求
                                            概念：
                                                协调者向参与者发送 PreCommit 请求，进入预提交阶段。
                                        2。事务预提交：
                                            概念
                                                参与者接收到 PreCommit 请求后执行事务操作，并将 Undo 和 Redo 信息记录到事务日志中。
                                        3。响应反馈：
                                            概念：
                                                如果参与者成功执行了事务操作，则返回 ACK 响应，同时开始等待最终指令。
                                情形二：
                                    假如任何一个参与者向协调者发送了“No”消息，或者等待超时之后，协调者都没有收到参与者的响应，就执行中断事务的操作
                                        1。发送中断请求。
                                            概念：
                                                协调者向所有参与者发送“Abort”消息。
                                        2。终断事务。
                                            概念：
                                                参与者收到“Abort”消息之后，或超时后仍未收到协调者的消息，执行事务的终断操作。

                        第三阶段：(DoCommit 阶段)
                            真正的事务提交，根据 PreCommit 阶段协调者发送的消息，进入执行提交阶段或事务中断阶段。
                                执行提交阶段：
                                    1。发送提交请求。
                                        概念：
                                            1。协调者接收到所有参与者发送的 Ack 响应，从预提交状态进入到提交状态
                                            2。并向所有参与者发送 DoCommit 消息。
                                    2。事务提交
                                        概念：
                                            参与者接收到 DoCommit 消息之后，正式提交事务。完成事务提交之后，释放所有锁住的资源。
                                    3。响应反馈
                                        概念：
                                            参与者提交完事务之后，向协调者发送 Ack 响应。
                                    4。完成事务
                                        概念：
                                            协调者接收到所有参与者的 Ack 响应之后，完成事务。
                            事务中断阶段：
                                1。发送中断请求。
                                    概念：
                                        协调者向所有参与者发送 Abort 请求。
                                2。事务回滚
                                    概念：
                                        参与者接收到 Abort 消息之后，利用其在 PreCommit 阶段记录的 Undo 信息执行事务的回滚操作，并释放所有锁住的资源。
                                3。反馈结果
                                    概念：
                                        参与者完成事务回滚之后，向协调者发送 Ack 消息。
                                4。终断事务
                                    概念：
                                        协调者接收到参与者反馈的 Ack 消息之后，执行事务的终断，并结束事务。
                            注意：
                                1。当参与者向协调者发送 Ack 消息后，如果长时间没有得到协调者的响应
                                2。在默认情况下，参与者会自动将超时的事务进行提交，不会像两阶段提交那样被阻塞住。


        方法三：(采用了最终一致性，遵从 BASE 理论)
            基于消息的最终一致性方法。
                背景：
                    1。2PC 和 3PC 这两种方法，有两个共同的缺点
                        1。一是都需要锁定资源，降低系统性能；
                        2。二是，没有解决数据不一致的问题
                    2。因此，便有了通过分布式消息来确保事务最终一致性的方案。
                案例：
                    在 eBay 的分布式系统架构中，架构师解决一致性问题的核心思想就是
                        1。将需要分布式处理的事务通过消息或者日志的方式异步执行
                        2。消息或日志可以存到本地文件、数据库或消息队列中，再通过业务规则进行失败重试。
                        3。这个案例，就是使用基于分布式消息的最终一致性方案解决了分布式事务的问题。
            消息中间件：（Message Queue，MQ）
                背景：
                    基于分布式消息的最终一致性方案的事务处理，引入了一个消息中间件
                作用：
                    用于在多个应用之间进行消息传递
                例子：
                    1。仍然以网上购物为例。假设用户 A 在某电商平台下了一个订单，需要支付 50 元
                    2。发现自己的账户余额共 150 元，就使用余额支付，支付成功之后
                    3。订单状态修改为支付成功，然后通知仓库发货。
                    分析：
                        1。在该事件中，涉及到了订单系统、支付系统、仓库系统
                        2。这三个系统是相互独立的应用，通过远程服务进行调用
                        3。根据基于分布式消息的最终一致性方案，用户 A 通过终端手机首先在订单系统上操作
                        4。然后整个购物的流程如下所示。
                            第一步：
                                订单系统把订单消息发给消息中间件，消息状态标记为“待确认”。
                            第二步：
                                1。消息中间件收到消息后，进行消息持久化操作
                                2。即在消息存储系统中新增一条状态为“待发送”的消息。
                            第三步：
                                消息中间件返回消息持久化结果（成功 / 失败），订单系统根据返回结果判断如何进行业务操作
                                    情形一：
                                        失败，放弃订单，结束（必要时向上层返回失败结果）
                                    情形二：
                                        成功，则创建订单。
                            第四步：
                                订单操作完成后，把操作结果（成功 / 失败）发送给消息中间件。
                            第五步：
                                消息中间件收到业务操作结果后，根据结果进行处理
                                情形一：
                                    失败，删除消息存储中的消息，结束；
                                情形二：
                                    成功，则更新消息存储中的消息状态为“待发送（可发送）”，并执行消息投递
                            第六步：
                                1。如果消息状态为“可发送”，则 MQ 会将消息发送给支付系统，表示已经创建好订单，需要对订单进行支付
                                2。支付系统也按照上述方式进行订单支付操作。
                            第七步：
                                1。订单系统支付完成后，会将支付消息返回给消息中间件
                                2。中间件将消息传送给订单系统。订单系统再调用库存系统，进行出货操作。
                注意：
                    1。分布式事务中，当且仅当所有的事务均成功时整个流程才成功
                    2。分布式事务的一致性是实现分布式事务的关键问题
                    3。目前来看还没有一种很简单、完美的方案可以应对所有场景。

    三种实现方式对比
        参考：
            第06讲分布式事务实现方式对比.png
        扩展：
            在讨论事务的时候，我们经常会提到刚性事务与柔性事务，但却很难区分这两种事务
        问题：
            什么是刚性事务、柔性事务，以及两者之间有何区别？
            答案：
                刚性事务：
                    概念：
                        遵循 ACID 原则，具有强一致性
                    例子：
                        数据库事务。
                柔性事务：
                    概念：
                        1。其实就是根据不同的业务场景使用不同的方法实现最终一致性
                        2。也就是说我们可以根据业务的特性做部分取舍，容忍一定时间内的数据不一致。
        总结：
            1。与刚性事务不同，柔性事务允许一定时间内，不同节点的数据不一致，但要求最终一致
            2。而柔性事务的最终一致性，遵循的是 BASE 理论。

07 | 分布式锁：关键重地，非请勿入
    锁：
        背景：
            1。在单机多线程环境中，我们经常遇到多个线程访问同一个共享资源的情况
                共享资源：在很多地方，这种资源会称为临界资源，
            2。为了维护数据的一致性，我们需要某种机制来保证只有满足某个条件的线程才能访问资源
            3。不满足条件的线程只能等待，在下一轮竞争中重新满足条件时才能访问资源。
            机制：
                概念：
                    1。为了实现分布式互斥，在某个地方做个标记，这个标记每个线程都能看到
                    2。到标记不存在时可以设置该标记，当标记被设置后，其他线程只能等待拥有该标记的线程执行完成
                    3。并释放该标记后，才能去设置该标记和访问共享资源
                    4。这里的标记就是我们说的锁
        概念：
            实现多线程同时访问同一共享资源，保证同一时刻只有一个线程可访问共享资源所做的一种标记。
    分布式锁：
        概念：
            1。分布式环境下，系统部署在多个机器中，实现多进程分布式互斥的一种锁
            2。为了保证多个进程能看到锁，锁被存在公共存储（比如 Redis、Memcache、数据库等三方存储中）
            3。以实现多个进程并发访问同一个临界资源，同一时刻只有一个进程可访问共享资源，确保数据的一致性。
        场景：
            1。现在某电商要售卖某大牌吹风机（以下简称“吹风机”），库存只有 2 个
            2。但有 5 个来自不同地区的用户{A,B,C,D,E}几乎同时下单，那么这 2 个吹风机到底会花落谁家呢？
            现象：
                1。对于订单的优先级，不同电商往往采取不同的策略
                    例子一：
                        有些电商根据下单时间判断谁可以购买成功
                    例子二：
                        有些电商则是根据付款时间来判断
                2。无论采用什么样的规则去判断谁能购买成功，都必须要保证吹风机售出时，数据库中更新的库存是正确的
            方法一：
                谁先提交订单请求，谁就购买成功呗
                现象：
                    但实际业务中，为了高并发地接受大量用户订单请求，很少有电商网站真正实施这么简单的措施。
            方法二：
                给吹风机的库存数加一个锁。
                具体实现：
                    1。当有一个用户提交订单后，后台服务器给库存数加一个锁，根据该用户的订单修改库存
                    2。而其他用户必须等到锁释放以后，才能重新获取库存数，继续购买。
                    分析：
                        1。吹风机的库存就是共享资源，不同的购买者对应着多个进程
                        2。后台服务器对共享资源加的锁就是告诉其他进程“关键重地，非请勿入”。
                问题：
                    想象一下，用户 A 想买 1 个吹风机，用户 B 想买 2 个吹风机。
                        理想情况下：
                            用户 A 网速好先买走了 1 个，库存还剩下 1 个，此时应该提示用户 B 库存不足，用户 B 购买失败
                        实际情况是：
                            1。用户 A 和用户 B 同时获取到商品库存还剩 2 个
                            2。用户 A 买走 1 个，在用户 A 更新库存之前，用户 B 又买走了 2 个，此时用户 B 更新库存，商品还剩 0 个
                        现象：
                            1。这时，电商就头大了，总共 2 个吹风机，却卖出去了 3 个。
                        结论：
                            如果只使用单机锁将会出现不可预知的后果
                    解决方案：
                        1。在高并发场景下，为了保证临界资源同一时间只能被一个进程使用
                        2。从而确保数据的一致性，我们就需要引入分布式锁了。
                    此外：
                        1。在大规模分布式系统中，单个机器的线程锁无法管控多个机器对同一资源的访问
                        2。这时使用分布式锁，就可以把整个集群当作一个应用一样去处理，实用性和扩展性更好。
    分布式锁的 3 种主流方法:
        1。基于数据库实现分布式锁，这里的数据库指的是关系型数据库；
            方式：
                就是创建一张锁表，然后通过操作该表中的数据来实现。
            例子：
                1。当我们要锁住某个资源时，就在该表中增加一条记录，想要释放锁的时候就删除这条记录
                2。数据库对共享资源做了唯一性约束，如果有多个请求被同时提交到数据库的话
                3。数据库会保证只有一个操作可以成功，操作成功的那个线程就获得了访问共享资源的锁，可以进行操作。
            场景：
                适用于并发量低，对性能要求低的场景
                原因：
                    数据库需要落到硬盘上，频繁读取数据库会导致 IO 开销大
                注意：
                    1。对于双 11、双 12 等需求量激增的场景，数据库锁是无法满足其性能要求的
                    2。而在平日的购物中，我们可以在局部场景中使用数据库锁实现对资源的互斥访问。
            例子：
                1。我们还是以电商售卖吹风机的场景为例
                2。吹风机库存是 2 个，有 5 个来自不同地区的用户{A,B,C,D,E}想要购买
                3。其中用户 A 想买 1 个，用户 B 想买 2 个，用户 C 想买 1 个。
                分析：
                    用户A：
                        1。用户 A 和用户 B 几乎同时下单，但用户 A 的下单请求最先到达服务器。
                        2。因此，该商家的产品数据库中增加了一条关于用户 A 的记录，用户 A 获得了锁
                        3。他的订单请求被处理，服务器修改吹风机库存数，减去 1 后还剩下 1 个。
                        4。当用户 A 的订单请求处理完成后，有关用户 A 的记录被删除
                    用户B
                        1。服务器开始处理用户 B 的订单请求
                        2。这时，库存只有 1 个了，无法满足用户 B 的订单需求，因此用户 B 购买失败。
                        3。从数据库中，删除用户 B 的记录
                    用户C：
                        1。服务器开始处理用户 C 的订单请求，库存中 1 个吹风机满足用户 C 的订单需求
                        2。数据库中增加了一条关于用户 C 的记录，用户 C 获得了锁
                        3。他的订单请求被处理，服务器修改吹风机数量，减去 1 后还剩下 0 个。
                    以上思路：
                        1。基于数据库实现分布式锁比较简单，绝招在于创建一张锁表
                        2。为申请者在锁表里建立一条记录，记录建立成功则获得锁，消除记录则释放锁
            缺点：
                1。单点故障问题。
                    概念：
                        一旦数据库不可用，会导致整个系统崩溃
                2。死锁问题
                    说明：
                        1。数据库锁没有失效时间，未获得锁的进程只能一直等待已获得锁的进程主动释放锁
                        2。一旦已获得锁的进程挂掉或者解锁操作失败，会导致锁记录一直存在数据库中，其他进程无法获得锁。

        2。基于缓存实现分布式锁
            背景：
                1。数据库的性能限制了业务的并发量
                2。那么对于双 11、双 12 等需求量激增的场景是否有解决方法呢？
                方法：
                    基于缓存实现分布式锁的方式，
            概念：
                所谓基于缓存，也就是说把数据存放在计算机内存中
            优势：
                不需要写入磁盘，减少了 IO 读写
            实现方式
                Redis 通常可以使用 setnx(key, value) 函数来实现分布式锁
                    说明：
                        1。key 和 value 就是基于缓存的分布式锁的两个属性
                            key：表示锁 id
                            value：= currentTime + timeOut，表示当前时间 + 超时时间
                        2。某个进程获得 key 这把锁后，如果在 value 的时间内未释放锁，系统就会主动释放锁。
                        3。setnx 函数的返回值有 0 和 1：
                            返回1：
                                说明该服务器获得锁，setnx 将 key 对应的 value 设置为当前时间 + 锁的有效时间。
                            返回0：
                                说明其他服务器已经获得了锁，进程不能进入临界区。该服务器可以不断尝试 setnx 操作，以获得锁。
            例子：
                以电商售卖吹风机的场景为例，和你说明基于缓存实现的分布式锁，假设现在库存数量是足够的。
                用户A：
                    1。用户 A 的请求因为网速快，最先到达 Server2，setnx 操作返回 1
                    2。并获取到购买吹风机的锁
                用户B：
                    1。用户 B 和用户 C 的请求，几乎同时到达了 Server1 和 Server3，
                    2。但因为这时 Server2 获取到了吹风机数据的锁，所以只能加入等待队列。
                接下来Server2 ：
                    1。Server2 获取到锁后，负责管理吹风机的服务器执行业务逻辑，只用了 1s 就完成了订单
                    2。订单请求完成后，删除锁的 key，从而释放锁
                    3。此时，排在第二顺位的 Server1 获得了锁，可以访问吹风机的数据资源
                    4。但不巧的是，Server1 在完成订单后发生了故障，无法主动释放锁。
                第三顺位的Server3
                    1。于是，排在第三顺位的 Server3 只能等设定的有效时间（比如 30 分钟）到期
                    2。锁自动释放后，才能访问吹风机的数据资源，也就是说用户 C 只能到 00:30:01 以后才能继续抢购
            总结：
                1。Redis 通过队列来维持进程访问共享资源的先后顺序
                2。Redis 锁主要基于 setnx 函数实现分布式锁，当进程通过 setnx<key,value> 函数返回 1 时，表示已经获得锁
                3。排在后面的进程只能等待前面的进程主动释放锁，或者等到时间超时才能获得锁。
            优点：
                相对于基于数据库实现分布式锁的方案来说，基于缓存实现的分布式锁的优势表现在以下几个方面：
                    1。性能更好
                        解释：
                            数据被存放在内存，而不是磁盘，避免了频繁的 IO 操作。
                    2。很多缓存可以跨集群部署，避免了单点故障问题。
                    3。很多缓存服务都提供了可以用来实现分布式锁的方法
                    4。可以直接设置超时时间来控制锁的释放
                        原因：
                            因为这些缓存服务器一般支持自动删除过期数据。
            缺点：
                通过超时时间来控制锁的失效时间，并不是十分靠谱
                原因：
                    一个进程执行时间可能比较长，或受系统进程做内存回收等影响，导致时间超时，从而不正确地释放了锁。

        3。基于 ZooKeeper 实现分布式锁。
            背景：
                1。为了解决基于缓存实现的分布式锁的这些问题
                2。我们再来看看基于 ZooKeeper 实现的分布式锁吧。
            ZooKeeper：
                概念：
                    基于树形数据存储结构实现分布式锁
                作用：
                    来解决多个进程同时访问同一临界资源时，数据的一致性问题
                4种节点：
                    1。持久节点：
                        概念：
                            这是默认的节点类型，一直存在于 ZooKeeper 中。
                    2。持久顺序节点：
                        概念：
                            在创建节点时，ZooKeeper 根据节点创建的时间顺序对节点进行编号。
                    3。临时节点：
                        概念：
                            与持久节点不同，当客户端与 ZooKeeper 断开连接后，该进程创建的临时节点就会被删除。
                    4。临时顺序节点：
                        概念：
                            就是按时间顺序编号的临时节点
                扩展：
                    根据它们的特征，ZooKeeper 基于临时顺序节点实现了分布锁。
                案例：
                    1。还是以电商售卖吹风机的场景为例
                    2。假设用户 A、B、C 同时在 11 月 11 日的零点整提交了购买吹风机的请求，ZooKeeper 会采用如下方法来实现分布式锁：
                    步骤一：
                        1。在与该方法对应的持久节点 shared_lock 的目录下，为每个进程创建一个临时顺序节点
                        2。如下图所示，吹风机就是一个拥有 shared_lock 的目录，当有人买吹风机时，会为他创建一个临时顺序节点。
                        参考
                            第07讲ZooKeeper分布式锁.png
                    步骤二：
                        1。每个进程获取 shared_lock 目录下的所有临时节点列表
                        2。注册子节点变更的 Watcher，并监听节点。
                    步骤三：
                        每个节点确定自己的编号是否是 shared_lock 下所有子节点中最小的，若最小，则获得锁
                            例子：
                                1。用户 A 的订单最先到服务器，因此创建了编号为 1 的临时顺序节点 LockNode1。
                                2。该节点的编号是持久节点目录下最小的，因此获取到分布式锁，可以访问临界资源，从而可以购买吹风机
                    步骤四：
                        若本进程对应的临时节点编号不是最小的，则分为两种情况：
                            a.本进程为读请求，如果比自己序号小的节点中有写请求，则等待；
                            b.本进程为写请求，如果比自己序号小的节点中有读请求，则等待。
                        例子：
                            1。用户 B 也想要买吹风机，但在他之前，用户 C 想看看吹风机的库存量
                            2。因此，用户 B 只能等用户 A 买完吹风机、用户 C 查询完库存量后，才能购买吹风机。
                优点：
                    1。使用 ZooKeeper 可以完美解决设计分布式锁时遇到的各种问题
                        例如：
                            1。单点故障
                            2。不可重入、
                            3。、死锁等问题
                    2。几乎能涵盖所有分布式锁的特性，且易于实现
                缺点；
                    频繁地添加和删除节点，所以性能不如基于缓存实现的分布式锁。
    三种实现方式对比
        参考：
            第07讲分布式锁三种实现方式对比.png
        总结：
            1。ZooKeeper 分布式锁的可靠性最高，有封装好的框架，很容易实现分布式锁的功能
            2。并且几乎解决了数据库锁和缓存式锁的不足，因此是实现分布式锁的首选方法。
        扩展：
            确保分布式锁的可用性，我们在设计时应考虑到以下几点：
                1。互斥性
                    概念：
                        即在分布式系统环境下，分布式锁应该能保证一个资源或一个方法在同一时间只能被一个机器的一个线程或进程操作。
                2。具备锁失效机制，防止死锁
                    概念：
                        即使有一个进程在持有锁的期间因为崩溃而没有主动解锁，也能保证后续其他进程可以获得锁。
                3。可重入性，即进程未释放锁时，可以多次访问临界资源。
                4。有高可用的获取锁和释放锁的功能，且性能要好。
    知识扩展：
        问题：
            如何解决分布式锁的羊群效应问题？
        背景：
            在分布式锁问题中，会经常遇到羊群效应
        羊群效应：
            概念：
                1。在整个分布式锁的竞争过程中，大量的“Watcher 通知”和“子节点列表的获取”操作重复运行
                2。并且大多数节点的运行结果都是判断出自己当前并不是编号最小的节点
                3。继续等待下一次通知，而不是执行业务逻辑。
                现象：
                    1。这就会对 ZooKeeper 服务器造成巨大的性能影响和网络冲击。
                    2。如果同一时间多个节点对应的客户端完成事务或事务中断引起节点消失，ZooKeeper 服务器就会在短时间内向其他客户端发送大量的事件通知。
        解决方案
            具体方法可以分为以下三步。
            第一步：
                在与该方法对应的持久节点的目录下，为每个进程创建一个临时顺序节点。
            第二步：
                每个进程获取所有临时节点列表，对比自己的编号是否最小，若最小，则获得锁。
            第三步：
                若本进程对应的临时节点编号不是最小的，则继续判断
                    情形一：
                        1。若本进程为读请求，则向比自己序号小的最后一个写请求节点注册 watch 监听
                        2。当监听到该节点释放锁后，则获取锁；
                    情形二：
                        1。若本进程为写请求，则向比自己序号小的最后一个读请求节点注册 watch 监听
                        2。当监听到该节点释放锁后，获取锁。

08 | 答疑篇：分布式技术是如何引爆人工智能的？
    人工智能：
        概念：
            就是机器模拟人的思维，像人那样智能呗
        四类定义：
            1。像人一样思考
            2。像人一样行动
            3。理性地思考
            4。理性地行动
            行动：
                指的是采取行动或制定行动的决策。
        人工智能要模拟人的智能：
            1。需要通过大量的数据进行学习和分析获得规律（即建立一个模型）
            2。然后利用该规律或模型对未知数据进行预测，以判断是否与建模数据具有相同特征。
        人工智能的三大核心：
            1。数据
                作用：
                在一定程度上数据决定了机器学习的上限
            2。模型（也叫作算法）
                作用：
                    而模型为逼近这个上限提供方法
            3。算力
                作用：
                    决定了数据处理和模型训练的实用性能
        三者联系：
            1。数据处理和模型训练是人工智能的关键技术，
            2。算力决定了数据处理和模型训练的实用性能，而分布式技术就是解决算力的不二妙招。
    数据处理：
        概念：
            1。又称数据预处理，是指通过数据统计、数据集成、数据清理、数据规约、数据变换等方法
            2。对数据缺失、数据噪声、数据冗余、多数据源等问题进行处理以得到高质量数据
            3。为模型训练提供高质量输入，是人工智能不可缺少的环节。
            类似：
                1。我们的知识整理过程。一个精心打造的、体系化梳理过的专栏文章，可以帮助我们在学习一门课程时
                2。少走弯路、避免踩雷、达到事半功倍的效果
                3。同样地，一个精心处理过的数据集，对于人工智能的模型训练也能起到事半功倍的效果
                4。一方面可以缩短机器学习的周期，另一方面也可以提高机器学习的质量。
        数据预处理的方法：
            1。数据统计
                概念：
                    数据统计是数据预处理的第一步，其范围、规模、方式等会直接影响数据分析的结果
                统计特征：
                    有最大值、最小值、均值、中位数、方差、标准差等。
            2。数据集成
                概念：
                    1。数据收集的途径：
                        比如文件数据、数据库数据、问卷数据等
                    2。不同的数据源，其数据的存储方式、命名规则、单位等不尽相同
                    3。所以我们需要数据集成来将多个数据源的数据整合到一起，以保证数据结构、属性的一致性，并去除冗余数据，方便后续分析。
            3。数据清理
                背景：
                    1。由于用户忘记或设备损坏，经常会造成部分数据缺失
                    2。由于仪器故障或用户填写错误，经常会出现数据错误（噪声数据）等
                现象：
                    如果不对这些数据做任何处理，后面的模型训练过程将产生严重偏差
                目的：
                    数据清理过程就是用来解决这个问题的，它可以通过平均值或众数等来填充丢失值或修改这些噪声值。
            4。数据规约
                背景：
                    由于机器学习中的数据量很大，因此会导致很多重复的特征，或者很多不重要的特征（比如 ID 号等）
                目的：
                    就是去除重复特征及不重要的特征，从而减少数据的维度或者数据量，降低问题复杂度，同时不影响后面训练的结果
                方法：
                    有主成分分析法 (Principal Component Analysis，PCA)、小波变换 (Wavelet Transform，WT) 等
            5。数据变换
                背景：
                    1。数据经过集成、清理与规约等步骤后，要将数据进行标准化
                    2。离散化、分层化，使得数据更加一致、更加容易被模型处理。
                方法：
                    主要有数据标准化、数据离散化和数据泛化三类。
        单台机器：
            对于小样本数据处理时，单台机器的处理能力就足够了，所以采用单台机器进行处理即可
        分布式处理：
            对于大规模数据来说，单台机器的处理能力已成为瓶颈，此时，不得不需要分布式数据处理了。
        分布式计算框架
            MapReduce、Spark
        分布式存储框架
            HDFS、HBASE 等，来进行分布式数据处理。

    分布式模型训练
        模型训练：
            概念：
                从已知数据中找到规律
                说明：
                    具体来说就是，不断通过已有数据进行验证增强，最终给出最适合的模型参数，以此来预测给定的未知数据。
            例子：
                1。比如有一堆橘子和西瓜，可以通过模型训练得到：大的、绿色的判定为西瓜，小的、黄色的判定为橘子
                2。那么当给出一个未知数据时，我们通过它的大小及颜色信息就可以判断该水果是橘子还是西瓜。
                3。这就是模型训练。
                分析：
                    1。大小和颜色属于预测的两个特征，而它们的具体数值
                    2。(比如，大于 10 厘米等，颜色 RGB 的数值范围）就是模型参数。
        分布式模型训练
            概念：
                1。利用分布式集群，将多个计算机的存储能力、计算能力等进行统一管理和调度，从而实现模型训练
                    前提：
                        有一个分布式集群：
                            因此一个高效、可靠的分布式集群是基础
                2。而这个分布式集群的架构、选主、调度、可靠性等关键技术，便奠定了分布式模型训练的基础。

    分布式模型训练模式
        1。数据分布式训练
        2。模型分布式训练
        3。混合模型训练

09 | 分布式体系结构之集中式结构：一人在上，万人在
集中式结构
    概念：
        1。由一台或多台服务器组成中央服务器，系统内的所有数据都存储在中央服务器中
        2。系统内所有的业务也均先由中央服务器处理。
        3。多个节点服务器与中央服务器连接，并将自己的信息汇报给中央服务器，由中央服务器统一进行资源和任务调度
        4。中央服务器根据这些信息，将任务下达给节点服务器
        5。节点服务器执行任务，并将结果反馈给中央服务器
    特点：
        部署结构简单
        原因：
            1。集中式系统的中央服务器往往是多个具有较强计算能力和存储能力的计算机
            2。为此中央服务器进行统一管理和调度任务时，无需考虑对任务的多节点部署
            3。而节点服务器之间无需通信和协作，只要与中央服务器通信协作即可
经典集中式结构：
    1。Google Borg
        概念：
            1。Borg 是 Google 内部使用的集群管理系统
            2。采用了典型的集中式结构，负责提交、调度、开始、重启和管理 Google 运行在其上的所有应用。
        结构：
            1。在 Borg 中，一个集群称为一个 Cell，每个 Cell 里面有一个 Leader，称为 BorgMaster，即为中央服务器
            2。其他服务器为节点服务器或从服务器，被称为 Borglet。
            1。BorgMaster：
                概念：
                    由两个进程组成
                组成：
                    1。Borgmaster 主进程
                        作用：
                            1。主进程处理客户端的 RPC 请求
                                例子：
                                    比如任务的执行状态更新或者查询等
                            2。管理系统中所有实体的状态
                                例子：
                                    比如，服务器、任务等
                            3。并负责和 Borglet 通信。
                    2。独立的 scheduler 进程
                        作用：
                            1。进程负责任务调度，通过任务对资源的需求以及当前 Borglet 所在服务器的资源情况进行匹配
                            2。为任务寻找一个合适的节点服务器执行。
            2。Borglet
                概念：
                    运行在每个节点机器的一个 agent
                作用：
                    1。负责任务的拉起、停止、重启等，并管理和搜集本服务器资源
                    2。将任务的状态、服务器状态等信息上报给 BorgMaster
            两者的联系：
                BorgMaster 会周期性地轮询每个 Borglet，以获取节点服务器的状态和资源信息等。
        用户：
            概念：
                Borg 的主要用户是 Google 的开发者以及运行 Google 应用和服务的系统管理员（（网站可靠性工程师，简称 SRE））
            工作形式：
                1。用户以 Job 的形式向 Borg 提交工作，每个 Job 由运行一个或多个运行相同程序的 Task 组成。
                2。每个 Job 运行在一个 Borg Cell 中，并将一组机器当做一个单元进行管理。

        Borg 可以运行各种各样的任务，这些任务主要分为两类：
            第一类：
                长服务：
                    概念：
                        即长时间运行不停止的服务，并且要求能够处理短暂的、延迟敏感的请求（延迟要求在几微秒到几百毫秒之间）
                    作用：
                        1。主要用于面向终端用户的服务（比如 Gmail、Google Docs、Web 搜索）
                        2。以及内部的一些基础设施服务（比如 BigTable）。
            第二类：
                批处理任务：
                    概念：
                        通常需要几秒到几天的时间来完成的批处理 Job，这些 Job 对短时间的性能波动并不是非常敏感。
            联系：
                1。这些负载通常在 Cell 之间混合分布，每个 Cell 随着主要租户以及时间的不同会运行各种不同的应用：
                2。批处理类型的 Job 来了又走，而许多面向终端用户的 Job 又期望一个能长时间使用的模式。
        优点：
            1。开发者只需关注应用，不需要关注底层资源管理。它隐藏了资源管理以及错误处理，因此用户能集中精力开发应用。
            2。高可靠性和可用性，支持多种应用。
            3。支持上千级服务器的管理和运行。

    2。Kubernetes
        概念：
            1。Kubernetes 是 Google 开源的容器集群管理系统，是 Borg 的一个开源版本
            2。Kubernetes 是用于自动部署、扩展和管理容器化应用程序的开源系统
        核心：
            在集群的节点上运行容器化应用，可以进行自动化容器操作，包括部署、调度和在节点间弹性伸缩等。
        组成：
            主要由 Master 节点和 Worker 节点组成，以及客户端命令行工具 kubectl 和其他附加项。
            Master 节点：
                概念：
                    它运行在中心服务器上，Master 节点由 API Server、Scheduler、Cluster State Store 和 Control Manger Server 组成
                    API Server
                        作用：
                            是所有 REST 命令的入口，负责处理 REST 的操作，确保它们生效，并执行相关业务逻辑。
                    Scheduler：
                        作用：
                            根据容器需要的资源以及当前 Worker 节点所在节点服务器的资源信息，自动为容器选择合适的节点服务器。
                    Cluster State Store：
                        概念：
                            集群状态存储，默认采用 etcd，etcd 是一个分布式 key-value 存储
                        作用：
                            主要用来做共享配置和服务发现。
                    Control Manager：
                        作用：
                            用于执行大部分的集群层次的功能
                        例子：
                            比如执行生命周期功能（命名空间创建和生命周期、事件垃圾收集、已终止垃圾收集、级联删除垃圾收集等）和 API 业务逻辑。
            Worker 节点：
                概念：
                    1。它作为真正的工作节点，运行在从节点服务器
                    2。包括 kubelet 和 kube-proxy 核心组件，负责运行业务应用的容器。
                        kubelet：
                            概念：
                                用于通过命令行与 API Server 进行交互，根据接收到的请求对 Worker 节点进行操作
                            作用：
                                1。通过与 API Server 进行通信，接收 Master 节点根据调度策略发出的请求或命令
                                2。在 Worker 节点上管控容器（Pod），并管控容器的运行状态（比如，重新启动出现故障的 Pod）等
                                    Pod：
                                        概念：
                                            是 Kubernetes 的最小工作单元，每个 Pod 包含一个或多个容器。
                        kube-proxy：
                            作用：
                                1。主要负责管理 Service 的访问入口，即实现集群内的 Pod 客户端访问 Service
                                2。或者是集群外访问 Service，具有相同服务的一组 Pod 可抽象为一个 Service
                                3。每个 Service 都有一个虚拟 IP 地址（VIP）和端口号供客户端访问。
                                Service：
                                    作用：
                                        1。负责为容器（Pod）创建网络代理 / 负载平衡服务
                                        2。从 API Server 获取所有 Server 信息，并根据 Server 信息创建代理服务
                                        3。这种代理服务称之为 Service
                        Kube DNS ：
                            作用：
                                负责为整个集群提供 DNS 服务
                        CNI：
                            概念：
                                是 Container Network Interface 的一个标准的通用接口
                            作用：
                                用于连接容器管理系统和网络插件。
                参考：
                    第09讲Kubernetes 架构示意图.png
        作用：
            负责对集群进行调度管理。
        应用：
            比如网易云、华为在需要使用容器进行资源隔离以运行相关业务的场景下，采用了大规模 Kubernetes 集群。
        优点：
            1。自动化容器的部署和复制
                概念：
                    Kubernetes 执行容器编排，因此不必人工编写这些任务的脚本。
            2。将容器组织为组，弹性伸缩
                概念：
                    1。Kubernetes 引入 Pod 机制，Pod 代表着能够作为单一应用程序加以控制的一组容器集合
                    2。通过 Pod 机制，Kubernetes 实现了多个容器的协作，能够有效避免将太多功能集中到单一容器镜像这样的错误实践中
                    3。软件可以向外扩展跨越多个 Pods 实现初步部署，且相关部署可随时进行规模伸缩。
            3。容器间负载均衡
                概念：
                    Services 用于将具备类似功能的多个 Pod 整合为一组，可轻松进行配置以实现其可发现性、可观察性、横向扩展以及负载均衡
            4。易于版本控制与滚动更新
                概念：
                    1。Kubernetes 采取“滚动方式”实现编排，且可跨越部署范围内的全部 Pod
                    2。这些滚动更新可进行编排，并以预定义方式配合当前可能尚不可用的 Pods 数量，以及暂时存在的闲置 Pods 数量
                    3。Kubernetes 利用新的应用程序镜像版本对已部署 Pods 进行更新，并在发现当前版本存在不稳定问题时回滚至早期部署版本。
    3。Apache Mesos
        概念：
            它被称为是分布式系统的内核，最初由加州大学伯克利分校的 AMPLab 开发，后在 Twitter 得到广泛使用
        区别：
            Borg：
                Borg 的 Master 直接对接用户应用，也就是说用户可以向 Borg 的 Master 直接请求任务。
            Mesos：
                Mesos 不可以，Mesos 只负责底层资源的管理和分配，并不涉及存储、 任务调度等功能
                应用：
                    1。 Mesos Master 对接的是 Spark、Hadoop、Marathon 等框架
                    2。用户的任务需要提交到这些框架上。也正因为此，Mesos 的任务调度框架是双层结构。
        组成：
            1。在 Mesos 中，一个集群包括 Mesos Master 和多个 Mesos Agent
            2。其中，Mesos Master 运行在中央服务器，Mesos Agent 运行在节点服务器上。
            Mesos Master：
                作用：
                    1。负责收集和管理所有 Agent 所在服务器的资源和状态，并且对接 Spark、Hadoop 等框架
                    2。将集群中服务器的资源信息告知给这些框架，以便这些框架进行任务资源匹配和调度
                扩展：
                    1。通常采用一主两备的方式，以方便故障处理和恢复
                    2。而 Mesos Master 的选主策略，采用的就是我们在第 4 篇文章“分布式选举：国不可一日无君”中介绍的 ZAB 算法
            Mesos Agent：
                作用：
                    1。Mesos Agent 负责任务的拉起、停止、重启等
                    2。并负责收集所在服务器的资源 (比如 CPU、内存等) 信息和状态，上报给 Mesos Master。
        应用：
            1。国外的 Twitter、Apple、Airbnb、Uber 等
            2。国内的爱奇艺、去哪儿、携程、当当等。
        优点：
            1。效率
                说明：
                    1。Mesos 对物理资源进行了逻辑抽象，在应用层而不是物理层分配资源，通过容器而不是虚拟机（VM）分配任务
                    2。因为应用程序的调度器知道如何最有效地利用资源，所以在应用层分配资源能够为每个应用程序的特殊需求做考量 ; 
                    3。而通过容器分配任务则能更好地进行“装箱”。
            2。可扩展性
                1。Mesos 可扩展设计的关键是两级调度架构
                    1。其中 Framework 进行任务调度
                    2。Mesos Master 进行资源分配
                2。由于 Master 不必知道每种类型的应用程序背后复杂的调度逻辑，不必为每个任务做调度
                3。因此可以用非常轻量级的代码实现，更易于扩展集群规模。
            3。模块化
                1。每接入一种新的框架，Master 无需增加新的代码，并且 Agent 模块可以复用
                2。为此开发者可以专注于应用和框架的选择。
                3。这，就使得 Mesos 可以支持多种框架，适应不同的应用场景。
    分析对比
        第09讲集中式架构的三种实现方式的对比.png


























